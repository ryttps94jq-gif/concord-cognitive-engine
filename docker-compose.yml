version: '3.8'

services:
  # Backend API Server
  backend:
    build:
      context: ./server
      dockerfile: Dockerfile
    container_name: concord-backend
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - PORT=5050
      - DATA_DIR=/data
      - STATE_PATH=/data/concord_state.json
      - OLLAMA_HOST=${OLLAMA_HOST:-http://ollama:11434}
      - ALLOWED_ORIGINS=${ALLOWED_ORIGINS:-https://concord-os.org}
      # Auth - MUST set these in .env file
      - JWT_SECRET=${JWT_SECRET}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD}
      - AUTH_ENABLED=${AUTH_ENABLED:-true}
      # LLM - set OPENAI_API_KEY in .env for AI features
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL_FAST=${OPENAI_MODEL_FAST:-gpt-4o-mini}
      - OPENAI_MODEL_SMART=${OPENAI_MODEL_SMART:-gpt-4o}
      # Optional features
      - EMBEDDINGS_ENABLED=${EMBEDDINGS_ENABLED:-true}
      - FEDERATION_ENABLED=${FEDERATION_ENABLED:-false}
    volumes:
      - concord-data:/data
    networks:
      - concord-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5050/ready && curl -f http://localhost:5050/api/status | grep -q '\"database\":{\"type\":\"sqlite\"'"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Frontend Next.js App
  frontend:
    build:
      context: ./concord-frontend
      dockerfile: Dockerfile
      args:
        - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL:-https://concord-os.org}
        - NEXT_PUBLIC_SOCKET_URL=${NEXT_PUBLIC_SOCKET_URL:-https://concord-os.org}
    container_name: concord-frontend
    restart: unless-stopped
    environment:
      - NODE_ENV=production
    depends_on:
      - backend
    networks:
      - concord-network

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: concord-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./certbot/conf:/etc/letsencrypt:ro
      - ./certbot/www:/var/www/certbot:ro
    depends_on:
      - frontend
      - backend
    networks:
      - concord-network
    command: "/bin/sh -c 'while :; do sleep 6h & wait $${!}; nginx -s reload; done & nginx -g \"daemon off;\"'"

  # Certbot for SSL certificates
  certbot:
    image: certbot/certbot
    container_name: concord-certbot
    volumes:
      - ./certbot/conf:/etc/letsencrypt
      - ./certbot/www:/var/www/certbot
    entrypoint: |
      /bin/sh -c '
      trap exit TERM
      while :; do
        certbot renew --quiet --non-interactive 2>&1 | tee -a /var/log/certbot.log || echo "[Certbot] Renewal check completed with warnings at $$(date)"
        sleep 12h & wait
      done
      '
    healthcheck:
      test: ["CMD", "test", "-f", "/etc/letsencrypt/renewal-hooks/deploy/reload-nginx.sh", "-o", "-d", "/etc/letsencrypt/live"]
      interval: 86400s
      timeout: 10s
      retries: 1
      start_period: 60s

  # Optional: Ollama for local LLM (comment out if using external)
  ollama:
    image: ollama/ollama
    container_name: concord-ollama
    restart: unless-stopped
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - concord-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    # Resource limits to prevent OOM
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4'
        reservations:
          memory: 2G
          cpus: '1'
    # Uncomment for GPU support:
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

networks:
  concord-network:
    driver: bridge

volumes:
  concord-data:
    driver: local
  ollama-data:
    driver: local
