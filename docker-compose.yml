services:
  # Backend API Server
  backend:
    build:
      context: ./server
      dockerfile: Dockerfile
    container_name: concord-backend
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    read_only: false  # Data dir needs writes; consider tmpfs for /tmp
    tmpfs:
      - /tmp:noexec,nosuid,size=100M
    environment:
      - NODE_ENV=production
      - PORT=5050
      - DATA_DIR=/data
      - DB_PATH=/data/db/concord.db
      - STATE_PATH=/data/concord_state.json
      - OLLAMA_HOST=${OLLAMA_HOST:-http://ollama-conscious:11434}
      - ALLOWED_ORIGINS=${ALLOWED_ORIGINS:-https://concord-os.org}
      # Four-Brain Cognitive Architecture
      - BRAIN_CONSCIOUS_URL=${BRAIN_CONSCIOUS_URL:-http://ollama-conscious:11434}
      - BRAIN_CONSCIOUS_MODEL=${BRAIN_CONSCIOUS_MODEL:-qwen2.5:7b}
      - BRAIN_SUBCONSCIOUS_URL=${BRAIN_SUBCONSCIOUS_URL:-http://ollama-subconscious:11434}
      - BRAIN_SUBCONSCIOUS_MODEL=${BRAIN_SUBCONSCIOUS_MODEL:-qwen2.5:1.5b}
      - BRAIN_UTILITY_URL=${BRAIN_UTILITY_URL:-http://ollama-utility:11434}
      - BRAIN_UTILITY_MODEL=${BRAIN_UTILITY_MODEL:-qwen2.5:3b}
      - BRAIN_REPAIR_URL=${BRAIN_REPAIR_URL:-http://ollama-repair:11434}
      - BRAIN_REPAIR_MODEL=${BRAIN_REPAIR_MODEL:-qwen2.5:0.5b}
      # Auth - MUST set these in .env file
      - JWT_SECRET=${JWT_SECRET}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD}
      - AUTH_MODE=${AUTH_MODE:-hybrid}
      - AUTH_ENABLED=${AUTH_ENABLED:-true}
      # LLM - set OPENAI_API_KEY in .env for AI features
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL_FAST=${OPENAI_MODEL_FAST:-gpt-4o-mini}
      - OPENAI_MODEL_SMART=${OPENAI_MODEL_SMART:-gpt-4o}
      # Stripe — set these in .env to enable payments
      - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY:-}
      - STRIPE_WEBHOOK_SECRET=${STRIPE_WEBHOOK_SECRET:-}
      - STRIPE_PRICE_PRO=${STRIPE_PRICE_PRO:-}
      - STRIPE_PRICE_TEAMS=${STRIPE_PRICE_TEAMS:-}
      - FRONTEND_URL=${FRONTEND_URL:-https://concord-os.org}
      # Optional features
      - EMBEDDINGS_ENABLED=${EMBEDDINGS_ENABLED:-true}
      - FEDERATION_ENABLED=${FEDERATION_ENABLED:-false}
      # Unsafe surfaces — disabled by default in production
      - ENABLE_TERMINAL_EXEC=${ENABLE_TERMINAL_EXEC:-false}
    depends_on:
      ollama-conscious:
        condition: service_healthy
      ollama-subconscious:
        condition: service_healthy
      ollama-utility:
        condition: service_healthy
      ollama-repair:
        condition: service_healthy
    volumes:
      - concord-data:/data
    networks:
      - concord-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5050/ready || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '0.75'
        reservations:
          memory: 512M
          cpus: '0.25'

  # Frontend Next.js App
  frontend:
    build:
      context: ./concord-frontend
      dockerfile: Dockerfile
      args:
        - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL:-https://concord-os.org}
        - NEXT_PUBLIC_SOCKET_URL=${NEXT_PUBLIC_SOCKET_URL:-https://concord-os.org}
    container_name: concord-frontend
    restart: unless-stopped
    environment:
      - NODE_ENV=production
    depends_on:
      backend:
        condition: service_healthy
    volumes:
      - frontend-data:/data
    networks:
      - concord-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.1'

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: concord-nginx
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./certbot/conf:/etc/letsencrypt:ro
      - ./certbot/www:/var/www/certbot:ro
    depends_on:
      - frontend
      - backend
    networks:
      - concord-network
    command: "/bin/sh -c 'while :; do sleep 6h & wait $${!}; nginx -s reload; done & nginx -g \"daemon off;\"'"

  # Certbot for SSL certificates
  certbot:
    image: certbot/certbot
    container_name: concord-certbot
    volumes:
      - ./certbot/conf:/etc/letsencrypt
      - ./certbot/www:/var/www/certbot
    entrypoint: |
      /bin/sh -c '
      trap exit TERM
      while :; do
        certbot renew --quiet --non-interactive 2>&1 | tee -a /var/log/certbot.log || echo "[Certbot] Renewal check completed with warnings at $$(date)"
        sleep 12h & wait
      done
      '
    healthcheck:
      test: ["CMD", "test", "-f", "/etc/letsencrypt/renewal-hooks/deploy/reload-nginx.sh", "-o", "-d", "/etc/letsencrypt/live"]
      interval: 86400s
      timeout: 10s
      retries: 1
      start_period: 60s

  # Prometheus — scrapes /metrics from backend
  prometheus:
    image: prom/prometheus:latest
    container_name: concord-prometheus
    restart: unless-stopped
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.retention.time=30d"
      - "--web.enable-lifecycle"
    networks:
      - concord-network
    depends_on:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "wget --quiet --tries=1 --spider http://localhost:9090/-/healthy || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.25'

  # Grafana — dashboards for Concord metrics
  grafana:
    image: grafana/grafana:latest
    container_name: concord-grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:?GRAFANA_USER must be set in .env}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:?GRAFANA_PASSWORD must be set in .env}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    # Bind Grafana to localhost only — access via SSH tunnel or VPN in production
    ports:
      - "127.0.0.1:3001:3000"
    networks:
      - concord-network
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD-SHELL", "wget --quiet --tries=1 --spider http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.15'

  # ── Four-Brain Cognitive Architecture ──
  # Brain 1: Conscious — chat and deep reasoning (7B, 4 cores, ~5GB RAM)
  ollama-conscious:
    image: ollama/ollama
    container_name: concord-ollama-conscious
    restart: unless-stopped
    volumes:
      - ollama-conscious-data:/root/.ollama
    networks:
      - concord-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 6G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'

  # Brain 2: Subconscious — autogen, dream, evolution, synthesis, birth (1.5B, 2 cores, ~1GB RAM)
  ollama-subconscious:
    image: ollama/ollama
    container_name: concord-ollama-subconscious
    restart: unless-stopped
    volumes:
      - ollama-subconscious-data:/root/.ollama
    networks:
      - concord-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 512M
          cpus: '1.0'

  # Brain 3: Utility — lens interactions, entity actions, quick domain tasks (3B, 2 cores, ~2.5GB RAM)
  ollama-utility:
    image: ollama/ollama
    container_name: concord-ollama-utility
    restart: unless-stopped
    volumes:
      - ollama-utility-data:/root/.ollama
    networks:
      - concord-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'

  # Brain 4: Repair — error detection, auto-fix (0.5B, shares cores with subconscious, ~512MB RAM)
  ollama-repair:
    image: ollama/ollama
    container_name: concord-ollama-repair
    restart: unless-stopped
    volumes:
      - ollama-repair-data:/root/.ollama
    networks:
      - concord-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags || exit 1"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '2.0'
        reservations:
          memory: 256M
          cpus: '0.5'

networks:
  concord-network:
    driver: bridge

volumes:
  concord-data:
    driver: local
  ollama-conscious-data:
    driver: local
  ollama-subconscious-data:
    driver: local
  ollama-utility-data:
    driver: local
  ollama-repair-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  frontend-data:
    driver: local
