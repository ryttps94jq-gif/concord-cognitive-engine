# ============================================================
# Concord Cognitive Engine — Server Environment Configuration
# Copy this file to .env and adjust values for your deployment
# ============================================================

# ---- Core Server ----
PORT=5050
NODE_ENV=development
DATA_DIR=./data
# DB_PATH=./data/concord.db            # SQLite database path
# STATE_PATH=./data/concord_state.json  # State persistence path
# STATE_BACKEND=sqlite                  # Use "sqlite" for production state backend
# SHUTDOWN_TIMEOUT_MS=10000

# ---- Logging ----
# LOG_LEVEL=debug           # debug | info | warn | error (default: debug in dev, info in prod)
# LOG_FORMAT=pretty          # pretty | json (default: pretty in dev, json in prod)

# ---- Authentication (REQUIRED in production) ----
# JWT secret — minimum 32 characters (generate with: openssl rand -hex 64)
JWT_SECRET=change-me-to-a-random-string-at-least-32-chars
# Admin password — minimum 12 characters
ADMIN_PASSWORD=changeme12345!
# JWT token expiry
JWT_EXPIRES_IN=7d
# Refresh token expiry
REFRESH_TOKEN_EXPIRES=30d
# Bcrypt hashing rounds
# BCRYPT_ROUNDS=12

# Auth mode: "public" (no auth), "hybrid" (optional auth), "private" (require auth)
AUTH_MODE=hybrid
AUTH_ENABLED=true

# ---- CORS & Security ----
# Comma-separated list of allowed CORS origins (REQUIRED in production)
ALLOWED_ORIGINS=http://localhost:3000
# FOUNDER_SECRET=            # Emergency admin secret (generate with: openssl rand -hex 32)

# ---- Rate Limiting ----
# RATE_LIMIT_WINDOW_MS=60000
# RATE_LIMIT_MAX=100
# SLIDING_WINDOW_RPM=120
# SLOW_REQUEST_MS=2000

# ---- LLM / OpenAI ----
# OPENAI_API_KEY=sk-...
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_MODEL_FAST=gpt-4o-mini
# OPENAI_MODEL_SMART=gpt-4.1
# CLOUD_LLM_ENABLED=false
# CONCORD_LLM_DEFAULT_FORCED=          # Force LLM default on/off
# LLM_BUDGET_TOKENS=1000000            # Daily global token budget
# LLM_USER_BUDGET_TOKENS=50000         # Daily per-user token budget
# LLM_MAX_RETRIES=3
# LLM_CONCURRENCY_LIMIT=5

# ---- Ollama (local LLM) ----
# OLLAMA_HOST=http://localhost:11434
# OLLAMA_URL=http://localhost:11434

# ---- Embeddings ----
EMBEDDINGS_ENABLED=true

# ---- WebSocket ----
# CONCORD_WS_ENABLED=true               # Set to "false" to disable WebSocket

# ---- Terminal Execution (DANGEROUS — disabled by default) ----
# ENABLE_TERMINAL_EXEC=false

# ---- Backup ----
# BACKUP_DIR=./data/backups
# AUTO_BACKUP=true
# BACKUP_INTERVAL_HOURS=24

# ---- Federation (multi-instance sync) ----
FEDERATION_ENABLED=false
# REDIS_URL=redis://localhost:6379
# FEDERATION_CHANNEL=lattice_broadcast
# NODE_ID=node-1

# ---- Lattice / C3 Cognitive Engine ----
# LATTICE_CRON_MS=15000
# C3_META_PROB=0.10
# C3_META_MIN_MATURITY=0.75

# ---- Stripe Payments (optional) ----
# STRIPE_SECRET_KEY=sk_test_...
# STRIPE_WEBHOOK_SECRET=whsec_...
# STRIPE_PRICE_PRO=price_...
# STRIPE_PRICE_TEAMS=price_...
# FRONTEND_URL=http://localhost:3000

# ---- Vision / Multimodal (optional) ----
# WHISPER_CPP_BIN=/path/to/whisper
# PIPER_BIN=/path/to/piper
# SD_URL=http://localhost:7860/sdapi/v1/txt2img
# COMFYUI_URL=http://localhost:8188/prompt
