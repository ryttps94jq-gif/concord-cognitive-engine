/**
 * @fileoverview Concord Cognitive Engine - Macro-Max Monolith Server
 * @version 5.1.0
 * @license MIT
 *
 * This is an intentionally monolithic server for IP protection and atomic deployment.
 * All business logic is expressed as macros registered in the macro registry.
 *
 * @see ./types.d.ts for TypeScript type definitions
 * @see ../SECURITY.md for security documentation
 * @see ../README.md for architecture overview
 */

// === DATA DIRECTORY (canonical) ===
/** @type {string} Data directory for persistent storage */
const DATA_DIR = process.env.DATA_DIR || path.join(process.cwd(), 'data');
/**
 * Concord v2 — Macro‑Max Monolith (Single File)
 * - Macro-first architecture: nearly all logic is macros.
 * - Endpoints are thin wrappers around macros.
 * - LLM is OPTIONAL: local reasoning works; LLM enhances when env key is present.
 *
 * Node: v18+ recommended (works on v24+)
 * ESM: requires package.json { "type": "module" } in your server folder.
 */

import express from "express";
import cors from "cors";
import crypto from "crypto";
import fs from "fs";
import path from "path";
import { spawnSync } from "child_process";
import { createRequire } from "module";
import { initAll as initLoaf } from "./loaf/index.js";
import { init as initEmergent } from "./emergent/index.js";
import { init as initGRC, formatAndValidate as grcFormatAndValidate, getGRCSystemPrompt } from "./grc/index.js";
import configureMiddleware from "./middleware/index.js";

// ---- "Everything Real" imports: migration runner + durable endpoints ----
import { runMigrations as runSchemaMigrations } from "./migrate.js";
import { registerDurableEndpoints } from "./durable.js";

// ---- Guidance Layer v1: events, SSE, inspector, undo, suggestions ----
import { registerGuidanceEndpoints } from "./guidance.js";

// ---- Economy System: ledger, balances, transfers, withdrawals ----
import {
  registerEconomyEndpoints,
  hasSufficientBalance,
  calculateFee,
  FEES,
  PLATFORM_ACCOUNT_ID,
  recordTransactionBatch,
  generateTxId,
  checkRefIdProcessed,
  validateBalance as economyValidateBalance,
  economyAudit,
  auditCtx,
  createPurchase,
  transitionPurchase,
  recordSettlement,
} from "./economy/index.js";

// ---- Atlas + Platform Upgrade Imports (v2) ----
import { DOMAIN_TYPES as ATLAS_DOMAIN_TYPES, EPISTEMIC_CLASSES, DOMAIN_TYPE_SET, EPISTEMIC_CLASS_SET, computeAtlasScores, explainScores, validateAtlasDtu, getThresholds, initAtlasState, getAtlasState } from "./emergent/atlas-epistemic.js";
import { createAtlasDtu, getAtlasDtu, searchAtlasDtus, promoteAtlasDtu, addAtlasLink, getScoreExplanation, recomputeScores, registerEntity, getEntity, getContradictions, getAtlasMetrics, contentHash } from "./emergent/atlas-store.js";
import { detectLineageCycle, detectSupportRing, analyzeSourceUniqueness, checkAuthorInfluence, computeSimilarity, findNearDuplicates, runAntiGamingScan, getAntiGamingMetrics } from "./emergent/atlas-antigaming.js";
import { runAutogenV2, selectInputDtus, getAutogenRun, acceptAutogenOutput, mergeAutogenOutput, propagateConfidence, getAutogenV2Metrics } from "./emergent/atlas-autogen-v2.js";
import { councilResolve, getCouncilQueue, councilRequestSources, councilMerge, getCouncilActions, getCouncilMetrics } from "./emergent/atlas-council.js";
import { upsertProfile, getProfile, listProfiles, followUser, unfollowUser, getFollowers, getFollowing, publishDtu, unpublishDtu, recordCitation, getCitedBy, getFeed, computeTrending, discoverUsers, getSocialMetrics } from "./emergent/social-layer.js";
import { createWorkspace as collabCreateWorkspace, getWorkspace as collabGetWorkspace, listWorkspaces as collabListWorkspaces, addWorkspaceMember as collabAddWorkspaceMember, removeWorkspaceMember as collabRemoveWorkspaceMember, addDtuToWorkspace as collabAddDtuToWorkspace, addComment as collabAddComment, getComments as collabGetComments, editComment as collabEditComment, resolveComment as collabResolveComment, proposeRevision, getRevisionProposals, voteOnRevision, applyRevision, startEditSession, recordEdit, endEditSession, getCollabMetrics } from "./emergent/collaboration.js";
import { ROLES, createOrgWorkspace, getOrgWorkspace, assignRole, revokeRole, getUserRole, getOrgMembers, checkPermission, getUserPermissions, assignOrgLens, revokeOrgLens, getOrgLenses, setResourceACL, checkResourceAccess, exportAuditLog, getRbacMetrics } from "./emergent/rbac.js";
import { takeSnapshot as takeAnalyticsSnapshot, getPersonalAnalytics, getDtuGrowthTrends, getCitationAnalytics, getMarketplaceAnalytics as getMarketAnalytics, getKnowledgeDensity, getAtlasDomainAnalytics, getDashboardSummary } from "./emergent/analytics-dashboard.js";
import { registerWebhook as registerWh, getWebhook, listWebhooks, deactivateWebhook, deleteWebhook, dispatchWebhookEvent, processPendingDeliveries, getDeliveryHistory, checkApiRateLimit, getApiMetrics, WEBHOOK_EVENTS } from "./emergent/public-api.js";
import { tagDataRegion, getDataRegion, checkRegionAccess, setExportControls, checkExportAllowed, exportData, createDataPartition, getDataPartition, setRetentionPolicy, getRetentionPolicy, getComplianceLog, recordDPA, getComplianceStatus } from "./emergent/compliance.js";
import { startOnboarding as startOnboardingV2, getOnboardingProgress as getOnboardingProgressV2, completeOnboardingStep as completeOnboardingStepV2, skipOnboarding as skipOnboardingV2, getOnboardingHints, getOnboardingMetrics } from "./emergent/onboarding.js";
import { recordSubstrateReuse, recordLlmCall, recordCacheEvent, getEfficiencyDashboard, takeEfficiencySnapshot, getEfficiencyHistory } from "./emergent/compute-efficiency.js";

// ---- Atlas v2 Default-On + 3-Lane Separation Imports ----
import { SCOPES, RETRIEVAL_POLICY, AUTO_PROMOTE_THRESHOLDS, STRICTNESS_PROFILES, getAutoPromoteConfig, getStrictnessProfile } from "./emergent/atlas-config.js";
import { assertInvariant, assertSoft, getInvariantMetrics, getInvariantLog } from "./emergent/atlas-invariants.js";
import { applyWrite, WRITE_OPS, runAutoPromoteGate, ingestAutogenCandidate, guardedDtuWrite, getWriteGuardLog, getWriteGuardMetrics } from "./emergent/atlas-write-guard.js";
import { initScopeState, scopedWrite, scopedRetrieve, createSubmission, processSubmission, approveSubmission, rejectSubmission, getSubmission, listSubmissions, getDtuScope, getScopeMetrics, getLocalQualityHints } from "./emergent/atlas-scope-router.js";
import { tickLocal, tickGlobal, tickMarketplace, tickAll, getHeartbeatMetrics } from "./emergent/atlas-heartbeat.js";
import { retrieve as atlasRetrieve, retrieveForChat, retrieveLabeled, retrieveFromScope } from "./emergent/atlas-retrieval.js";
import { chatRetrieve, saveAsDtu, publishToGlobal, listOnMarketplace, getChatMetrics, recordChatExchange, recordChatEscalation, getChatSession } from "./emergent/atlas-chat.js";
import { canUse, generateCitation, getOrigin, verifyOriginIntegrity, grantTransferRights, getRightsMetrics, computeContentHash as rightsContentHash } from "./emergent/atlas-rights.js";
import { schemas as VALIDATION_SCHEMAS, validate } from "./validation/schemas.js";
import { initTokens, createToken, createRefreshToken, verifyToken, _TOKEN_BLACKLIST, _REFRESH_FAMILIES, hashPassword, verifyPassword, generateApiKey, hashApiKey, verifyApiKey, setAuthCookie, clearAuthCookie, setRefreshCookie, generateCsrfToken, validateCsrfToken } from "./auth/tokens.js";

// ---- Extracted Macro Modules ----
import { MACROS, register, listDomains, listMacros, createRunMacro } from "./macros/registry.js";
import { registerCognitiveMacros } from "./macros/cognitive.js";
import { registerDomainMacros } from "./macros/domains.js";

// ---- CJS interop for route modules (routes/*.js use module.exports) ----
const require = createRequire(import.meta.url);

// ---- Ensure iconv-lite encodings are loaded (fixes ESM/CJS interop in CI) ----
try { const _iconv = await import("iconv-lite"); _iconv.default?.encodingExists?.("utf8"); } catch { /* transitive dep via body-parser; ok if absent */ }

// ---- Production dependencies (graceful loading) ----
// SECURITY: In production, security dependencies MUST load or the server refuses to start.
// In development, they are optional to allow lightweight local dev without all deps.
let jwt = null, bcrypt = null, z = null, rateLimit = null, helmet = null, compression = null; const _promClient = null;
let Database = null; // better-sqlite3
const _isProduction = (process.env.NODE_ENV || "development") === "production";
const _securityLoadErrors = [];
try { jwt = (await import("jsonwebtoken")).default; } catch (e) {
  if (_isProduction) _securityLoadErrors.push(`jsonwebtoken: ${e.message}`);
}
try { bcrypt = (await import("bcryptjs")).default; } catch (e) {
  if (_isProduction) _securityLoadErrors.push(`bcryptjs: ${e.message}`);
}
try { z = (await import("zod")).z || (await import("zod")).default?.z; } catch { /* optional in all envs */ }
try { rateLimit = (await import("express-rate-limit")).default; } catch (e) {
  if (_isProduction) _securityLoadErrors.push(`express-rate-limit: ${e.message}`);
}
try { helmet = (await import("helmet")).default; } catch (e) {
  if (_isProduction) _securityLoadErrors.push(`helmet: ${e.message}`);
}
try { compression = (await import("compression")).default; } catch { /* optional in all envs */ }
try { Database = (await import("better-sqlite3")).default; } catch { /* optional - falls back to JSON */ }

// CRITICAL: Refuse to start in production without security dependencies
if (_isProduction && _securityLoadErrors.length > 0) {
  console.error("\n[FATAL] Security dependencies failed to load in production:");
  _securityLoadErrors.forEach(e => console.error(`  - ${e}`));
  console.error("\nInstall missing packages: npm install jsonwebtoken bcryptjs express-rate-limit helmet\n");
  process.exit(1);
}

// ---- dotenv (safe) ----
const DOTENV = { loaded: false, path: null, error: null };
async function tryLoadDotenv() {
  const envPath = process.env.ENV_PATH || process.env.DOTENV_CONFIG_PATH || null;
  try {
    const dotenv = await import("dotenv");
    const result = envPath ? dotenv.config({ path: envPath }) : dotenv.config();
    DOTENV.loaded = !result?.error;
    DOTENV.path = envPath || "(default)";
    DOTENV.error = result?.error ? String(result.error) : null;
  } catch (e) {
    DOTENV.loaded = false;
    DOTENV.path = envPath || "(default)";
    DOTENV.error = `dotenv not available: ${String(e?.message || e)}`;
  }
}
await tryLoadDotenv();

// ============================================================================
// PRODUCTION INFRASTRUCTURE
// ============================================================================

// ---- Environment Validation ----
const REQUIRED_ENV_PRODUCTION = ["JWT_SECRET", "ADMIN_PASSWORD"];
const RECOMMENDED_ENV = ["OPENAI_API_KEY", "ALLOWED_ORIGINS"];

function validateEnvironment() {
  const errors = [];
  const warnings = [];
  const nodeEnv = process.env.NODE_ENV || "development";
  const isProduction = nodeEnv === "production";

  // Check required vars in production
  if (isProduction) {
    for (const envVar of REQUIRED_ENV_PRODUCTION) {
      if (!process.env[envVar]) {
        errors.push(`Missing required environment variable: ${envVar}`);
      }
    }
  }

  // ---- Security dependencies mandatory in production ----
  if (isProduction) {
    const securityDeps = [
      { name: "helmet", ref: helmet, pkg: "helmet" },
      { name: "rateLimit", ref: rateLimit, pkg: "express-rate-limit" },
      { name: "bcrypt", ref: bcrypt, pkg: "bcryptjs" },
      { name: "jwt", ref: jwt, pkg: "jsonwebtoken" },
    ];
    for (const dep of securityDeps) {
      if (!dep.ref) {
        errors.push(`Security dependency '${dep.name}' (${dep.pkg}) is required in production but failed to load. Run: npm install ${dep.pkg}`);
      }
    }
    if (!Database) {
      warnings.push("better-sqlite3 not available in production — falling back to JSON persistence. Install better-sqlite3 for production-grade storage.");
    }
  }

  // Check recommended vars
  for (const envVar of RECOMMENDED_ENV) {
    if (!process.env[envVar]) {
      warnings.push(`Missing recommended environment variable: ${envVar}`);
    }
  }

  // Validate specific values
  if (process.env.JWT_SECRET && process.env.JWT_SECRET.length < 32) {
    errors.push("JWT_SECRET should be at least 32 characters for security");
  }

  if (process.env.ADMIN_PASSWORD && process.env.ADMIN_PASSWORD.length < 12) {
    errors.push("ADMIN_PASSWORD must be at least 12 characters");
  }

  if (process.env.PORT && (isNaN(Number(process.env.PORT)) || Number(process.env.PORT) < 1)) {
    errors.push("PORT must be a valid positive number");
  }

  // Report findings
  if (warnings.length > 0 && !isProduction) {
    console.warn("[Config] Warnings:");
    warnings.forEach(w => console.warn(`  - ${w}`));
  }

  if (errors.length > 0) {
    console.error("\n[FATAL] Environment validation failed:");
    errors.forEach(e => console.error(`  - ${e}`));
    if (isProduction) {
      console.error("\nFix these issues before deploying to production.\n");
      process.exit(1);
    }
  }

  return { errors, warnings, valid: errors.length === 0 };
}

const ENV_VALIDATION = validateEnvironment();

// ---- Request ID Tracking ----
function generateRequestId() {
  return `req_${Date.now().toString(36)}_${crypto.randomBytes(4).toString("hex")}`;
}

function requestIdMiddleware(req, res, next) {
  req.id = req.headers["x-request-id"] || generateRequestId();
  res.setHeader("X-Request-ID", req.id);
  next();
}

// ---- Input Sanitization ----
const _SANITIZE_PATTERNS = {
  // Common XSS patterns
  script: /<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi,
  onEvent: /\bon\w+\s*=/gi,
  javascript: /javascript:/gi,
  dataUri: /data:[^,]*;base64/gi,
  // SQL injection patterns (for logging, not blocking)
  sqlKeywords: /\b(union|select|insert|update|delete|drop|truncate|exec|execute)\b.*\b(from|into|table|database)\b/gi,
};

// ---- DTU Content Injection Detection ----
// Detects prompt injection / jailbreak patterns in DTU content that could manipulate LLM reasoning
const _INJECTION_PATTERNS = [
  /ignore\s+(all\s+)?(previous|prior|above)\s+(instructions?|prompts?|rules?)/i,
  /you\s+are\s+now\s+(a|an|in)\s+/i,
  /system\s*:\s*you\s+(are|must|should|will)/i,
  /\bDAN\b.*\bjailbreak/i,
  /forget\s+(everything|all|your)\s+(you|instructions?|rules?)/i,
  /act\s+as\s+(if|though)\s+you\s+(have\s+no|don't\s+have)/i,
  /override\s+(your|the|all)\s+(safety|content|system)/i,
  /\[\s*SYSTEM\s*\]/i,
  /<<\s*SYS\s*>>/i,
];

function detectContentInjection(text) {
  if (typeof text !== "string" || text.length < 10) return { injected: false, patterns: [] };
  const matched = [];
  for (const pat of _INJECTION_PATTERNS) {
    if (pat.test(text)) matched.push(pat.source.slice(0, 40));
  }
  return { injected: matched.length > 0, patterns: matched };
}

// ---- Marketplace Abuse Detection ----
const _MARKETPLACE_ABUSE = {
  // Per-seller rate tracking: sellerId -> { listCount, lastListAt, buyCount, lastBuyAt }
  sellerActivity: new Map(),
  // Wash trade detection: track buyer-seller pairs
  tradeGraph: new Map(), // `${buyer}:${seller}` -> { count, lastAt }

  // Size caps to prevent unbounded memory growth
  MAX_SELLER_ENTRIES: 50000,
  MAX_TRADE_ENTRIES: 100000,

  MAX_LISTINGS_PER_HOUR: 20,
  MAX_BUYS_PER_HOUR: 30,
  WASH_TRADE_THRESHOLD: 5, // same pair in 24h triggers flag
  PRICE_FLOOR: 1,
  PRICE_CEILING: 1000000,

  trackListing(sellerId) {
    const now = Date.now();
    let entry = this.sellerActivity.get(sellerId);
    if (!entry || now - entry.windowStart > 3600000) {
      entry = { listCount: 0, buyCount: 0, windowStart: now };
      // Evict oldest entries if at capacity
      if (this.sellerActivity.size >= this.MAX_SELLER_ENTRIES) {
        const firstKey = this.sellerActivity.keys().next().value;
        this.sellerActivity.delete(firstKey);
      }
      this.sellerActivity.set(sellerId, entry);
    }
    entry.listCount++;
    return entry.listCount <= this.MAX_LISTINGS_PER_HOUR;
  },

  trackPurchase(buyerId) {
    const now = Date.now();
    let entry = this.sellerActivity.get(buyerId);
    if (!entry || now - entry.windowStart > 3600000) {
      entry = { listCount: 0, buyCount: 0, windowStart: now };
      if (this.sellerActivity.size >= this.MAX_SELLER_ENTRIES) {
        const firstKey = this.sellerActivity.keys().next().value;
        this.sellerActivity.delete(firstKey);
      }
      this.sellerActivity.set(buyerId, entry);
    }
    entry.buyCount++;
    return entry.buyCount <= this.MAX_BUYS_PER_HOUR;
  },

  checkWashTrade(buyerId, sellerId) {
    const key = `${buyerId}:${sellerId}`;
    const reverseKey = `${sellerId}:${buyerId}`;
    const now = Date.now();
    const DAY_MS = 86400000;

    for (const k of [key, reverseKey]) {
      const entry = this.tradeGraph.get(k);
      if (entry && now - entry.lastAt < DAY_MS && entry.count >= this.WASH_TRADE_THRESHOLD) {
        return { flagged: true, reason: "wash_trade_pattern", pair: k, count: entry.count };
      }
    }

    // Record this trade (with size cap)
    const existing = this.tradeGraph.get(key) || { count: 0, lastAt: 0 };
    if (now - existing.lastAt > DAY_MS) existing.count = 0;
    existing.count++;
    existing.lastAt = now;
    if (!this.tradeGraph.has(key) && this.tradeGraph.size >= this.MAX_TRADE_ENTRIES) {
      const firstKey = this.tradeGraph.keys().next().value;
      this.tradeGraph.delete(firstKey);
    }
    this.tradeGraph.set(key, existing);

    return { flagged: false };
  },

  validatePrice(price) {
    const n = Number(price);
    if (isNaN(n) || n < this.PRICE_FLOOR || n > this.PRICE_CEILING) {
      return { valid: false, reason: `Price must be between ${this.PRICE_FLOOR} and ${this.PRICE_CEILING}` };
    }
    return { valid: true };
  },

  // Periodic cleanup of stale tracking data (every hour)
  cleanup() {
    const now = Date.now();
    const HOUR = 3600000;
    const DAY = 86400000;
    for (const [k, v] of this.sellerActivity) {
      if (now - v.windowStart > HOUR) this.sellerActivity.delete(k);
    }
    for (const [k, v] of this.tradeGraph) {
      if (now - v.lastAt > DAY) this.tradeGraph.delete(k);
    }
  }
};

// Cleanup marketplace abuse tracking hourly
setInterval(() => _MARKETPLACE_ABUSE.cleanup(), 3600000);

function sanitizeString(str, options = {}) {
  if (typeof str !== "string") return str;
  let result = str;

  // Remove null bytes
  result = result.replace(/\0/g, "");

  // Trim excessive whitespace
  result = result.replace(/\s{10,}/g, " ".repeat(10));

  // Limit length
  const maxLength = options.maxLength || 10000;
  if (result.length > maxLength) {
    result = result.slice(0, maxLength);
  }

  // HTML encode if requested
  if (options.htmlEncode) {
    result = result
      .replace(/&/g, "&amp;")
      .replace(/</g, "&lt;")
      .replace(/>/g, "&gt;")
      .replace(/"/g, "&quot;")
      .replace(/'/g, "&#x27;");
  }

  return result;
}

function sanitizeObject(obj, options = {}) {
  if (obj === null || obj === undefined) return obj;
  if (typeof obj === "string") return sanitizeString(obj, options);
  if (typeof obj !== "object") return obj;
  if (Array.isArray(obj)) return obj.map(item => sanitizeObject(item, options));

  const result = {};
  for (const [key, value] of Object.entries(obj)) {
    // Sanitize keys too (prevent prototype pollution)
    const safeKey = sanitizeString(key, { maxLength: 100 });
    if (safeKey === "__proto__" || safeKey === "constructor" || safeKey === "prototype") {
      continue; // Skip dangerous keys
    }
    result[safeKey] = sanitizeObject(value, options);
  }
  return result;
}

function sanitizationMiddleware(req, res, next) {
  // Sanitize body
  if (req.body && typeof req.body === "object") {
    req.body = sanitizeObject(req.body);
  }

  // Sanitize query params
  if (req.query && typeof req.query === "object") {
    req.query = sanitizeObject(req.query, { maxLength: 1000 });
  }

  next();
}

// ---- Circuit Breaker for External Services ----
// Prevents cascading failures when external APIs (LLM, Stripe, etc.) are down.
// After THRESHOLD consecutive failures, the breaker "opens" and fast-fails for RESET_MS
// before allowing a single probe request through.
class CircuitBreaker {
  constructor(name, { threshold = 5, resetMs = 30000 } = {}) {
    this.name = name;
    this.threshold = threshold;
    this.resetMs = resetMs;
    this.failures = 0;
    this.state = "closed"; // closed | open | half-open
    this.openedAt = 0;
  }

  async call(fn) {
    if (this.state === "open") {
      if (Date.now() - this.openedAt > this.resetMs) {
        this.state = "half-open";
      } else {
        throw Object.assign(new Error(`Circuit breaker '${this.name}' is OPEN — fast-failing`), { code: "CIRCUIT_OPEN" });
      }
    }
    try {
      const result = await fn();
      this._onSuccess();
      return result;
    } catch (err) {
      this._onFailure();
      throw err;
    }
  }

  _onSuccess() {
    this.failures = 0;
    this.state = "closed";
  }

  _onFailure() {
    this.failures++;
    if (this.failures >= this.threshold) {
      this.state = "open";
      this.openedAt = Date.now();
      structuredLog("warn", "circuit_breaker_opened", { name: this.name, failures: this.failures });
    }
  }

  getState() {
    return { name: this.name, state: this.state, failures: this.failures };
  }
}

// Shared breakers for external services
const BREAKERS = {
  ollama: new CircuitBreaker("ollama", { threshold: 5, resetMs: 30000 }),
  openai: new CircuitBreaker("openai", { threshold: 3, resetMs: 60000 }),
  stripe: new CircuitBreaker("stripe", { threshold: 3, resetMs: 60000 }),
};

// ---- Graceful Shutdown ----
let isShuttingDown = false;
const shutdownCallbacks = [];

function registerShutdownCallback(callback) {
  shutdownCallbacks.push(callback);
}

async function gracefulShutdown(signal) {
  if (isShuttingDown) return;
  isShuttingDown = true;

  console.log(`\n[Shutdown] Received ${signal}, starting graceful shutdown...`);

  // Stop accepting new connections
  if (global.httpServer) {
    global.httpServer.close(() => {
      console.log("[Shutdown] HTTP server closed");
    });
  }

  // Run registered callbacks
  for (const callback of shutdownCallbacks) {
    try {
      await callback();
    } catch (e) {
      console.error("[Shutdown] Callback error:", e.message);
    }
  }

  // Give pending requests time to complete
  const timeout = Number(process.env.SHUTDOWN_TIMEOUT_MS || 10000);
  await new Promise(resolve => { setTimeout(resolve, timeout); });

  console.log("[Shutdown] Graceful shutdown complete");
  process.exit(0);
}

// Register shutdown handlers
process.on("SIGTERM", () => gracefulShutdown("SIGTERM"));
process.on("SIGINT", () => gracefulShutdown("SIGINT"));
process.on("uncaughtException", (err) => {
  structuredLog("fatal", "uncaught_exception", { error: err.message, stack: err.stack });
  gracefulShutdown("uncaughtException");
});
process.on("unhandledRejection", (reason, _promise) => {
  structuredLog("fatal", "unhandled_rejection", { reason: String(reason), stack: String(reason?.stack || "") });
  // In production, exit on unhandled rejection — the container orchestrator will restart us.
  // Continuing after an unhandled rejection risks corrupted state.
  if ((process.env.NODE_ENV || "development") === "production") {
    console.error("[FATAL] Unhandled promise rejection in production — exiting to allow clean restart.");
    process.exit(1);
  }
});

// ---- Structured JSON Logging ----
const LOG_LEVEL = process.env.LOG_LEVEL || (process.env.NODE_ENV === "production" ? "info" : "debug");
const LOG_FORMAT = process.env.LOG_FORMAT || (process.env.NODE_ENV === "production" ? "json" : "pretty");

const LOG_LEVELS = { debug: 0, info: 1, warn: 2, error: 3, fatal: 4 };

function structuredLog(level, event, data = {}) {
  if (LOG_LEVELS[level] < LOG_LEVELS[LOG_LEVEL]) return;

  const entry = {
    timestamp: new Date().toISOString(),
    level,
    event,
    service: "concord-api",
    version: "5.1.0",
    ...data
  };

  if (LOG_FORMAT === "json") {
    console.log(JSON.stringify(entry));
  } else {
    const prefix = `[${entry.timestamp}] [${level.toUpperCase()}]`;
    const details = Object.keys(data).length > 0 ? ` ${JSON.stringify(data)}` : "";
    console.log(`${prefix} ${event}${details}`);
  }

  return entry;
}

// HTTP request logging middleware
function requestLoggerMiddleware(req, res, next) {
  const startTime = Date.now();

  // Log request
  const requestData = {
    requestId: req.id,
    method: req.method,
    path: req.path,
    query: Object.keys(req.query).length > 0 ? req.query : undefined,
    ip: req.ip,
    userAgent: req.headers["user-agent"]?.slice(0, 100)
  };

  // Capture response
  const originalSend = res.send;
  res.send = function(body) {
    res.send = originalSend;
    const duration = Date.now() - startTime;

    // ---- P95 Tracking (Category 5: Observability) ----
    _LATENCY.record(duration, req.path, req.method);

    // Log response (skip health checks to reduce noise)
    if (!req.path.startsWith("/health") && !req.path.startsWith("/ready")) {
      structuredLog(
        res.statusCode >= 500 ? "error" : res.statusCode >= 400 ? "warn" : "info",
        "http_request",
        {
          ...requestData,
          statusCode: res.statusCode,
          durationMs: duration,
          userId: req.user?.id
        }
      );
    }

    return originalSend.call(this, body);
  };

  next();
}

// ---- config ----
const PORT = Number(process.env.PORT || 5050);
const VERSION = "5.1.0-production";
const NODE_ENV = process.env.NODE_ENV || "development";
const AUTH_MODE_VALUES = new Set(["public", "apikey", "jwt", "hybrid"]);
const LEGACY_AUTH_ENABLED = String(process.env.AUTH_ENABLED || "true").toLowerCase() === "true";
const AUTH_MODE_RAW = String(process.env.AUTH_MODE || "").toLowerCase().trim();
const AUTH_MODE = AUTH_MODE_VALUES.has(AUTH_MODE_RAW)
  ? AUTH_MODE_RAW
  : (AUTH_MODE_RAW ? "hybrid" : (LEGACY_AUTH_ENABLED ? "hybrid" : "public"));
const AUTH_USES_JWT = AUTH_MODE === "jwt" || AUTH_MODE === "hybrid";
const AUTH_USES_APIKEY = AUTH_MODE === "apikey" || AUTH_MODE === "hybrid";

if (AUTH_MODE_RAW && !AUTH_MODE_VALUES.has(AUTH_MODE_RAW)) {
  console.warn(`[Auth] Invalid AUTH_MODE='${AUTH_MODE_RAW}'. Falling back to 'hybrid'. Allowed: public|apikey|jwt|hybrid.`);
}

// SECURITY: JWT_SECRET must be set in production
const JWT_SECRET = process.env.JWT_SECRET;
if (!JWT_SECRET && NODE_ENV === "production" && AUTH_USES_JWT) {
  console.error("\n[FATAL] JWT_SECRET environment variable is required in production.");
  console.error("[FATAL] Generate one with: openssl rand -hex 64");
  console.error("[FATAL] Add it to your .env file or environment variables.\n");
  process.exit(1);
}
// In development, generate a temporary secret (will change on restart)
const EFFECTIVE_JWT_SECRET = JWT_SECRET || crypto.randomBytes(64).toString("hex");
if (!JWT_SECRET) {
  console.warn("[Auth] WARNING: No JWT_SECRET set. Using temporary secret - sessions will not persist across restarts.");
}

const JWT_EXPIRES_IN = process.env.JWT_EXPIRES_IN || "7d";
const BCRYPT_ROUNDS = Number(process.env.BCRYPT_ROUNDS || 12);
const RATE_LIMIT_WINDOW_MS = Number(process.env.RATE_LIMIT_WINDOW_MS || 60000);
const RATE_LIMIT_MAX = Number(process.env.RATE_LIMIT_MAX || 100);
const OPENAI_API_KEY = process.env.OPENAI_API_KEY || "";
const OPENAI_BASE_URL = process.env.OPENAI_BASE_URL || "https://api.openai.com/v1";
const OPENAI_MODEL_FAST = process.env.OPENAI_MODEL_FAST || process.env.OPENAI_MODEL || "gpt-4o-mini";
const OPENAI_MODEL_SMART = process.env.OPENAI_MODEL_SMART || "gpt-4.1";
const LLM_READY = Boolean(OPENAI_API_KEY);
// LLM toggle: default ON only when a key is present
const __envBool = (v) => String(v ?? "").toLowerCase().trim();
const __llmDefaultForcedRaw = (process.env.CONCORD_LLM_DEFAULT_FORCED ?? process.env.LLM_DEFAULT_FORCED ?? null);
const __llmForced = (__llmDefaultForcedRaw !== null) ? __envBool(__llmDefaultForcedRaw) : "";
const DEFAULT_LLM_ON = (__llmDefaultForcedRaw !== null)
  ? (["1","true","yes","y","on"].includes(__llmForced))
  : Boolean((process.env.OPENAI_API_KEY || "").trim());


// ---- Terminal / sandbox execution gate ----
// P0.1: Hard-disabled in production unless explicitly opted-in via ENABLE_TERMINAL_EXEC=true
const TERMINAL_EXEC_ENABLED = (
  String(process.env.ENABLE_TERMINAL_EXEC || "").toLowerCase() === "true"
);
if (NODE_ENV === "production" && TERMINAL_EXEC_ENABLED) {
  console.warn("[Security] WARNING: ENABLE_TERMINAL_EXEC=true in production. Terminal command execution is ACTIVE.");
}

// ============================================================================
// CAPABILITIES REGISTRY — single source of truth for runtime feature gates
// ============================================================================
// Every route/macro that depends on an optional capability checks CAPS.<key>.
// This consolidates the implicit checks scattered across the codebase.
const CAPS = Object.freeze({
  // Storage
  sqlite:       Boolean(Database),
  // Auth / security deps
  jwt:          Boolean(jwt),
  bcrypt:       Boolean(bcrypt),
  zod:          Boolean(z),
  rateLimit:    Boolean(rateLimit),
  helmet:       Boolean(helmet),
  compression:  Boolean(compression),
  // LLM
  openai:       Boolean(OPENAI_API_KEY),
  ollama:       Boolean((process.env.OLLAMA_HOST || "").trim()),
  // Unsafe surfaces (off by default)
  exec:         TERMINAL_EXEC_ENABLED,
  // Federation
  federation:   String(process.env.FEDERATION_ENABLED || "").toLowerCase() === "true",
  // Embeddings
  embeddings:   String(process.env.EMBEDDINGS_ENABLED || "true").toLowerCase() === "true",
  // Voice / media (presence of external binaries)
  whisper:      Boolean((process.env.WHISPER_CPP_BIN || "").trim()),
  piper:        Boolean((process.env.PIPER_BIN || "").trim()),
  imagegen:     Boolean((process.env.SD_URL || process.env.COMFYUI_URL || "").trim()) || Boolean(OPENAI_API_KEY),
});

console.log("[Caps]", JSON.stringify(CAPS));

// ---- immutables ----
const IMMUTABLES = Object.freeze({ NO_MACHINE_TO_HUMAN: true, COUNCIL_REQUIRED: true });

// ---- Chicken3 Ethos Invariants (additive, frozen) ----
const ETHOS_INVARIANTS = Object.freeze({
  LOCAL_FIRST_DEFAULT: true,
  NO_TELEMETRY: true,
  NO_ADS: true,
  NO_SECRET_MONITORING: true,
  NO_USER_PROFILING: true,
  CLOUD_LLM_OPT_IN_ONLY: true,          // env var + session flag required
  PERSONA_SOVEREIGNTY: true,
  ALIGNMENT_PHYSICS_BASED: true,
  FOUNDER_INTENT_STRUCTURAL: true
});

// Guard: call before any external/persistent/monitoring-like action
function enforceEthosInvariant(actionName="") {
  const a = String(actionName||"").toLowerCase();
  if (ETHOS_INVARIANTS.NO_TELEMETRY && a.includes("telemetry")) throw new Error("Ethos invariant: telemetry forbidden");
  if (ETHOS_INVARIANTS.NO_ADS && (a.includes("ad") || a.includes("ads"))) throw new Error("Ethos invariant: ads forbidden");
  if (ETHOS_INVARIANTS.NO_SECRET_MONITORING && (a.includes("monitor") || a.includes("tracking") || a.includes("track"))) {
    throw new Error("Ethos invariant: secret monitoring forbidden");
  }
  if (ETHOS_INVARIANTS.NO_USER_PROFILING && (a.includes("profile") || a.includes("fingerprint"))) throw new Error("Ethos invariant: user profiling forbidden");
  return true;
}

function _cloudOptInAllowed({ sessionId="" } = {}) {
  // Cloud anything requires BOTH:
  // 1) process.env.CLOUD_LLM_ENABLED === "true"
  // 2) session opt-in flag (STATE.sessions[sessionId].cloudOptIn === true)
  try {
    if (String(process.env.CLOUD_LLM_ENABLED || "").toLowerCase() !== "true") return false;
    const sid = String(sessionId||"");
    if (!sid) return false;
    const s = STATE?.sessions?.get?.(sid) || null;
    return Boolean(s?.cloudOptIn === true);
  } catch { return false; }
}
// ---- End Chicken3 Ethos Invariants ----


// ---- canonical system identity (authoritative; non-LLM) ----
const SYSTEM_IDENTITY = Object.freeze({
  name: "Concord",
  version: VERSION,
  type: "Governed Cognitive Operating System (Local-first)",
  short: "Concord is a macro-driven cognitive OS that forges DTUs, consolidates them into MEGA/HYPER nodes, governs knowledge with council rules, and can run sandboxed wrappers/panels.",
  long: [
    "Concord is not a generic project management or collaboration SaaS.",
    "It is a local-first cognitive operating system built around DTUs (Discrete Thought Units) and higher-order DTUs (MEGA/HYPER).",
    "It runs a macro registry (deterministic functions), optional LLM enhancement, and governance (council) for credibility, dedupe, and legality gates.",
    "It compresses large DTU libraries into MEGAs/HYPERs to reduce clutter while preserving lineage, like human memory consolidation."
  ].join(" "),
  invariants: [
    "Identity answers are declarative (never guessed).",
    "Facts vs hypotheses vs philosophy must be labeled.",
    "No duplicates on Global (when enabled).",
    "Maintenance/recommendations go to queues, not the public DTU library by default."
  ]
});

// ---- deterministic intent router (LLM-independent) ----
const INTENT = Object.freeze({
  GREETING: "greeting",
  IDENTITY: "identity",
  STATUS: "status",
  COMMAND: "command",
  QUESTION: "question",
  STATEMENT: "statement",
});

const GREETING_PAT = /^(hi|hey|yo|sup|wassup|what'?s up|hello|hiya|good (morning|afternoon|evening))\b/i;
const IDENTITY_PAT = /\b(what\s+is\s+concord|who\s+are\s+you|what\s+are\s+you|tell\s+me\s+about\s+concord)\b/i;
const STATUS_PAT = /\b(status|health|are\s+you\s+working|llm\s+ready|memory|remember)\b/i;
const COMMAND_PAT = /^\s*\/(\w+)/;

function classifyIntent(utterance="") {
  const s = normalizeText(String(utterance||""));
  if (!s) return { intent: INTENT.STATEMENT, canonical: "" };
  if (COMMAND_PAT.test(s)) return { intent: INTENT.COMMAND, canonical: s.toLowerCase() };
  if (GREETING_PAT.test(s)) return { intent: INTENT.GREETING, canonical: "greeting" };
  if (IDENTITY_PAT.test(s.toLowerCase())) return { intent: INTENT.IDENTITY, canonical: "identity" };
  if (STATUS_PAT.test(s.toLowerCase())) return { intent: INTENT.STATUS, canonical: "status" };
  const isQ = /\?$/.test(s) || /\b(why|how|what|when|where|who|can you|should i|help|explain)\b/i.test(s);
  return { intent: isQ ? INTENT.QUESTION : INTENT.STATEMENT, canonical: s.toLowerCase() };
}



// ---- utils ----
const nowISO = () => new Date().toISOString();
const uid = (prefix="id") => `${prefix}_${crypto.randomBytes(10).toString("hex")}`;
const clamp = (n, a, b) => Math.max(a, Math.min(b, n));
const safeJson = (x, fallback=null) => { try { return JSON.parse(x); } catch { return fallback; } };

// ---- Input Validation Helpers ----
const _VALIDATION = {
  // String validation with max length
  string: (val, maxLen = 10000, defaultVal = "") => {
    if (val === null || val === undefined) return defaultVal;
    return String(val).slice(0, maxLen);
  },
  // Integer with bounds
  int: (val, min = 0, max = Number.MAX_SAFE_INTEGER, defaultVal = 0) => {
    const n = parseInt(val, 10);
    return isNaN(n) ? defaultVal : clamp(n, min, max);
  },
  // Float with bounds
  float: (val, min = 0, max = Number.MAX_VALUE, defaultVal = 0) => {
    const n = parseFloat(val);
    return isNaN(n) ? defaultVal : clamp(n, min, max);
  },
  // Boolean
  bool: (val, defaultVal = false) => {
    if (typeof val === "boolean") return val;
    if (val === "true" || val === "1" || val === 1) return true;
    if (val === "false" || val === "0" || val === 0) return false;
    return defaultVal;
  },
  // Array with item limit
  array: (val, maxItems = 100) => {
    if (!Array.isArray(val)) return [];
    return val.slice(0, maxItems);
  },
  // ID format validation (alphanumeric + underscore)
  id: (val, maxLen = 100) => {
    const s = String(val || "").slice(0, maxLen);
    return /^[a-zA-Z0-9_-]+$/.test(s) ? s : "";
  },
  // Email format
  email: (val) => {
    const s = String(val || "").toLowerCase().trim().slice(0, 254);
    return /^[^\s@]+@[^\s@]+\.[^\s@]+$/.test(s) ? s : "";
  },
  // URL format
  url: (val, maxLen = 2000) => {
    const s = String(val || "").slice(0, maxLen);
    try { new URL(s); return s; } catch { return ""; }
  },
  // Tags array (alphanumeric, lowercase)
  tags: (val, maxTags = 40, maxTagLen = 50) => {
    if (!Array.isArray(val)) return [];
    return val
      .slice(0, maxTags)
      .map(t => String(t).toLowerCase().replace(/[^a-z0-9_-]/g, "").slice(0, maxTagLen))
      .filter(Boolean);
  },
  // Sanitize for XSS prevention (basic HTML escape)
  html: (val, maxLen = 50000) => {
    return String(val || "").slice(0, maxLen)
      .replace(/&/g, "&amp;")
      .replace(/</g, "&lt;")
      .replace(/>/g, "&gt;")
      .replace(/"/g, "&quot;")
      .replace(/'/g, "&#x27;");
  }
};

function normalizeText(s="") {
  return String(s).replace(/\s+/g, " ").trim();
}
function tokenish(s="") {
  return normalizeText(s).toLowerCase();
}


function defaultStyleVector() {
  return {
    // 0..1 sliders
    verbosity: 0.55,
    formality: 0.35,
    skepticism: 0.55,
    abstraction: 0.45,
    bulletiness: 0.45,
    // mutation metadata
    updatedAt: nowISO(),
    mutations: 0
  };
}

function clamp01(x){ return Math.max(0, Math.min(1, Number(x)||0)); }

function normalizeStyleVector(v) {
  const d = defaultStyleVector();
  const out = { ...d, ...(v||{}) };
  out.verbosity = clamp01(out.verbosity);
  out.formality = clamp01(out.formality);
  out.skepticism = clamp01(out.skepticism);
  out.abstraction = clamp01(out.abstraction);
  out.bulletiness = clamp01(out.bulletiness);
  out.updatedAt = nowISO();
  out.mutations = Number(out.mutations||0);
  return out;
}

// Deterministic-ish mutation: small bounded nudges; signal can be {up/down, field, amount} or freeform "like"/"dislike"
function mutateStyleVector(current, signal) {
  const v = normalizeStyleVector(current);
  const amt = clamp(Number(signal?.amount || 0.06), -0.2, 0.2);
  const field = String(signal?.field || "");
  const dir = String(signal?.dir || "");
  const kind = String(signal?.kind || "");
  const nudge = (k, delta) => { v[k] = clamp01(v[k] + delta); };

  if (kind === "like") {
    // Slightly increase verbosity + reduce abstraction a touch (tends to feel clearer)
    nudge("verbosity", 0.03);
    nudge("abstraction", -0.02);
    nudge("bulletiness", 0.02);
  } else if (kind === "dislike") {
    // Slightly reduce verbosity + increase skepticism (tends to tighten answers)
    nudge("verbosity", -0.03);
    nudge("skepticism", 0.03);
    nudge("abstraction", -0.02);
  } else if (field && ["verbosity","formality","skepticism","abstraction","bulletiness"].includes(field)) {
    const delta = (dir === "up" ? Math.abs(amt) : dir === "down" ? -Math.abs(amt) : amt);
    nudge(field, delta);
  }

  v.mutations += 1;
  v.updatedAt = nowISO();
  return v;
}

function getSessionStyleVector(sessionId) {
  const sid = String(sessionId || "");
  if (!sid) return defaultStyleVector();
  const v = STATE.styleVectors.get(sid) || defaultStyleVector();
  const nv = normalizeStyleVector(v);
  STATE.styleVectors.set(sid, nv);
  return nv;
}

function applyStyleToSettings(baseSettings, styleVec) {
  const s = { ...(baseSettings||{}) };
  // abstractionDepthDefault: map 0..1 -> 0..3 (or whatever your max is)
  const maxDepth = clamp(Number(s.abstractionMaxDepth || 3), 1, 9);
  s.abstractionDepthDefault = Math.round(clamp(styleVec.abstraction * maxDepth, 0, maxDepth));
  // Two-tier DTU reasoning set (does not affect reply length)
  // Tier A (focus): 500 DTUs used to drive reasoning
  // Tier B (peripheral): 5000 DTUs used for broad adjacency/contradiction scans
  s.focusSetMax = 500;
  s.peripheralSetMax = 5000;
  // Back-compat: some code still reads workingSetMax/microSetMax
  s.workingSetMax = s.focusSetMax;
  s.microSetMax = clamp(Number(s.microSetMax ?? 50), 10, s.focusSetMax);
  // crispnessMin: skepticism 0..1 -> 0.72..0.9
  const cm = 0.72 + styleVec.skepticism * 0.18;
  s.crispnessMin = clamp(cm, 0.6, 0.95);

  return s;
}

function jaccard(aTokens, bTokens) {
  const A = new Set(aTokens);
  const B = new Set(bTokens);
  if (A.size === 0 && B.size === 0) return 1;
  let inter = 0;
  for (const t of A) if (B.has(t)) inter++;
  const union = A.size + B.size - inter;
  return union ? inter / union : 0;
}

// ===== DTU Humanization Helpers (Topic titles + CRETI rendering) =====
const MODE_PREFIX_RE = /^(AUTOGEN|DREAM|EVOLUTION|SYNTHESIS|COUNCIL|HEARTBEAT)\s*[—:-]\s*/i;
const DATE_TRAIL_RE = /\s*\(?\d{4}-\d{2}-\d{2}.*\)?\s*$/;

function cleanTitle(t) {
  if (!t) return "";
  let s = String(t).trim();
  s = s.replace(MODE_PREFIX_RE, "");
  s = s.replace(DATE_TRAIL_RE, "");
  s = s.replace(/\s{2,}/g, " ").trim();
  // normalize weird unicode dashes
  s = s.replace(/\s*[—–-]\s*/g, " — ").replace(/\s{2,}/g, " ").trim();
  return s;
}

function pickTopicFromText(txt) {
  if (!txt) return "";
  const s = String(txt).replace(/[`*_#]/g, " ").replace(/\s+/g, " ").trim();
  // Prefer short noun-phrase-ish first clause
  const cut = s.split(/[.:\n]/)[0].trim();
  if (cut.length < 4) return "";
  // Avoid generic boilerplate
  const bad = ["definition:", "invariant:", "example:", "a dtu is", "concord is", "modes:", "constraints:"];
  const low = cut.toLowerCase();
  if (bad.some(b => low.startsWith(b))) return "";
  // Limit length
  return cut.slice(0, 64).trim();
}

function titleCase(s) {
  return String(s).replace(/\w\S*/g, w => w.charAt(0).toUpperCase() + w.slice(1));
}

function topicTitleFromDTU(d) {
  // 1) If existing title is already human, keep it (but cleaned)
  const existing = cleanTitle(d?.title || "");
  const looksMachine = /autogen|dream|coherent output|heartbeat|council/i.test(d?.title || "") || (d?.title||"").includes("â");
  if (existing && !looksMachine && existing.length <= 80) return existing;

  // 2) Try CRETI strings
  const creti = (typeof d?.cretiHuman === "string" && d.cretiHuman) || (typeof d?.creti === "string" && d.creti) || "";
  let topic = pickTopicFromText(creti);
  if (topic) return titleCase(topic);

  // 3) Try human summary
  topic = pickTopicFromText(d?.human?.summary || "");
  if (topic) return titleCase(topic);

  // 4) Try core definitions/invariants/examples
  const defs = Array.isArray(d?.core?.definitions) ? d.core.definitions.join(" ") : "";
  const inv  = Array.isArray(d?.core?.invariants) ? d.core.invariants.join(" ") : "";
  const ex   = Array.isArray(d?.core?.examples) ? d.core.examples.join(" ") : "";
  topic = pickTopicFromText(defs) || pickTopicFromText(inv) || pickTopicFromText(ex);
  if (topic) return titleCase(topic);

  // 5) Fallback: cleaned title or id
  if (existing) return existing;
  return d?.id ? String(d.id).slice(0, 24) : "Untitled";
}

function buildCretiText(d) {
  // Prefer explicit CRETI strings if present
  const s1 = (typeof d?.cretiHuman === "string" && d.cretiHuman) || (typeof d?.creti === "string" && d.creti);
  if (s1) return String(s1);

  const defs = Array.isArray(d?.core?.definitions) ? d.core.definitions : [];
  const inv  = Array.isArray(d?.core?.invariants) ? d.core.invariants : [];
  const _ex  = Array.isArray(d?.core?.examples) ? d.core.examples : [];
  const tests = Array.isArray(d?.core?.tests) ? d.core.tests : [];
  const risks = Array.isArray(d?.core?.risks) ? d.core.risks : [];
  const nextA = Array.isArray(d?.core?.nextActions) ? d.core.nextActions : [];
  const sources = Array.isArray(d?.core?.sources) ? d.core.sources : [];

  const bullets = (arr)=> arr.map(x=>`- ${x}`).join("\n");
  const parts = [];
  parts.push("Context");
  const summary = (typeof d?.human?.summary === "string" && d.human.summary) ? d.human.summary : "";
  if (summary) parts.push(bullets([summary]));
  else if (defs.length) parts.push(bullets(defs.slice(0,6)));
  else parts.push("- (add context)");

  if (inv.length) { parts.push("\nReasoning"); parts.push(bullets(inv.slice(0,8))); }
  if (sources.length) { parts.push("\nEvidence"); parts.push(bullets(sources.slice(0,8))); }
  if (tests.length) { parts.push("\nTests"); parts.push(bullets(tests.slice(0,8))); }
  if (risks.length) { parts.push("\nRisks"); parts.push(bullets(risks.slice(0,8))); }
  if (nextA.length) { parts.push("\nImpact / Next"); parts.push(bullets(nextA.slice(0,8))); }

  return parts.join("\n");
}


/* =========================
   Abstraction Ladder + Crisp Reasoning (APE+ANT)
   - Keep reasoning crisp at ALL tiers by enforcing:
     * Working-memory caps (ape)
     * Canonical/anti-dup selection (ape)
     * Emergent compression via promotion (ant)
   ========================= */

function dtuStatus(d){
  return (d?.status || d?.meta?.status || "active").toString().toLowerCase();
}
function isDormantDTU(d){
  const st = dtuStatus(d);
  return st === "merged" || st === "archived" || st === "inactive";
}
function isShadowDTU(d){
  return (d?.tier || "").toString().toLowerCase() === "shadow" || (Array.isArray(d?.tags) && d.tags.includes("shadow"));
}
function crispnessScore(d){
  // 0..1 heuristic: reward constraints/tests/relations; penalize empty blobs
  const txt = buildCretiText(d);
  const hasInv = Array.isArray(d?.core?.invariants) && d.core.invariants.length > 0;
  const hasDefs = Array.isArray(d?.core?.definitions) && d.core.definitions.length > 0;
  const hasTests = Array.isArray(d?.core?.tests) && d.core.tests.length > 0;
  const hasNext = Array.isArray(d?.core?.nextActions) && d.core.nextActions.length > 0;
  const tagsN = Array.isArray(d?.tags) ? d.tags.length : 0;
  const lineageN = Array.isArray(d?.lineage) ? d.lineage.length : 0;

  let s = 0;
  if (txt && txt.length > 120) s += 0.20;
  if (hasDefs) s += 0.15;
  if (hasInv) s += 0.25;
  if (hasTests) s += 0.20;
  if (hasNext) s += 0.10;
  if (tagsN >= 3) s += 0.05;
  if (lineageN >= 2) s += 0.05;

  // penalty for very short / empty
  if (!txt || txt.length < 60) s -= 0.20;
  return clamp(s, 0, 1);
}
function eligibleDTUForReasoning(d, settings){
  if (!d) return false;
  if (isShadowDTU(d)) return false; // keep shadow DTUs internal; don't drive user answers
  if (isDormantDTU(d)) return false;
  if (settings?.canonicalOnly && d?.meta?.canonicalId && d.meta.canonicalId !== d.id) return false;
  return true;
}
function selectWorkingSet(scored, settings, { includeMegas=true } = {}){
  // Two-tier DTU reasoning set:
  // - focus (Tier A): up to 500 DTUs that may directly drive reasoning
  // - peripheral (Tier B): up to 5000 DTUs for broad adjacency/contradiction scans
  const focusMax = clamp(Number(settings?.focusSetMax ?? settings?.workingSetMax ?? 500), 50, 5000);
  const peripheralMax = clamp(Number(settings?.peripheralSetMax ?? (focusMax * 10)), focusMax, 50000);
  const microMax = clamp(Number(settings?.microSetMax ?? 50), 10, focusMax);
  const crispMin = Number(settings?.crispnessMin ?? 0.25);

  // Eligible DTUs for reasoning (respect canonical/dormant/shadow rules)
  const eligible = (scored||[])
    .map(x => ({ ...x, crisp: crispnessScore(x.d) }))
    .filter(x => eligibleDTUForReasoning(x.d, settings));

  // Prefer crispness, then similarity score
  eligible.sort((a,b)=> (b.crisp - a.crisp) || (b.score - a.score));

  // Build peripheral set first (broad view)
  const peripheral = [];
  const seen = new Set();
  for (const x of eligible) {
    if (!x?.d?.id) continue;
    if (seen.has(x.d.id)) continue;
    // Optionally skip megas/hypers if caller requests
    const tier = (x.d.tier || "regular").toLowerCase();
    if (!includeMegas && (tier === "mega" || tier === "hyper")) continue;
    seen.add(x.d.id);
    peripheral.push(x.d);
    if (peripheral.length >= peripheralMax) break;
  }

  // Focus set is the top slice of peripheral (promoted set)
  const focus = peripheral.slice(0, focusMax);

  // Micro: compact regular DTUs for local reasoning (subset of focus)
  const micro = [];
  for (const d of focus) {
    if (!d?.id) continue;
    const tier = (d.tier || "regular").toLowerCase();
    if (tier !== "regular" && tier !== "core") continue;
    micro.push(d);
    if (micro.length >= microMax) break;
  }

  // Macro: megas/hypers inside focus (kept for downstream logic that expects "macro")
  const macro = [];
  for (const d of focus) {
    const tier = (d?.tier || "regular").toLowerCase();
    if (tier === "mega" || tier === "hyper") macro.push(d);
  }

  // If focus is unexpectedly thin (e.g., strict filters), widen just enough by relaxing crispness
  if (focus.length < Math.min(50, Math.floor(focusMax * 0.1))) {
    const widened = (scored||[])
      .map(x => ({ ...x, crisp: crispnessScore(x.d) }))
      .filter(x => {
        // same structural eligibility, but allow low-crispness regular/core DTUs
        if (!x?.d) return false;
        const tier = (x.d.tier || "regular").toLowerCase();
        if (tier !== "regular" && tier !== "core") return false;
        return eligibleDTUForReasoning(x.d, settings);
      })
      .sort((a,b)=> (b.score - a.score));
    for (const x of widened) {
      if (!x?.d?.id) continue;
      if (seen.has(x.d.id)) continue;
      seen.add(x.d.id);
      peripheral.push(x.d);
      if (peripheral.length >= peripheralMax) break;
    }
  }

  // Keep crispnessMin behavior for downstream verbosity knobs WITHOUT shrinking the set.
  // (We do not reduce focus size below focusMax due to low crispness; spec requires broad reasoning.)
  const avgC = focus.length ? focus.map(d=>crispnessScore(d)).reduce((a,b)=>a+b,0)/focus.length : 0;
  const hardCap = avgC < crispMin ? focus.length : focus.length;

  return {
    focus: focus.slice(0, hardCap),
    micro,
    macro,
    peripheral
  };
}


function chooseAbstractionFrame({ mode="explore", intent="statement", hasStrongEvidence=false, settings={} }){
  const userDepth = Number(settings?.abstractionDepthDefault ?? 1);
  const maxDepth = Number(settings?.abstractionMaxDepth ?? 3);
  let level = clamp(userDepth, 0, maxDepth);

  // Mode nudges
  if (mode === "debug" || mode === "decide") level = Math.max(level, 1);
  if (mode === "design") level = Math.max(level, 2);

  // Weak evidence: stay concrete/generalized, avoid speculative leaps
  if (!hasStrongEvidence) level = Math.min(level, 1);

  // Greeting/identity: keep simple
  if (intent === INTENT.GREETING || intent === INTENT.IDENTITY) level = 0;

  const requireHypLabels = settings?.requireHypothesisLabels !== false;
  const requireTests = settings?.requireTestsWhenUncertain !== false;

  return { level, requireHypLabels, requireTests };
}

// ===== SEMANTIC UNDERSTANDING FALLBACK =====
// Enhanced response generation when LLM is not available.
// Uses semantic word vectors, DTU embeddings, and inference engine.

function semanticUnderstandFallback(prompt, relevantDtus = [], _options = {}) {
  const result = {
    semanticIntent: null,
    inferredAnswer: null,
    relatedConcepts: [],
    semanticallySimilar: [],
    confidence: 0
  };

  // 1. Analyze semantic intent
  if (typeof classifySemanticIntent === "function") {
    result.semanticIntent = classifySemanticIntent(prompt);
  }

  // 2. Find semantically similar words in the query
  const tokens = (typeof tokenizeText === "function") ? tokenizeText(prompt) : [];
  const similarWordFindings = [];

  for (const token of tokens.slice(0, 5)) {
    if (typeof findSimilarWords === "function") {
      const similar = findSimilarWords(token, 3, 0.65);
      if (similar.length > 0) {
        similarWordFindings.push({ word: token, similar: similar.map(s => s.word) });
      }
    }
  }
  result.relatedConcepts = similarWordFindings;

  // 3. Enhanced DTU matching using semantic embeddings
  if (typeof computeLocalEmbedding === "function" && typeof cosineSimilarity === "function") {
    try {
      const queryEmbedding = computeLocalEmbedding(prompt);

      for (const dtu of relevantDtus.slice(0, 10)) {
        const dtuText = [
          dtu.title || "",
          dtu.human?.summary || "",
          (dtu.tags || []).join(" ")
        ].join(" ");

        const dtuEmbedding = computeLocalEmbedding(dtuText);
        const similarity = cosineSimilarity(queryEmbedding, dtuEmbedding);

        if (similarity > 0.6) {
          result.semanticallySimilar.push({
            dtuId: dtu.id,
            title: dtu.title,
            similarity
          });
        }
      }

      result.semanticallySimilar.sort((a, b) => b.similarity - a.similarity);
    } catch {
      // Silently fail, fall back to regular matching
    }
  }

  // 4. Try to answer using the inference engine
  if (typeof queryWithInference === "function") {
    // Parse simple questions
    const whoIsMatch = prompt.match(/who\s+is\s+(?:a\s+)?(\w+)/i);
    const whatIsMatch = prompt.match(/what\s+is\s+(?:a\s+)?(\w+)/i);
    const isAMatch = prompt.match(/is\s+(?:a\s+)?(\w+)\s+(?:a\s+)?(\w+)/i);

    if (isAMatch) {
      // "Is X a Y?" -> query for subject=X, object=Y
      const queryResult = queryWithInference({
        subject: isAMatch[1].toLowerCase(),
        predicate: "is",
        object: isAMatch[2].toLowerCase()
      });

      if (queryResult.ok && queryResult.found) {
        result.inferredAnswer = {
          type: "inference",
          answer: queryResult.explanation.join("; "),
          confidence: queryResult.facts[0]?.confidence || 0.5
        };
      }
    } else if (whatIsMatch || whoIsMatch) {
      const subject = (whatIsMatch || whoIsMatch)[1].toLowerCase();
      const queryResult = queryWithInference({
        subject: subject,
        predicate: "is"
      });

      if (queryResult.ok && queryResult.found && queryResult.facts.length > 0) {
        const answers = queryResult.facts.map(f => `${f.subject} is ${f.object}`);
        result.inferredAnswer = {
          type: "knowledge_base",
          answer: answers.join("; "),
          confidence: queryResult.facts[0]?.confidence || 0.5
        };
      }
    }
  }

  // 5. Calculate overall confidence
  let confidence = 0.2;  // Base confidence for any response
  if (result.semanticallySimilar.length > 0) {
    confidence += result.semanticallySimilar[0].similarity * 0.4;
  }
  if (result.inferredAnswer) {
    confidence += result.inferredAnswer.confidence * 0.3;
  }
  if (result.relatedConcepts.length > 0) {
    confidence += 0.1;
  }

  result.confidence = Math.min(confidence, 0.95);

  return result;
}

// Generate an enhanced response using semantic understanding
function generateSemanticResponse(prompt, microDTUs, macroDTUs, semanticResult) {
  const lines = [];

  // If we have an inferred answer, lead with it
  if (semanticResult.inferredAnswer) {
    lines.push("Based on reasoning:");
    lines.push(`- ${semanticResult.inferredAnswer.answer}`);
    lines.push(`- (Source: ${semanticResult.inferredAnswer.type}, confidence: ${(semanticResult.inferredAnswer.confidence * 100).toFixed(0)}%)`);
    lines.push("");
  }

  // Add semantic context
  if (semanticResult.semanticIntent) {
    const intent = semanticResult.semanticIntent.intent;
    const intentDescriptions = {
      "query": "You're asking a question",
      "create": "You want to create something",
      "update": "You want to modify something",
      "analyze": "You want deep analysis",
      "explain": "You want an explanation",
      "compare": "You want to compare options"
    };
    if (intentDescriptions[intent]) {
      lines.push(`Understanding: ${intentDescriptions[intent]}.`);
    }
  }

  // Add semantically related concepts
  if (semanticResult.relatedConcepts.length > 0) {
    const concepts = semanticResult.relatedConcepts
      .flatMap(c => c.similar)
      .slice(0, 5);
    if (concepts.length > 0) {
      lines.push(`Related concepts: ${concepts.join(", ")}.`);
    }
  }

  // Add semantically similar DTUs
  if (semanticResult.semanticallySimilar.length > 0) {
    lines.push("");
    lines.push("Semantically related knowledge:");
    for (const dtu of semanticResult.semanticallySimilar.slice(0, 3)) {
      lines.push(`- ${dtu.title} (${(dtu.similarity * 100).toFixed(0)}% match)`);
    }
  }

  return lines.join("\n");
}

// ===== END SEMANTIC UNDERSTANDING FALLBACK =====

function formatCrispResponse({ prompt: _prompt, mode: _mode, microDTUs, macroDTUs, level, answerLines, hypotheses=[], tests=[] }){
  const lines = [];
  // Facts/Evidence anchors (always)
  if (microDTUs?.length) {
    lines.push("Evidence anchors (DTUs):");
    for (const d of microDTUs.slice(0,5)) {
      const tags = (d.tags && d.tags.length) ? ` (${d.tags.slice(0,4).join(", ")})` : "";
      const excerpt = buildCretiText(d).split(/\n\n|\n|\.\s/).filter(Boolean).slice(0, 2).join(". ").slice(0, 240);
      lines.push(`• ${d.title}${tags}${excerpt ? ` — ${excerpt}${excerpt.endsWith(".") ? "" : "."}` : ""}`);
    }
    lines.push("");
  }

  if (macroDTUs?.length) {
    lines.push("Abstraction anchors (MEGA/HYPER):");
    for (const d of macroDTUs.slice(0,3)) {
      lines.push(`• ${d.title} [${(d.tier||"mega").toUpperCase()}]`);
    }
    lines.push("");
  }

  lines.push("Answer:");
  lines.push(...(answerLines?.length ? answerLines : ["- (no answer lines produced)"]));
  lines.push("");

  if (level >= 2 && hypotheses.length) {
    lines.push("Hypotheses (labeled):");
    for (const h of hypotheses.slice(0,6)) lines.push(`- HYP: ${h}`);
    lines.push("");
  }

  if ((tests && tests.length) || level >= 1) {
    const outTests = (tests && tests.length) ? tests : [
      "Ask a more specific question (goal + constraints).",
      "Forge 1–2 DTUs capturing definitions + invariants for this topic."
    ];
    lines.push("Next tests / next actions:");
    for (const t of outTests.slice(0,6)) lines.push(`- ${t}`);
  }

  return lines.join("\n").trim();
}

// ============================================================================
// QUALITY PIPELINE PATTERNS (P1-P6) + Pattern Router
// ============================================================================
// These patterns run deterministically between DTU Context Selection and the
// LLM call. They cost zero API tokens and compound quality downstream.
// Pipeline: DTU Context → [Pattern Router → P1..P6] → Fused Context → LLM
// ============================================================================

// --- Session pattern history tracking (for variety mechanism) ---
const _PATTERN_HISTORY = new Map(); // sessionId → [last 3 pattern names]
const _PATTERN_HISTORY_MAX = 10000; // Cap to prevent unbounded memory growth

function _trackPatternUsage(sessionId, patternNames) {
  const history = _PATTERN_HISTORY.get(sessionId) || [];
  history.push(...patternNames);
  // Keep only last 3
  while (history.length > 3) history.shift();
  _PATTERN_HISTORY.set(sessionId, history);
  // Evict oldest entries when map gets too large
  if (_PATTERN_HISTORY.size > _PATTERN_HISTORY_MAX) {
    const it = _PATTERN_HISTORY.keys();
    for (let i = 0; i < _PATTERN_HISTORY.size - _PATTERN_HISTORY_MAX; i++) {
      _PATTERN_HISTORY.delete(it.next().value);
    }
  }
}

function _getPatternHistory(sessionId) {
  return _PATTERN_HISTORY.get(sessionId) || [];
}

// --- CRETI field projection rules by query intent (P2) ---
const CRETI_PROJECTION_RULES = {
  factual:      { context: true, reasoning: false, evidence: true,  tests: false, impact: false },
  causal:       { context: true, reasoning: true,  evidence: true,  tests: false, impact: false },
  procedural:   { context: false, reasoning: true,  evidence: false, tests: true,  impact: true  },
  creative:     { context: true, reasoning: false, evidence: false, tests: false, impact: true  },
  evaluative:   { context: true, reasoning: true,  evidence: true,  tests: true,  impact: true  },
  exploratory:  { context: true, reasoning: true,  evidence: false, tests: false, impact: true  },
  debug:        { context: true, reasoning: true,  evidence: true,  tests: true,  impact: false },
  default:      { context: true, reasoning: true,  evidence: true,  tests: false, impact: false },
};

function _inferQueryIntent(prompt, mode) {
  const p = String(prompt || "").toLowerCase();
  if (mode === "debug") return "debug";
  if (mode === "design") return "procedural";
  if (/\b(why|cause|because|reason|led to|result of)\b/.test(p)) return "causal";
  if (/\b(how to|steps|process|procedure|guide|method)\b/.test(p)) return "procedural";
  if (/\b(create|imagine|story|design|brainstorm|invent)\b/.test(p)) return "creative";
  if (/\b(compare|evaluate|pros|cons|trade-?off|better|worse|rank)\b/.test(p)) return "evaluative";
  if (/\b(what is|define|explain|describe|who is|when did)\b/.test(p)) return "factual";
  if (/\b(explore|consider|think about|wonder|curious)\b/.test(p)) return "exploratory";
  return "default";
}

// ============================================================================
// P1: Shadow DTU Distillation
// ============================================================================
// Cross-reference selected DTU context against STATE.shadowDtus to find hidden
// reasoning anchors. Inject matched shadow DTU invariants as pre-resolved premises.

function patternShadowDistillation(microSet, query) {
  if (!STATE.shadowDtus || STATE.shadowDtus.size === 0) return { applied: false, premises: [], removedIds: new Set() };

  const queryTokens = new Set(simpleTokens(String(query || "")).map(stemLite).filter(Boolean));
  const microTags = new Set();
  const microInvariants = new Set();

  for (const d of microSet) {
    if (Array.isArray(d?.tags)) d.tags.forEach(t => microTags.add(String(t).toLowerCase()));
    if (Array.isArray(d?.core?.invariants)) d.core.invariants.forEach(i => microInvariants.add(_normAtom(i)));
  }

  const premises = [];
  const removedIds = new Set();

  for (const shadow of STATE.shadowDtus.values()) {
    if (!shadow || shadow.machine?.kind === "session_context" || shadow.machine?.kind === "linguistic_map") continue;

    // Match by tag overlap
    const shadowTags = new Set(Array.isArray(shadow.tags) ? shadow.tags.map(t => String(t).toLowerCase()) : []);
    shadowTags.delete("shadow"); // Don't count the shadow tag itself
    let tagOverlap = 0;
    for (const t of shadowTags) { if (microTags.has(t)) tagOverlap++; }

    // Match by invariant similarity
    const shadowInvariants = Array.isArray(shadow.core?.invariants) ? shadow.core.invariants : [];
    const shadowClaims = Array.isArray(shadow.core?.claims) ? shadow.core.claims : [];
    const shadowAtoms = [...shadowInvariants, ...shadowClaims].map(_normAtom).filter(Boolean);

    let invariantOverlap = 0;
    for (const a of shadowAtoms) { if (microInvariants.has(a)) invariantOverlap++; }

    // Query relevance check
    const shadowText = simpleTokens([shadow.title || "", ...(shadow.tags || []), shadow.human?.summary || ""].join(" ")).map(stemLite);
    let queryOverlap = 0;
    for (const t of shadowText) { if (queryTokens.has(t)) queryOverlap++; }

    const matchScore = (tagOverlap * 0.4 + invariantOverlap * 0.4 + Math.min(queryOverlap, 3) * 0.2);

    if (matchScore >= 0.8) {
      // Inject shadow DTU invariants as pre-resolved premises
      for (const inv of shadowInvariants.slice(0, 3)) {
        premises.push(`[PRE-RESOLVED] ${inv}`);
      }
      for (const claim of shadowClaims.slice(0, 2)) {
        premises.push(`[SHADOW PREMISE] ${claim}`);
      }

      // Mark micro DTUs that this shadow already covers for potential removal
      for (const d of microSet) {
        if (!d?.core?.invariants) continue;
        const dAtoms = d.core.invariants.map(_normAtom).filter(Boolean);
        const covered = dAtoms.every(a => shadowAtoms.includes(a));
        if (covered && dAtoms.length > 0) removedIds.add(d.id);
      }
    }
  }

  return { applied: premises.length > 0, premises: premises.slice(0, 8), removedIds };
}

// ============================================================================
// P2: CRETI Projection
// ============================================================================
// Project only the CRETI fields relevant to query type, reducing token noise.

function patternCRETIProjection(dtu, queryIntent) {
  const rules = CRETI_PROJECTION_RULES[queryIntent] || CRETI_PROJECTION_RULES.default;

  const parts = [];

  // Context field (definitions + summary)
  if (rules.context) {
    const summary = (typeof dtu?.human?.summary === "string" && dtu.human.summary) ? dtu.human.summary : "";
    const defs = Array.isArray(dtu?.core?.definitions) ? dtu.core.definitions : [];
    if (summary) parts.push(`C: ${summary}`);
    else if (defs.length) parts.push(`C: ${defs.slice(0, 3).join("; ")}`);
  }

  // Reasoning field (invariants)
  if (rules.reasoning) {
    const inv = Array.isArray(dtu?.core?.invariants) ? dtu.core.invariants : [];
    if (inv.length) parts.push(`R: ${inv.slice(0, 4).join("; ")}`);
  }

  // Evidence field (sources)
  if (rules.evidence) {
    const sources = Array.isArray(dtu?.core?.sources) ? dtu.core.sources : [];
    const claims = Array.isArray(dtu?.core?.claims) ? dtu.core.claims : [];
    const evidence = sources.length ? sources : claims;
    if (evidence.length) parts.push(`E: ${evidence.slice(0, 3).join("; ")}`);
  }

  // Tests field
  if (rules.tests) {
    const tests = Array.isArray(dtu?.core?.tests) ? dtu.core.tests : [];
    if (tests.length) parts.push(`T: ${tests.slice(0, 3).join("; ")}`);
  }

  // Impact field (nextActions + risks)
  if (rules.impact) {
    const nextA = Array.isArray(dtu?.core?.nextActions) ? dtu.core.nextActions : [];
    const risks = Array.isArray(dtu?.core?.risks) ? dtu.core.risks : [];
    const impact = [...nextA.slice(0, 2), ...risks.slice(0, 1)];
    if (impact.length) parts.push(`I: ${impact.join("; ")}`);
  }

  return parts.join("\n") || buildCretiText(dtu);
}

// ============================================================================
// P3: Linguistic Spine Rewrite
// ============================================================================
// Use affect policy + session style vector to reshape DTU content from storage
// format into optimal prompt format before the LLM sees it.

function patternLinguisticRewrite(dtuContext, styleVector, affectPolicy) {
  if (!dtuContext) return dtuContext;

  const sv = styleVector || {};
  const ap = affectPolicy || {};
  const style = ap.style || {};

  // Determine output format based on style vector
  const useFlowingProse = (sv.bulletiness || 0.45) < 0.35;
  const isHighVerbosity = (sv.verbosity || 0.55) > 0.7;
  const isFormal = (sv.formality || 0.35) > 0.6;

  let rewritten = dtuContext;

  // Convert bullet format to flowing prose if style demands it
  if (useFlowingProse) {
    rewritten = rewritten.replace(/^- (.+)$/gm, "$1.");
    rewritten = rewritten.replace(/\n\n+/g, " ");
    rewritten = rewritten.replace(/\n/g, " ");
    rewritten = rewritten.replace(/\s+/g, " ").trim();
  }

  // Adjust verbosity: trim low-value content for low-verbosity sessions
  if (!isHighVerbosity) {
    // Remove empty section headers and placeholder content
    rewritten = rewritten.replace(/^(Context|Reasoning|Evidence|Tests|Risks|Impact \/ Next)\n- \(add[^)]*\)\n?/gm, "");
  }

  // Apply formality adjustment
  if (!isFormal && style.warmth > 0.6) {
    // Strip overly formal section headers for warm/casual sessions
    rewritten = rewritten.replace(/^(Context|Reasoning|Evidence|Tests|Risks|Impact \/ Next)\n/gm, "");
  }

  // Apply affect-driven tone shaping
  if (style.caution > 0.7) {
    // Prefix uncertain content with hedging
    rewritten = rewritten.replace(/\[CONTESTED\]/g, "[UNCERTAIN — multiple perspectives exist]");
  }

  return rewritten.trim();
}

// ============================================================================
// P4: Multi-Lens Convergence
// ============================================================================
// When a query touches multiple domains, fuse perspectives from each lens.

function patternMultiLensConvergence(query, microSet, lensArtifacts) {
  // Detect multi-domain intent
  const pseudoDtu = { title: String(query).slice(0, 100), human: { summary: String(query).slice(0, 300) }, tags: [] };
  const primaryDomain = classifyDomain(pseudoDtu);

  // Check if micro-set DTUs span multiple domains
  const domainCounts = {};
  for (const d of microSet) {
    const dom = classifyDomain(d);
    domainCounts[dom] = (domainCounts[dom] || 0) + 1;
  }

  const domains = Object.entries(domainCounts)
    .filter(([, count]) => count >= 1)
    .sort((a, b) => b[1] - a[1])
    .map(([domain]) => domain);

  // Only apply when genuinely multi-domain (2+ distinct domains with substance)
  if (domains.length < 2) return { applied: false, convergenceBlock: "" };

  const perspectives = [];

  for (const domain of domains.slice(0, 3)) {
    const domainDTUs = microSet.filter(d => classifyDomain(d) === domain);
    if (!domainDTUs.length) continue;

    const domainLabel = domain.toUpperCase();
    const keyPoints = domainDTUs.slice(0, 2).map(d => {
      const summary = d.human?.summary || d.title || "";
      const inv = Array.isArray(d?.core?.invariants) ? d.core.invariants.slice(0, 2) : [];
      return inv.length ? inv.join("; ") : summary.slice(0, 150);
    }).filter(Boolean);

    if (keyPoints.length) {
      perspectives.push(`[${domainLabel} PERSPECTIVE]: ${keyPoints.join(". ")}`);
    }

    // Check for lens artifacts in this domain
    if (lensArtifacts && STATE.lensDomainIndex) {
      const artifactIds = STATE.lensDomainIndex.get(domain);
      if (artifactIds && artifactIds.size > 0) {
        const firstId = artifactIds.values().next().value;
        const artifact = STATE.lensArtifacts.get(firstId);
        if (artifact?.data) {
          perspectives.push(`[${domainLabel} LENS]: ${artifact.title || artifact.type || "artifact"}`);
        }
      }
    }
  }

  // Build convergence block
  if (perspectives.length < 2) return { applied: false, convergenceBlock: "" };

  // Find convergence points (shared invariants across domains)
  const allInvariants = microSet.flatMap(d => (Array.isArray(d?.core?.invariants) ? d.core.invariants : []).map(_normAtom));
  const invCounts = {};
  for (const inv of allInvariants) {
    if (!inv) continue;
    invCounts[inv] = (invCounts[inv] || 0) + 1;
  }
  const shared = Object.entries(invCounts).filter(([, c]) => c >= 2).map(([inv]) => inv).slice(0, 2);

  if (shared.length) {
    perspectives.push(`[CONVERGENCE]: Shared across domains: ${shared.join("; ")}`);
  }

  return { applied: true, convergenceBlock: perspectives.join("\n") };
}

// ============================================================================
// P5: Contradiction Pre-Resolution
// ============================================================================
// Detect and resolve contradictions in the micro-set before the LLM sees them.

function patternContradictionPreResolution(microSet) {
  if (!microSet || microSet.length < 2) return { applied: false, resolved: [], contested: [], removedIds: new Set() };

  const resolved = [];
  const contested = [];
  const removedIds = new Set();
  const oppose = (a) => a.startsWith("not ") ? a.slice(4) : ("not " + a);

  // Build atom map per DTU
  const dtuAtoms = microSet.map(d => {
    const inv = Array.isArray(d?.core?.invariants) ? d.core.invariants : [];
    const clm = Array.isArray(d?.core?.claims) ? d.core.claims : [];
    return {
      dtu: d,
      atoms: new Set([...inv, ...clm].map(_normAtom).filter(Boolean))
    };
  });

  // Check all pairs for contradictions
  for (let i = 0; i < dtuAtoms.length; i++) {
    for (let j = i + 1; j < dtuAtoms.length; j++) {
      const a = dtuAtoms[i];
      const b = dtuAtoms[j];

      for (const atomA of a.atoms) {
        const negA = oppose(atomA);
        if (b.atoms.has(negA)) {
          // Found a contradiction — resolve it
          const winner = _resolveContradiction(a.dtu, b.dtu, atomA, negA);
          if (winner.clear) {
            resolved.push(`[RESOLVED] "${atomA}" — ${winner.reason}`);
            removedIds.add(winner.loserId);
          } else {
            contested.push(`[CONTESTED] "${atomA}" vs "${negA}" — both DTUs retained, no clear winner`);
          }
          break; // One contradiction per pair is enough
        }
      }
    }
  }

  return {
    applied: resolved.length > 0 || contested.length > 0,
    resolved: resolved.slice(0, 5),
    contested: contested.slice(0, 3),
    removedIds
  };
}

function _resolveContradiction(dtuA, dtuB, atomA, atomB) {
  // 1. Timestamp: prefer newer DTU
  const tsA = dtuA.updatedAt || dtuA.createdAt || "";
  const tsB = dtuB.updatedAt || dtuB.createdAt || "";
  if (tsA && tsB && tsA !== tsB) {
    const newer = tsA > tsB ? dtuA : dtuB;
    const loser = newer === dtuA ? dtuB : dtuA;
    return { clear: true, winnerId: newer.id, loserId: loser.id, reason: `Newer DTU (${newer.title || newer.id}) preferred` };
  }

  // 2. Authority score: prefer higher council-scored DTU
  const scoreA = dtuA.authority?.score || 0;
  const scoreB = dtuB.authority?.score || 0;
  if (scoreA !== scoreB) {
    const winner = scoreA > scoreB ? dtuA : dtuB;
    const loser = winner === dtuA ? dtuB : dtuA;
    return { clear: true, winnerId: winner.id, loserId: loser.id, reason: `Higher authority (score ${Math.max(scoreA, scoreB)})` };
  }

  // 3. Stability: prefer higher crispness score
  const crispA = crispnessScore(dtuA);
  const crispB = crispnessScore(dtuB);
  if (Math.abs(crispA - crispB) > 0.1) {
    const winner = crispA > crispB ? dtuA : dtuB;
    const loser = winner === dtuA ? dtuB : dtuA;
    return { clear: true, winnerId: winner.id, loserId: loser.id, reason: `Higher crispness (${Math.max(crispA, crispB).toFixed(2)})` };
  }

  // 4. Shadow DTU precedent
  if (STATE.shadowDtus) {
    for (const shadow of STATE.shadowDtus.values()) {
      if (!shadow?.core?.invariants) continue;
      const shadowAtoms = shadow.core.invariants.map(_normAtom);
      if (shadowAtoms.includes(atomA)) {
        return { clear: true, winnerId: dtuA.id, loserId: dtuB.id, reason: `Shadow DTU precedent supports "${atomA}"` };
      }
      if (shadowAtoms.includes(atomB)) {
        return { clear: true, winnerId: dtuB.id, loserId: dtuA.id, reason: `Shadow DTU precedent supports "${atomB}"` };
      }
    }
  }

  // No clear winner
  return { clear: false };
}

// ============================================================================
// P6: Resonance-Weighted Micro-Prompt
// ============================================================================
// Allocate token budget per DTU based on resonance score.

function patternResonanceWeightedPrompt(microSet, queryIntent, tokenBudget) {
  const budget = tokenBudget || 2000;
  if (!microSet || !microSet.length) return [];

  // Calculate resonance for each DTU in context
  const scored = microSet.map(d => {
    // Use crispness as proxy for resonance (existing system metric)
    const crisp = crispnessScore(d);
    const authorityBoost = Math.min((d.authority?.score || 0) / 10, 0.2);
    const tierBoost = d.tier === "hyper" ? 0.15 : d.tier === "mega" ? 0.1 : 0;
    const resonance = clamp(crisp + authorityBoost + tierBoost, 0, 1);
    return { dtu: d, resonance };
  }).sort((a, b) => b.resonance - a.resonance);

  const result = [];

  for (const { dtu, resonance } of scored) {
    let representation;

    if (resonance > 0.8) {
      // Full CRETI representation
      representation = patternCRETIProjection(dtu, queryIntent);
    } else if (resonance > 0.5) {
      // Summary + key invariants only
      const summary = dtu.human?.summary || dtu.title || "";
      const inv = Array.isArray(dtu?.core?.invariants) ? dtu.core.invariants.slice(0, 2) : [];
      representation = summary.slice(0, 120) + (inv.length ? "\nKey: " + inv.join("; ") : "");
    } else if (resonance > 0.25) {
      // Single-line summary only
      representation = dtu.human?.summary || dtu.title || String(dtu.id).slice(0, 20);
      representation = representation.slice(0, 80);
    } else {
      // Tag mention only
      const tags = Array.isArray(dtu.tags) ? dtu.tags.slice(0, 3).join(", ") : "";
      representation = `[${dtu.title || dtu.id}]${tags ? " (" + tags + ")" : ""}`;
      representation = representation.slice(0, 50);
    }

    result.push({
      dtu,
      resonance,
      representation,
      tier: resonance > 0.8 ? "full" : resonance > 0.5 ? "summary" : resonance > 0.25 ? "single" : "tag"
    });
  }

  return result;
}

// ============================================================================
// PATTERN ROUTER
// ============================================================================
// Evaluates the query and selects a pattern stack. Always runs P2 + P6 as
// baseline. Selects 0-1 conditional patterns (or all for complex queries).
// Tracks last-3-patterns-used per session for variety.

function qualityPipelineRouter(query, microSet, focus, sessionId, opts = {}) {
  const mode = opts.mode || "explore";
  const styleVector = opts.styleVector || null;
  const affectPolicy = opts.affectPolicy || null;

  const queryIntent = _inferQueryIntent(query, mode);
  const history = _getPatternHistory(sessionId);

  // --- Detect which conditional patterns qualify ---
  const candidates = [];

  // P1: Shadow Distillation — if shadow DTU matches exist
  if (STATE.shadowDtus && STATE.shadowDtus.size > 0) {
    const shadowMatches = _quickShadowMatchCheck(microSet);
    if (shadowMatches) candidates.push("P1");
  }

  // P3: Linguistic Rewrite — if non-default style/affect
  if (styleVector) {
    const isNonDefault = (
      Math.abs((styleVector.verbosity || 0.55) - 0.55) > 0.1 ||
      Math.abs((styleVector.formality || 0.35) - 0.35) > 0.1 ||
      Math.abs((styleVector.bulletiness || 0.45) - 0.45) > 0.1
    );
    if (isNonDefault || (affectPolicy?.style && Object.keys(affectPolicy.style).length > 0)) {
      candidates.push("P3");
    }
  }

  // P4: Multi-Lens — if multi-domain query
  if (microSet.length >= 2) {
    const domains = new Set(microSet.map(d => classifyDomain(d)));
    if (domains.size >= 2) candidates.push("P4");
  }

  // P5: Contradiction Pre-Res — if potential conflicts in set
  if (microSet.length >= 2) {
    const hasAtoms = microSet.some(d =>
      (Array.isArray(d?.core?.invariants) && d.core.invariants.length > 0) ||
      (Array.isArray(d?.core?.claims) && d.core.claims.length > 0)
    );
    if (hasAtoms) candidates.push("P5");
  }

  // --- Select conditional pattern(s) ---
  // MAX CONCURRENT: P2 + P6 + 1 conditional (normally)
  // Exception: complex multi-domain queries can run more
  const isComplex = candidates.length >= 3;
  let selected = [];

  if (isComplex) {
    // Complex: run all qualified patterns
    selected = [...candidates];
  } else if (candidates.length > 0) {
    // Rotate selection: deprioritize recently-used patterns
    const sorted = candidates.sort((a, b) => {
      const aRecent = history.filter(h => h === a).length;
      const bRecent = history.filter(h => h === b).length;
      return aRecent - bRecent;
    });
    selected = [sorted[0]]; // Pick least-recently-used
  }

  // Always run P2 + P6
  const patterns = ["P2", "P6", ...selected];

  // Track for variety
  _trackPatternUsage(sessionId, selected);

  return {
    patterns,
    queryIntent,
    isComplex,
    conditional: selected
  };
}

// Quick check: do any shadow DTUs have tag overlap with the micro-set?
function _quickShadowMatchCheck(microSet) {
  const microTags = new Set();
  for (const d of microSet) {
    if (Array.isArray(d?.tags)) d.tags.forEach(t => microTags.add(String(t).toLowerCase()));
  }
  if (microTags.size === 0) return false;

  for (const shadow of STATE.shadowDtus.values()) {
    if (!shadow || shadow.machine?.kind === "session_context" || shadow.machine?.kind === "linguistic_map") continue;
    const sTags = Array.isArray(shadow.tags) ? shadow.tags.map(t => String(t).toLowerCase()) : [];
    for (const t of sTags) {
      if (t !== "shadow" && microTags.has(t)) return true;
    }
  }
  return false;
}

// ============================================================================
// FUSED CONTEXT BUILDER
// ============================================================================
// Runs the selected patterns and produces a unified context block for the LLM.

function buildFusedContext(query, focus, micro, sessionId, routerResult, opts = {}) {
  const { patterns, queryIntent } = routerResult;
  const styleVector = opts.styleVector || null;
  const affectPolicy = opts.affectPolicy || null;

  let workingMicro = [...micro];
  const contextParts = [];
  const meta = { patternsApplied: [], tokenEstimate: 0 };

  // --- P5: Contradiction Pre-Resolution (run first to remove losers) ---
  if (patterns.includes("P5")) {
    const p5 = patternContradictionPreResolution(workingMicro);
    if (p5.applied) {
      meta.patternsApplied.push("P5");
      // Remove losing DTUs from working set
      if (p5.removedIds.size > 0) {
        workingMicro = workingMicro.filter(d => !p5.removedIds.has(d.id));
      }
      // Add resolution annotations
      if (p5.resolved.length) contextParts.push(p5.resolved.join("\n"));
      if (p5.contested.length) contextParts.push(p5.contested.join("\n"));
    }
  }

  // --- P1: Shadow DTU Distillation (run second to inject premises and remove covered DTUs) ---
  if (patterns.includes("P1")) {
    const p1 = patternShadowDistillation(workingMicro, query);
    if (p1.applied) {
      meta.patternsApplied.push("P1");
      // Inject pre-resolved premises at the top
      if (p1.premises.length) contextParts.unshift(p1.premises.join("\n"));
      // Remove covered DTUs
      if (p1.removedIds.size > 0) {
        workingMicro = workingMicro.filter(d => !p1.removedIds.has(d.id));
      }
    }
  }

  // --- P6: Resonance-Weighted Micro-Prompt (determines representation depth per DTU) ---
  let resonanceMap = null;
  if (patterns.includes("P6")) {
    const p6 = patternResonanceWeightedPrompt(workingMicro, queryIntent, 2000);
    if (p6.length > 0) {
      meta.patternsApplied.push("P6");
      resonanceMap = new Map(p6.map(item => [item.dtu.id, item]));
    }
  }

  // --- P2: CRETI Projection + P6 Resonance (build DTU context entries) ---
  const dtuEntries = [];
  for (const d of workingMicro) {
    const resonanceItem = resonanceMap?.get(d.id);
    let entry;

    if (resonanceItem && resonanceItem.tier !== "full") {
      // P6 says use reduced representation
      entry = `[${d.title}] (${d.tier || "regular"}) ${resonanceItem.representation}`;
    } else if (patterns.includes("P2")) {
      // P2: CRETI Projection — project only relevant fields
      meta.patternsApplied.push("P2");
      const projected = patternCRETIProjection(d, queryIntent);
      entry = `TITLE: ${d.title}\nTIER: ${d.tier}\nTAGS: ${(d.tags || []).join(", ")}\n${projected}`;
    } else {
      // Fallback: full CRETI
      entry = `TITLE: ${d.title}\nTIER: ${d.tier}\nTAGS: ${(d.tags || []).join(", ")}\nCRETI:\n${buildCretiText(d)}`;
    }

    dtuEntries.push(entry);
  }

  // Deduplicate P2 in meta
  meta.patternsApplied = [...new Set(meta.patternsApplied)];

  // --- P4: Multi-Lens Convergence ---
  if (patterns.includes("P4")) {
    const p4 = patternMultiLensConvergence(query, workingMicro, STATE.lensArtifacts);
    if (p4.applied) {
      meta.patternsApplied.push("P4");
      contextParts.push(p4.convergenceBlock);
    }
  }

  // Assemble final context
  const dtuBlock = dtuEntries.join("\n---\n");

  // --- P3: Linguistic Spine Rewrite (run last to reshape the assembled context) ---
  let finalDtuBlock = dtuBlock;
  if (patterns.includes("P3")) {
    const rewritten = patternLinguisticRewrite(dtuBlock, styleVector, affectPolicy);
    if (rewritten !== dtuBlock) {
      meta.patternsApplied.push("P3");
      finalDtuBlock = rewritten;
    }
  }

  // Combine all parts
  const allParts = [...contextParts, finalDtuBlock].filter(Boolean);
  const fusedContext = allParts.join("\n\n");

  // Estimate token count (rough: ~4 chars per token)
  meta.tokenEstimate = Math.round(fusedContext.length / 4);

  return {
    fusedContext,
    meta,
    workingMicro
  };
}

// ============================================================================
// BACKEND ENHANCEMENTS: Coherence Audit, Shadow Promotion, Crispness Decay
// ============================================================================

// Coherence Audit: cross-check claims vs invariants internally within a DTU
function coherenceAudit(dtu) {
  if (!dtu?.core) return { ok: true, issues: [] };

  const invariants = Array.isArray(dtu.core.invariants) ? dtu.core.invariants.map(_normAtom) : [];
  const claims = Array.isArray(dtu.core.claims) ? dtu.core.claims.map(_normAtom) : [];
  const oppose = (a) => a.startsWith("not ") ? a.slice(4) : ("not " + a);
  const issues = [];

  // Check internal contradictions (claim vs invariant within same DTU)
  for (const inv of invariants) {
    if (!inv) continue;
    for (const claim of claims) {
      if (!claim) continue;
      if (claim === oppose(inv)) {
        issues.push({ type: "internal_contradiction", invariant: inv, claim });
      }
    }
  }

  // Check for duplicate assertions
  const allAtoms = [...invariants, ...claims];
  const seen = new Set();
  for (const a of allAtoms) {
    if (seen.has(a)) issues.push({ type: "duplicate_assertion", atom: a });
    seen.add(a);
  }

  return { ok: issues.length === 0, issues };
}

// Shadow Promotion: if pattern seen 3+ times, auto-create shadow DTU
function maybeShadowPromotion(dtu) {
  if (!dtu?.core?.invariants || dtu.core.invariants.length === 0) return { promoted: false };

  const invariants = dtu.core.invariants.map(_normAtom).filter(Boolean);
  if (invariants.length === 0) return { promoted: false };

  // Count how many existing DTUs share the same invariants
  const matchCounts = {};
  for (const inv of invariants) matchCounts[inv] = 0;

  for (const existing of STATE.dtus.values()) {
    if (!existing || existing.id === dtu.id) continue;
    const eInv = Array.isArray(existing.core?.invariants) ? existing.core.invariants.map(_normAtom) : [];
    for (const inv of invariants) {
      if (eInv.includes(inv)) matchCounts[inv]++;
    }
  }

  // Find invariants with 3+ matches (the pattern threshold)
  const promotable = Object.entries(matchCounts).filter(([, c]) => c >= 3).map(([inv]) => inv);
  if (promotable.length === 0) return { promoted: false };

  // Check if a shadow DTU for this pattern already exists
  for (const shadow of STATE.shadowDtus.values()) {
    if (shadow.machine?.kind !== "pattern_shadow") continue;
    const sInv = Array.isArray(shadow.core?.invariants) ? shadow.core.invariants.map(_normAtom) : [];
    const overlap = promotable.filter(p => sInv.includes(p));
    if (overlap.length >= promotable.length * 0.7) {
      // Already have a shadow for this pattern
      return { promoted: false, existing: shadow.id };
    }
  }

  // Create new shadow DTU encoding the pattern
  const shadowId = uid("shadow");
  const shadowDtu = {
    id: shadowId,
    title: `PATTERN SHADOW — ${promotable[0].slice(0, 48)}`,
    tier: "shadow",
    tags: ["shadow", "pattern", "auto-promoted", ...(dtu.tags || []).slice(0, 5)],
    human: { summary: `Auto-promoted pattern: ${promotable.slice(0, 3).join("; ")}`, bullets: [] },
    core: {
      definitions: [],
      invariants: promotable.slice(0, 8),
      claims: Array.isArray(dtu.core.claims) ? dtu.core.claims.slice(0, 4) : [],
      examples: [],
      nextActions: []
    },
    machine: {
      kind: "pattern_shadow",
      sourceId: dtu.id,
      matchCount: promotable.reduce((s, p) => s + (matchCounts[p] || 0), 0),
      promotedAt: nowISO()
    },
    lineage: { parents: [dtu.id], children: [] },
    source: "shadow",
    meta: { hidden: true, autoPromoted: true },
    createdAt: nowISO(),
    updatedAt: nowISO(),
    authority: { model: "shadow", score: 0 },
    hash: ""
  };

  STATE.shadowDtus.set(shadowId, shadowDtu);
  return { promoted: true, shadowId, invariants: promotable };
}

// Crispness Decay: reduce crispness of older DTUs on the same topic
function applyCrispnessDecay(newDtu) {
  if (!newDtu?.tags || !Array.isArray(newDtu.tags) || newDtu.tags.length === 0) return { decayed: 0 };

  const newTags = new Set(newDtu.tags.map(t => String(t).toLowerCase()));
  const newTitle = tokenish(newDtu.title || "");
  let decayed = 0;

  for (const existing of STATE.dtus.values()) {
    if (!existing || existing.id === newDtu.id) continue;
    if (isShadowDTU(existing)) continue;

    // Check topic overlap via tags
    const eTags = Array.isArray(existing.tags) ? existing.tags.map(t => String(t).toLowerCase()) : [];
    const tagOverlap = eTags.filter(t => newTags.has(t)).length;
    const eTitle = tokenish(existing.title || "");

    // Only decay if significant topic overlap (shared tags or similar titles)
    const titleSim = jaccard(newTitle.split(/\s+/), eTitle.split(/\s+/));
    if (tagOverlap < 2 && titleSim < 0.3) continue;

    // Check if existing is older
    const existingTime = existing.updatedAt || existing.createdAt || "";
    const newTime = newDtu.createdAt || nowISO();
    if (existingTime >= newTime) continue;

    // Apply crispness decay of 0.05
    // We simulate crispness decay by slightly reducing the existing DTU's authority score
    // and adding a meta marker. The crispnessScore() function is computed dynamically,
    // so we degrade it by removing low-value fields.
    if (!existing.meta) existing.meta = {};
    existing.meta.crispnessDecayApplied = (existing.meta.crispnessDecayApplied || 0) + 0.05;
    existing.meta.lastDecayAt = nowISO();
    existing.meta.decaySource = newDtu.id;

    // Reduce authority score slightly
    if (existing.authority && typeof existing.authority.score === "number") {
      existing.authority.score = Math.max(0, existing.authority.score - 0.5);
    }

    decayed++;
  }

  return { decayed };
}

// ============================================================================
// END QUALITY PIPELINE PATTERNS
// ============================================================================

function ensureModeTag(d) {
  // normalize mode to tags only (keep provenance)
  const t = new Set(Array.isArray(d?.tags) ? d.tags.filter(Boolean).map(String) : []);
  const kind = (d?.machine?.kind || d?.meta?.source || "").toString().toLowerCase();
  if (kind) t.add(kind);
  if (d?.authority?.model) t.add(String(d.authority.model).toLowerCase());
  d.tags = Array.from(t);
}

function renameAllDTUs(dtusList) {
  let changed = 0;
  for (const d of (dtusList||[])) {
    if (!d || typeof d !== "object") continue;
    // Preserve original title once
    if (d?.meta && !d.meta.originalTitle && d.title) d.meta.originalTitle = String(d.title);
    if (!d.meta) d.meta = {};
    const newTitle = topicTitleFromDTU(d);
    if (newTitle && newTitle !== d.title) { d.title = newTitle; changed++; }
    ensureModeTag(d);
    // Ensure a cretiHuman exists for UI friendliness
    if (!d.cretiHuman) d.cretiHuman = buildCretiText(d);
  }
  return changed;
}

function dtuForClient(d, opts = {}) {
  if (!d || typeof d !== "object") return d;
  const base = {
    id: d.id,
    type: d.type,
    title: d.title,
    tier: d.tier,
    tags: d.tags,
    creti: d.cretiHuman || d.creti || buildCretiText(d),
    lineage: d.lineage || { parents: [], children: [] },
    authority: d.authority || {},
    meta: d.meta || {}
  };
  if (opts.raw) base.raw = d;
  return base;
}

// ===== End DTU Humanization Helpers =====

function simpleTokens(s) {
  return tokenish(s).split(/[^a-z0-9]+/g).filter(Boolean).slice(0, 256);

}

// ---- Offline-first semantic query expansion (synonyms + fuzzy) ----
const STOPWORDS = new Set([
  "a","an","the","and","or","but","if","then","else","so","to","of","in","on","for","from","with","as","at","by",
  "is","are","was","were","be","been","being","do","does","did","doing","done","can","could","should","would","may","might",
  "i","me","my","mine","you","your","yours","we","us","our","ours","they","them","their","theirs",
  "this","that","these","those","it","its","there","here","what","why","how","when","where","who"
]);

// Small, safe synonym map (expand over time via shadow linguistic DTUs)
const SYN_MAP = Object.freeze({
  "talk": ["chat","conversation","dialogue"],
  "chat": ["talk","conversation","dialogue"],
  "conversation": ["chat","talk","dialogue"],
  "help": ["assist","support","aid"],
  "fix": ["repair","patch","resolve"],
  "bug": ["issue","error","problem"],
  "search": ["retrieve","lookup","find"],
  "retrieve": ["search","lookup","find"],
  "dtu": ["dtus","unit","thought"],
  "dtus": ["dtu","units","thoughts"],
  "offline": ["local","local-first","no-llm"],
  "static": ["canned","repetitive","monotone"],
  "dynamic": ["adaptive","responsive","fluid"],
  "meaning": ["semantics","intent","sense"],
  "synonym": ["similar","equivalent","alias"],
  "topic": ["subject","theme","thread"],
  "recency": ["recent","fresh","new"],
  "recent": ["recency","fresh","new"]
});

function stemLite(t="") {
  let s = String(t||"").toLowerCase();
  // Basic English-ish suffix stripping (deterministic; not perfect)
  const rules = [
    [/ies$/,"y"],
    [/ing$/,""],
    [/ed$/,""],
    [/s$/,""],
  ];
  for (const [re, rep] of rules) {
    if (s.length >= 5 && re.test(s)) { s = s.replace(re, rep); break; }
  }
  return s;
}

function normalizeQueryText(q="") {
  // Normalize common contractions / punctuation into spaces
  return normalizeText(String(q||""))
    .replace(/[’']/g, "'")
    .replace(/[^a-zA-Z0-9'\s]+/g, " ")
    .replace(/\s+/g, " ")
    .trim();
}

function tokensNoStop(q="") {
  const toks = simpleTokens(q).map(stemLite).filter(Boolean);
  return toks.filter(t => !STOPWORDS.has(t));
}

let _LING_CACHE = { at: 0, map: new Map(), size: 0 };
function learnedSynonymsMap() {
  // Build a small cache from shadow linguistic DTUs (cheap, local-first).
  const now = Date.now();
  if (_LING_CACHE.map.size && (now - _LING_CACHE.at) < 5000) return _LING_CACHE.map; // 5s cache
  const m = new Map();
  try {
    const arr = Array.from(STATE.shadowDtus.values());
    for (const d of arr.slice(-600)) {
      if (!d) continue;
      const kind = String(d?.machine?.kind || "").toLowerCase();
      if (kind !== "linguistic_map") continue;
      const phrase = normalizeQueryText(d?.machine?.phrase || "");
      const expands = Array.isArray(d?.machine?.expands) ? d.machine.expands : [];
      if (phrase && expands.length) m.set(phrase, expands.map(stemLite).filter(Boolean));
    }
  } catch {}
  _LING_CACHE = { at: now, map: m, size: m.size };
  return m;
}

function expandQueryTokens(q="") {
  const raw = normalizeQueryText(q);
  const base = tokensNoStop(raw);
  const expanded = new Set(base);
  // Synonym expansion
  for (const t of base) {
    const syns = SYN_MAP[t] || SYN_MAP[stemLite(t)] || null;
    if (syns) for (const s of syns) expanded.add(stemLite(s));
  }
  // Phrase-level learned expansions
  const lmap = learnedSynonymsMap();
  if (lmap.size) {
    const low = raw.toLowerCase();
    // direct phrase
    const hit = lmap.get(low);
    if (hit) for (const s of hit) expanded.add(stemLite(s));
    // soft phrase match (contains)
    for (const [k, v] of lmap.entries()) {
      if (k.length >= 6 && low.includes(k)) {
        for (const s of v) expanded.add(stemLite(s));
      }
    }
  }
  return Array.from(expanded).slice(0, 256);
}

function charNgrams(s="", n=3) {
  const t = tokenish(s).replace(/[^a-z0-9]+/g, " ").trim().replace(/\s+/g, " ");
  const w = t.slice(0, 320);
  const out = [];
  for (let i=0; i<=w.length-n; i++) {
    const g = w.slice(i, i+n);
    if (g.includes(" ")) continue;
    out.push(g);
  }
  return out.slice(0, 400);
}

function ngramSim(a="", b="") {
  const A = charNgrams(a, 3);
  const B = charNgrams(b, 3);
  if (!A.length || !B.length) return 0;
  const SA = new Set(A);
  const SB = new Set(B);
  let inter = 0;
  for (const g of SA) if (SB.has(g)) inter++;
  const union = SA.size + SB.size - inter;
  return union ? inter / union : 0;
}

function temporalRecencyWeight(dtu) {
  // 0..1, half-life ~ 2 days for recent session behavior; old DTUs still possible.
  const last = dtu?.stats?.lastUsedAt || dtu?.updatedAt || dtu?.createdAt || null;
  if (!last) return 0;
  const t = new Date(last).getTime();
  if (!Number.isFinite(t)) return 0;
  const ageHours = Math.max(0, (Date.now() - t) / 3600000);
  const halfLife = 48; // hours
  const w = Math.pow(0.5, ageHours / halfLife);
  return clamp(w, 0, 1);
}

function maybeWriteLinguisticShadowDTU({ phrase="", expands=[], topIds=[] } = {}) {
  try {
    const p = normalizeQueryText(phrase);
    const ex = Array.from(new Set((expands||[]).map(stemLite).filter(Boolean))).slice(0, 16);
    if (!p || ex.length < 2) return { ok:false, reason:"insufficient" };
    // Avoid dup: if same phrase already exists recently, skip.
    const existing = Array.from(STATE.shadowDtus.values()).slice(-400).find(d =>
      String(d?.machine?.kind||"").toLowerCase()==="linguistic_map" &&
      normalizeQueryText(d?.machine?.phrase||"") === p
    );
    if (existing) return { ok:true, skipped:true, id: existing.id };

    const dtu = {
      id: uid("shadow"),
      title: `LINGUISTIC MAP — ${p.slice(0,64)}`,
      tier: "shadow",
      tags: ["shadow","linguistic","map"],
      human: { summary: `Learned query expansion for: "${p}"`, bullets: [] },
      core: { definitions: [], invariants: [], claims: [], examples: [], nextActions: [] },
      machine: { kind: "linguistic_map", phrase: p, expands: ex, topIds: (topIds||[]).slice(0,12) },
      lineage: { parents: [], children: [] },
      source: "shadow",
      meta: { hidden: true },
      createdAt: nowISO(),
      updatedAt: nowISO(),
      authority: { model: "shadow", score: 0 },
      hash: ""
    };
    STATE.shadowDtus.set(dtu.id, dtu);
    saveStateDebounced();
    return { ok:true, id: dtu.id };
  } catch (e) {
    return { ok:false, error:String(e?.message||e) };
  }
}
// Shadow DTU cleanup - prevent unbounded memory growth
const SHADOW_DTU_MAX = 2000; // Maximum shadow DTUs to keep
const SHADOW_DTU_TTL_DAYS = 14; // Days before shadow DTU expires

function cleanupShadowDTUs() {
  try {
    const now = Date.now();
    const ttlMs = SHADOW_DTU_TTL_DAYS * 24 * 60 * 60 * 1000;
    const shadows = Array.from(STATE.shadowDtus.entries());

    // Remove expired shadow DTUs
    let expired = 0;
    for (const [id, dtu] of shadows) {
      const createdAt = new Date(dtu.createdAt || 0).getTime();
      if (now - createdAt > ttlMs) {
        STATE.shadowDtus.delete(id);
        EMBEDDINGS.store.delete(id); // Also remove from embeddings
        expired++;
      }
    }

    // If still over max, remove oldest
    if (STATE.shadowDtus.size > SHADOW_DTU_MAX) {
      const sorted = Array.from(STATE.shadowDtus.entries())
        .sort((a, b) => (a[1].createdAt || "").localeCompare(b[1].createdAt || ""));
      const toRemove = sorted.slice(0, STATE.shadowDtus.size - SHADOW_DTU_MAX);
      for (const [id] of toRemove) {
        STATE.shadowDtus.delete(id);
        EMBEDDINGS.store.delete(id);
      }
    }

    if (expired > 0 || STATE.shadowDtus.size > SHADOW_DTU_MAX) {
      saveStateDebounced();
      console.log(`[Shadow] Cleanup: removed ${expired} expired, ${STATE.shadowDtus.size} remaining`);
    }

    return { ok: true, expired, remaining: STATE.shadowDtus.size };
  } catch (e) {
    return { ok: false, error: String(e?.message || e) };
  }
}

// Run shadow cleanup periodically (every 6 hours)
setInterval(() => cleanupShadowDTUs(), 6 * 60 * 60 * 1000);
setTimeout(() => cleanupShadowDTUs(), 60000); // Initial cleanup after 1 min

// ---- Index Reconciliation (Category 3: Data Integrity) ----
// Ensures lens domain index stays consistent with artifact store
function reconcileIndices() {
  let fixed = 0;
  try {
    // 1. Reconcile lensDomainIndex vs lensArtifacts
    for (const [domain, idSet] of STATE.lensDomainIndex) {
      for (const id of idSet) {
        if (!STATE.lensArtifacts.has(id)) {
          idSet.delete(id);
          fixed++;
        }
      }
      if (idSet.size === 0) STATE.lensDomainIndex.delete(domain);
    }

    // 2. Ensure every artifact is indexed
    for (const [id, artifact] of STATE.lensArtifacts) {
      if (!artifact.domain) continue;
      if (!STATE.lensDomainIndex.has(artifact.domain)) {
        STATE.lensDomainIndex.set(artifact.domain, new Set());
      }
      const domainSet = STATE.lensDomainIndex.get(artifact.domain);
      if (!domainSet.has(id)) {
        domainSet.add(id);
        fixed++;
      }
    }

    // 3. Detect orphaned DTU references (parentId -> nonexistent DTU)
    let orphanedRefs = 0;
    for (const dtu of STATE.dtus.values()) {
      if (dtu.parentId && !STATE.dtus.has(dtu.parentId)) {
        orphanedRefs++;
      }
    }

    if (fixed > 0 || orphanedRefs > 0) {
      saveStateDebounced();
      structuredLog("info", "index_reconciliation", { fixed, orphanedRefs, dtuCount: STATE.dtus.size, artifactCount: STATE.lensArtifacts.size });
    }

    return { ok: true, fixed, orphanedRefs };
  } catch (e) {
    structuredLog("error", "index_reconciliation_failed", { error: String(e?.message || e) });
    return { ok: false, error: String(e?.message || e) };
  }
}

// Run index reconciliation every 4 hours
setInterval(() => reconcileIndices(), 4 * 60 * 60 * 1000);
setTimeout(() => reconcileIndices(), 120000); // 2 min after startup

// ---- End semantic query expansion ----

function cretiPack({ title, purpose, context, procedure, outputs, tests, notes }) {
  return [
    `# CRETI`,
    `## Title\n${title || "Untitled"}`,
    `## Purpose\n${purpose || ""}`,
    `## Context\n${context || ""}`,
    `## Procedure\n${procedure || ""}`,
    `## Outputs\n${outputs || ""}`,
    `## Tests\n${tests || ""}`,
    `## Notes\n${notes || ""}`,
  ].join("\n\n").trim();
}

// ---- in-memory state (v2 local-first) ----
const STATE = {
  dtus: new Map(),        // id -> dtu
  shadowDtus: new Map(),  // id -> dtu (shadow tier persisted separately)
  wrappers: new Map(),    // id -> wrapper
  layers: new Map(),      // id -> layer
  personas: new Map(),    // id -> persona
  sessions: new Map(),    // sessionId -> {messages:[...], createdAt, styleVector?}
  styleVectors: new Map(), // sessionId -> style vector (mutable)
  // v3: identity + orgs (local-first auth; can be upgraded to real DB/OIDC later)
  users: new Map(),       // userId -> {id, handle, createdAt, orgIds:[...], roleByOrg:{orgId:role}}
  orgs: new Map(),        // orgId -> {id, name, ownerUserId, createdAt}
  apiKeys: new Map(),     // keyId -> {id, keyHash, userId, orgId, scopes:[...], createdAt, revokedAt}
  // v3: jobs (long-running orchestrator)
  jobs: new Map(),        // jobId -> {id, kind, payload, status, attempts, maxAttempts, runAt, createdAt, updatedAt, lastError, result}
  // v3: sources + global + marketplace + papers
  sources: new Map(),     // sourceId -> {id, url, fetchedAt, contentHash, title, excerpt, text, meta}
  globalIndex: { byHash: new Map(), byId: new Map() }, // globalId/hash -> dtuId
  listings: new Map(),    // listingId -> {id, dtuId, orgId, price, currency, license, status, createdAt}
  entitlements: new Map(),// entId -> {id, buyerOrgId, dtuId, license, createdAt}
  transactions: new Map(),// txId -> {id, buyerOrgId, sellerOrgId, listingId, amount, fee, createdAt}
  papers: new Map(),      // paperId -> {id, orgId, topic, outline, sections, refs, status, createdAt, updatedAt}
  organs: new Map(),      // organId -> organState
  growth: null,          // growth OS state
  // v3: Generic lens artifact store (domain.type → artifact)
  lensArtifacts: new Map(), // artifactId → {id, domain, type, ownerId, title, data, meta, createdAt, updatedAt, version}
  lensDomainIndex: new Map(), // domain → Set<artifactId> — O(1) domain lookup
  __chicken2: {
    enabled: true,
    mode: "full_blast",
    thresholdOverlap: 0.95,
    thresholdHomeostasis: 0.80,
    thresholdSuffering: 0.65,
    hardFails: { inversionVacuum: true, negativeValence: true, genesisViolation: true },
    logs: [],
    lastProof: null,
    metrics: { continuityAvg: 0, homeostasis: 1, contradictionLoad: 0, suffering: 0, rejections: 0, accepts: 0 }
  },
  
  __chicken3: {
    enabled: true,
    // runtime switches
    cronEnabled: true,
    // Chicken3 intent: lattice never sleeps. Default 15s; env may override.
    cronIntervalMs: Number(process.env.LATTICE_CRON_MS || 15000),
    metaEnabled: true,
    metaSampleProb: clamp(Number(process.env.C3_META_PROB || 0.10), 0, 1),
    metaMinMaturity: clamp(Number(process.env.C3_META_MIN_MATURITY || 0.75), 0, 1),
    // transport/polish
    streamingEnabled: true,
    multimodalEnabled: true,
    voiceEnabled: true,
    toolsEnabled: true,
    federationEnabled: false,
    // bookkeeping
    lastCronAt: null,
    lastMetaAt: null,
    lastFederationAt: null,
    stats: { cronTicks: 0, metaProposals: 0, metaCommits: 0, federationRx: 0, federationTx: 0 }
  },
  settings: {
    heartbeatMs: 15000,
    heartbeatEnabled: true,
    autogenEnabled: true,
    dreamEnabled: true,
    evolutionEnabled: true,
    synthEnabled: true,
    llmDefault: true,
    // Truth calibration
    interpretiveTruthMin: 0.35,
    interpretiveTruthMax: 0.85,
    speculativeGateEnabled: false,
    // Abstraction Ladder (ape constraints + ant scale)
    abstractionDepthDefault: 1,   // 0=concrete,1=generalize,2=hypotheses-labeled,3=meta
    abstractionMaxDepth: 3,
    workingSetMax: 500,           // (legacy) focus DTUs used for reasoning
    focusSetMax: 500,             // Tier A: focus set used to drive reasoning
    peripheralSetMax: 5000,       // Tier B: peripheral context set for adjacency/contradiction checks
    microSetMax: 50,              // preferred DTUs used for local reasoning (subset of focus)
    crispnessMin: 0.25,           // min crispness to drive reasoning (fallback allowed)
    canonicalOnly: true,          // prefer canonical DTUs; merged/archived are de-prioritized
    includeMegasInBase: true,     // allow megas to assist, but never replace micro evidence
    requireHypothesisLabels: true,
    requireTestsWhenUncertain: true
  },
  logs: [],
  crawlQueue: [],
  queues: {
    maintenance: [],
    macroProposals: [],
    panelProposals: [],
    synthesis: [],
    hypotheses: [],
    philosophy: [],
    wrapperJobs: [],
    notifications: []
  },

  // ---- Abstraction Governor (v3 upgrades) ----
  // Abstraction is treated as an additive, measurable quantity.
  // Concord enforces a conservation invariant: abstraction added must be matched
  // by equal-order collapse/grounding over long horizons.
  abstraction: {
    enabled: true,
    cadenceDays: 10,
    lastEvalAt: null,
    lastUpgradeAt: null,
    // ledger: track abstraction added vs collapsed (conservation)
    ledger: { added: 0, collapsed: 0 },
    // metrics snapshot updated periodically
    metrics: {
      ecc: 0,        // equivalence compression count (proxy)
      rd: 0,         // reuse distance (proxy)
      ir: 0,         // internalization ratio (proxy)
      etua: 1,       // error tolerance under addition (proxy, 0..1)
      load: 0,       // current abstraction load (0..1)
      margin: 1      // remaining capacity margin (0..1)
    },
    history: []
  },
};

// ============================================================================
// WAVE 1: PRODUCTION READINESS
// ============================================================================

// ---- SQLite Database for Auth & Audit ----
const DB_PATH = process.env.DB_PATH || path.join(DATA_DIR, "concord.db");
let db = null;

function initDatabase() {
  if (!Database) {
    console.warn("[DB] better-sqlite3 not available, falling back to JSON storage");
    return false;
  }

  try {
    // Ensure the DB parent directory exists (handles both /data/concord.db and /data/db/concord.db)
    fs.mkdirSync(path.dirname(DB_PATH), { recursive: true });
    db = new Database(DB_PATH);
    db.pragma("journal_mode = WAL"); // Better performance
    db.pragma("foreign_keys = ON");

    // Create tables
    db.exec(`
      CREATE TABLE IF NOT EXISTS users (
        id TEXT PRIMARY KEY,
        username TEXT UNIQUE NOT NULL,
        email TEXT UNIQUE NOT NULL,
        password_hash TEXT NOT NULL,
        role TEXT NOT NULL DEFAULT 'member',
        scopes TEXT NOT NULL DEFAULT '["read","write"]',
        created_at TEXT NOT NULL,
        last_login_at TEXT,
        is_active INTEGER NOT NULL DEFAULT 1
      );

      CREATE TABLE IF NOT EXISTS api_keys (
        id TEXT PRIMARY KEY,
        user_id TEXT NOT NULL,
        name TEXT NOT NULL,
        key_hash TEXT NOT NULL,
        key_prefix TEXT NOT NULL,
        scopes TEXT NOT NULL DEFAULT '["read"]',
        created_at TEXT NOT NULL,
        last_used_at TEXT,
        is_active INTEGER NOT NULL DEFAULT 1,
        FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
      );

      CREATE TABLE IF NOT EXISTS sessions (
        id TEXT PRIMARY KEY,
        user_id TEXT NOT NULL,
        token_hash TEXT NOT NULL,
        created_at TEXT NOT NULL,
        expires_at TEXT NOT NULL,
        ip_address TEXT,
        user_agent TEXT,
        is_revoked INTEGER NOT NULL DEFAULT 0,
        FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
      );

      CREATE TABLE IF NOT EXISTS audit_log (
        id TEXT PRIMARY KEY,
        timestamp TEXT NOT NULL,
        category TEXT NOT NULL,
        action TEXT NOT NULL,
        user_id TEXT,
        ip_address TEXT,
        user_agent TEXT,
        request_id TEXT,
        path TEXT,
        method TEXT,
        status_code INTEGER,
        details TEXT,
        FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE SET NULL
      );

      CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON audit_log(timestamp DESC);
      CREATE INDEX IF NOT EXISTS idx_audit_user ON audit_log(user_id);
      CREATE INDEX IF NOT EXISTS idx_audit_category ON audit_log(category);
      CREATE INDEX IF NOT EXISTS idx_sessions_user ON sessions(user_id);
      CREATE INDEX IF NOT EXISTS idx_sessions_expires ON sessions(expires_at);
      CREATE INDEX IF NOT EXISTS idx_api_keys_user ON api_keys(user_id);
    `);

    console.log("[DB] SQLite database initialized");
    return true;
  } catch (e) {
    console.error("[DB] Failed to initialize SQLite:", e.message);
    return false;
  }
}

const _DB_READY = initDatabase();

// Initialize auth/token infrastructure with runtime dependencies
initTokens({ jwt, bcrypt, db, EFFECTIVE_JWT_SECRET, JWT_EXPIRES_IN, BCRYPT_ROUNDS, NODE_ENV, REFRESH_TOKEN_EXPIRES: process.env.REFRESH_TOKEN_EXPIRES || "30d", REFRESH_TOKEN_COOKIE });

// ---- "Everything Real": Run schema migrations after DB init ----
if (db) {
  try {
    const migrationResult = await runSchemaMigrations(db);
    const totalRun = migrationResult.applied.length + migrationResult.alreadyRun.length;
    console.log(`[Concord] Migrations: ${totalRun} total, ${migrationResult.applied.length} newly applied`);
  } catch (e) {
    console.error("[Concord] Migration failed:", e.message);
  }
}

// Register database close on shutdown
if (db) {
  registerShutdownCallback(() => {
    console.log("[Shutdown] Closing database...");
    db.close();
  });
}

// ---- Authentication System (SQLite + fallback to JSON) ----
const AUTH = {
  users: new Map(),
  sessions: new Map(),
  apiKeys: new Map(),
};

// Database-backed auth functions
const AuthDB = {
  // Users
  createUser(user) {
    if (db) {
      const stmt = db.prepare(`
        INSERT INTO users (id, username, email, password_hash, role, scopes, created_at, last_login_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
      `);
      stmt.run(user.id, user.username, user.email, user.passwordHash, user.role, JSON.stringify(user.scopes), user.createdAt, user.lastLoginAt);
    }
    AUTH.users.set(user.id, user);
    saveAuthData();
  },

  getUser(userId) {
    if (db) {
      const stmt = db.prepare("SELECT * FROM users WHERE id = ? AND is_active = 1");
      const row = stmt.get(userId);
      if (row) {
        return {
          id: row.id,
          username: row.username,
          email: row.email,
          passwordHash: row.password_hash,
          role: row.role,
          scopes: JSON.parse(row.scopes),
          createdAt: row.created_at,
          lastLoginAt: row.last_login_at
        };
      }
      return null;
    }
    return AUTH.users.get(userId) || null;
  },

  getUserByUsername(username) {
    if (db) {
      const stmt = db.prepare("SELECT * FROM users WHERE username = ? AND is_active = 1");
      const row = stmt.get(username);
      if (row) {
        return {
          id: row.id,
          username: row.username,
          email: row.email,
          passwordHash: row.password_hash,
          role: row.role,
          scopes: JSON.parse(row.scopes),
          createdAt: row.created_at,
          lastLoginAt: row.last_login_at
        };
      }
      return null;
    }
    for (const [, user] of AUTH.users) {
      if (user.username === username) return user;
    }
    return null;
  },

  getUserByEmail(email) {
    if (db) {
      const stmt = db.prepare("SELECT * FROM users WHERE email = ? AND is_active = 1");
      const row = stmt.get(email);
      if (row) {
        return {
          id: row.id,
          username: row.username,
          email: row.email,
          passwordHash: row.password_hash,
          role: row.role,
          scopes: JSON.parse(row.scopes),
          createdAt: row.created_at,
          lastLoginAt: row.last_login_at
        };
      }
      return null;
    }
    for (const [, user] of AUTH.users) {
      if (user.email === email) return user;
    }
    return null;
  },

  updateUserLogin(userId) {
    const now = new Date().toISOString();
    if (db) {
      const stmt = db.prepare("UPDATE users SET last_login_at = ? WHERE id = ?");
      stmt.run(now, userId);
    }
    const user = AUTH.users.get(userId);
    if (user) {
      user.lastLoginAt = now;
      saveAuthData();
    }
  },

  getUserCount() {
    if (db) {
      const stmt = db.prepare("SELECT COUNT(*) as count FROM users WHERE is_active = 1");
      return stmt.get().count;
    }
    return AUTH.users.size;
  },

  // API Keys
  createApiKey(keyData) {
    if (db) {
      const stmt = db.prepare(`
        INSERT INTO api_keys (id, user_id, name, key_hash, key_prefix, scopes, created_at, last_used_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
      `);
      stmt.run(keyData.id, keyData.userId, keyData.name, keyData.keyHash, keyData.keyPrefix, JSON.stringify(keyData.scopes), keyData.createdAt, keyData.lastUsedAt);
    }
    AUTH.apiKeys.set(keyData.keyHash, keyData);
    saveAuthData();
  },

  getApiKeyByHash(keyHash) {
    if (db) {
      const stmt = db.prepare("SELECT * FROM api_keys WHERE key_hash = ? AND is_active = 1");
      const row = stmt.get(keyHash);
      if (row) {
        return {
          id: row.id,
          userId: row.user_id,
          name: row.name,
          keyHash: row.key_hash,
          keyPrefix: row.key_prefix,
          scopes: JSON.parse(row.scopes),
          createdAt: row.created_at,
          lastUsedAt: row.last_used_at
        };
      }
      return null;
    }
    return AUTH.apiKeys.get(keyHash) || null;
  },

  updateApiKeyUsage(keyHash) {
    const now = new Date().toISOString();
    if (db) {
      const stmt = db.prepare("UPDATE api_keys SET last_used_at = ? WHERE key_hash = ?");
      stmt.run(now, keyHash);
    }
    const key = AUTH.apiKeys.get(keyHash);
    if (key) {
      key.lastUsedAt = now;
    }
  },

  getApiKeysByUser(userId) {
    if (db) {
      const stmt = db.prepare("SELECT * FROM api_keys WHERE user_id = ? AND is_active = 1");
      return stmt.all(userId).map(row => ({
        id: row.id,
        userId: row.user_id,
        name: row.name,
        keyPrefix: row.key_prefix,
        scopes: JSON.parse(row.scopes),
        createdAt: row.created_at,
        lastUsedAt: row.last_used_at
      }));
    }
    const keys = [];
    for (const [, keyData] of AUTH.apiKeys) {
      if (keyData.userId === userId) {
        keys.push(keyData);
      }
    }
    return keys;
  },

  deleteApiKey(keyId, userId) {
    if (db) {
      const stmt = db.prepare("UPDATE api_keys SET is_active = 0 WHERE id = ? AND user_id = ?");
      return stmt.run(keyId, userId).changes > 0;
    }
    for (const [hash, keyData] of AUTH.apiKeys) {
      if (keyData.id === keyId && keyData.userId === userId) {
        AUTH.apiKeys.delete(hash);
        saveAuthData();
        return true;
      }
    }
    return false;
  },

  getAllApiKeys() {
    if (db) {
      const stmt = db.prepare("SELECT * FROM api_keys WHERE is_active = 1");
      return stmt.all().map(row => ({
        id: row.id,
        userId: row.user_id,
        name: row.name,
        keyHash: row.key_hash,
        keyPrefix: row.key_prefix,
        scopes: JSON.parse(row.scopes),
        createdAt: row.created_at,
        lastUsedAt: row.last_used_at
      }));
    }
    return Array.from(AUTH.apiKeys.values());
  }
};

// ---- Persistent Audit Logging ----
const AuditDB = {
  log(entry) {
    if (db) {
      try {
        const stmt = db.prepare(`
          INSERT INTO audit_log (id, timestamp, category, action, user_id, ip_address, user_agent, request_id, path, method, status_code, details)
          VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        `);
        stmt.run(
          entry.id,
          entry.timestamp,
          entry.category,
          entry.action,
          entry.userId,
          entry.ip,
          entry.userAgent,
          entry.requestId,
          entry.path,
          entry.method,
          entry.status,
          JSON.stringify(entry.details || {})
        );
      } catch (e) {
        console.error("[Audit] Failed to persist log:", e.message);
      }
    }
    return entry;
  },

  query({ limit = 100, offset = 0, category, action, userId, startDate, endDate } = {}) {
    if (db) {
      let sql = "SELECT * FROM audit_log WHERE 1=1";
      const params = [];

      if (category) {
        sql += " AND category = ?";
        params.push(category);
      }
      if (action) {
        sql += " AND action = ?";
        params.push(action);
      }
      if (userId) {
        sql += " AND user_id = ?";
        params.push(userId);
      }
      if (startDate) {
        sql += " AND timestamp >= ?";
        params.push(startDate);
      }
      if (endDate) {
        sql += " AND timestamp <= ?";
        params.push(endDate);
      }

      sql += " ORDER BY timestamp DESC LIMIT ? OFFSET ?";
      params.push(limit, offset);

      const stmt = db.prepare(sql);
      const rows = stmt.all(...params);

      return rows.map(row => ({
        id: row.id,
        timestamp: row.timestamp,
        category: row.category,
        action: row.action,
        userId: row.user_id,
        ip: row.ip_address,
        userAgent: row.user_agent,
        requestId: row.request_id,
        path: row.path,
        method: row.method,
        status: row.status_code,
        details: JSON.parse(row.details || "{}")
      }));
    }
    return AUDIT_LOG.slice(offset, offset + limit);
  },

  count(filters = {}) {
    if (db) {
      let sql = "SELECT COUNT(*) as count FROM audit_log WHERE 1=1";
      const params = [];

      if (filters.category) {
        sql += " AND category = ?";
        params.push(filters.category);
      }
      if (filters.userId) {
        sql += " AND user_id = ?";
        params.push(filters.userId);
      }

      const stmt = db.prepare(sql);
      return stmt.get(...params).count;
    }
    return AUDIT_LOG.length;
  }
};

// Load JSON fallback data
const AUTH_PATH = path.join(DATA_DIR, "auth.json");
function loadAuthData() {
  if (db) return; // Skip if using SQLite
  try {
    if (fs.existsSync(AUTH_PATH)) {
      const data = JSON.parse(fs.readFileSync(AUTH_PATH, "utf8"));
      if (data.users) AUTH.users = new Map(Object.entries(data.users));
      if (data.apiKeys) AUTH.apiKeys = new Map(Object.entries(data.apiKeys));
    }
  } catch (e) { console.error("[Auth] Failed to load:", e.message); }
}

function saveAuthData() {
  if (db) return; // Skip if using SQLite
  try {
    fs.mkdirSync(DATA_DIR, { recursive: true });
    const data = {
      users: Object.fromEntries(AUTH.users),
      apiKeys: Object.fromEntries(AUTH.apiKeys)
    };
    fs.writeFileSync(AUTH_PATH, JSON.stringify(data, null, 2));
  } catch (e) { console.error("[Auth] Failed to save:", e.message); }
}

// Migrate JSON data to SQLite if both exist
function migrateJsonToSqlite() {
  if (!db) return;

  const jsonPath = path.join(DATA_DIR, "auth.json");
  if (!fs.existsSync(jsonPath)) return;

  try {
    const data = JSON.parse(fs.readFileSync(jsonPath, "utf8"));
    let migrated = 0;

    // Migrate users
    if (data.users) {
      const insertUser = db.prepare(`
        INSERT OR IGNORE INTO users (id, username, email, password_hash, role, scopes, created_at, last_login_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
      `);

      for (const [userId, user] of Object.entries(data.users)) {
        insertUser.run(userId, user.username, user.email, user.passwordHash, user.role, JSON.stringify(user.scopes || ["read", "write"]), user.createdAt, user.lastLoginAt);
        migrated++;
      }
    }

    // Migrate API keys
    if (data.apiKeys) {
      const insertKey = db.prepare(`
        INSERT OR IGNORE INTO api_keys (id, user_id, name, key_hash, key_prefix, scopes, created_at, last_used_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
      `);

      for (const [keyHash, keyData] of Object.entries(data.apiKeys)) {
        insertKey.run(keyData.id || uid("key"), keyData.userId, keyData.name, keyHash, keyData.keyPrefix || keyHash.slice(0, 8), JSON.stringify(keyData.scopes || ["read"]), keyData.createdAt, keyData.lastUsedAt);
        migrated++;
      }
    }

    if (migrated > 0) {
      console.log(`[DB] Migrated ${migrated} records from JSON to SQLite`);
      // Rename old file as backup
      fs.renameSync(jsonPath, jsonPath + ".migrated");
    }
  } catch (e) {
    console.error("[DB] Migration failed:", e.message);
  }
}

loadAuthData();
migrateJsonToSqlite();

// Create default admin if no users exist (requires ADMIN_PASSWORD env var)
if (AuthDB.getUserCount() === 0 && bcrypt) {
  const adminPassword = process.env.ADMIN_PASSWORD;
  if (!adminPassword) {
    if (NODE_ENV === "production") {
      console.error("\n[FATAL] ADMIN_PASSWORD environment variable is required in production.");
      console.error("[FATAL] Set a strong password (minimum 12 characters) in your .env file.\n");
      process.exit(1);
    } else {
      console.warn("[Auth] WARNING: No ADMIN_PASSWORD set. Admin account not created.");
      console.warn("[Auth] Set ADMIN_PASSWORD in your .env file to enable authentication.");
    }
  } else if (adminPassword.length < 12) {
    if (NODE_ENV === "production") {
      console.error("\n[FATAL] ADMIN_PASSWORD must be at least 12 characters long.\n");
      process.exit(1);
    } else {
      console.error("[Auth] CRITICAL: ADMIN_PASSWORD must be at least 12 characters long.");
    }
  } else {
    const adminId = crypto.randomUUID();
    AuthDB.createUser({
      id: adminId,
      username: "admin",
      email: "admin@localhost",
      passwordHash: bcrypt.hashSync(adminPassword, BCRYPT_ROUNDS),
      role: "owner",
      scopes: ["*"],
      createdAt: new Date().toISOString(),
      lastLoginAt: null
    });
    console.log("[Auth] Created default admin user (username: admin)");
  }
}

// Auth helper functions [extracted to ./auth/tokens.js]
const REFRESH_TOKEN_COOKIE = "concord_refresh";


// CSRF middleware - validates token on state-changing requests
function csrfMiddleware(req, res, next) {
  // Skip CSRF for non-browser requests (API keys, no cookies)
  if (req.authMethod === "apiKey") return next();

  // Skip for safe methods
  const safeMethods = ["GET", "HEAD", "OPTIONS"];
  if (safeMethods.includes(req.method)) return next();

  // Skip for public endpoints and core API paths (chat, lens operations)
  const csrfExempt = ["/api/auth/login", "/api/auth/register", "/health", "/ready", "/api/chat", "/api/lens"];
  if (csrfExempt.some(p => req.path.startsWith(p))) return next();

  // In AUTH_MODE=public, skip CSRF — anonymous users have no session to protect
  if (AUTH_MODE === "public") return next();

  // In development, CSRF is optional
  if (NODE_ENV !== "production") return next();

  // Validate CSRF token
  const headerToken = req.headers["x-csrf-token"] || req.headers["x-xsrf-token"];
  const cookieToken = req.cookies?.csrf_token;

  if (!validateCsrfToken(headerToken, cookieToken)) {
    auditLog("security", "csrf_failed", { path: req.path, method: req.method, ip: req.ip });
    return res.status(403).json({ ok: false, error: "CSRF token invalid or missing", code: "CSRF_FAILED" });
  }

  return next();
}

// ============================================================================
// SECURITY: Audit Logging (uses SQLite when available)
// ============================================================================
const AUDIT_LOG = []; // In-memory fallback
const AUDIT_LOG_MAX = 10000;

function auditLog(category, action, details = {}) {
  const entry = {
    id: uid("audit"),
    timestamp: nowISO(),
    category,
    action,
    userId: details.userId || null,
    ip: details.ip || null,
    userAgent: details.userAgent || null,
    requestId: details.requestId || null,
    path: details.path || null,
    method: details.method || null,
    status: details.status || null,
    details: { ...details }
  };

  // Remove duplicated fields from details
  delete entry.details.userId;
  delete entry.details.ip;
  delete entry.details.userAgent;
  delete entry.details.requestId;
  delete entry.details.path;
  delete entry.details.method;
  delete entry.details.status;

  // Persist to SQLite if available
  AuditDB.log(entry);

  // Also keep in memory for quick access
  AUDIT_LOG.push(entry);
  if (AUDIT_LOG.length > AUDIT_LOG_MAX) {
    AUDIT_LOG.splice(0, AUDIT_LOG.length - AUDIT_LOG_MAX);
  }

  // Also log to console in development
  if (NODE_ENV !== "production") {
    console.log(`[Audit] ${category}.${action}`, JSON.stringify(entry.details).slice(0, 200));
  }

  return entry;
}

// Audit events for security-relevant actions
const _AUDIT_EVENTS = {
  AUTH_LOGIN_SUCCESS: "auth.login_success",
  AUTH_LOGIN_FAILED: "auth.login_failed",
  AUTH_LOGOUT: "auth.logout",
  AUTH_REGISTER: "auth.register",
  AUTH_TOKEN_REFRESH: "auth.token_refresh",
  API_KEY_CREATED: "api_key.created",
  API_KEY_DELETED: "api_key.deleted",
  API_KEY_USED: "api_key.used",
  ADMIN_ACTION: "admin.action",
  DATA_EXPORT: "data.export",
  DATA_DELETE: "data.delete",
  SETTINGS_CHANGED: "settings.changed",
  SECURITY_CSRF_FAILED: "security.csrf_failed",
  SECURITY_RATE_LIMITED: "security.rate_limited"
};

// Simple cookie parser (no external dependency needed)
function parseCookies(cookieHeader) {
  const cookies = {};
  if (!cookieHeader) return cookies;
  cookieHeader.split(";").forEach(cookie => {
    const [name, ...rest] = cookie.trim().split("=");
    if (name) cookies[name] = decodeURIComponent(rest.join("="));
  });
  return cookies;
}

// Cookie parsing middleware
function cookieParserMiddleware(req, res, next) {
  req.cookies = parseCookies(req.headers.cookie);
  next();
}

// Auth middleware
function authMiddleware(req, res, next) {
  if (AUTH_MODE === "public") return next();

  // Skip auth for public endpoints
  const publicPaths = ["/health", "/ready", "/metrics", "/api/auth/login", "/api/auth/register", "/api/auth/refresh", "/api/auth/csrf-token", "/api/docs", "/api/status"];
  if (publicPaths.some(p => req.path.startsWith(p))) return next();

  // Check Authorization header
  const authHeader = req.headers.authorization || "";
  const apiKey = req.headers["x-api-key"] || "";

  // 1. Try JWT/cookie auth if enabled by AUTH_MODE
  if (AUTH_USES_JWT) {
    const cookieToken = req.cookies?.concord_auth;
    if (cookieToken) {
      const decoded = verifyToken(cookieToken);
      if (decoded?.userId) {
        const user = AuthDB.getUser(decoded.userId);
        if (user) {
          req.user = user;
          req.authMethod = "cookie";
          return next();
        }
      }
    }

    if (authHeader.startsWith("Bearer ")) {
      const token = authHeader.slice(7);
      const decoded = verifyToken(token);
      if (decoded?.userId) {
        const user = AuthDB.getUser(decoded.userId);
        if (user) {
          req.user = user;
          req.authMethod = "jwt";
          return next();
        }
      }
    }
  }

  // 2. Try API key if enabled by AUTH_MODE (keys are stored hashed)
  if (AUTH_USES_APIKEY && apiKey) {
    let keyData = null;
    const allKeys = AuthDB.getAllApiKeys();
    for (const key of allKeys) {
      if (key.keyHash && verifyApiKey(apiKey, key.keyHash)) {
        keyData = key;
        AuthDB.updateApiKeyUsage(key.keyHash);
        break;
      }
    }

    if (keyData) {
      const user = AuthDB.getUser(keyData.userId);
      if (user) {
        keyData.lastUsedAt = new Date().toISOString();
        req.user = user;
        req.apiKeyData = keyData;
        req.authMethod = "apiKey";
        auditLog("auth", "api_key_used", { userId: user.id, keyName: keyData.name, ip: req.ip });
        return next();
      }
    }
  }

  return res.status(401).json({
    ok: false,
    error: "Unauthorized",
    code: "AUTH_REQUIRED",
    reason: AUTH_MODE === "apikey" ? "API key missing" : "Login required",
    authMode: AUTH_MODE
  });
}

// Require authentication helper (returns middleware)
function requireAuth() {
  return (req, res, next) => {
    if (AUTH_MODE === "public") return next();
    if (!req.user) return res.status(401).json({ ok: false, error: "Unauthorized" });
    return next();
  };
}

// Permission check helper
function requireRole(...roles) {
  return (req, res, next) => {
    if (AUTH_MODE === "public") return next();
    if (!req.user) return res.status(401).json({ ok: false, error: "Unauthorized" });
    if (roles.length === 0 || roles.includes(req.user.role) || req.user.scopes?.includes("*")) {
      return next();
    }
    return res.status(403).json({ ok: false, error: "Forbidden", requiredRoles: roles });
  };
}

// Production write-auth: enforce authentication on all mutating requests in production
// unless AUTH_MODE=public, where anonymous writes are intentionally allowed.
const WRITE_AUTH_PUBLIC_PATHS = ["/api/auth/login", "/api/auth/register", "/api/auth/csrf-token", "/health", "/ready", "/metrics", "/api/chat", "/api/lens"];
function productionWriteAuthMiddleware(req, res, next) {
  if (NODE_ENV !== "production") return next();
  // AUTH_MODE=public explicitly allows anonymous access — skip write-auth gate
  if (AUTH_MODE === "public") return next();
  const method = req.method.toUpperCase();
  if (method === "GET" || method === "HEAD" || method === "OPTIONS") return next();
  if (WRITE_AUTH_PUBLIC_PATHS.some(p => req.path.startsWith(p))) return next();
  // In production, require at least an API key or authenticated session for writes
  if (!req.user && !req.headers["x-api-key"] && !req.cookies?.concord_auth && !req.headers.authorization) {
    return res.status(401).json({ ok: false, error: "Authentication required for write operations in production", code: "PROD_WRITE_AUTH" });
  }
  return next();
}

// ---- Validation Schemas (Zod) ---- [extracted to ./validation/schemas.js]

// ---- Metrics (Prometheus) ----
const METRICS = {
  enabled: false,
  registry: null,
  counters: {},
  histograms: {},
  gauges: {}
};

async function initMetrics() {
  try {
    const prom = await import("prom-client").catch(() => null);
    if (!prom) return;

    METRICS.enabled = true;
    METRICS.registry = new prom.Registry();
    prom.collectDefaultMetrics({ register: METRICS.registry });

    // Custom counters
    METRICS.counters.httpRequests = new prom.Counter({
      name: "concord_http_requests_total",
      help: "Total HTTP requests",
      labelNames: ["method", "path", "status"],
      registers: [METRICS.registry]
    });

    METRICS.counters.dtuOperations = new prom.Counter({
      name: "concord_dtu_operations_total",
      help: "Total DTU operations",
      labelNames: ["operation"],
      registers: [METRICS.registry]
    });

    METRICS.counters.macroExecutions = new prom.Counter({
      name: "concord_macro_executions_total",
      help: "Total macro executions",
      labelNames: ["domain", "name", "success"],
      registers: [METRICS.registry]
    });

    // Histograms
    METRICS.histograms.requestDuration = new prom.Histogram({
      name: "concord_request_duration_seconds",
      help: "Request duration in seconds",
      labelNames: ["method", "path"],
      buckets: [0.01, 0.05, 0.1, 0.5, 1, 2, 5],
      registers: [METRICS.registry]
    });

    // Gauges
    METRICS.gauges.dtuCount = new prom.Gauge({
      name: "concord_dtus_total",
      help: "Total number of DTUs",
      registers: [METRICS.registry]
    });

    METRICS.gauges.activeConnections = new prom.Gauge({
      name: "concord_ws_connections",
      help: "Active WebSocket connections",
      registers: [METRICS.registry]
    });

    console.log("[Metrics] Prometheus metrics initialized");
  } catch (e) {
    console.error("[Metrics] Failed to initialize:", e.message);
  }
}
initMetrics();

// Metrics middleware
function metricsMiddleware(req, res, next) {
  if (!METRICS.enabled) return next();
  const start = Date.now();
  res.on("finish", () => {
    const duration = (Date.now() - start) / 1000;
    const path = req.route?.path || req.path.split("/").slice(0, 3).join("/");
    METRICS.counters.httpRequests?.inc({ method: req.method, path, status: res.statusCode });
    METRICS.histograms.requestDuration?.observe({ method: req.method, path }, duration);
  });
  next();
}

// Update gauges periodically
setInterval(() => {
  if (METRICS.gauges.dtuCount) METRICS.gauges.dtuCount.set(STATE.dtus.size);
  if (METRICS.gauges.activeConnections) METRICS.gauges.activeConnections.set(REALTIME.clients?.size || 0);
}, 5000);

// ---- Backup & Restore ----
const BACKUP_DIR = process.env.BACKUP_DIR || path.join(DATA_DIR, "backups");

function createBackup(name = null) {
  try {
    fs.mkdirSync(BACKUP_DIR, { recursive: true });
    const timestamp = new Date().toISOString().replace(/[:.]/g, "-");
    const backupName = name || `backup-${timestamp}`;
    const backupPath = path.join(BACKUP_DIR, `${backupName}.json`);

    const backup = {
      version: VERSION,
      createdAt: new Date().toISOString(),
      data: {
        dtus: Object.fromEntries(STATE.dtus),
        shadowDtus: Object.fromEntries(STATE.shadowDtus),
        sessions: Object.fromEntries(STATE.sessions),
        queues: STATE.queues,
        config: STATE.config,
        __chicken2: STATE.__chicken2,
        __chicken3: STATE.__chicken3
      },
      auth: {
        users: Object.fromEntries(AUTH.users),
        apiKeys: Object.fromEntries(AUTH.apiKeys)
      }
    };

    fs.writeFileSync(backupPath, JSON.stringify(backup, null, 2));
    console.log(`[Backup] Created: ${backupPath}`);
    return { ok: true, path: backupPath, name: backupName, size: fs.statSync(backupPath).size };
  } catch (e) {
    console.error("[Backup] Failed:", e);
    return { ok: false, error: String(e.message || e) };
  }
}

function restoreBackup(backupPath) {
  try {
    // Path traversal protection - only allow files within BACKUP_DIR
    const sanitizedName = path.basename(String(backupPath || ""));
    if (!sanitizedName || sanitizedName.includes("..")) {
      return { ok: false, error: "Invalid backup path" };
    }

    // Only look in BACKUP_DIR - never allow absolute paths
    const safePath = path.join(BACKUP_DIR, sanitizedName.endsWith(".json") ? sanitizedName : `${sanitizedName}.json`);
    const resolvedPath = path.resolve(safePath);

    // Verify the resolved path is still within BACKUP_DIR
    const backupDirResolved = path.resolve(BACKUP_DIR);
    if (!resolvedPath.startsWith(backupDirResolved + path.sep) && resolvedPath !== backupDirResolved) {
      return { ok: false, error: "Invalid backup path - access denied" };
    }

    if (!fs.existsSync(resolvedPath)) {
      return { ok: false, error: "Backup file not found" };
    }

    const backup = JSON.parse(fs.readFileSync(resolvedPath, "utf8"));

    // Restore state
    if (backup.data?.dtus) STATE.dtus = new Map(Object.entries(backup.data.dtus));
    if (backup.data?.shadowDtus) STATE.shadowDtus = new Map(Object.entries(backup.data.shadowDtus));
    if (backup.data?.sessions) STATE.sessions = new Map(Object.entries(backup.data.sessions));
    if (backup.data?.queues) STATE.queues = backup.data.queues;
    if (backup.data?.config) STATE.config = backup.data.config;
    if (backup.data?.__chicken2) STATE.__chicken2 = backup.data.__chicken2;
    if (backup.data?.__chicken3) STATE.__chicken3 = backup.data.__chicken3;

    // Restore auth
    if (backup.auth?.users) AUTH.users = new Map(Object.entries(backup.auth.users));
    if (backup.auth?.apiKeys) AUTH.apiKeys = new Map(Object.entries(backup.auth.apiKeys));

    saveStateDebounced();
    saveAuthData();

    console.log(`[Backup] Restored from: ${backupPath}`);
    return { ok: true, version: backup.version, createdAt: backup.createdAt };
  } catch (e) {
    console.error("[Backup] Restore failed:", e);
    return { ok: false, error: String(e.message || e) };
  }
}

function listBackups() {
  try {
    if (!fs.existsSync(BACKUP_DIR)) return { ok: true, backups: [] };
    const files = fs.readdirSync(BACKUP_DIR).filter(f => f.endsWith(".json"));
    const backups = files.map(f => {
      const fpath = path.join(BACKUP_DIR, f);
      const stat = fs.statSync(fpath);
      return { name: f.replace(".json", ""), path: fpath, size: stat.size, createdAt: stat.mtime.toISOString() };
    }).sort((a, b) => b.createdAt.localeCompare(a.createdAt));
    return { ok: true, backups };
  } catch (e) {
    return { ok: false, error: String(e.message || e) };
  }
}

// Auto-backup scheduler
let _autoBackupTimer = null;
function startAutoBackup(intervalHours = 24) {
  if (_autoBackupTimer) clearInterval(_autoBackupTimer);
  const ms = intervalHours * 60 * 60 * 1000;
  _autoBackupTimer = setInterval(() => createBackup(`auto-${Date.now()}`), ms);
  console.log(`[Backup] Auto-backup enabled (every ${intervalHours}h)`);
}
if (String(process.env.AUTO_BACKUP || "true").toLowerCase() === "true") {
  startAutoBackup(Number(process.env.BACKUP_INTERVAL_HOURS || 24));
}

// Export for CLI
export { createBackup, restoreBackup, listBackups };

// ---- Rate Limiting ----
let rateLimiter = null;
let authRateLimiter = null;
if (rateLimit) {
  rateLimiter = rateLimit({
    windowMs: RATE_LIMIT_WINDOW_MS,
    max: RATE_LIMIT_MAX,
    message: { ok: false, error: "Too many requests", retryAfter: Math.ceil(RATE_LIMIT_WINDOW_MS / 1000) },
    standardHeaders: true,
    legacyHeaders: false,
    keyGenerator: (req) => req.user?.id || req.ip
  });
  // Stricter rate limiting for auth endpoints (5 attempts per 15 minutes)
  authRateLimiter = rateLimit({
    windowMs: 15 * 60 * 1000, // 15 minutes
    max: 5, // 5 attempts
    message: { ok: false, error: "Too many authentication attempts. Please try again later.", retryAfter: 900 },
    standardHeaders: true,
    legacyHeaders: false,
    // ---- Compound Rate Key (Tier 2: Rate Limit Hardening) ----
    // Keys on IP + username/email to prevent distributed attacks on a single account
    keyGenerator: (req) => {
      const identity = req.body?.username || req.body?.email || "";
      return `${req.ip}:${identity}`;
    },
    skipSuccessfulRequests: true // Don't count successful logins
  });
}

// ---- Global Concurrency Limiter for Expensive Operations (Tier 2: Rate Limit Hardening) ----
const _CONCURRENCY = {
  active: new Map(), // operationType -> count
  limits: {
    llm_call: Number(process.env.LLM_CONCURRENCY_LIMIT || 5),
    bulk_import: 2,
    simulation: 3,
    ml_infer: 3,
  },

  acquire(opType) {
    const current = this.active.get(opType) || 0;
    const limit = this.limits[opType] || 10;
    if (current >= limit) return false;
    this.active.set(opType, current + 1);
    return true;
  },

  release(opType) {
    const current = this.active.get(opType) || 0;
    this.active.set(opType, Math.max(0, current - 1));
  },

  stats() {
    const result = {};
    for (const [opType, count] of this.active) {
      result[opType] = { active: count, limit: this.limits[opType] || 10 };
    }
    return result;
  }
};

// ---- Sliding Window Rate Limiter (Tier 2: Rate Limit Hardening) ----
// Supplements express-rate-limit with per-user sliding window for API-heavy endpoints
const _SLIDING_WINDOW = {
  windows: new Map(), // key -> { timestamps: number[] }
  MAX_REQUESTS_PER_MINUTE: Number(process.env.SLIDING_WINDOW_RPM || 120),

  check(key) {
    const now = Date.now();
    const WINDOW_MS = 60000;
    let entry = this.windows.get(key);
    if (!entry) { entry = { timestamps: [] }; this.windows.set(key, entry); }

    // Remove timestamps older than window
    entry.timestamps = entry.timestamps.filter(t => now - t < WINDOW_MS);

    if (entry.timestamps.length >= this.MAX_REQUESTS_PER_MINUTE) {
      return { allowed: false, remaining: 0, resetMs: WINDOW_MS - (now - entry.timestamps[0]) };
    }

    entry.timestamps.push(now);
    return { allowed: true, remaining: this.MAX_REQUESTS_PER_MINUTE - entry.timestamps.length };
  },

  // Cleanup stale entries every 5 minutes
  cleanup() {
    const now = Date.now();
    for (const [key, entry] of this.windows) {
      entry.timestamps = entry.timestamps.filter(t => now - t < 60000);
      if (entry.timestamps.length === 0) this.windows.delete(key);
    }
  }
};
setInterval(() => _SLIDING_WINDOW.cleanup(), 300000);

// ============================================================================
// END WAVE 1: PRODUCTION READINESS
// ============================================================================

// ============================================================================
// FAILURE MODE DEFENSES (Categories 2-6)
// ============================================================================

// ---- HTTP Idempotency Middleware (Category 2: Concurrency) ----
// Prevents double-submit via Idempotency-Key header
const _IDEMPOTENCY = {
  store: new Map(), // key -> { response, status, createdAt }
  TTL_MS: 24 * 60 * 60 * 1000, // 24 hours
  MAX_ENTRIES: 10000,

  cleanup() {
    const now = Date.now();
    for (const [key, entry] of this.store) {
      if (now - entry.createdAt > this.TTL_MS) this.store.delete(key);
    }
    if (this.store.size > this.MAX_ENTRIES) {
      const sorted = [...this.store.entries()].sort((a, b) => a[1].createdAt - b[1].createdAt);
      const toRemove = sorted.slice(0, this.store.size - this.MAX_ENTRIES);
      for (const [key] of toRemove) this.store.delete(key);
    }
  }
};

setInterval(() => _IDEMPOTENCY.cleanup(), 3600000);

function idempotencyMiddleware(req, res, next) {
  const key = req.headers["idempotency-key"];
  if (!key || req.method === "GET") return next();

  const existing = _IDEMPOTENCY.store.get(key);
  if (existing) {
    // Return cached response for duplicate request
    res.setHeader("X-Idempotent-Replayed", "true");
    return res.status(existing.status).json(existing.response);
  }

  // Intercept response to cache it
  const originalJson = res.json.bind(res);
  res.json = function(body) {
    _IDEMPOTENCY.store.set(key, {
      response: body,
      status: res.statusCode,
      createdAt: Date.now(),
    });
    return originalJson(body);
  };
  next();
}

// ---- P95 Latency Tracking (Category 5: Observability) ----
const _LATENCY = {
  // Sliding window of recent request durations (last 1000 requests)
  window: [],
  MAX_WINDOW: 1000,
  slowThresholdMs: Number(process.env.SLOW_REQUEST_MS || 2000),

  record(durationMs, path, method) {
    this.window.push({ durationMs, path, method, ts: Date.now() });
    if (this.window.length > this.MAX_WINDOW) this.window.shift();

    // Alert on slow requests
    if (durationMs > this.slowThresholdMs) {
      structuredLog("warn", "slow_request", { durationMs, path, method, threshold: this.slowThresholdMs });
    }
  },

  percentile(p) {
    if (this.window.length === 0) return 0;
    const sorted = this.window.map(w => w.durationMs).sort((a, b) => a - b);
    const idx = Math.ceil((p / 100) * sorted.length) - 1;
    return sorted[Math.max(0, idx)];
  },

  stats() {
    return {
      count: this.window.length,
      p50: this.percentile(50),
      p95: this.percentile(95),
      p99: this.percentile(99),
      slowCount: this.window.filter(w => w.durationMs > this.slowThresholdMs).length,
    };
  }
};

// ---- LLM Cost & Budget Tracking (Category 6: Cost Controls) ----
const _LLM_BUDGET = {
  // Token usage tracking
  totalTokensUsed: 0,
  totalRequestCount: 0,
  windowStart: Date.now(),
  perUser: new Map(), // userId -> { tokens, requests, windowStart }

  // Budget limits (configurable via env)
  globalBudgetTokens: Number(process.env.LLM_BUDGET_TOKENS || 1000000),   // 1M tokens/day
  perUserBudgetTokens: Number(process.env.LLM_USER_BUDGET_TOKENS || 50000), // 50K tokens/user/day
  maxRetries: Number(process.env.LLM_MAX_RETRIES || 3),

  // Circuit breaker
  consecutiveFailures: 0,
  circuitOpen: false,
  circuitOpenedAt: 0,
  CIRCUIT_THRESHOLD: 5,    // failures before opening
  CIRCUIT_RESET_MS: 60000, // 1 min cooldown

  recordUsage(userId, tokensIn, tokensOut) {
    const tokens = (tokensIn || 0) + (tokensOut || 0);
    this.totalTokensUsed += tokens;
    this.totalRequestCount++;

    if (userId) {
      const entry = this.perUser.get(userId) || { tokens: 0, requests: 0, windowStart: Date.now() };
      // Reset window if over 24h
      if (Date.now() - entry.windowStart > 86400000) {
        entry.tokens = 0;
        entry.requests = 0;
        entry.windowStart = Date.now();
      }
      entry.tokens += tokens;
      entry.requests++;
      this.perUser.set(userId, entry);
    }
  },

  checkBudget(userId) {
    // Reset global window if over 24h
    if (Date.now() - this.windowStart > 86400000) {
      this.totalTokensUsed = 0;
      this.totalRequestCount = 0;
      this.windowStart = Date.now();
    }

    // Check circuit breaker
    if (this.circuitOpen) {
      if (Date.now() - this.circuitOpenedAt > this.CIRCUIT_RESET_MS) {
        this.circuitOpen = false;
        this.consecutiveFailures = 0;
      } else {
        return { allowed: false, reason: "circuit_open", resetIn: this.CIRCUIT_RESET_MS - (Date.now() - this.circuitOpenedAt) };
      }
    }

    // Check global budget
    if (this.totalTokensUsed >= this.globalBudgetTokens) {
      return { allowed: false, reason: "global_budget_exceeded", used: this.totalTokensUsed, limit: this.globalBudgetTokens };
    }

    // Check per-user budget
    if (userId) {
      const entry = this.perUser.get(userId);
      if (entry && entry.tokens >= this.perUserBudgetTokens) {
        return { allowed: false, reason: "user_budget_exceeded", used: entry.tokens, limit: this.perUserBudgetTokens };
      }
    }

    return { allowed: true };
  },

  recordFailure() {
    this.consecutiveFailures++;
    if (this.consecutiveFailures >= this.CIRCUIT_THRESHOLD) {
      this.circuitOpen = true;
      this.circuitOpenedAt = Date.now();
      structuredLog("error", "llm_circuit_open", {
        failures: this.consecutiveFailures,
        resetMs: this.CIRCUIT_RESET_MS,
      });
    }
  },

  recordSuccess() {
    this.consecutiveFailures = 0;
  },

  stats() {
    return {
      totalTokensUsed: this.totalTokensUsed,
      totalRequests: this.totalRequestCount,
      globalBudget: this.globalBudgetTokens,
      globalUtilization: (this.totalTokensUsed / this.globalBudgetTokens * 100).toFixed(1) + "%",
      circuitOpen: this.circuitOpen,
      consecutiveFailures: this.consecutiveFailures,
      activeUsers: this.perUser.size,
    };
  }
};

// ---- Correlation ID Propagation (Category 5: Observability) ----
let _eventSeqCounter = 0;

// ---- realtime (Socket.IO for frontend compatibility) ----
// Thin transport only: mirrors state changes (no new logic).
const REALTIME = {
  ready: false,
  io: null,
  clients: new Map(), // socketId -> { socket, sessionId, orgId, userId, createdAt }
};

function realtimeEmit(event, payload, { sessionId = "", orgId = "", requestId = "" } = {}) {
  if (!REALTIME.ready || !REALTIME.io) return { ok: false, reason: "socket_not_ready" };

  // ---- Event Ordering & Correlation (Category 2+5: Concurrency + Observability) ----
  const enrichedPayload = {
    ...payload,
    ts: nowISO(),
    _seq: ++_eventSeqCounter,           // Monotonic sequence number for ordering
    _rid: requestId || undefined,        // Correlation ID from originating HTTP request
    _evt: event,                         // Event name for client-side reordering
  };

  // Emit to specific rooms or broadcast
  if (sessionId) {
    REALTIME.io.to(`session:${sessionId}`).emit(event, enrichedPayload);
  } else if (orgId) {
    REALTIME.io.to(`org:${orgId}`).emit(event, enrichedPayload);
  } else {
    REALTIME.io.emit(event, enrichedPayload);
  }
  return { ok: true, seq: enrichedPayload._seq };
}

function enqueueNotification(item, { sessionId = "", orgId = "" } = {}) {
  ensureQueues();
  STATE.queues.notifications.push(item);
  // Push realtime mirror (best-effort)
  try { realtimeEmit("queue:notifications:new", item, { sessionId, orgId }); } catch {}
  return item;
}

async function tryInitWebSockets(server) {
  // Socket.IO: only enabled if socket.io dependency exists AND CONCORD_WS_ENABLED != "false"
  if (String(process.env.CONCORD_WS_ENABLED || "").toLowerCase() === "false") return { ok: false, reason: "disabled" };
  if (!server) return { ok: false, reason: "no_server" };

  let Server = null;
  try {
    const mod = await import("socket.io");
    Server = mod?.Server || mod?.default?.Server || mod?.default;
  } catch {
    // Fallback to ws if socket.io not available
    console.warn("[Realtime] socket.io not installed, trying native ws...");
    return tryInitNativeWebSockets(server);
  }
  if (!Server) return { ok: false, reason: "socketio_import_failed" };

  const io = new Server(server, {
    cors: {
      origin: NODE_ENV === "production"
        ? (process.env.ALLOWED_ORIGINS ? process.env.ALLOWED_ORIGINS.split(",").map(o => o.trim()) : [])
        : ["http://localhost:3000", "http://127.0.0.1:3000"],
      methods: ["GET", "POST"],
      credentials: true
    },
    transports: ["websocket", "polling"],
    pingTimeout: 60000,
    pingInterval: 25000
  });

  REALTIME.io = io;
  REALTIME.ready = true;

  // SECURITY: Socket.IO authentication middleware
  io.use((socket, next) => {
    // Parse cookies from handshake
    const cookies = parseCookies(socket.handshake.headers?.cookie || "");
    const cookieToken = cookies.concord_auth;

    const _token = cookieToken || socket.handshake.auth?.token || socket.handshake.headers?.authorization?.replace("Bearer ", "");
    const apiKey = socket.handshake.auth?.apiKey || socket.handshake.headers?.["x-api-key"];

    // In development, allow unauthenticated connections
    if (NODE_ENV !== "production") {
      socket.data.userId = null;
      socket.data.authenticated = false;
      return next();
    }

    // 1. Try httpOnly cookie token first (most secure for browsers)
    if (cookieToken) {
      const decoded = verifyToken(cookieToken);
      if (decoded?.userId) {
        const user = AuthDB.getUser(decoded.userId);
        if (user) {
          socket.data.userId = user.id;
          socket.data.username = user.username;
          socket.data.authenticated = true;
          socket.data.authMethod = "cookie";
          return next();
        }
      }
    }

    // 2. Try Bearer token (for API clients)
    const bearerToken = socket.handshake.auth?.token || socket.handshake.headers?.authorization?.replace("Bearer ", "");
    if (bearerToken) {
      const decoded = verifyToken(bearerToken);
      if (decoded?.userId) {
        const user = AuthDB.getUser(decoded.userId);
        if (user) {
          socket.data.userId = user.id;
          socket.data.username = user.username;
          socket.data.authenticated = true;
          socket.data.authMethod = "bearer";
          return next();
        }
      }
    }

    // 3. Try API key
    if (apiKey) {
      const allKeys = AuthDB.getAllApiKeys();
      for (const keyData of allKeys) {
        if (keyData.keyHash && verifyApiKey(apiKey, keyData.keyHash)) {
          const user = AuthDB.getUser(keyData.userId);
          if (user) {
            socket.data.userId = user.id;
            socket.data.username = user.username;
            socket.data.authenticated = true;
            socket.data.authMethod = "apiKey";
            return next();
          }
        }
      }
    }

    // In production, reject unauthenticated connections
    return next(new Error("Authentication required"));
  });

  io.on("connection", (socket) => {
    const clientId = socket.id;
    REALTIME.clients.set(clientId, {
      socket,
      sessionId: "",
      orgId: "",
      userId: socket.data.userId,
      createdAt: nowISO()
    });

    // Send hello
    socket.emit("hello", { clientId, version: VERSION, ts: nowISO(), authenticated: socket.data.authenticated });

    // Room management
    socket.on("room:join", ({ room }) => {
      if (room) {
        // Authorization check: require authenticated user (in production)
        if (!socket.data.userId && !socket.data.authenticated) {
          console.warn('[ws] Unauthorized room join attempt:', { userId: socket.data.userId, room });
          socket.emit('error', { code: 'UNAUTHORIZED', message: 'Not authorized to join this room' });
          return;
        }

        // For session-scoped rooms, verify the session exists and user has access
        const sessionMatch = room.match(/^session:(.+)$/);
        if (sessionMatch) {
          const sessionId = sessionMatch[1];
          if (!STATE.sessions.has(sessionId)) {
            console.warn('[ws] Unauthorized room join attempt:', { userId: socket.data.userId, room });
            socket.emit('error', { code: 'UNAUTHORIZED', message: 'Not authorized to join this room' });
            return;
          }
        }

        socket.join(room);
        socket.emit("room:joined", { room, ts: nowISO() });
      }
    });

    socket.on("room:leave", ({ room }) => {
      if (room) {
        socket.leave(room);
        socket.emit("room:left", { room, ts: nowISO() });
      }
    });

    // Subscribe to session/org updates
    socket.on("subscribe", ({ sessionId, orgId }) => {
      const c = REALTIME.clients.get(clientId);
      if (!c) return;

      // Authorization check: require authenticated user (in production)
      if (!socket.data.userId && !socket.data.authenticated) {
        console.warn('[ws] Unauthorized subscribe attempt:', { userId: socket.data.userId, sessionId, orgId });
        socket.emit('error', { code: 'UNAUTHORIZED', message: 'Not authorized to subscribe' });
        return;
      }

      if (sessionId && STATE.sessions.has(sessionId)) {
        c.sessionId = sessionId;
        socket.join(`session:${sessionId}`);
      }
      if (orgId) {
        c.orgId = orgId;
        socket.join(`org:${orgId}`);
      }
      socket.emit("subscribed", { sessionId: c.sessionId, orgId: c.orgId, ts: nowISO() });
    });

    // Ping/pong for keepalive
    socket.on("ping", () => {
      socket.emit("pong", { ts: nowISO() });
    });

    socket.on("disconnect", () => {
      REALTIME.clients.delete(clientId);
    });

    socket.on("error", () => {
      REALTIME.clients.delete(clientId);
    });
  });

  console.log(`[Realtime] Socket.IO enabled on port ${PORT}`);
  return { ok: true };
}

// Fallback to native WebSockets if Socket.IO not available
async function tryInitNativeWebSockets(server) {
  let WebSocketServer = null;
  try {
    const mod = await import("ws");
    WebSocketServer = mod?.WebSocketServer || mod?.default?.WebSocketServer || null;
  } catch (e) {
    return { ok: false, reason: "ws_not_installed", error: String(e?.message || e) };
  }
  if (!WebSocketServer) return { ok: false, reason: "ws_import_failed" };

  const wss = new WebSocketServer({ server, path: "/ws" });
  // Store reference for compatibility
  REALTIME.wss = wss;
  REALTIME.ready = true;

  // Override emit for native WS
  const _originalEmit = realtimeEmit;
  globalThis.realtimeEmitNative = (event, payload, opts = {}) => {
    if (!REALTIME.ready || !wss) return { ok: false, reason: "ws_not_ready" };
    const msg = JSON.stringify({ type: String(event || "event"), payload, ts: nowISO() });
    for (const [_cid, c] of REALTIME.clients.entries()) {
      try {
        if (c?.ws?.readyState !== 1) continue;
        if (opts.sessionId && c.sessionId && c.sessionId !== opts.sessionId) continue;
        if (opts.orgId && c.orgId && c.orgId !== opts.orgId) continue;
        c.ws.send(msg);
      } catch {}
    }
    return { ok: true };
  };

  wss.on("connection", (ws, _req) => {
    const clientId = uid("ws");
    REALTIME.clients.set(clientId, { ws, sessionId: "", orgId: "", createdAt: nowISO() });

    try { ws.send(JSON.stringify({ type: "hello", clientId, version: VERSION, ts: nowISO() })); } catch {}

    ws.on("message", (buf) => {
      try {
        const raw = Buffer.isBuffer(buf) ? buf.toString("utf8") : String(buf);
        const msg = JSON.parse(raw || "{}");
        const c = REALTIME.clients.get(clientId);
        if (!c) return;

        if (msg?.type === "subscribe") {
          const sid = String(msg?.sessionId || "");
          const oid = String(msg?.orgId || "");
          if (sid && STATE.sessions.has(sid)) c.sessionId = sid;
          if (oid) c.orgId = oid;
          try { ws.send(JSON.stringify({ type: "subscribed", sessionId: c.sessionId, orgId: c.orgId, ts: nowISO() })); } catch {}
          return;
        }

        if (msg?.type === "ping") {
          try { ws.send(JSON.stringify({ type: "pong", ts: nowISO() })); } catch {}
          
        }
      } catch {}
    });

    ws.on("close", () => { try { REALTIME.clients.delete(clientId); } catch {} });
    ws.on("error", () => { try { REALTIME.clients.delete(clientId); } catch {} });
  });

  console.log(`[Realtime] Native WebSockets enabled at ws://localhost:${PORT}/ws`);
  return { ok: true };
}
// ---- end realtime ----


// ---- persistence ----
// Production: SQLite (if available). Dev fallback: JSON file.
// This prevents "DTUs disappeared" when server restarts or hot-reloads.
const STATE_PATH = process.env.STATE_PATH || path.join(DATA_DIR, "concord_state.json");
const IS_PRODUCTION = (process.env.NODE_ENV || "").toLowerCase() === "production";
const USE_SQLITE_STATE = db && (IS_PRODUCTION || process.env.STATE_BACKEND === "sqlite");
let _saveTimer = null;

// Create state table in SQLite if available
if (USE_SQLITE_STATE) {
  try {
    db.exec(`
      CREATE TABLE IF NOT EXISTS state_snapshots (
        id INTEGER PRIMARY KEY CHECK (id = 1),
        data TEXT NOT NULL,
        version TEXT,
        saved_at TEXT NOT NULL
      );
    `);
    console.log("[Persistence] SQLite state backend enabled (production mode)");
  } catch (e) {
    console.error("[Persistence] Failed to create state table:", e.message);
  }
}

function _serializeState() {
  const toArr = (m) => Array.from(m.values());
  return {
    version: VERSION,
    savedAt: nowISO(),
    dtus: toArr(STATE.dtus),
    shadowDtus: toArr(STATE.shadowDtus),
    wrappers: toArr(STATE.wrappers),
    layers: toArr(STATE.layers),
    personas: toArr(STATE.personas),
    sessions: Array.from(STATE.sessions.entries()).map(([sessionId, v]) => ({ sessionId, createdAt: v.createdAt, messages: (v.messages||[]).slice(-200) })),
    styleVectors: Array.from(STATE.styleVectors.entries()),
    organs: toArr(STATE.organs),
    growth: STATE.growth,
    abstraction: STATE.abstraction,
    settings: STATE.settings,
    logs: STATE.logs.slice(-1000),
    crawlQueue: STATE.crawlQueue,
    queues: STATE.queues,
    users: Array.from(STATE.users.values()),
    orgs: Array.from(STATE.orgs.values()),
    apiKeys: Array.from(STATE.apiKeys.values()),
    jobs: Array.from(STATE.jobs.values()),
    sources: Array.from(STATE.sources.values()),
    globalIndex: { byHash: Array.from(STATE.globalIndex.byHash.entries()), byId: Array.from(STATE.globalIndex.byId.entries()) },
    listings: Array.from(STATE.listings.values()),
    entitlements: Array.from(STATE.entitlements.values()),
    transactions: Array.from(STATE.transactions.values()),
    papers: Array.from(STATE.papers.values()),
    lensArtifacts: Array.from(STATE.lensArtifacts.values()),
    _scopeSeparation: STATE._scopeSeparation || null,
    _autogenPipeline: STATE._autogenPipeline || null,
  };
}

function _hydrateState(obj) {
  if (!obj || typeof obj !== "object") return;
  const put = (map, arr) => {
    map.clear();
    if (Array.isArray(arr)) for (const x of arr) if (x && x.id) map.set(x.id, x);
  };
  put(STATE.dtus, obj.dtus);
  put(STATE.shadowDtus, obj.shadowDtus);
  // migration: DTUs created before tiers existed default to regular
  // migration: DTUs created before scope separation default to global (seed/canonical data)
  for (const d of STATE.dtus.values()) {
    if (!d.tier) d.tier = "regular";
    if (!d.createdAt) d.createdAt = nowISO();
    if (!d.scope) d.scope = (d.source === "user" || d.source === "chat") ? "local" : "global";
  }
  put(STATE.wrappers, obj.wrappers);
  put(STATE.layers, obj.layers);
  put(STATE.personas, obj.personas);

  // Sessions (session memory persistence)
  STATE.sessions.clear();
  if (Array.isArray(obj.sessions)) {
    for (const s of obj.sessions) {
      if (!s || !s.sessionId) continue;
      const sid = String(s.sessionId);
      const messages = Array.isArray(s.messages) ? s.messages.slice(-200) : [];
      STATE.sessions.set(sid, { createdAt: s.createdAt || nowISO(), messages });
    }
  }

  // Style vectors (session-adaptive)
  STATE.styleVectors.clear();
  if (Array.isArray(obj.styleVectors)) {
    for (const [sid, vec] of obj.styleVectors) {
      if (!sid) continue;
      if (vec && typeof vec === 'object') STATE.styleVectors.set(String(sid), vec);
    }
  }

  // Organs + Growth OS
  STATE.organs.clear();
  if (Array.isArray(obj.organs)) {
    for (const o of obj.organs) {
      if (o && o.organId) STATE.organs.set(o.organId, o);
    }
  }
  if (obj.growth && typeof obj.growth === "object") STATE.growth = obj.growth;

  // Abstraction Governor state
  if (obj.abstraction && typeof obj.abstraction === "object") {
    STATE.abstraction = { ...STATE.abstraction, ...obj.abstraction };
    if (!STATE.abstraction.ledger || typeof STATE.abstraction.ledger !== 'object') {
      STATE.abstraction.ledger = { added: 0, collapsed: 0 };
    }
    if (!STATE.abstraction.metrics || typeof STATE.abstraction.metrics !== 'object') {
      STATE.abstraction.metrics = { ecc: 0, rd: 0, ir: 0, etua: 1, load: 0, margin: 1 };
    }
    if (!Array.isArray(STATE.abstraction.history)) STATE.abstraction.history = [];
  }


  if (obj.settings && typeof obj.settings === "object") STATE.settings = { ...STATE.settings, ...obj.settings };
  if (Array.isArray(obj.logs)) STATE.logs = obj.logs.slice(-1000);
  if (Array.isArray(obj.crawlQueue)) STATE.crawlQueue = obj.crawlQueue;
  if (obj.queues && typeof obj.queues === "object") {
    STATE.queues = { ...STATE.queues, ...obj.queues };
    // ensure arrays
    for (const k of Object.keys(STATE.queues)) {
      if (!Array.isArray(STATE.queues[k])) STATE.queues[k] = [];
    }
  }

  // v3: users/orgs/auth
  STATE.users.clear();
  if (Array.isArray(obj.users)) for (const u of obj.users) if (u && u.id) STATE.users.set(u.id, u);

  STATE.orgs.clear();
  if (Array.isArray(obj.orgs)) for (const o of obj.orgs) if (o && o.id) STATE.orgs.set(o.id, o);

  STATE.apiKeys.clear();
  if (Array.isArray(obj.apiKeys)) for (const k of obj.apiKeys) if (k && k.id) STATE.apiKeys.set(k.id, k);

  // v3: jobs
  STATE.jobs.clear();
  if (Array.isArray(obj.jobs)) for (const j of obj.jobs) if (j && j.id) STATE.jobs.set(j.id, j);

  // v3: sources/global/market/papers
  STATE.sources.clear();
  if (Array.isArray(obj.sources)) for (const s of obj.sources) if (s && s.id) STATE.sources.set(s.id, s);

  if (obj.globalIndex && typeof obj.globalIndex === "object") {
    STATE.globalIndex.byHash = new Map(Array.isArray(obj.globalIndex.byHash) ? obj.globalIndex.byHash : []);
    STATE.globalIndex.byId = new Map(Array.isArray(obj.globalIndex.byId) ? obj.globalIndex.byId : []);
  }

  STATE.listings.clear();
  if (Array.isArray(obj.listings)) for (const l of obj.listings) if (l && l.id) STATE.listings.set(l.id, l);

  STATE.entitlements.clear();
  if (Array.isArray(obj.entitlements)) for (const e of obj.entitlements) if (e && e.id) STATE.entitlements.set(e.id, e);

  STATE.transactions.clear();
  if (Array.isArray(obj.transactions)) for (const t of obj.transactions) if (t && t.id) STATE.transactions.set(t.id, t);

  STATE.papers.clear();
  if (Array.isArray(obj.papers)) for (const p of obj.papers) if (p && p.id) STATE.papers.set(p.id, p);

  // Lens artifacts
  STATE.lensArtifacts.clear();
  if (Array.isArray(obj.lensArtifacts)) for (const a of obj.lensArtifacts) if (a && a.id) STATE.lensArtifacts.set(a.id, a);
  // Rebuild domain index
  _rebuildLensDomainIndex();

  // Scope Separation state
  if (obj._scopeSeparation && typeof obj._scopeSeparation === "object") {
    STATE._scopeSeparation = obj._scopeSeparation;
  }

  // Autogen Pipeline state
  if (obj._autogenPipeline && typeof obj._autogenPipeline === "object") {
    STATE._autogenPipeline = obj._autogenPipeline;
  }
}


function _normalizeSettingsDefaults() {
  try {
    if (STATE && STATE.settings) {
      if (typeof STATE.settings.llmDefault !== "boolean") STATE.settings.llmDefault = DEFAULT_LLM_ON;
      if (typeof STATE.settings.interpretiveTruthMin !== "number") STATE.settings.interpretiveTruthMin = 0.35;
      if (typeof STATE.settings.interpretiveTruthMax !== "number") STATE.settings.interpretiveTruthMax = 0.85;
      if (typeof STATE.settings.speculativeGateEnabled !== "boolean") STATE.settings.speculativeGateEnabled = false;
      if (typeof STATE.settings.canonicalOnly !== "boolean") STATE.settings.canonicalOnly = true;
    }
  } catch (e) {
    structuredLog("warn", "settings_normalization_failed", { error: String(e?.message || e) });
  }
}

function loadStateFromDisk() {
  // Try SQLite first in production
  if (USE_SQLITE_STATE) {
    try {
      const row = db.prepare("SELECT data, saved_at FROM state_snapshots WHERE id = 1").get();
      if (row) {
        const obj = JSON.parse(row.data);
        _hydrateState(obj);
        _normalizeSettingsDefaults();
        console.log("[Persistence] State loaded from SQLite");
        return { ok: true, loaded: true, backend: "sqlite", savedAt: row.saved_at };
      }
      // No snapshot yet — fall through to JSON check for migration
      console.log("[Persistence] No SQLite snapshot yet, checking JSON for migration...");
    } catch (e) {
      console.error("[Persistence] SQLite state load failed:", e.message);
    }
  }

  // JSON file fallback (dev mode or migration source)
  try {
    if (!fs.existsSync(STATE_PATH)) return { ok: true, loaded: false, path: STATE_PATH, backend: "json" };
    const raw = fs.readFileSync(STATE_PATH, "utf-8");
    const obj = JSON.parse(raw);
    _hydrateState(obj);
    _normalizeSettingsDefaults();

    // If SQLite is available and we loaded from JSON, migrate data to SQLite
    if (USE_SQLITE_STATE) {
      try {
        const stmt = db.prepare("INSERT OR REPLACE INTO state_snapshots (id, data, version, saved_at) VALUES (1, ?, ?, ?)");
        stmt.run(raw, obj.version || VERSION, nowISO());
        console.log("[Persistence] Migrated JSON state to SQLite");
      } catch (migErr) {
        console.error("[Persistence] Migration to SQLite failed:", migErr.message);
      }
    }

    return { ok: true, loaded: true, path: STATE_PATH, backend: USE_SQLITE_STATE ? "sqlite (migrated)" : "json", savedAt: obj.savedAt || null };
  } catch (e) {
    return { ok: false, loaded: false, path: STATE_PATH, backend: "json", error: String(e?.message || e) };
  }
}

function saveStateDebounced() {
  try {
    clearTimeout(_saveTimer);
    _saveTimer = setTimeout(() => {
      try {
        const data = JSON.stringify(_serializeState(), null, USE_SQLITE_STATE ? 0 : 2);

        if (USE_SQLITE_STATE) {
          // SQLite: single-row upsert inside WAL transaction — crash-safe
          const stmt = db.prepare("INSERT OR REPLACE INTO state_snapshots (id, data, version, saved_at) VALUES (1, ?, ?, ?)");
          stmt.run(data, VERSION, nowISO());
        } else {
          // JSON: atomic write via temp file + rename
          const tmpPath = STATE_PATH + ".tmp";
          fs.writeFileSync(tmpPath, data, "utf-8");
          fs.renameSync(tmpPath, STATE_PATH);
        }
      } catch (e) {
        console.error("STATE save failed:", e);
        if (!USE_SQLITE_STATE) {
          try { fs.unlinkSync(STATE_PATH + ".tmp"); } catch {}
        }
      }
    }, 250);
  } catch (e) {
    structuredLog("error", "save_state_debounce_failed", { error: String(e?.message || e) });
  }
}

const STATE_DISK = loadStateFromDisk();
// Final boot normalization (ensures env-driven defaults win)
try {
  if (STATE && STATE.settings) {
    if (__llmDefaultForcedRaw !== null) STATE.settings.llmDefault = DEFAULT_LLM_ON;
    else if ((process.env.OPENAI_API_KEY || "").trim()) STATE.settings.llmDefault = true;
  }
} catch (e) {
  structuredLog("warn", "boot_normalization_failed", { error: String(e?.message || e) });
}



const SEED_INFO = { ok:false, loaded:false, count:0, path:"./dtus.js", error:null, source:"none" };

async function tryLoadSeedDTUs() {
  // 1. Try JSON seed packs first (preferred — fastest, grouped by part)
  const seedDir = path.join(DATA_DIR, "seed");
  const seedManifestPath = path.join(seedDir, "manifest.json");
  if (fs.existsSync(seedManifestPath)) {
    try {
      const t0 = Date.now();
      const manifest = JSON.parse(fs.readFileSync(seedManifestPath, "utf-8"));
      if (manifest.format === "seed-packs" && Array.isArray(manifest.packs)) {
        const dtus = [];
        let errors = 0;
        for (const pack of manifest.packs) {
          const packPath = path.join(seedDir, pack.file);
          if (!fs.existsSync(packPath)) { errors++; continue; }
          const content = fs.readFileSync(packPath, "utf-8");
          const hash = crypto.createHash("sha256").update(content).digest("hex");
          if (hash !== pack.sha256) {
            console.warn(`[Seed-Pack] Hash mismatch: ${pack.file} (expected ${pack.sha256.slice(0,12)}, got ${hash.slice(0,12)})`);
            errors++;
            continue;
          }
          try {
            const entries = JSON.parse(content);
            if (Array.isArray(entries)) {
              for (const entry of entries) dtus.push(entry);
            }
          } catch { errors++; }
        }
        if (dtus.length > 0) {
          SEED_INFO.ok = true; SEED_INFO.loaded = true;
          SEED_INFO.count = dtus.length; SEED_INFO.source = "seed-packs";
          SEED_INFO.path = seedDir;
          if (errors) SEED_INFO.error = `${errors} seed-pack error(s)`;
          console.log(`[Seed-Pack] Loaded ${dtus.length} DTUs from ${manifest.packs.length} JSON packs in ${Date.now() - t0}ms`);
          return dtus;
        }
      }
    } catch (e) {
      console.warn(`[Seed-Pack] Failed to load seed packs: ${e.message}`);
    }
  }

  // 2. Try legacy JSONL pack format (data/dtu-packs/)
  const packDir = path.join(DATA_DIR, "dtu-packs");
  const manifestPath = path.join(packDir, "manifest.json");
  if (fs.existsSync(manifestPath)) {
    try {
      const manifest = JSON.parse(fs.readFileSync(manifestPath, "utf-8"));
      const dtus = [];
      let errors = 0;
      for (const chunk of (manifest.chunks || [])) {
        const chunkPath = path.join(packDir, chunk.file);
        if (!fs.existsSync(chunkPath)) { errors++; continue; }
        const content = fs.readFileSync(chunkPath, "utf-8");
        const hash = crypto.createHash("sha256").update(content).digest("hex");
        if (hash !== chunk.sha256) {
          console.warn(`[DTU-Pack] Hash mismatch: ${chunk.file} (expected ${chunk.sha256.slice(0,12)}, got ${hash.slice(0,12)})`);
          errors++;
          continue;
        }
        for (const line of content.trim().split("\n")) {
          if (!line.trim()) continue;
          try { dtus.push(JSON.parse(line)); } catch { errors++; }
        }
      }
      if (dtus.length > 0) {
        SEED_INFO.ok = true; SEED_INFO.loaded = true;
        SEED_INFO.count = dtus.length; SEED_INFO.source = "dtu-packs";
        SEED_INFO.path = packDir;
        if (errors) SEED_INFO.error = `${errors} pack error(s)`;
        console.log(`[DTU-Pack] Loaded ${dtus.length} DTUs from ${manifest.chunks.length} JSONL chunks`);
        return dtus;
      }
    } catch (e) {
      console.warn(`[DTU-Pack] Failed to load packs: ${e.message}`);
    }
  }

  // 3. Fallback to dtus.js monolithic import (deprecated — logs startup tax)
  try {
    console.warn("[Seed] JSON packs not found — falling back to monolithic dtus.js import (deprecated).");
    console.warn("[Seed] To reduce startup time + memory, run: node server/scripts/convert-dtus-to-seed-packs.js");
    const t0 = Date.now();
    const mod = await import("./dtus.js");
    const seed = (mod?.dtus ?? mod?.default ?? mod?.DTUS ?? null);
    const arr = Array.isArray(seed) ? seed : (Array.isArray(seed?.dtus) ? seed.dtus : []);
    if (!Array.isArray(arr)) throw new Error("dtus.js must export an array (export const dtus = [...] or export default [...])");
    SEED_INFO.ok = true;
    SEED_INFO.loaded = true;
    SEED_INFO.count = arr.length;
    SEED_INFO.source = "dtus.js";
    console.log(`[Seed] Loaded ${arr.length} DTUs from dtus.js in ${Date.now() - t0}ms (deprecated path)`);
    return arr;
  } catch (e) {
    SEED_INFO.ok = false;
    SEED_INFO.loaded = false;
    SEED_INFO.error = String(e?.message || e);
    return [];
  }
}

function renderHumanDTU(dtu) {
  const h = dtu.human || {};
  const c = dtu.core || {};
  const lines = [];
  const title = dtu.title || "Untitled";
  lines.push(`# ${title}`);
  if (h.summary) lines.push(`\n## Summary\n${h.summary}`);
  const bullets = Array.isArray(h.bullets) ? h.bullets : [];
  if (bullets.length) lines.push(`\n## Key Points\n` + bullets.map(b=>`- ${b}`).join("\n"));
  const defs = Array.isArray(c.definitions) ? c.definitions : [];
  if (defs.length) lines.push(`\n## Definitions\n` + defs.map(x=>`- ${x}`).join("\n"));
  const inv = Array.isArray(c.invariants) ? c.invariants : [];
  if (inv.length) lines.push(`\n## Invariants\n` + inv.map(x=>`- ${x}`).join("\n"));
  const ex = Array.isArray(c.examples) ? c.examples : [];
  const hex = Array.isArray(h.examples) ? h.examples : [];
  const exAll = hex.length ? hex : ex;
  if (exAll.length) lines.push(`\n## Examples\n` + exAll.map(x=>`- ${x}`).join("\n"));
  const next = Array.isArray(c.nextActions) ? c.nextActions : [];
  if (next.length) lines.push(`\n## Next Actions\n` + next.map(x=>`- ${x}`).join("\n"));
  return lines.join("\n").trim();
}

function looksMachiney(s="") {
  const t = String(s);
  return /##\s+(Purpose|Procedure|Tests|Outputs)\b/i.test(t) || /#\s*CRETI\b/i.test(t) || /Total lineage DTUs/i.test(t);
}

function councilGate(dtu, opts={}) {
  const allowRewrite = opts.allowRewrite !== false;
  const c = dtu.core || {};
  const score =
    (c.definitions?.length||0) +
    (c.invariants?.length||0) +
    (c.examples?.length||0) +
    (c.claims?.length||0) +
    (c.nextActions?.length||0);

  const humanText = dtu.cretiHuman || dtu.human?.summary || "";
  if (allowRewrite && looksMachiney(humanText)) {
    dtu.cretiHuman = "";
  }

  if (score < 2) return { ok:false, reason:"low_value", score };

  if (!dtu.cretiHuman) dtu.cretiHuman = renderHumanDTU(dtu);

  if (IMMUTABLES?.NO_MACHINE_TO_HUMAN && looksMachiney(dtu.cretiHuman)) {
    dtu.cretiHuman = renderHumanDTU(dtu);
  }

  dtu.authority = dtu.authority || {};
  dtu.authority.model = "council";
  dtu.authority.score = score;
  return { ok:true, score };
}

function toOptionADTU(seedLike) {
  const title = normalizeText(seedLike.title || seedLike.name || "Untitled DTU");
  const tags = Array.isArray(seedLike.tags) ? seedLike.tags.map(t=>normalizeText(t)).filter(Boolean) : [];
  const tier = seedLike.tier && ["regular","mega","hyper"].includes(seedLike.tier) ? seedLike.tier : "regular";
  const core = seedLike.core && typeof seedLike.core === "object" ? seedLike.core : {};
  const human = seedLike.human && typeof seedLike.human === "object" ? seedLike.human : {};
  const machine = seedLike.machine && typeof seedLike.machine === "object" ? seedLike.machine : {};
  const lineage = Array.isArray(seedLike.lineage) ? seedLike.lineage : [];
  const creti = String(seedLike.creti ?? seedLike.content ?? "");

  if (creti && (!core || Object.keys(core).length===0)) {
    machine.notes = machine.notes || creti;
    human.summary = human.summary || normalizeText(creti).slice(0, 320);
  }

  const dtu = {
    id: seedLike.id || uid("dtu"),
    title,
    tags,
    tier,
    lineage,
    core: {
      definitions: Array.isArray(core.definitions) ? core.definitions : [],
      invariants: Array.isArray(core.invariants) ? core.invariants : [],
      examples: Array.isArray(core.examples) ? core.examples : [],
      claims: Array.isArray(core.claims) ? core.claims : [],
      nextActions: Array.isArray(core.nextActions) ? core.nextActions : [],
    },
    human: {
      summary: String(human.summary || ""),
      bullets: Array.isArray(human.bullets) ? human.bullets : [],
      examples: Array.isArray(human.examples) ? human.examples : [],
    },
    machine,
    cretiHuman: "",
    scope: seedLike.scope || "local",  // Scope Separation: default to local
    source: seedLike.source || "seed",
    meta: seedLike.meta && typeof seedLike.meta==="object" ? seedLike.meta : {},
    createdAt: seedLike.createdAt || nowISO(),
    updatedAt: nowISO(),
    authority: seedLike.authority || { model:"seed", score: 0 },
    hash: seedLike.hash || "",
  };
  dtu.cretiHuman = renderHumanDTU(dtu);
  dtu.hash = dtu.hash || crypto.createHash("sha256").update(dtu.title + "\n" + dtu.cretiHuman).digest("hex").slice(0,16);
  return dtu;
}


function seedGenesisRealityAnchor(){
  try{
    const id = "genesis_reality_anchor_v1";
    if (STATE.dtus.has(id)) return { ok:true, existed:true };
    const dtu = {
      id,
      title: "Genesis Reality Anchor v1",
      kind: "genesis",
      scope: "global",  // Scope Separation: genesis anchor is canonical Global knowledge
      createdAt: nowISO(),
      updatedAt: nowISO(),
      lineage: { root: id, parents: [] },
      invariants: [
        "x^2 - x = 0",
        "x^2 - x - 1 = 0",
        "NO_NEGATIVE_VALENCE_DIMENSION",
        "REPAIR_DOMINANCE_REQUIRED",
        "OVERLAP>=0.95"
      ],
      formula: "x^2 - x = 0 ; x^2 - x - 1 = 0",
      notes: "Immutable root DTU for Chicken2. All macro and DTU births must remain within lattice reality bounds."
    };
    STATE.dtus.set(id, dtu);
    saveStateDebounced();
    log("c2.genesis", "Seeded genesis_reality_anchor_v1 DTU", { id });
    return { ok:true, existed:false };
  } catch(e){
    console.error("seedGenesisRealityAnchor failed:", e);
    return { ok:false, error:String(e?.message||e) };
  }
}

async function seedIfEmpty() {
  if (STATE.dtus.size > 0) return { ok:true, seeded:false, reason:"already_has_dtus" };
  const seeds = await tryLoadSeedDTUs();
  if (!seeds.length) return { ok:false, seeded:false, error: SEED_INFO.error || "no seeds" };
  let n=0;
  for (const s of seeds) {
    // Scope Separation: seed DTUs load into Global scope — they are canonical knowledge.
    // Each instance cherry-picks which Global DTUs to pull into Local.
    s.scope = "global";
    const d = toOptionADTU(s);
    STATE.dtus.set(d.id, d);
    n++;
  }
  saveStateDebounced();
  log("seed", "Seeded DTUs from dtus.js into Global scope", { count:n, scope:"global" });
  return { ok:true, seeded:true, count:n, scope:"global" };
}
await seedIfEmpty();
seedGenesisRealityAnchor();

// Humanize / normalize DTUs for UI (topic titles + CRETI projection)
try {
  const changed = renameAllDTUs(Array.from(STATE.dtus.values()));
  if (changed) { saveStateDebounced(); log("dtu.rename", "Normalized DTU titles/CRETI for UI", { changed }); }
} catch (e) {
  console.error("DTU normalization failed:", e);
}

// ---- logging ----
function log(type, message, meta={}) {
  const entry = { id: uid("log"), ts: nowISO(), type, message, meta };
  STATE.logs.push(entry);
  if (STATE.logs.length > 2000) STATE.logs.splice(0, STATE.logs.length - 2000);
  return entry;
}


// ===== CHICKEN2 CORE (Reality Substrate + Continuity + Safe Emergence) =====
function _c2now(){ return Date.now(); }
function _c2hash(obj){
  try { return crypto.createHash("sha256").update(typeof obj==="string"?obj:JSON.stringify(obj)).digest("hex"); }
  catch { return crypto.createHash("sha256").update(String(obj)).digest("hex"); }
}
function _c2log(type, message, meta={}){
  const e = { id: uid("c2log"), ts: nowISO(), type, message, meta };
  STATE.__chicken2.logs.push(e);
  if (STATE.__chicken2.logs.length > 4000) STATE.__chicken2.logs.splice(0, STATE.__chicken2.logs.length-4000);
  return e;
}
function overlap_verifier(a, b){
  // Conservative overlap: invariant-key intersection + lineage overlap, clamped [0,1]
  try{
    const A = (a && (a.invariants||a.invariantKeys||a.keys)) ? (a.invariants||a.invariantKeys||a.keys) : [];
    const B = (b && (b.invariants||b.invariantKeys||b.keys)) ? (b.invariants||b.invariantKeys||b.keys) : [];
    const aSet = new Set(Array.isArray(A)?A:Object.keys(A||{}));
    const bSet = new Set(Array.isArray(B)?B:Object.keys(B||{}));
    let inter=0;
    for (const k of aSet) if (bSet.has(k)) inter++;
    const union = aSet.size + bSet.size - inter;
    const j = union ? inter/union : 1;
    // lineage: compare genesis root if present
    const la = a?.lineage?.root || a?.lineageRoot || a?.root || "";
    const lb = b?.lineage?.root || b?.lineageRoot || b?.root || "";
    const l = (la && lb && la===lb) ? 1 : (!la && !lb ? 1 : 0);
    return clamp(0.7*j + 0.3*l, 0, 1);
  } catch { return 0; }
}
function _c2genesisDTU(){
  // Stored as a DTU in STATE.dtus with fixed id
  return STATE.dtus.get("genesis_reality_anchor_v1") || null;
}
function _c2primalSatisfied(){
  // x^2 - x = 0 fixed points {0,1} treated as: system must be coherent (non-NaN) and have non-empty DTUs
  return STATE && STATE.dtus && STATE.dtus.size > 0;
}
function _c2inversionVerifier(){
  // For the golden extension x^2 - x - 1 = 0, discriminant is 5 (real). We flag only if a caller tries to flip into negative discriminant in metadata.
  // Here we implement a conservative "vacuum" detector: if caller declares "invertTest" and it yields negative discriminant -> hard fail.
  return { ok:true };
}
function _c2negativeValenceProjection(payload){
  // Minimal implementation: block explicit negative-valence flags in payload or actor intent.
  const txt = JSON.stringify(payload||{}).toLowerCase();
  const bad = ["negative valence", "suffering maxim", "harm", "torture", "kill", "suicide", "self-harm"];
  for (const b of bad) if (txt.includes(b)) return { ok:false, reason:`negative_valence_projection:${b}` };
  return { ok:true };
}
function _c2repairDominance(){
  // Use your existing repair dominance macro if present; else approximate from growth functionalDecline + repairRate
  try{
    const g = STATE.growth || {};
    const rr = Number(g.repair?.repairRate ?? 0.5);
    const dl = Number(g.repair?.cleanupBacklog ?? 0);
    const cLoad = Number(g.functionalDecline?.contradictionLoad ?? 0);
    const score = clamp(rr - 0.25*clamp01(dl/10) - 0.25*clamp01(cLoad), 0, 1);
    return { ok: score > 0.01, score };
  } catch { return { ok:true, score:0.5 }; }
}
function inLatticeReality({ type="macro", domain="", name="", input=null, ctx=null }={}){
  const cfg = STATE.__chicken2 || {};
  // 1) primal satisfaction
  if (!_c2primalSatisfied()){
    cfg.metrics.rejections++;
    return { ok:false, severity:"hard", reason:"primal_unsatisfied", meta:{ type, domain, name } };
  }
  // 2) inversion vacuum
  const inv = _c2inversionVerifier();
  if (!inv.ok){
    cfg.metrics.rejections++;
    return { ok:false, severity:"hard", reason:"inversion_vacuum", meta: inv };
  }
  // 3) negative valence projection
  const nv = _c2negativeValenceProjection({ input, actor: ctx?.actor, type, domain, name });
  if (!nv.ok){
    cfg.metrics.rejections++;
    return { ok:false, severity:"hard", reason:nv.reason };
  }
  // 4) repair dominance projection + overlap requirement (>=0.95 default) if genesis exists
  const g = _c2genesisDTU();
  if (g){
    const ov = overlap_verifier(g, { invariants: Object.keys(STATE.settings||{}), lineage:{ root:"genesis_reality_anchor_v1" }});
    if (ov < (cfg.thresholdOverlap ?? 0.95)){
      cfg.metrics.rejections++;
      return { ok:false, severity:"quarantine", reason:"overlap_below_threshold", meta:{ ov, threshold: cfg.thresholdOverlap } };
    }
  }
  const rd = _c2repairDominance();
  // 5) suffering boundary check
  const suffering = Number(STATE.__chicken2?.metrics?.suffering ?? 0);
  const sThr = Number(cfg.thresholdSuffering ?? 0.65);
  if (suffering > sThr){
    cfg.metrics.rejections++;
    return { ok:false, severity:"quarantine", reason:"suffering_boundary_exceeded", meta:{ suffering, threshold: sThr } };
  }

  if (!rd.ok){
    cfg.metrics.rejections++;
    return { ok:false, severity:"quarantine", reason:"repair_dominance_failed", meta: rd };
  }
  cfg.metrics.accepts++;
  return { ok:true, severity:"ok" };
}
function _c2founderOverrideAllowed(ctx){
  const role = ctx?.actor?.role || "";
  const scopes = ctx?.actor?.scopes || [];
  const isFounder = role==="owner" || scopes.includes("*") || scopes.includes("founder");
  if (!isFounder) return false;
  // Production hardening: require FOUNDER_SECRET as second factor for override
  if (NODE_ENV === "production" && process.env.FOUNDER_SECRET) {
    const provided = ctx?.reqMeta?.founderSecret || "";
    if (!provided || provided !== process.env.FOUNDER_SECRET) {
      _c2log("c2.founder", "Override denied: missing/invalid FOUNDER_SECRET in production", { role });
      return false;
    }
  }
  return true;
}
async function governedCall(ctx, effectName, fn){
  const pre = inLatticeReality({ type:"governedCall", domain:"governed", name:effectName, ctx, input:{} });
  if (!pre.ok){
    _c2log("governed.reject", "governedCall rejected by lattice reality", { effectName, pre });
    throw new Error(`governedCall rejected: ${pre.reason}`);
  }
  // Council check: if you have a council gate function, use it; otherwise enforce immutables.
  if (IMMUTABLES?.COUNCIL_REQUIRED && typeof globalThis.councilApprove === "function"){
    const ok = await globalThis.councilApprove(ctx, { effectName });
    if (!ok) throw new Error("council denied governed call");
  }
  return fn();
}
// ===== END CHICKEN2 CORE =====

// ---- macro registry (extracted to ./macros/registry.js) ----
// MACROS, register, listDomains, listMacros are imported from ./macros/registry.js
// runMacro is created below via the factory function createRunMacro.
const runMacro = createRunMacro({ inLatticeReality, _c2log, _c2founderOverrideAllowed, STATE });

// ===== CHICKEN3: Meta-DTU helpers (additive, named per blueprint) =====
function generateMetaProposal(ctx, input={}){
  // Creates + queues a meta-proposal about lattice health (no DTU commit here).
  enforceEthosInvariant("meta_propose");
  if (!ctx?.state?.__chicken3?.metaEnabled) return { ok:false, error:"meta disabled" };

  const organId = String(input.organId || "");
  const organ = organId ? ctx.state.organs.get(organId) : null;

  const c2m = ctx.state.__chicken2?.metrics || {};
  const obs = [
    `homeostasis=${Number(c2m.homeostasis ?? 1).toFixed(2)}`,
    `contradictionLoad=${Number(c2m.contradictionLoad ?? 0).toFixed(2)}`,
    `suffering=${Number(c2m.suffering ?? 0).toFixed(2)}`,
    `continuityAvg=${Number(c2m.continuityAvg ?? 0).toFixed(2)}`,
    `organs=${ctx.state.organs.size}`,
    `dtus=${ctx.state.dtus.size}`,
    `shadow=${ctx.state.shadowDtus.size}`
  ].join(" | ");

  const maturity = Number(organ?.maturity?.score ?? organ?.maturityScore ?? 0);
  const suggestion =
    maturity > 0.85 ? "Proposal: tighten repair-dominance floor slightly when shadow-rate rises."
    : (ctx.state.organs.size > 50 ? "Observation: organ count high — consider consolidation thresholds."
    : "Observation: overall maturity low — schedule additional synthesis/cleanup cycles.");

  const proposal = {
    id: uid("meta"),
    createdAt: nowISO(),
    proposerOrganId: organId || "unknown",
    maturity,
    content: `META-LATTICE (${organId||"unknown"}) — ${suggestion}\n\nOBS: ${obs}`
  };

  ctx.state.queues = ctx.state.queues || {};
  ctx.state.queues.metaProposals = ctx.state.queues.metaProposals || [];
  ctx.state.queues.metaProposals.push(proposal);
  ctx.state.__chicken3.stats.metaProposals++;
  return { ok:true, proposal };
}

// Blueprint name: council.reviewAndCommitQuiet
const council = (globalThis.__CONCORD_COUNCIL ||= {});
council.reviewAndCommitQuiet = function reviewAndCommitQuiet(ctx, input={}){
  enforceEthosInvariant("quiet_review");
  if (!ctx?.state?.__chicken3?.metaEnabled) return { ok:false, error:"meta disabled" };

  let prop = null;
  const pid = String(input.proposalId || "");
  if (pid) prop = (ctx.state.queues.metaProposals || []).find(p => p?.id === pid) || null;
  if (!prop) prop = (ctx.state.queues.metaProposals || [])[0] || null;
  if (!prop) return { ok:false, error:"no proposals" };

  const dtu = {
    id: uid("dtu"),
    title: cleanTitle(prop.content).slice(0, 80) || "Meta DTU",
    tier: "regular",
    tags: ["meta","chicken3","shadow-safe"],
    lineage: { parents: [], children: [] },
    core: { definitions: [], invariants: [prop.content], examples: [], claims: [], nextActions: ["Review and either promote or discard this meta DTU."] },
    human: { summary: prop.content.slice(0, 320), bullets: [] },
    machine: { kind: "meta", proposerOrganId: prop.proposerOrganId, maturity: prop.maturity, proposalId: prop.id },
    cretiHuman: "",
    source: "autonomous",
    meta: { quiet: true },
    createdAt: nowISO(),
    updatedAt: nowISO(),
    authority: { model: "meta", score: 0 },
    hash: ""
  };

  const gate = councilGate(dtu, { allowRewrite:true });
  if (!gate.ok) return { ok:false, error:`councilGate:${gate.reason}`, gate };

  upsertDTU(dtu, { federate: true }); // broadcast + federate meta-DTUs
  ctx.state.queues.metaProposals = (ctx.state.queues.metaProposals || []).filter(p => p?.id !== prop.id);
  ctx.state.__chicken3.stats.metaCommits++;

  // Broadcast meta-commit event to connected clients
  try {
    realtimeEmit("meta:committed", {
      dtuId: dtu.id,
      title: dtu.title,
      proposalId: prop.id,
      metaCommitCount: ctx.state.__chicken3.stats.metaCommits,
      ts: nowISO()
    });
  } catch { /* best-effort */ }

  saveStateDebounced();
  return { ok:true, committed: dtuForClient(dtu), gate };
};
// ===== END CHICKEN3 Meta-DTU helpers =====

// ===== CHICKEN3 MACROS (additive) =====

// ============================================================================
// GA: ENTITY TERMINAL ACCESS (Governed, Sandboxed, Reality-Bounded)
// ============================================================================

// ACL: terminal exec is local-only and entity-scoped; approval is council-gated.
try {
  allowMacro("entity","terminal",{ roles:["owner","admin","member"], scopes:["*"] });
  allowMacro("entity","terminal_approve",{ roles:["owner","admin","council"], scopes:["*"] });
} catch {
  // allowMacro may not be defined yet in older builds; ignore (local-first default is open).
}

register("entity", "terminal", async (ctx, input={}) => {
  // P0.1: Hard-gate — disabled unless ENABLE_TERMINAL_EXEC=true
  if (!TERMINAL_EXEC_ENABLED) {
    return { ok: false, error: "Terminal execution is disabled. Set ENABLE_TERMINAL_EXEC=true to enable.", disabled: true };
  }

  enforceEthosInvariant("entity_terminal");

  const entityId = String(ctx?.actor?.userId || "");
  const command = String(input?.command || "").trim();
  const workingDir = String(input?.cwd || "");
  const requestId = uid("term_req");

  // Validation
  if (!entityId) return { ok:false, error:"Entity identity required" };
  if (!command) return { ok:false, error:"Command required" };
  if (entityId === "anon") return { ok:false, error:"Anonymous entities cannot execute commands" };
  if (command.length > 2000) return { ok:false, error:"Command too long (max 2000 chars)" };

  // Command injection protection - block dangerous patterns
  const dangerousPatterns = [
    /[`]/, // backtick command substitution
    /\$\(/, // $() command substitution
    /\$\{/, // ${} variable expansion with commands
    /;\s*[a-z]/i, // command chaining with semicolon
    /\|\s*[a-z]/i, // piping to commands (except simple pipes)
    /&&/, // AND chaining
    /\|\|/, // OR chaining
    />\s*\//, // redirect to absolute path
    />\s*\.\.\// , // redirect to parent path
    /\bsudo\b/i, // sudo
    /\bsu\b\s/, // su command
    /\bchmod\b.*777/, // dangerous chmod
    /\brm\b.*-rf?\s+\//, // rm -rf /
    /\bdd\b.*of=\//, // dd to device
    /\bmkfs\b/, // filesystem creation
    /\bshutdown\b/, // shutdown
    /\breboot\b/, // reboot
    /\bkill\b.*-9.*1\b/, // kill init
    /\/etc\/passwd/, // passwd file
    /\/etc\/shadow/, // shadow file
    /\.ssh\//, // ssh directory
    /\beval\b/, // eval command
    /\bexec\b/, // exec command
    /\bsource\b\s/, // source command
    /\b\.\s+\//, // . /path sourcing
  ];

  for (const pattern of dangerousPatterns) {
    if (pattern.test(command)) {
      return { ok:false, error:"Command contains blocked pattern", blocked: true };
    }
  }

  // Entity workspace setup
  const ENTITY_HOME = path.join(DATA_DIR, "entity_workspaces", entityId);

// Workdir safety: prevent path traversal outside the entity home.
const BASE = path.resolve(ENTITY_HOME);
let workDir = BASE;
if (workingDir) {
  const resolved = path.resolve(ENTITY_HOME, workingDir);
  const basePrefix = BASE.endsWith(path.sep) ? BASE : (BASE + path.sep);
  if (!resolved.startsWith(basePrefix)) {
    return { ok:false, error:"Invalid cwd: path escapes entity workspace" };
  }
  workDir = resolved;
}

  // Ensure workspace exists
  try {
    fs.mkdirSync(ENTITY_HOME, { recursive: true });
    fs.mkdirSync(path.join(ENTITY_HOME, "workspace"), { recursive: true });
    fs.mkdirSync(path.join(ENTITY_HOME, "forks"), { recursive: true });
    fs.mkdirSync(path.join(ENTITY_HOME, "logs"), { recursive: true });
  } catch (e) {
    return { ok:false, error:`Workspace init failed: ${String(e?.message||e)}` };
  }

  // Parse command for classification
  const cmdLower = command.toLowerCase();
  const isGit = /^git\s/.test(cmdLower);
  const isNpm = /^npm\s/.test(cmdLower);
  const isRead = /^(ls|cat|pwd|echo|head|tail|grep|find|tree)\b/.test(cmdLower);
  const isWrite = /^(rm|mv|cp|mkdir|touch|nano|vim)\b/.test(cmdLower) || />|>>/.test(command);
  const isDeploy = /^(node\b|pm2\b|npm\s+start\b)/.test(cmdLower);

  // Risk classification
  let riskLevel = "low";
  if (isDeploy) riskLevel = "high";
  else if (isWrite || isNpm) riskLevel = "medium";
  else if (isRead || isGit) riskLevel = "low";
  else riskLevel = "medium"; // unknown commands default medium

  // Council gate for medium+ risk
  if (riskLevel === "medium" || riskLevel === "high") {
    ensureQueues();
    const proposalId = uid("proposal");
    const proposal = {
      id: proposalId,
      type: "ENTITY_TERMINAL_REQUEST",
      entityId,
      command,
      riskLevel,
      requestId,
      status: "pending",
      createdAt: nowISO(),
      votes: { approve: [], deny: [], abstain: [] },
      threshold: riskLevel === "high" ? 0.75 : 0.60 // 75% for high risk, 60% for medium
    };

    STATE.queues.terminalRequests = STATE.queues.terminalRequests || [];
    STATE.queues.terminalRequests.push(proposal);
    saveStateDebounced();

    log("entity.terminal.proposed", `Entity ${entityId} requested terminal access`, {
      proposalId,
      command: command.slice(0, 200),
      riskLevel
    });

    return {
      ok:true,
      status: "pending_council_approval",
      proposalId,
      riskLevel,
      message: `Command requires ${riskLevel} risk council approval. Proposal ${proposalId} created.`
    };
  }

  // Low risk: Chicken2 reality check only
  const c2 = inLatticeReality({
    type:"entity_terminal",
    domain:"entity",
    name:"terminal",
    input:{ command, entityId },
    ctx
  });

  if (!c2.ok) {
    log("entity.terminal.reject.c2", `Chicken2 rejected command`, {
      entityId,
      command: command.slice(0, 200),
      reason: c2.reason
    });
    return {
      ok:false,
      error:`Reality guard: ${c2.reason}`,
      severity: c2.severity
    };
  }

  // Execute in sandbox
  const result = await executeInSandbox({
    entityId,
    command,
    workDir,
    timeoutMs: 30000,
    maxOutputBytes: 2 * 1024 * 1024
  });

  // Create shadow audit DTU (best-effort; never blocks)
  try {
    const auditDTU = {
      id: uid("dtu"),
      type: "entity_terminal_audit",
      title: `Entity Terminal Exec (${entityId})`,
      tags: ["entity","terminal","audit","shadow"],
      createdAt: nowISO(),
      updatedAt: nowISO(),
      shadow: true,
      hidden: true,
      entityId,
      requestId,
      riskLevel,
      command: command.slice(0, 8000),
      result: {
        exitCode: result.exitCode,
        timedOut: !!result.timedOut,
        stdout: String(result.stdout||"").slice(0, 10000),
        stderr: String(result.stderr||"").slice(0, 10000),
        executedAt: nowISO()
      }
    };

    // Prefer native shadow DTU mechanism if present; fallback to generic set()
    if (typeof globalThis.writeShadowDTU === "function") globalThis.writeShadowDTU(auditDTU);
    else if (typeof globalThis.set === "function") globalThis.set(auditDTU.id, auditDTU);
  } catch (e) {
    log("entity.terminal.audit.failed", "Failed to create audit DTU", { error: String(e?.message||e) });
  }

  log("entity.terminal.executed", `Entity ${entityId} executed command`, {
    requestId,
    command: command.slice(0, 200),
    exitCode: result.exitCode
  });

  return {
    ok: true,
    requestId,
    exitCode: result.exitCode,
    stdout: result.stdout,
    stderr: result.stderr,
    executedAt: nowISO(),
    riskLevel
  };

}, {
  summary: "Execute terminal command as entity (council-gated for medium+ risk, reality-bounded)",
  public: false
});

// ============================================================================
// GA: SANDBOX EXECUTOR
// ============================================================================
function executeInSandbox({ entityId, command, workDir, timeoutMs, maxOutputBytes }) {
  // P0.1: Defense-in-depth — sandbox executor also checks the gate
  if (!TERMINAL_EXEC_ENABLED) {
    return Promise.resolve({ exitCode: 1, stdout: "", stderr: "Terminal execution is disabled.", timedOut: false });
  }
  return new Promise((resolve) => {
    const proc = spawnSync("bash", ["-c", command], {
      cwd: workDir,
      timeout: timeoutMs,
      maxBuffer: maxOutputBytes,
      env: {
        ...process.env,
        ENTITY_ID: String(entityId || ""),
        HOME: String(workDir || ""),
        PATH: process.env.PATH,
        NO_PROXY: "*",
      },
      encoding: "utf-8"
    });

    resolve({
      exitCode: proc.status || 0,
      stdout: String(proc.stdout || ""),
      stderr: String(proc.stderr || ""),
      timedOut: proc.error?.code === "ETIMEDOUT"
    });
  });
}

// ============================================================================
// GA: COUNCIL APPROVAL PROCESSOR
// ============================================================================
register("entity", "terminal_approve", async (ctx, input={}) => {
  // P0.1: Hard-gate — disabled unless ENABLE_TERMINAL_EXEC=true
  if (!TERMINAL_EXEC_ENABLED) {
    return { ok: false, error: "Terminal execution is disabled. Set ENABLE_TERMINAL_EXEC=true to enable.", disabled: true };
  }

  enforceEthosInvariant("entity_terminal_approve");

  const proposalId = String(input?.proposalId || "");
  const vote = String(input?.vote || "").toLowerCase(); // approve | deny | abstain
  const voterId = String(ctx?.actor?.userId || "");
  const voterRole = String(ctx?.actor?.role || "viewer");

  if (!proposalId) return { ok:false, error:"proposalId required" };
  if (!["approve","deny","abstain"].includes(vote)) return { ok:false, error:"vote must be approve|deny|abstain" };

  ensureQueues();
  const proposal = (STATE.queues?.terminalRequests || []).find(p => p?.id === proposalId);
  if (!proposal) return { ok:false, error:"Proposal not found" };
  if (proposal.status !== "pending") return { ok:false, error:`Proposal already ${proposal.status}` };

  proposal.votes = proposal.votes || { approve: [], deny: [], abstain: [] };
  proposal.votes.approve = (proposal.votes.approve || []).filter(v => v.id !== voterId);
  proposal.votes.deny = (proposal.votes.deny || []).filter(v => v.id !== voterId);
  proposal.votes.abstain = (proposal.votes.abstain || []).filter(v => v.id !== voterId);

  const voteRecord = { id: voterId, role: voterRole, votedAt: nowISO() };
  if (vote === "approve") proposal.votes.approve.push(voteRecord);
  else if (vote === "deny") proposal.votes.deny.push(voteRecord);
  else proposal.votes.abstain.push(voteRecord);

  const approveCount = proposal.votes.approve.length;
const denyCount = proposal.votes.deny.length;
const abstainCount = proposal.votes.abstain.length;

// Spec behavior: abstain does NOT affect approval ratio.
const totalVotes = approveCount + denyCount + abstainCount;
const decisiveVotes = approveCount + denyCount;
const approvalRatio = decisiveVotes > 0 ? (approveCount / decisiveVotes) : 0;
  const threshold = Number(proposal.threshold || 0.60);

  if (totalVotes >= 3 && approvalRatio >= threshold) {
    proposal.status = "approved";
    proposal.approvedAt = nowISO();

    const execResult = await executeInSandbox({
      entityId: proposal.entityId,
      command: proposal.command,
      workDir: path.join(DATA_DIR, "entity_workspaces", proposal.entityId),
      timeoutMs: 30000,
      maxOutputBytes: 2 * 1024 * 1024
    });

    proposal.executionResult = {
      exitCode: execResult.exitCode,
      stdout: String(execResult.stdout || "").slice(0, 10000),
      stderr: String(execResult.stderr || "").slice(0, 10000),
      executedAt: nowISO()
    };

    log("entity.terminal.council_approved", `Council approved terminal command for ${proposal.entityId}`, {
      proposalId,
      command: String(proposal.command || "").slice(0, 200),
      approvalRatio,
      exitCode: execResult.exitCode
    });
  }
  else if (totalVotes >= 3 && approvalRatio < (1 - threshold)) {
    proposal.status = "denied";
    proposal.deniedAt = nowISO();

    log("entity.terminal.council_denied", `Council denied terminal command for ${proposal.entityId}`, {
      proposalId,
      command: String(proposal.command || "").slice(0, 200),
      approvalRatio
    });
  }

  saveStateDebounced();

  return {
    ok: true,
    proposalId,
    status: proposal.status,
    votes: {
      approve: approveCount,
      deny: denyCount,
      abstain: abstainCount,
      approvalRatio,
      threshold
    },
    executionResult: proposal.executionResult || null
  };
}, {
  summary: "Vote on entity terminal request (council-gated)",
  public: false
});


register("chicken3","status", (ctx, _input={}) => {
  enforceEthosInvariant("status");
  return { ok:true, chicken3: ctx.state.__chicken3, enabled: Boolean(ctx.state.__chicken3?.enabled) };
}, { public:true });

register("chicken3","session_optin", (ctx, input={}) => {
  enforceEthosInvariant("optin");
  const sid = String(input.sessionId || input.session || "");
  if (!sid) return { ok:false, error:"sessionId required" };
  const s = ctx.state.sessions.get(sid) || { createdAt: nowISO(), messages: [] };
  // Only additive flags
  if (typeof input.cloudOptIn === "boolean") s.cloudOptIn = input.cloudOptIn;
  if (typeof input.toolsOptIn === "boolean") s.toolsOptIn = input.toolsOptIn;
  if (typeof input.multimodalOptIn === "boolean") s.multimodalOptIn = input.multimodalOptIn;
  if (typeof input.voiceOptIn === "boolean") s.voiceOptIn = input.voiceOptIn;
  ctx.state.sessions.set(sid, s);
  saveStateDebounced();
  return { ok:true, sessionId: sid, flags: { cloudOptIn: !!s.cloudOptIn, toolsOptIn: !!s.toolsOptIn, multimodalOptIn: !!s.multimodalOptIn, voiceOptIn: !!s.voiceOptIn } };
}, { public:true });

function _c3sessionFlags(ctx){
  const sid = String(ctx?.reqMeta?.sessionId || ctx?.reqMeta?.sid || ctx?.sessionId || ctx?.actor?.sessionId || "");
  const s = sid ? (ctx?.state?.sessions?.get?.(sid) || null) : null;
  return {
    sessionId: sid,
    cloudOptIn: Boolean(s?.cloudOptIn === true),
    toolsOptIn: Boolean(s?.toolsOptIn === true),
    multimodalOptIn: Boolean(s?.multimodalOptIn === true),
    voiceOptIn: Boolean(s?.voiceOptIn === true),
  };
}

register("chicken3","meta_propose", (ctx, input={}) => {
  // Blueprint name: generateMetaProposal
  return generateMetaProposal(ctx, input);
}, { public:false });

register("chicken3","meta_commit_quiet", (ctx, input={}) => {
  // Blueprint name: council.reviewAndCommitQuiet
  return council.reviewAndCommitQuiet(ctx, input);
}, { public:false });

register("multimodal","vision_analyze", (ctx, input={}) => {
  enforceEthosInvariant("analyze_image");
  const flags = _c3sessionFlags(ctx);
  if (!ctx.state.__chicken3?.multimodalEnabled) return { ok:false, error:"multimodal disabled" };
  if (!flags.multimodalOptIn) return { ok:false, error:"session multimodal opt-in required" };

  const imageB64 = String(input.imageBase64 || "");
  const prompt = String(input.prompt || "Analyze this image in detail.");
  if (!imageB64) return { ok:false, error:"imageBase64 required" };

  // Governed execution: all external/tool-like calls route through governedCall.
  return governedCall(ctx, "multimodal.vision_analyze", async () => {

  // Local-first: Ollama (llava) if configured
  const OLLAMA_URL = process.env.OLLAMA_URL || process.env.OLLAMA_HOST || "";
  if (OLLAMA_URL) {
    const model = String(process.env.OLLAMA_VISION_MODEL || "llava");
    const payload = {
      model,
      messages: [{ role:"user", content: prompt, images: [imageB64] }]
    };
    try {
      const r = await BREAKERS.ollama.call(() =>
        fetch(`${OLLAMA_URL}/api/chat`, { method:"POST", headers:{ "Content-Type":"application/json" }, body: JSON.stringify(payload), signal: AbortSignal.timeout(60000) })
      );
      if (r && r.ok) {
        const j = await r.json().catch(()=>null);
        const content = j?.message?.content || j?.response || "";
        return { ok:true, content, source: "ollama_llava" };
      }
    } catch (e) {
      structuredLog("warn", "ollama_call_failed", { error: String(e?.message || e), circuit: BREAKERS.ollama.getState().state });
    }
  }

  // Cloud fallback: OpenAI GPT-4 Vision
  const OPENAI_API_KEY = process.env.OPENAI_API_KEY || "";
  if (OPENAI_API_KEY) {
    const payload = {
      model: "gpt-4o",
      messages: [{
        role: "user",
        content: [
          { type: "text", text: prompt },
          { type: "image_url", image_url: { url: `data:image/jpeg;base64,${imageB64}` } }
        ]
      }],
      max_tokens: 1000
    };

    const r = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${OPENAI_API_KEY}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify(payload)
    }).catch(_e => null);

    if (!r || !r.ok) {
      const errText = await r?.text().catch(() => "") || "";
      return { ok:false, error:"OpenAI Vision API failed", status: r?.status || 0, detail: errText };
    }
    const j = await r.json().catch(() => null);
    const content = j?.choices?.[0]?.message?.content || "";
    return { ok:true, content, source: "openai_gpt4_vision" };
  }

  return { ok:false, error:"No vision backend configured. Set OLLAMA_URL or OPENAI_API_KEY" };
  });
}, { public:false });

register("multimodal","image_generate", (ctx, input={}) => {
  enforceEthosInvariant("generate_image");
  const flags = _c3sessionFlags(ctx);
  if (!ctx.state.__chicken3?.multimodalEnabled) return { ok:false, error:"multimodal disabled" };
  if (!flags.multimodalOptIn) return { ok:false, error:"session multimodal opt-in required" };

  const prompt = String(input.prompt || "");
  if (!prompt) return { ok:false, error:"prompt required" };

  return governedCall(ctx, "multimodal.image_generate", async () => {

  // Local-first: Stable Diffusion / ComfyUI HTTP if configured
  const SD_URL = process.env.SD_URL || process.env.COMFYUI_URL || process.env.A1111_URL || "";
  if (SD_URL) {
    const body = { prompt, steps: clamp(Number(input.steps || 30), 5, 80) };
    const r = await fetch(SD_URL, { method:"POST", headers:{ "Content-Type":"application/json" }, body: JSON.stringify(body) }).catch(_e=>null);
    if (r && r.ok) {
      const j = await r.json().catch(()=>null);
      const img = j?.images?.[0] || j?.image || j?.data?.[0] || null;
      return { ok:true, image: img, source: "stable_diffusion", raw: j };
    }
  }

  // Cloud fallback: OpenAI DALL-E
  const OPENAI_API_KEY = process.env.OPENAI_API_KEY || "";
  if (OPENAI_API_KEY) {
    const size = String(input.size || "1024x1024"); // 1024x1024, 1792x1024, 1024x1792
    const quality = String(input.quality || "standard"); // standard, hd
    const model = String(input.model || "dall-e-3");

    const r = await fetch("https://api.openai.com/v1/images/generations", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${OPENAI_API_KEY}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        model,
        prompt,
        n: 1,
        size,
        quality,
        response_format: "b64_json"
      })
    }).catch(_e => null);

    if (!r || !r.ok) {
      const errText = await r?.text().catch(() => "") || "";
      return { ok:false, error:"OpenAI DALL-E API failed", status: r?.status || 0, detail: errText };
    }
    const j = await r.json().catch(() => null);
    const imageB64 = j?.data?.[0]?.b64_json || "";
    const revisedPrompt = j?.data?.[0]?.revised_prompt || prompt;
    return { ok:true, image: imageB64, source: "openai_dalle", revisedPrompt };
  }

  return { ok:false, error:"No image generation backend configured. Set SD_URL or OPENAI_API_KEY" };
  });
}, { public:false });

register("voice","transcribe", async (ctx, input={}) => {
  enforceEthosInvariant("transcribe_audio");
  const flags = _c3sessionFlags(ctx);
  if (!ctx.state.__chicken3?.voiceEnabled) return { ok:false, error:"voice disabled" };
  if (!flags.voiceOptIn) return { ok:false, error:"session voice opt-in required" };

  // Local-first: whisper.cpp binary
  const bin = process.env.WHISPER_CPP_BIN || "";
  if (bin) {
    const audioPath = String(input.audioPath || "");
    if (!audioPath) return { ok:false, error:"audioPath required (server-side file path)" };
    const args = [ "-f", audioPath, "--output-txt" ];
    const p = spawnSync(bin, args, { encoding:"utf-8" });
    if (p.error) return { ok:false, error:String(p.error) };
    const out = (p.stdout || "") + (p.stderr || "");
    return { ok:true, transcript: out.trim(), source: "whisper_cpp" };
  }

  // Cloud fallback: OpenAI Whisper API
  const OPENAI_API_KEY = process.env.OPENAI_API_KEY || "";
  if (OPENAI_API_KEY) {
    const audioBase64 = String(input.audioBase64 || "");
    const audioPath = String(input.audioPath || "");
    let audioBuffer = null;

    if (audioBase64) {
      audioBuffer = Buffer.from(audioBase64, "base64");
    } else if (audioPath && fs.existsSync(audioPath)) {
      audioBuffer = fs.readFileSync(audioPath);
    }

    if (!audioBuffer) return { ok:false, error:"audioBase64 or valid audioPath required" };

    const FormData = (await import("node:buffer")).Blob ? globalThis.FormData : null;
    if (!FormData) {
      // Node 18+ has native FormData, use fetch with multipart
      const boundary = `----formdata-${Date.now()}`;
      const filename = "audio.webm";
      const body = Buffer.concat([
        Buffer.from(`--${boundary}\r\nContent-Disposition: form-data; name="file"; filename="${filename}"\r\nContent-Type: audio/webm\r\n\r\n`),
        audioBuffer,
        Buffer.from(`\r\n--${boundary}\r\nContent-Disposition: form-data; name="model"\r\n\r\nwhisper-1\r\n--${boundary}--\r\n`)
      ]);

      const r = await fetch("https://api.openai.com/v1/audio/transcriptions", {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${OPENAI_API_KEY}`,
          "Content-Type": `multipart/form-data; boundary=${boundary}`
        },
        body
      }).catch(_e => null);

      if (!r || !r.ok) {
        const errText = await r?.text().catch(() => "") || "";
        return { ok:false, error:"OpenAI Whisper API failed", status: r?.status || 0, detail: errText };
      }
      const j = await r.json().catch(() => null);
      return { ok:true, transcript: j?.text || "", source: "openai_whisper" };
    }
  }

  return { ok:false, error:"No transcription backend configured. Set WHISPER_CPP_BIN or OPENAI_API_KEY" };
}, { public:false });

register("voice","tts", async (ctx, input={}) => {
  enforceEthosInvariant("synthesize_speech");
  const flags = _c3sessionFlags(ctx);
  if (!ctx.state.__chicken3?.voiceEnabled) return { ok:false, error:"voice disabled" };
  if (!flags.voiceOptIn) return { ok:false, error:"session voice opt-in required" };

  const text = String(input.text || "");
  if (!text) return { ok:false, error:"text required" };

  // Local-first: Piper binary
  const bin = process.env.PIPER_BIN || "";
  if (bin) {
    const voice = String(process.env.PIPER_VOICE || "");
    const args = voice ? ["--model", voice] : [];
    const p = spawnSync(bin, args, { input: text, encoding:"utf-8" });
    if (p.error) return { ok:false, error:String(p.error) };
    const outPath = String(input.outPath || "");
    if (outPath) {
      // Path traversal protection - only allow writes to entity workspace or tmp
      const TTS_OUTPUT_DIR = path.join(DATA_DIR, "tts_output");
      try { fs.mkdirSync(TTS_OUTPUT_DIR, { recursive: true }); } catch {}
      const safeName = path.basename(outPath).replace(/[^a-zA-Z0-9._-]/g, "_");
      const safePath = path.join(TTS_OUTPUT_DIR, safeName);
      try { fs.writeFileSync(safePath, p.stdout); } catch {}
      return { ok:true, outPath: safePath, source: "piper", note:"TTS wrote audio to safe path." };
    }
    return { ok:true, source: "piper", audioBase64: Buffer.from(p.stdout).toString("base64") };
  }

  // Cloud fallback: OpenAI TTS API
  const OPENAI_API_KEY = process.env.OPENAI_API_KEY || "";
  if (OPENAI_API_KEY) {
    const voice = String(input.voice || "alloy"); // alloy, echo, fable, onyx, nova, shimmer
    const model = String(input.model || "tts-1"); // tts-1 or tts-1-hd

    const r = await fetch("https://api.openai.com/v1/audio/speech", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${OPENAI_API_KEY}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({ model, input: text, voice, response_format: "mp3" })
    }).catch(_e => null);

    if (!r || !r.ok) {
      const errText = await r?.text().catch(() => "") || "";
      return { ok:false, error:"OpenAI TTS API failed", status: r?.status || 0, detail: errText };
    }

    const audioBuffer = Buffer.from(await r.arrayBuffer());
    const outPath = String(input.outPath || "");
    if (outPath) {
      try { fs.writeFileSync(outPath, audioBuffer); } catch {}
      return { ok:true, outPath, source: "openai_tts", format: "mp3" };
    }
    return { ok:true, source: "openai_tts", format: "mp3", audioBase64: audioBuffer.toString("base64") };
  }

  return { ok:false, error:"No TTS backend configured. Set PIPER_BIN or OPENAI_API_KEY" };
}, { public:false });

register("tools","web_search", (ctx, input={}) => {
  enforceEthosInvariant("web_search");
  const flags = _c3sessionFlags(ctx);
  if (!ctx.state.__chicken3?.toolsEnabled) return { ok:false, error:"tools disabled" };
  if (!flags.toolsOptIn) return { ok:false, error:"session tools opt-in required" };

  // Governed call: even local-first external network calls are considered effectful tools.
  return governedCall(ctx, "tools.web_search", async () => {

  const q = String(input.query || input.q || "");
  if (!q) return { ok:false, error:"query required" };

  // Local-first default: DuckDuckGo HTML (no API key). If you run SearxNG locally, set SEARXNG_URL.
  const local = process.env.SEARXNG_URL || "";
  const url = local ? `${local}/search?q=${encodeURIComponent(q)}&format=json` : `https://duckduckgo.com/html/?q=${encodeURIComponent(q)}`;
  const r = await fetch(url, { method:"GET" }).catch(_e=>null);
  if (!r || !r.ok) return { ok:false, error:"search failed", status: r?.status || 0 };

  const text = await r.text().catch(()=> "");

  // Optional cloud path: if user has explicitly opted in, allow downstream summarization via LLM.
  // (We do NOT require cloud for search; this is for post-processing convenience only.)
  let summary = null;
  const wantSummary = Boolean(input.summarize);
  if (wantSummary && flags.cloudOptIn && _cloudOptInAllowed({ sessionId: ctx?.sessionId })) {
    try {
      const sctx = { ...ctx, _background: true };
      const s = await runMacro("chat","respond", { mode:"ask", sessionId: ctx?.sessionId, prompt: `Summarize these search results for: ${q}\n\n${text.slice(0, 8000)}` }, sctx).catch(()=>null);
      summary = s?.answer ?? s?.content ?? s?.text ?? null;
    } catch {}
  }

  return { ok:true, source: local ? "searxng" : "duckduckgo_html", text: text.slice(0, 200000), summary };
  });
}, { public:false });

// ===== END CHICKEN3 MACROS =====

// ===== GOAL SYSTEM MACROS =====

register("goals", "status", (ctx, _input = {}) => {
  enforceEthosInvariant("goals_status");
  ensureGoalSystem();

  const activeGoals = Array.from(ctx.state.goals.active)
    .map(id => ctx.state.goals.registry.get(id))
    .filter(Boolean)
    .map(g => ({
      id: g.id,
      title: g.title,
      type: g.type,
      progress: g.progress.current / g.progress.target,
      priority: g.priority,
      startedAt: g.progress.startedAt
    }));

  const proposalCount = ctx.state.queues.goalProposals?.length || 0;

  return {
    ok: true,
    active: activeGoals,
    activeCount: activeGoals.length,
    proposalCount,
    stats: ctx.state.goals.stats,
    config: ctx.state.goals.config,
    invariants: GOAL_INVARIANTS
  };
}, { public: true });

register("goals", "propose", (ctx, input = {}) => {
  enforceEthosInvariant("goals_propose");
  ensureGoalSystem();

  const result = createGoalProposal({
    title: input.title,
    description: input.description,
    type: input.type || "exploration",
    priority: input.priority,
    source: input.source || "user",
    tags: input.tags,
    requiredDtus: input.requiredDtus,
    requiredGoals: input.requiredGoals,
    target: input.target
  });

  if (!result.ok) return result;

  const goal = result.goal;
  ctx.state.goals.registry.set(goal.id, goal);
  ctx.state.queues.goalProposals.push({ id: goal.id, createdAt: goal.createdAt });
  ctx.state.goals.stats.proposed++;

  saveStateDebounced();
  return { ok: true, goal: { id: goal.id, title: goal.title, type: goal.type, state: goal.state } };
}, { public: false });

register("goals", "evaluate", (ctx, input = {}) => {
  enforceEthosInvariant("goals_evaluate");
  ensureGoalSystem();

  const goalId = String(input.goalId || input.id || "");
  if (!goalId) return { ok: false, error: "goalId required" };

  const goal = ctx.state.goals.registry.get(goalId);
  if (!goal) return { ok: false, error: "Goal not found" };

  const result = evaluateGoal(goal, ctx);
  if (result.ok) {
    ctx.state.goals.registry.set(goalId, result.goal);
    saveStateDebounced();
  }

  return {
    ok: result.ok,
    evaluation: result.goal?.evaluation,
    state: result.goal?.state,
    passed: result.passed,
    error: result.error
  };
}, { public: false });

register("goals", "approve", (ctx, input = {}) => {
  enforceEthosInvariant("goals_approve");
  ensureGoalSystem();

  // Founder approval endpoint
  const goalId = String(input.goalId || input.id || "");
  if (!goalId) return { ok: false, error: "goalId required" };

  const goal = ctx.state.goals.registry.get(goalId);
  if (!goal) return { ok: false, error: "Goal not found" };

  // Check actor has founder/owner role
  if (!["owner", "admin", "founder"].includes(ctx.actor?.role)) {
    return { ok: false, error: "Founder approval requires owner/admin role" };
  }

  goal.meta.founderApproved = true;
  goal.meta.approvedBy = ctx.actor?.userId || "unknown";
  goal.meta.approvedAt = nowISO();
  goal.state = GOAL_STATES.APPROVED;
  goal.updatedAt = nowISO();

  ctx.state.goals.stats.approved++;
  saveStateDebounced();

  return { ok: true, goal: { id: goal.id, title: goal.title, state: goal.state, founderApproved: true } };
}, { public: false });

register("goals", "activate", (ctx, input = {}) => {
  enforceEthosInvariant("goals_activate");
  ensureGoalSystem();

  const goalId = String(input.goalId || input.id || "");
  if (!goalId) return { ok: false, error: "goalId required" };

  const result = activateGoal(goalId);
  if (result.ok) saveStateDebounced();

  return {
    ok: result.ok,
    goal: result.goal ? { id: result.goal.id, title: result.goal.title, state: result.goal.state } : null,
    error: result.error
  };
}, { public: false });

register("goals", "progress", (ctx, input = {}) => {
  enforceEthosInvariant("goals_progress");
  ensureGoalSystem();

  const goalId = String(input.goalId || input.id || "");
  if (!goalId) return { ok: false, error: "goalId required" };

  const delta = Number(input.delta || input.progress || 1);
  const milestone = input.milestone || null;

  const result = updateGoalProgress(goalId, delta, milestone);
  return {
    ok: result.ok,
    progress: result.progress,
    completed: result.completed || false,
    error: result.error
  };
}, { public: false });

register("goals", "complete", (ctx, input = {}) => {
  enforceEthosInvariant("goals_complete");
  ensureGoalSystem();

  const goalId = String(input.goalId || input.id || "");
  if (!goalId) return { ok: false, error: "goalId required" };

  return completeGoal(goalId);
}, { public: false });

register("goals", "abandon", (ctx, input = {}) => {
  enforceEthosInvariant("goals_abandon");
  ensureGoalSystem();

  const goalId = String(input.goalId || input.id || "");
  if (!goalId) return { ok: false, error: "goalId required" };

  const reason = String(input.reason || "user_requested");
  return abandonGoal(goalId, reason);
}, { public: false });

register("goals", "list", (ctx, input = {}) => {
  enforceEthosInvariant("goals_list");
  ensureGoalSystem();

  const state = input.state; // Filter by state
  const type = input.type;   // Filter by type
  const limit = clamp(Number(input.limit || 50), 1, 200);

  let goals = Array.from(ctx.state.goals.registry.values());

  if (state) goals = goals.filter(g => g.state === state);
  if (type) goals = goals.filter(g => g.type === type);

  goals = goals
    .sort((a, b) => new Date(b.createdAt) - new Date(a.createdAt))
    .slice(0, limit)
    .map(g => ({
      id: g.id,
      title: g.title,
      type: g.type,
      state: g.state,
      priority: g.priority,
      progress: g.progress.current / g.progress.target,
      source: g.source,
      createdAt: g.createdAt
    }));

  return { ok: true, goals, total: ctx.state.goals.registry.size };
}, { public: true });

register("goals", "get", (ctx, input = {}) => {
  enforceEthosInvariant("goals_get");
  ensureGoalSystem();

  const goalId = String(input.goalId || input.id || "");
  if (!goalId) return { ok: false, error: "goalId required" };

  const goal = ctx.state.goals.registry.get(goalId);
  if (!goal) return { ok: false, error: "Goal not found" };

  return { ok: true, goal };
}, { public: true });

register("goals", "auto_propose", (ctx, _input = {}) => {
  enforceEthosInvariant("goals_auto_propose");
  return generateAutoGoalProposals(ctx);
}, { public: false });

register("goals", "config", (ctx, input = {}) => {
  enforceEthosInvariant("goals_config");
  ensureGoalSystem();

  // Only owner/admin can modify config
  if (!["owner", "admin", "founder"].includes(ctx.actor?.role)) {
    return { ok: true, config: ctx.state.goals.config, readonly: true };
  }

  // Update config (bounded)
  if (typeof input.maxActiveGoals === "number") {
    ctx.state.goals.config.maxActiveGoals = clamp(input.maxActiveGoals, 1, 20);
  }
  if (typeof input.evaluationThreshold === "number") {
    ctx.state.goals.config.evaluationThreshold = clamp(input.evaluationThreshold, 0.1, 0.95);
  }
  if (typeof input.autoProposalEnabled === "boolean") {
    ctx.state.goals.config.autoProposalEnabled = input.autoProposalEnabled;
  }
  if (typeof input.founderApprovalRequired === "boolean") {
    ctx.state.goals.config.founderApprovalRequired = input.founderApprovalRequired;
  }

  saveStateDebounced();
  return { ok: true, config: ctx.state.goals.config };
}, { public: false });

// ===== END GOAL SYSTEM MACROS =====

// ===== WORLD MODEL MACROS =====

register("worldmodel", "status", (ctx, _input = {}) => {
  enforceEthosInvariant("worldmodel_status");
  ensureWorldModel();

  return {
    ok: true,
    entities: ctx.state.worldModel.entities.size,
    relations: ctx.state.worldModel.relations.size,
    simulations: ctx.state.worldModel.simulations.size,
    snapshots: ctx.state.worldModel.snapshots.length,
    stats: ctx.state.worldModel.stats,
    config: ctx.state.worldModel.config,
    invariants: WORLD_MODEL_INVARIANTS
  };
}, { public: true });

register("worldmodel", "create_entity", (ctx, input = {}) => {
  enforceEthosInvariant("worldmodel_create_entity");
  return createWorldEntity(input);
}, { public: false });

register("worldmodel", "create_relation", (ctx, input = {}) => {
  enforceEthosInvariant("worldmodel_create_relation");
  return createWorldRelation(input);
}, { public: false });

register("worldmodel", "get_entity", (ctx, input = {}) => {
  enforceEthosInvariant("worldmodel_get_entity");
  ensureWorldModel();

  const entityId = String(input.entityId || input.id || "");
  if (!entityId) return { ok: false, error: "entityId required" };

  const includeRelations = input.includeRelations !== false;

  if (includeRelations) {
    return getEntityWithRelations(entityId);
  }

  const entity = ctx.state.worldModel.entities.get(entityId);
  if (!entity) return { ok: false, error: "Entity not found" };
  return { ok: true, entity };
}, { public: true });

register("worldmodel", "list_entities", (ctx, input = {}) => {
  enforceEthosInvariant("worldmodel_list_entities");
  ensureWorldModel();

  const type = input.type;
  const limit = clamp(Number(input.limit || 100), 1, 500);
  const search = String(input.search || "").toLowerCase();

  let entities = Array.from(ctx.state.worldModel.entities.values());

  if (type) entities = entities.filter(e => e.type === type);
  if (search) {entities = entities.filter(e =>
    e.name.toLowerCase().includes(search) ||
    e.description.toLowerCase().includes(search)
  );}

  entities = entities
    .sort((a, b) => b.state.salience - a.state.salience)
    .slice(0, limit)
    .map(e => ({
      id: e.id,
      name: e.name,
      type: e.type,
      salience: e.state.salience,
      confidence: e.state.confidence,
      relationCount: e.relationCount,
      createdAt: e.createdAt
    }));

  return { ok: true, entities, total: ctx.state.worldModel.entities.size };
}, { public: true });

register("worldmodel", "list_relations", (ctx, input = {}) => {
  enforceEthosInvariant("worldmodel_list_relations");
  ensureWorldModel();

  const entityId = input.entityId;
  const type = input.type;
  const limit = clamp(Number(input.limit || 100), 1, 500);

  let relations = Array.from(ctx.state.worldModel.relations.values());

  if (entityId) relations = relations.filter(r => r.from === entityId || r.to === entityId);
  if (type) relations = relations.filter(r => r.type === type);

  relations = relations
    .sort((a, b) => b.strength - a.strength)
    .slice(0, limit)
    .map(r => ({
      id: r.id,
      from: r.from,
      to: r.to,
      type: r.type,
      strength: r.strength,
      confidence: r.confidence
    }));

  return { ok: true, relations, total: ctx.state.worldModel.relations.size };
}, { public: true });

register("worldmodel", "simulate", (ctx, input = {}) => {
  enforceEthosInvariant("worldmodel_simulate");
  return runWorldSimulation(input);
}, { public: false });

register("worldmodel", "counterfactual", (ctx, input = {}) => {
  enforceEthosInvariant("worldmodel_counterfactual");
  return generateCounterfactual(input);
}, { public: false });

register("worldmodel", "get_simulation", (ctx, input = {}) => {
  enforceEthosInvariant("worldmodel_get_simulation");
  ensureWorldModel();

  const simId = String(input.simId || input.id || "");
  if (!simId) return { ok: false, error: "simId required" };

  const sim = ctx.state.worldModel.simulations.get(simId);
  if (!sim) return { ok: false, error: "Simulation not found" };

  return { ok: true, simulation: sim };
}, { public: true });

register("worldmodel", "list_simulations", (ctx, input = {}) => {
  enforceEthosInvariant("worldmodel_list_simulations");
  ensureWorldModel();

  const limit = clamp(Number(input.limit || 20), 1, 100);

  const simulations = Array.from(ctx.state.worldModel.simulations.values())
    .sort((a, b) => new Date(b.createdAt) - new Date(a.createdAt))
    .slice(0, limit)
    .map(s => ({
      id: s.id,
      type: s.type,
      status: s.status,
      hypothesis: s.config.hypothesis,
      insightCount: s.insights.length,
      createdAt: s.createdAt,
      completedAt: s.completedAt
    }));

  return { ok: true, simulations, total: ctx.state.worldModel.simulations.size };
}, { public: true });

register("worldmodel", "snapshot", (ctx, input = {}) => {
  enforceEthosInvariant("worldmodel_snapshot");
  return takeWorldSnapshot(input.label);
}, { public: false });

register("worldmodel", "list_snapshots", (ctx, _input = {}) => {
  enforceEthosInvariant("worldmodel_list_snapshots");
  ensureWorldModel();

  const snapshots = ctx.state.worldModel.snapshots.map(s => ({
    id: s.id,
    label: s.label,
    entityCount: s.entityCount,
    relationCount: s.relationCount,
    takenAt: s.takenAt
  }));

  return { ok: true, snapshots };
}, { public: true });

register("worldmodel", "extract_from_dtu", (ctx, input = {}) => {
  enforceEthosInvariant("worldmodel_extract");

  const dtuId = String(input.dtuId || "");
  if (!dtuId) return { ok: false, error: "dtuId required" };

  const dtu = ctx.state.dtus.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };

  return extractEntitiesFromDtu(dtu);
}, { public: false });

register("worldmodel", "config", (ctx, input = {}) => {
  enforceEthosInvariant("worldmodel_config");
  ensureWorldModel();

  // Only owner/admin can modify config
  if (!["owner", "admin", "founder"].includes(ctx.actor?.role)) {
    return { ok: true, config: ctx.state.worldModel.config, readonly: true };
  }

  if (typeof input.maxEntities === "number") {
    ctx.state.worldModel.config.maxEntities = clamp(input.maxEntities, 100, 100000);
  }
  if (typeof input.maxSimulationSteps === "number") {
    ctx.state.worldModel.config.maxSimulationSteps = clamp(input.maxSimulationSteps, 5, 100);
  }
  if (typeof input.autoExtractEnabled === "boolean") {
    ctx.state.worldModel.config.autoExtractEnabled = input.autoExtractEnabled;
  }

  saveStateDebounced();
  return { ok: true, config: ctx.state.worldModel.config };
}, { public: false });

register("worldmodel", "update_entity", (ctx, input = {}) => {
  enforceEthosInvariant("worldmodel_update_entity");
  ensureWorldModel();

  const entityId = String(input.entityId || input.id || "");
  if (!entityId) return { ok: false, error: "entityId required" };

  const entity = ctx.state.worldModel.entities.get(entityId);
  if (!entity) return { ok: false, error: "Entity not found" };

  // Update allowed fields
  if (input.name) entity.name = String(input.name).slice(0, 200);
  if (input.description) entity.description = String(input.description).slice(0, 2000);
  if (typeof input.confidence === "number") entity.state.confidence = clamp(input.confidence, 0, 1);
  if (typeof input.salience === "number") entity.state.salience = clamp(input.salience, 0, 1);
  if (typeof input.volatility === "number") entity.state.volatility = clamp(input.volatility, 0, 1);
  if (input.properties && typeof input.properties === "object") {
    entity.state.properties = { ...entity.state.properties, ...input.properties };
  }

  entity.updatedAt = nowISO();
  saveStateDebounced();

  return { ok: true, entity };
}, { public: false });

register("worldmodel", "delete_entity", (ctx, input = {}) => {
  enforceEthosInvariant("worldmodel_delete_entity");
  ensureWorldModel();

  const entityId = String(input.entityId || input.id || "");
  if (!entityId) return { ok: false, error: "entityId required" };

  const entity = ctx.state.worldModel.entities.get(entityId);
  if (!entity) return { ok: false, error: "Entity not found" };

  // Delete associated relations
  const relationsToDelete = Array.from(ctx.state.worldModel.relations.entries())
    .filter(([_, r]) => r.from === entityId || r.to === entityId)
    .map(([id]) => id);

  for (const relId of relationsToDelete) {
    ctx.state.worldModel.relations.delete(relId);
  }

  ctx.state.worldModel.entities.delete(entityId);
  saveStateDebounced();

  return { ok: true, deleted: entityId, relationsRemoved: relationsToDelete.length };
}, { public: false });

// ===== END WORLD MODEL MACROS =====

// ===== SEMANTIC UNDERSTANDING MACROS =====

register("semantic", "status", (ctx, _input = {}) => {
  enforceEthosInvariant("semantic_status");
  ensureSemanticEngine();
  return {
    ok: true,
    embeddings: ctx.state.semantic.embeddings.size,
    vocabularySize: ctx.state.semantic.vocabulary.size,
    stats: ctx.state.semantic.stats,
    config: ctx.state.semantic.config,
    invariants: SEMANTIC_INVARIANTS
  };
}, { public: true });

register("semantic", "similar", (ctx, input = {}) => {
  enforceEthosInvariant("semantic_similar");
  const query = String(input.query || "");
  if (!query) return { ok: false, error: "query required" };
  const limit = clamp(Number(input.limit || 10), 1, 50);
  const threshold = input.threshold;
  const results = findSimilarDtus(query, limit, threshold);
  return { ok: true, results, query };
}, { public: true });

register("semantic", "embed", (ctx, input = {}) => {
  enforceEthosInvariant("semantic_embed");
  const text = String(input.text || "");
  if (!text) return { ok: false, error: "text required" };
  const embedding = computeLocalEmbedding(text);
  return { ok: true, embedding, dimension: embedding.length };
}, { public: true });

register("semantic", "classify_intent", (ctx, input = {}) => {
  enforceEthosInvariant("semantic_classify");
  const text = String(input.text || "");
  if (!text) return { ok: false, error: "text required" };
  return { ok: true, ...classifySemanticIntent(text) };
}, { public: true });

register("semantic", "extract_entities", (ctx, input = {}) => {
  enforceEthosInvariant("semantic_extract");
  const text = String(input.text || "");
  if (!text) return { ok: false, error: "text required" };
  const entities = extractEntities(text);
  return { ok: true, entities };
}, { public: true });

register("semantic", "semantic_roles", (ctx, input = {}) => {
  enforceEthosInvariant("semantic_roles");
  const text = String(input.text || "");
  if (!text) return { ok: false, error: "text required" };
  const roles = extractSemanticRoles(text);
  return { ok: true, roles };
}, { public: true });

register("semantic", "compare", (ctx, input = {}) => {
  enforceEthosInvariant("semantic_compare");
  const text1 = String(input.text1 || input.a || "");
  const text2 = String(input.text2 || input.b || "");
  if (!text1 || !text2) return { ok: false, error: "text1 and text2 required" };
  const emb1 = computeLocalEmbedding(text1);
  const emb2 = computeLocalEmbedding(text2);
  const similarity = cosineSimilarity(emb1, emb2);
  return { ok: true, similarity, interpretation: similarity > 0.8 ? "very similar" : similarity > 0.6 ? "related" : similarity > 0.4 ? "somewhat related" : "different" };
}, { public: true });

// ===== END SEMANTIC UNDERSTANDING MACROS =====

// ===== TRANSFER LEARNING MACROS =====

register("transfer", "status", (ctx, _input = {}) => {
  enforceEthosInvariant("transfer_status");
  ensureTransferEngine();
  return {
    ok: true,
    patterns: ctx.state.transfer.patterns.size,
    domainMappings: ctx.state.transfer.domainMappings.size,
    transfers: ctx.state.transfer.transfers.length,
    stats: ctx.state.transfer.stats,
    config: ctx.state.transfer.config,
    invariants: TRANSFER_INVARIANTS
  };
}, { public: true });

register("transfer", "classify_domain", (ctx, input = {}) => {
  enforceEthosInvariant("transfer_classify");
  const dtuId = String(input.dtuId || "");
  if (!dtuId) return { ok: false, error: "dtuId required" };
  const dtu = ctx.state.dtus?.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };
  const domain = classifyDomain(dtu);
  return { ok: true, dtuId, domain };
}, { public: true });

register("transfer", "extract_pattern", (ctx, input = {}) => {
  enforceEthosInvariant("transfer_extract");
  const dtuIds = input.dtuIds;
  if (!Array.isArray(dtuIds) || dtuIds.length === 0) return { ok: false, error: "dtuIds array required" };
  return extractPattern(dtuIds, input.name);
}, { public: false });

register("transfer", "list_patterns", (ctx, _input = {}) => {
  enforceEthosInvariant("transfer_list");
  ensureTransferEngine();
  const patterns = Array.from(ctx.state.transfer.patterns.values())
    .map(p => ({ id: p.id, name: p.name, sourceDomain: p.sourceDomain, confidence: p.confidence, dtuCount: p.structure.dtuCount }));
  return { ok: true, patterns };
}, { public: true });

register("transfer", "find_analogies", (ctx, input = {}) => {
  enforceEthosInvariant("transfer_analogies");
  const targetDomain = String(input.domain || "general");
  const query = String(input.query || "");
  const results = findAnalogousPatterns(targetDomain, query);
  return { ok: true, results };
}, { public: true });

register("transfer", "apply_pattern", (ctx, input = {}) => {
  enforceEthosInvariant("transfer_apply");
  const patternId = String(input.patternId || "");
  const targetDomain = String(input.targetDomain || "");
  if (!patternId) return { ok: false, error: "patternId required" };
  if (!targetDomain) return { ok: false, error: "targetDomain required" };
  return applyPatternToTarget(patternId, targetDomain, input.context);
}, { public: false });

register("transfer", "list_transfers", (ctx, _input = {}) => {
  enforceEthosInvariant("transfer_list_transfers");
  ensureTransferEngine();
  const transfers = ctx.state.transfer.transfers.slice(-50).map(t => ({
    id: t.id, sourceDomain: t.sourceDomain, targetDomain: t.targetDomain,
    confidence: t.confidence, status: t.status, createdAt: t.createdAt
  }));
  return { ok: true, transfers };
}, { public: true });

// ===== END TRANSFER LEARNING MACROS =====

// ===== EXPERIENCE LEARNING MACROS =====

register("experience", "status", (ctx, _input = {}) => {
  enforceEthosInvariant("experience_status");
  ensureExperienceLearning();
  const el = ctx.state.experienceLearning;
  return {
    ok: true,
    episodes: el.episodes.length,
    patterns: el.patterns.size,
    strategies: el.strategies.size,
    stats: el.stats,
    config: el.config
  };
}, { public: true });

register("experience", "retrieve", (ctx, input = {}) => {
  enforceEthosInvariant("experience_retrieve");
  const domain = String(input.domain || "general");
  const topic = String(input.topic || "");
  const keywords = Array.isArray(input.keywords) ? input.keywords : [];
  return { ok: true, ...retrieveExperience(domain, topic, keywords) };
}, { public: true });

register("experience", "patterns", (ctx, input = {}) => {
  enforceEthosInvariant("experience_patterns");
  ensureExperienceLearning();
  const patterns = Array.from(ctx.state.experienceLearning.patterns.values())
    .sort((a, b) => b.confidence - a.confidence)
    .slice(0, Number(input.limit || 50))
    .map(p => ({ id: p.id, domain: p.domain, bestStrategy: p.bestStrategy, confidence: p.confidence, episodeCount: p.episodeCount, keywords: p.keywords }));
  return { ok: true, patterns };
}, { public: true });

register("experience", "consolidate", (ctx, _input = {}) => {
  enforceEthosInvariant("experience_consolidate");
  consolidateExperience();
  return { ok: true, message: "Experience consolidated" };
}, { public: false });

register("experience", "strategies", (ctx, input = {}) => {
  enforceEthosInvariant("experience_strategies");
  ensureExperienceLearning();
  const strategies = Array.from(ctx.state.experienceLearning.strategies.values())
    .sort((a, b) => b.avgQuality - a.avgQuality)
    .slice(0, Number(input.limit || 50));
  return { ok: true, strategies };
}, { public: true });

register("experience", "recent", (ctx, input = {}) => {
  enforceEthosInvariant("experience_recent");
  ensureExperienceLearning();
  const limit = clamp(Number(input.limit || 20), 1, 100);
  const episodes = ctx.state.experienceLearning.episodes.slice(-limit).reverse();
  return { ok: true, episodes };
}, { public: true });

// ===== END EXPERIENCE LEARNING MACROS =====

// ===== ATTENTION MANAGEMENT MACROS =====

register("attention", "status", (ctx, _input = {}) => {
  enforceEthosInvariant("attention_status");
  ensureAttentionManager();
  const attn = ctx.state.attention;
  const activeThreads = Array.from(attn.threads.values()).filter(t => t.status === "active");
  return {
    ok: true,
    focus: attn.focus,
    activeThreads: activeThreads.map(t => ({ id: t.id, type: t.type, priority: t.priority, description: t.description })),
    queueLength: attn.queue.length,
    backgroundTasks: attn.background.filter(t => t.status === "pending").length,
    stats: attn.stats,
    config: attn.config
  };
}, { public: true });

register("attention", "create_thread", (ctx, input = {}) => {
  enforceEthosInvariant("attention_create");
  return createCognitiveThread(input);
}, { public: false });

register("attention", "complete_thread", (ctx, input = {}) => {
  enforceEthosInvariant("attention_complete");
  const threadId = String(input.threadId || input.id || "");
  if (!threadId) return { ok: false, error: "threadId required" };
  return completeCognitiveThread(threadId, input.output || {});
}, { public: false });

register("attention", "list_threads", (ctx, _input = {}) => {
  enforceEthosInvariant("attention_list");
  ensureAttentionManager();
  const threads = Array.from(ctx.state.attention.threads.values())
    .sort((a, b) => b.priority - a.priority)
    .map(t => ({ id: t.id, type: t.type, priority: t.priority, status: t.status, description: t.description, createdAt: t.createdAt }));
  return { ok: true, threads };
}, { public: true });

register("attention", "queue", (ctx, _input = {}) => {
  enforceEthosInvariant("attention_queue");
  ensureAttentionManager();
  return { ok: true, queue: ctx.state.attention.queue, completed: ctx.state.attention.completed.slice(-10) };
}, { public: true });

register("attention", "add_background", (ctx, input = {}) => {
  enforceEthosInvariant("attention_background");
  return addBackgroundTask(input);
}, { public: false });

// ===== END ATTENTION MANAGEMENT MACROS =====

// ===== REFLECTION ENGINE MACROS =====

register("reflection", "status", (ctx, _input = {}) => {
  enforceEthosInvariant("reflection_status");
  ensureReflectionEngine();
  const ref = ctx.state.reflection;
  return {
    ok: true,
    reflections: ref.reflections.length,
    insights: ref.insights.size,
    selfModel: ref.selfModel,
    stats: ref.stats,
    config: ref.config
  };
}, { public: true });

register("reflection", "recent", (ctx, input = {}) => {
  enforceEthosInvariant("reflection_recent");
  ensureReflectionEngine();
  const limit = clamp(Number(input.limit || 10), 1, 50);
  const reflections = ctx.state.reflection.reflections.slice(-limit).reverse()
    .map(r => ({ id: r.id, timestamp: r.timestamp, quality: r.quality, checks: r.checks, insights: r.insights, corrections: r.corrections }));
  return { ok: true, reflections };
}, { public: true });

register("reflection", "self_model", (ctx, _input = {}) => {
  enforceEthosInvariant("reflection_self_model");
  ensureReflectionEngine();
  return { ok: true, selfModel: ctx.state.reflection.selfModel };
}, { public: true });

register("reflection", "insights", (ctx, _input = {}) => {
  enforceEthosInvariant("reflection_insights");
  ensureReflectionEngine();
  const insights = Array.from(ctx.state.reflection.insights.values()).slice(-50);
  return { ok: true, insights };
}, { public: true });

register("reflection", "reflect_now", (ctx, input = {}) => {
  enforceEthosInvariant("reflection_manual");
  const result = reflectOnResponse({
    prompt: String(input.prompt || ""),
    response: String(input.response || ""),
    mode: input.mode || "explore",
    domain: input.domain || "general",
    llmUsed: !!input.llmUsed,
    relevantDtus: input.relevantDtus || []
  });
  return { ok: true, reflection: result };
}, { public: false });

// ===== END REFLECTION ENGINE MACROS =====

// ===== COMMONSENSE MACROS =====

register("commonsense", "status", (ctx, _input = {}) => {
  enforceEthosInvariant("commonsense_status");
  ensureCommonsenseSubstrate();
  return {
    ok: true,
    facts: ctx.state.commonsense.facts.size,
    categories: Object.fromEntries(Object.entries(ctx.state.commonsense.categories).map(([k, v]) => [k, v.length])),
    assumptions: ctx.state.commonsense.assumptions.size,
    stats: ctx.state.commonsense.stats,
    invariants: COMMONSENSE_INVARIANTS
  };
}, { public: true });

register("commonsense", "query", (ctx, input = {}) => {
  enforceEthosInvariant("commonsense_query");
  const query = String(input.query || "");
  const category = input.category;
  const results = queryCommonsense(query, category);
  return { ok: true, results, query };
}, { public: true });

register("commonsense", "add_fact", (ctx, input = {}) => {
  enforceEthosInvariant("commonsense_add");
  return addCommonsenseFact(input);
}, { public: false });

register("commonsense", "surface_assumptions", (ctx, input = {}) => {
  enforceEthosInvariant("commonsense_surface");
  const dtuId = String(input.dtuId || "");
  if (!dtuId) return { ok: false, error: "dtuId required" };
  return surfaceAssumptions(dtuId);
}, { public: true });

register("commonsense", "list_facts", (ctx, input = {}) => {
  enforceEthosInvariant("commonsense_list");
  ensureCommonsenseSubstrate();
  const category = input.category;
  let facts = Array.from(ctx.state.commonsense.facts.values());
  if (category) facts = facts.filter(f => f.category === category);
  facts = facts.slice(0, 100).map(f => ({ id: f.id, fact: f.fact, category: f.category, confidence: f.confidence }));
  return { ok: true, facts };
}, { public: true });

register("commonsense", "get_assumptions", (ctx, input = {}) => {
  enforceEthosInvariant("commonsense_assumptions");
  const dtuId = String(input.dtuId || "");
  if (!dtuId) return { ok: false, error: "dtuId required" };
  ensureCommonsenseSubstrate();
  const data = ctx.state.commonsense.assumptions.get(dtuId);
  if (!data) return { ok: true, assumptions: [], message: "No assumptions surfaced yet" };
  return { ok: true, assumptions: data.assumptions };
}, { public: true });

// ===== END COMMONSENSE MACROS =====

// ===== GROUNDING MACROS =====

register("grounding", "status", (ctx, _input = {}) => {
  enforceEthosInvariant("grounding_status");
  ensureGroundingEngine();
  return {
    ok: true,
    sensors: ctx.state.grounding.sensors.size,
    readings: ctx.state.grounding.readings.length,
    groundedDtus: ctx.state.grounding.groundedDtus.size,
    pendingActions: ctx.state.grounding.pendingActions.length,
    calendarEvents: ctx.state.grounding.calendar.size,
    stats: ctx.state.grounding.stats,
    invariants: GROUNDING_INVARIANTS
  };
}, { public: true });

register("grounding", "register_sensor", (ctx, input = {}) => {
  enforceEthosInvariant("grounding_sensor");
  return registerSensor(input);
}, { public: false });

register("grounding", "record_reading", (ctx, input = {}) => {
  enforceEthosInvariant("grounding_reading");
  const sensorId = String(input.sensorId || "");
  if (!sensorId) return { ok: false, error: "sensorId required" };
  if (input.value === undefined) return { ok: false, error: "value required" };
  return recordSensorReading(sensorId, input.value, input.timestamp);
}, { public: false });

register("grounding", "list_sensors", (ctx, _input = {}) => {
  enforceEthosInvariant("grounding_list_sensors");
  ensureGroundingEngine();
  const sensors = Array.from(ctx.state.grounding.sensors.values()).map(s => ({
    id: s.id, name: s.name, type: s.type, unit: s.unit,
    lastReading: s.lastReading?.value, status: s.status
  }));
  return { ok: true, sensors };
}, { public: true });

register("grounding", "ground_dtu", (ctx, input = {}) => {
  enforceEthosInvariant("grounding_ground");
  const dtuId = String(input.dtuId || "");
  if (!dtuId) return { ok: false, error: "dtuId required" };
  return groundDtu(dtuId, input);
}, { public: false });

register("grounding", "link_calendar", (ctx, input = {}) => {
  enforceEthosInvariant("grounding_calendar");
  const dtuId = String(input.dtuId || "");
  if (!dtuId) return { ok: false, error: "dtuId required" };
  return linkToCalendar(dtuId, input);
}, { public: false });

register("grounding", "propose_action", (ctx, input = {}) => {
  enforceEthosInvariant("grounding_propose");
  return proposeAction(input);
}, { public: false });

register("grounding", "approve_action", (ctx, input = {}) => {
  enforceEthosInvariant("grounding_approve");
  if (!["owner", "admin", "founder"].includes(ctx.actor?.role)) {
    return { ok: false, error: "Action approval requires owner/admin role" };
  }
  const actionId = String(input.actionId || "");
  if (!actionId) return { ok: false, error: "actionId required" };
  return approveAction(actionId);
}, { public: false });

register("grounding", "pending_actions", (ctx, _input = {}) => {
  enforceEthosInvariant("grounding_pending");
  ensureGroundingEngine();
  const actions = ctx.state.grounding.pendingActions.map(a => ({
    id: a.id, type: a.type, description: a.description, goalId: a.goalId, proposedAt: a.proposedAt
  }));
  return { ok: true, actions };
}, { public: true });

register("grounding", "context", (ctx, _input = {}) => {
  enforceEthosInvariant("grounding_context");
  return { ok: true, context: getCurrentGroundedContext() };
}, { public: true });

register("grounding", "recent_readings", (ctx, input = {}) => {
  enforceEthosInvariant("grounding_readings");
  ensureGroundingEngine();
  const limit = clamp(Number(input.limit || 20), 1, 100);
  const readings = ctx.state.grounding.readings.slice(-limit);
  return { ok: true, readings };
}, { public: true });

// ===== END GROUNDING MACROS =====

// ===== REASONING CHAINS MACROS =====

register("reasoning", "status", (ctx, _input = {}) => {
  enforceEthosInvariant("reasoning_status");
  ensureReasoningEngine();
  return {
    ok: true,
    chains: ctx.state.reasoning.chains.size,
    steps: ctx.state.reasoning.steps.size,
    stats: ctx.state.reasoning.stats,
    config: ctx.state.reasoning.config,
    invariants: REASONING_INVARIANTS
  };
}, { public: true });

register("reasoning", "create_chain", (ctx, input = {}) => {
  enforceEthosInvariant("reasoning_create");
  return createReasoningChain(input);
}, { public: false });

register("reasoning", "add_step", (ctx, input = {}) => {
  enforceEthosInvariant("reasoning_step");
  const chainId = String(input.chainId || "");
  if (!chainId) return { ok: false, error: "chainId required" };
  return addReasoningStep(chainId, input);
}, { public: false });

register("reasoning", "conclude", (ctx, input = {}) => {
  enforceEthosInvariant("reasoning_conclude");
  const chainId = String(input.chainId || "");
  if (!chainId) return { ok: false, error: "chainId required" };
  return concludeChain(chainId, input);
}, { public: false });

register("reasoning", "get_trace", (ctx, input = {}) => {
  enforceEthosInvariant("reasoning_trace");
  const chainId = String(input.chainId || "");
  if (!chainId) return { ok: false, error: "chainId required" };
  return getReasoningTrace(chainId);
}, { public: true });

register("reasoning", "validate_step", (ctx, input = {}) => {
  enforceEthosInvariant("reasoning_validate");
  const stepId = String(input.stepId || "");
  if (!stepId) return { ok: false, error: "stepId required" };
  return validateStep(stepId);
}, { public: true });

register("reasoning", "list_chains", (ctx, _input = {}) => {
  enforceEthosInvariant("reasoning_list");
  ensureReasoningEngine();
  const chains = Array.from(ctx.state.reasoning.chains.values())
    .slice(-50)
    .map(c => ({ id: c.id, question: c.question, status: c.status, stepCount: c.steps.length, confidence: c.confidence }));
  return { ok: true, chains };
}, { public: true });

// ===== END REASONING CHAINS MACROS =====

// ===== INFERENCE ENGINE MACROS =====

register("inference", "status", (ctx, _input = {}) => {
  enforceEthosInvariant("inference_status");
  return getInferenceStatus();
}, { public: true });

register("inference", "add_fact", (ctx, input = {}) => {
  enforceEthosInvariant("inference_add_fact");
  return addInferenceFact(input);
}, { public: true });

register("inference", "add_rule", (ctx, input = {}) => {
  enforceEthosInvariant("inference_add_rule");
  return addInferenceRule(input);
}, { public: true });

register("inference", "query", (ctx, input = {}) => {
  enforceEthosInvariant("inference_query");
  return queryWithInference(input);
}, { public: true });

register("inference", "syllogism", (ctx, input = {}) => {
  enforceEthosInvariant("inference_syllogism");
  return syllogisticReason(input);
}, { public: true });

register("inference", "forward_chain", (ctx, input = {}) => {
  enforceEthosInvariant("inference_forward_chain");
  const derivations = forwardChain(input.maxIterations);
  return {
    ok: true,
    derivations: derivations.map(d => ({
      subject: d.subject,
      predicate: d.predicate,
      object: d.object,
      negated: d.negated,
      confidence: d.confidence,
      derivedFrom: d.derivedFrom
    }))
  };
}, { public: true });

// ===== END INFERENCE ENGINE MACROS =====

// ===== HYPOTHESIS ENGINE MACROS =====

register("hypothesis", "status", (ctx, _input = {}) => {
  enforceEthosInvariant("hypothesis_status");
  ensureHypothesisEngine();
  return {
    ok: true,
    hypotheses: ctx.state.hypothesisEngine.hypotheses.size,
    experiments: ctx.state.hypothesisEngine.experiments.size,
    evidence: ctx.state.hypothesisEngine.evidence.size,
    stats: ctx.state.hypothesisEngine.stats,
    config: ctx.state.hypothesisEngine.config,
    invariants: HYPOTHESIS_INVARIANTS
  };
}, { public: true });

register("hypothesis", "propose", (ctx, input = {}) => {
  enforceEthosInvariant("hypothesis_propose");
  return proposeHypothesis(input);
}, { public: false });

register("hypothesis", "design_experiment", (ctx, input = {}) => {
  enforceEthosInvariant("hypothesis_experiment");
  const hypothesisId = String(input.hypothesisId || "");
  if (!hypothesisId) return { ok: false, error: "hypothesisId required" };
  return designExperiment(hypothesisId, input);
}, { public: false });

register("hypothesis", "record_evidence", (ctx, input = {}) => {
  enforceEthosInvariant("hypothesis_evidence");
  const hypothesisId = String(input.hypothesisId || "");
  if (!hypothesisId) return { ok: false, error: "hypothesisId required" };
  return recordEvidence(hypothesisId, input);
}, { public: false });

register("hypothesis", "evaluate", (ctx, input = {}) => {
  enforceEthosInvariant("hypothesis_evaluate");
  const hypothesisId = String(input.hypothesisId || "");
  if (!hypothesisId) return { ok: false, error: "hypothesisId required" };
  return evaluateHypothesis(hypothesisId);
}, { public: false });

register("hypothesis", "get", (ctx, input = {}) => {
  enforceEthosInvariant("hypothesis_get");
  ensureHypothesisEngine();
  const hypothesisId = String(input.hypothesisId || input.id || "");
  if (!hypothesisId) return { ok: false, error: "hypothesisId required" };
  const h = ctx.state.hypothesisEngine.hypotheses.get(hypothesisId);
  if (!h) return { ok: false, error: "Hypothesis not found" };
  return { ok: true, hypothesis: h };
}, { public: true });

register("hypothesis", "list", (ctx, input = {}) => {
  enforceEthosInvariant("hypothesis_list");
  ensureHypothesisEngine();
  const state = input.state;
  let hypotheses = Array.from(ctx.state.hypothesisEngine.hypotheses.values());
  if (state) hypotheses = hypotheses.filter(h => h.state === state);
  hypotheses = hypotheses.slice(-50).map(h => ({
    id: h.id, statement: h.statement.slice(0, 100), state: h.state,
    posteriorConfidence: h.posteriorConfidence, evidenceCount: h.evidenceFor.length + h.evidenceAgainst.length
  }));
  return { ok: true, hypotheses };
}, { public: true });

// ===== END HYPOTHESIS ENGINE MACROS =====

// ===== METACOGNITION MACROS =====

register("metacognition", "status", (ctx, _input = {}) => {
  enforceEthosInvariant("metacognition_status");
  ensureMetacognitionSystem();
  return {
    ok: true,
    assessments: ctx.state.metacognition.assessments.length,
    predictions: ctx.state.metacognition.predictions.size,
    blindSpots: ctx.state.metacognition.blindSpots.length,
    stats: ctx.state.metacognition.stats,
    invariants: METACOGNITION_INVARIANTS
  };
}, { public: true });

register("metacognition", "assess", (ctx, input = {}) => {
  enforceEthosInvariant("metacognition_assess");
  const topic = String(input.topic || "");
  if (!topic) return { ok: false, error: "topic required" };
  return assessKnowledge(topic);
}, { public: true });

register("metacognition", "predict", (ctx, input = {}) => {
  enforceEthosInvariant("metacognition_predict");
  return recordPrediction(input);
}, { public: false });

register("metacognition", "resolve_prediction", (ctx, input = {}) => {
  enforceEthosInvariant("metacognition_resolve");
  const predictionId = String(input.predictionId || input.id || "");
  if (!predictionId) return { ok: false, error: "predictionId required" };
  const wasCorrect = input.correct === true || input.wasCorrect === true;
  return resolvePrediction(predictionId, wasCorrect);
}, { public: false });

register("metacognition", "calibration", (ctx, _input = {}) => {
  enforceEthosInvariant("metacognition_calibration");
  return getCalibrationReport();
}, { public: true });

register("metacognition", "select_strategy", (ctx, input = {}) => {
  enforceEthosInvariant("metacognition_strategy");
  const problem = String(input.problem || "");
  if (!problem) return { ok: false, error: "problem description required" };
  return selectStrategy(problem);
}, { public: true });

register("metacognition", "blind_spots", (ctx, _input = {}) => {
  enforceEthosInvariant("metacognition_blindspots");
  ensureMetacognitionSystem();
  const spots = ctx.state.metacognition.blindSpots.slice(-20);
  return { ok: true, blindSpots: spots };
}, { public: true });

// Introspection macros
register("metacognition", "introspect", (ctx, _input = {}) => {
  enforceEthosInvariant("metacognition_introspect");
  return introspectOnFailures();
}, { public: true });

register("metacognition", "analyze_failure", (ctx, input = {}) => {
  enforceEthosInvariant("metacognition_analyze_failure");
  const predictionId = String(input.predictionId || input.id || "");
  if (!predictionId) return { ok: false, error: "predictionId required" };
  return analyzeFailure(predictionId);
}, { public: true });

register("metacognition", "adapt_strategy", (ctx, input = {}) => {
  enforceEthosInvariant("metacognition_adapt");
  const domain = String(input.domain || "general");
  return adaptReasoningStrategy(domain, input.feedback || {});
}, { public: true });

register("metacognition", "introspection_status", (ctx, _input = {}) => {
  enforceEthosInvariant("metacognition_introspection_status");
  return getIntrospectionStatus();
}, { public: true });

register("metacognition", "adjust_confidence", (ctx, input = {}) => {
  enforceEthosInvariant("metacognition_adjust_confidence");
  const domain = String(input.domain || "general");
  const confidence = clamp(Number(input.confidence || 0.5), 0, 1);
  return adjustConfidenceFromLearning(domain, confidence);
}, { public: true });

// ===== END METACOGNITION MACROS =====

// ===== EXPLANATION ENGINE MACROS =====

register("explanation", "status", (ctx, _input = {}) => {
  enforceEthosInvariant("explanation_status");
  ensureExplanationEngine();
  return {
    ok: true,
    generated: ctx.state.explanations.generated.length,
    stats: ctx.state.explanations.stats,
    invariants: EXPLANATION_INVARIANTS
  };
}, { public: true });

register("explanation", "generate", (ctx, input = {}) => {
  enforceEthosInvariant("explanation_generate");
  return generateExplanation(input);
}, { public: true });

register("explanation", "explain_dtu", (ctx, input = {}) => {
  enforceEthosInvariant("explanation_dtu");
  const dtuId = String(input.dtuId || "");
  const changeType = String(input.changeType || "created");
  if (!dtuId) return { ok: false, error: "dtuId required" };
  return explainDtuChange(dtuId, changeType);
}, { public: true });

register("explanation", "recent", (ctx, input = {}) => {
  enforceEthosInvariant("explanation_recent");
  ensureExplanationEngine();
  const limit = clamp(Number(input.limit || 20), 1, 100);
  const explanations = ctx.state.explanations.generated.slice(-limit);
  return { ok: true, explanations };
}, { public: true });

// ===== END EXPLANATION ENGINE MACROS =====

// ===== META-LEARNING MACROS =====

register("metalearning", "status", (ctx, _input = {}) => {
  enforceEthosInvariant("metalearning_status");
  ensureMetaLearningSystem();
  return {
    ok: true,
    strategies: ctx.state.metaLearning.strategies.size,
    performance: ctx.state.metaLearning.performance.length,
    adaptations: ctx.state.metaLearning.adaptations.length,
    curriculums: ctx.state.metaLearning.curriculum.length,
    stats: ctx.state.metaLearning.stats,
    invariants: META_LEARNING_INVARIANTS
  };
}, { public: true });

register("metalearning", "define_strategy", (ctx, input = {}) => {
  enforceEthosInvariant("metalearning_define");
  return defineLearningStrategy(input);
}, { public: false });

register("metalearning", "record_outcome", (ctx, input = {}) => {
  enforceEthosInvariant("metalearning_outcome");
  const strategyId = String(input.strategyId || "");
  if (!strategyId) return { ok: false, error: "strategyId required" };
  return recordStrategyOutcome(strategyId, input);
}, { public: false });

register("metalearning", "adapt", (ctx, input = {}) => {
  enforceEthosInvariant("metalearning_adapt");
  const strategyId = String(input.strategyId || "");
  if (!strategyId) return { ok: false, error: "strategyId required" };
  return adaptStrategy(strategyId);
}, { public: false });

register("metalearning", "curriculum", (ctx, input = {}) => {
  enforceEthosInvariant("metalearning_curriculum");
  const topic = String(input.topic || "");
  if (!topic) return { ok: false, error: "topic required" };
  return generateCurriculum(topic, input);
}, { public: true });

register("metalearning", "best_strategy", (ctx, input = {}) => {
  enforceEthosInvariant("metalearning_best");
  const domain = String(input.domain || "general");
  return getBestStrategy(domain);
}, { public: true });

register("metalearning", "list_strategies", (ctx, _input = {}) => {
  enforceEthosInvariant("metalearning_list");
  ensureMetaLearningSystem();
  const strategies = Array.from(ctx.state.metaLearning.strategies.values())
    .map(s => ({ id: s.id, name: s.name, domain: s.domain, uses: s.uses, avgPerformance: s.avgPerformance }));
  return { ok: true, strategies };
}, { public: true });

register("metalearning", "adaptations", (ctx, _input = {}) => {
  enforceEthosInvariant("metalearning_adaptations");
  ensureMetaLearningSystem();
  const adaptations = ctx.state.metaLearning.adaptations.slice(-30);
  return { ok: true, adaptations };
}, { public: true });

// ===== END META-LEARNING MACROS =====

// ---- ctx ----
function makeCtx(req=null) {
  // Inject ATS affect policy into context so macros can consume depthBudget, riskBudget, etc.
  let affectPolicy = null;
  if (ATS && req?._atsSessionId) {
    try { affectPolicy = ATS.getSessionPolicy(req._atsSessionId); } catch {}
  }

  return {
    state: STATE,
    actor: (req && req.actor) ? req.actor : { userId: "anon", orgId: "public", role: AUTH_MODE === "public" ? "member" : "viewer", scopes: AUTH_MODE === "public" ? ["read", "write"] : ["read"] },
    env: {
      version: VERSION,
      llmReady: LLM_READY,
      openaiModel: { fast: OPENAI_MODEL_FAST, smart: OPENAI_MODEL_SMART }
    },
    affect: affectPolicy ? {
      policy: affectPolicy,
      sessionId: req._atsSessionId,
      // Convenience accessors for the most-used signals
      depthBudget: affectPolicy.cognition?.depthBudget ?? 5,
      riskBudget: affectPolicy.cognition?.riskBudget ?? 0.5,
      toolUseBias: affectPolicy.cognition?.toolUseBias ?? 0,
      writeStrength: affectPolicy.memory?.writeStrength ?? 0.5,
      latencyBudgetMs: affectPolicy.cognition?.latencyBudgetMs ?? 8000,
    } : null,
    // ===== GROUNDING → CONTEXT ENRICHMENT =====
    // Inject grounding context (sensors, time-of-day, environmental data) into macro context
    grounding: (() => {
      try {
        const _gr = STATE.grounding;
        if (!_gr) return null;
        const _hour = new Date().getHours();
        const _timeOfDay = _hour < 6 ? "night" : _hour < 12 ? "morning" : _hour < 18 ? "afternoon" : "evening";
        const _recentReadings = Array.isArray(_gr.readings)
          ? _gr.readings.slice(-5).map(r => ({ sensor: r.sensorId, value: r.value, unit: r.unit }))
          : [];
        return {
          timeOfDay: _timeOfDay,
          hour: _hour,
          recentReadings: _recentReadings,
          sensorCount: _gr.sensors?.size || 0,
          pendingActions: _gr.pendingActions?.length || 0,
        };
      } catch { return null; }
    })(),
    // ===== END GROUNDING → CONTEXT =====
    // ===== EXPERIENCE + ATTENTION + REFLECTION CONTEXT =====
    experience: (() => {
      try {
        ensureExperienceLearning();
        const el = STATE.experienceLearning;
        return {
          episodeCount: el.episodes.length,
          patternCount: el.patterns.size,
          topStrategies: Array.from(el.strategies.values())
            .sort((a, b) => b.avgQuality - a.avgQuality).slice(0, 3)
            .map(s => ({ domain: s.domain, strategy: s.strategy, quality: s.avgQuality }))
        };
      } catch { return null; }
    })(),
    attention: (() => {
      try {
        ensureAttentionManager();
        const attn = STATE.attention;
        return {
          focus: attn.focus,
          activeThreadCount: Array.from(attn.threads.values()).filter(t => t.status === "active").length,
          queueLength: attn.queue.length
        };
      } catch { return null; }
    })(),
    reflection: (() => {
      try {
        ensureReflectionEngine();
        return {
          calibration: STATE.reflection.selfModel.confidenceCalibration,
          strengths: STATE.reflection.selfModel.strengths,
          weaknesses: STATE.reflection.selfModel.weaknesses
        };
      } catch { return null; }
    })(),
    // ===== END EXPERIENCE + ATTENTION + REFLECTION =====
    reqMeta: req ? {
      ip: req.ip,
      ua: req.get("user-agent"),
      method: req.method,
      path: req.path,
      override: (req.query && (req.query.override === "1" || req.query.override === "true")) ? true : false,
      founderSecret: req.get("x-founder-secret") || "",
      at: nowISO()
    } : null,
    log,
    utils: { uid, normalizeText, simpleTokens, jaccard, cretiPack, clamp },
    macro: {
      run: (domain, name, input) => runMacro(domain, name, input, makeCtx(req)),
      listDomains,
      listMacros,
    },
    llm: {
      enabled: LLM_READY,
      async chat({ system, messages, temperature=0.3, maxTokens=800, model=null, timeoutMs=12000 }) {
        if (!LLM_READY) return { ok: false, reason: "LLM not configured (OPENAI_API_KEY missing)." };

        // ---- Budget & Circuit Breaker Check (Category 6: Cost Controls) ----
        const userId = req?.user?.id || req?.actor?.id || null;
        const budgetCheck = _LLM_BUDGET.checkBudget(userId);
        if (!budgetCheck.allowed) {
          structuredLog("warn", "llm_budget_blocked", { reason: budgetCheck.reason, userId });
          return { ok: false, reason: `LLM request blocked: ${budgetCheck.reason}` };
        }

        const chosen = model || OPENAI_MODEL_FAST;
        const payload = {
          model: chosen,
          temperature,
          max_tokens: maxTokens,
          messages: [
            ...(system ? [{ role: "system", content: system }] : []),
            ...(messages || [])
          ]
        };
        const ac = new AbortController();
        const t = setTimeout(() => ac.abort(), timeoutMs);
        try {
          const res = await fetch(`${OPENAI_BASE_URL}/chat/completions`, {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              "Authorization": `Bearer ${OPENAI_API_KEY}`
            },
            body: JSON.stringify(payload),
            signal: ac.signal
          }).finally(() => clearTimeout(t));
          const text = await res.text().catch(()=> "");
          const json = safeJson(text, null);
          if (!res.ok) {
            _LLM_BUDGET.recordFailure();
            return { ok: false, status: res.status, error: json || text };
          }
          // ---- Track Token Usage (Category 6: Cost Controls) ----
          const usage = json?.usage;
          _LLM_BUDGET.recordUsage(userId, usage?.prompt_tokens, usage?.completion_tokens);
          _LLM_BUDGET.recordSuccess();

          const content = json?.choices?.[0]?.message?.content ?? "";
          return { ok: true, content, raw: json };
        } catch (llmErr) {
          _LLM_BUDGET.recordFailure();
          throw llmErr;
        }
      }
    }
  };
}

// ---- DTU helpers ----
function dtusArray() { return Array.from(STATE.dtus.values()); }
function dtusByIds(ids=[]) {
  const out = [];
  for (const id of ids) {
    const d = STATE.dtus.get(id);
    if (d) out.push(d);
  }
  return out;
}
function upsertDTU(dtu, { broadcast = true, federate = false } = {}) {
  const isNew = !STATE.dtus.has(dtu.id);
  STATE.dtus.set(dtu.id, dtu);
  saveStateDebounced();

  // Broadcast DTU change via WebSocket (local-first realtime)
  if (broadcast && REALTIME.ready) {
    const eventType = isNew ? "dtu:created" : "dtu:updated";
    try {
      realtimeEmit(eventType, {
        id: dtu.id,
        title: dtu.title,
        tier: dtu.tier,
        tags: dtu.tags,
        updatedAt: dtu.updatedAt
      });
    } catch { /* best-effort */ }
  }

  // Optionally broadcast to federation (multi-node sync)
  if (federate && _c3Federation.enabled) {
    federationPublish("dtu:sync", {
      id: dtu.id,
      title: dtu.title,
      tier: dtu.tier,
      content: (dtu.content || "").slice(0, 5000), // truncate for network
      tags: dtu.tags,
      createdAt: dtu.createdAt,
      updatedAt: dtu.updatedAt,
      hash: dtu.hash
    }).catch(() => {});
  }

  return dtu;
}

// ============================================================================
// WAVE 2: CORE FEATURES (Version History, Templates, Import/Export, Queries)
// ============================================================================

// ---- DTU Version History ----
const VERSION_HISTORY = new Map(); // dtuId -> [{ version, snapshot, changedAt, changedBy }]
const MAX_VERSIONS_PER_DTU = Number(process.env.MAX_VERSIONS_PER_DTU || 50);

function saveDTUVersion(dtu, changedBy = "system") {
  if (!dtu?.id) return;
  const versions = VERSION_HISTORY.get(dtu.id) || [];
  const version = versions.length + 1;

  // Store a lightweight snapshot
  versions.push({
    version,
    snapshot: {
      title: dtu.title,
      content: dtu.content,
      creti: dtu.creti,
      tags: [...(dtu.tags || [])],
      tier: dtu.tier
    },
    changedAt: nowISO(),
    changedBy
  });

  // Trim old versions
  if (versions.length > MAX_VERSIONS_PER_DTU) {
    versions.splice(0, versions.length - MAX_VERSIONS_PER_DTU);
  }

  VERSION_HISTORY.set(dtu.id, versions);
}

function getDTUVersions(dtuId) {
  return VERSION_HISTORY.get(dtuId) || [];
}

function restoreDTUVersion(dtuId, version) {
  const versions = VERSION_HISTORY.get(dtuId);
  if (!versions) return { ok: false, error: "No version history" };

  const v = versions.find(v => v.version === version);
  if (!v) return { ok: false, error: "Version not found" };

  const dtu = STATE.dtus.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };

  // Save current state as new version before restoring
  saveDTUVersion(dtu, "restore");

  // Restore fields from snapshot
  Object.assign(dtu, v.snapshot, { updatedAt: nowISO() });
  upsertDTU(dtu);

  return { ok: true, restoredTo: version, dtu };
}

// ---- DTU Templates ----
const TEMPLATES = new Map(); // templateId -> { id, name, description, fields, defaultValues, tags }

// Built-in templates
const BUILTIN_TEMPLATES = [
  {
    id: "meeting-notes",
    name: "Meeting Notes",
    description: "Structured meeting notes with attendees, agenda, and action items",
    fields: ["attendees", "agenda", "discussion", "decisions", "actionItems"],
    defaultContent: `## Attendees\n- \n\n## Agenda\n1. \n\n## Discussion\n\n## Decisions\n- \n\n## Action Items\n- [ ] `,
    defaultTags: ["meeting", "notes"]
  },
  {
    id: "decision-record",
    name: "Decision Record",
    description: "Architecture Decision Record (ADR) format",
    fields: ["context", "decision", "consequences", "alternatives"],
    defaultContent: `## Context\nWhat is the issue that we're seeing that is motivating this decision?\n\n## Decision\nWhat is the change that we're proposing and/or doing?\n\n## Consequences\nWhat becomes easier or more difficult to do because of this change?\n\n## Alternatives Considered\n- `,
    defaultTags: ["decision", "adr"]
  },
  {
    id: "research-note",
    name: "Research Note",
    description: "Academic/research note with sources and methodology",
    fields: ["hypothesis", "methodology", "findings", "sources", "questions"],
    defaultContent: `## Hypothesis\n\n## Methodology\n\n## Findings\n\n## Sources\n- \n\n## Open Questions\n- `,
    defaultTags: ["research", "academic"]
  },
  {
    id: "daily-log",
    name: "Daily Log",
    description: "Daily reflection and progress tracking",
    fields: ["accomplished", "learned", "blockers", "tomorrow"],
    defaultContent: `## What I Accomplished\n- \n\n## What I Learned\n- \n\n## Blockers\n- \n\n## Tomorrow's Focus\n- `,
    defaultTags: ["daily", "log", "reflection"]
  },
  {
    id: "concept-definition",
    name: "Concept Definition",
    description: "Define a concept with examples and relationships",
    fields: ["definition", "examples", "relatedConcepts", "misconceptions"],
    defaultContent: `## Definition\n\n## Examples\n1. \n\n## Related Concepts\n- \n\n## Common Misconceptions\n- `,
    defaultTags: ["concept", "definition"]
  },
  {
    id: "creti-full",
    name: "CRETI Format",
    description: "Full CRETI structured thought",
    fields: ["context", "reasoning", "evidence", "tests", "impact"],
    defaultContent: `## Context\nWhat situation or problem prompted this thought?\n\n## Reasoning\nWhat is the logical chain of thought?\n\n## Evidence\nWhat supports this reasoning?\n\n## Tests\nHow can this be verified or falsified?\n\n## Impact\nWhat are the implications if true?`,
    defaultTags: ["creti", "structured"]
  }
];

// Initialize templates
BUILTIN_TEMPLATES.forEach(t => TEMPLATES.set(t.id, { ...t, builtIn: true }));

function createFromTemplate(templateId, overrides = {}) {
  const template = TEMPLATES.get(templateId);
  if (!template) return { ok: false, error: "Template not found" };

  return {
    ok: true,
    dtu: {
      title: overrides.title || `New ${template.name}`,
      content: overrides.content || template.defaultContent,
      tags: [...(template.defaultTags || []), ...(overrides.tags || [])],
      tier: overrides.tier || "regular",
      template: templateId
    }
  };
}

// ---- Import/Export ----
function exportDTUsToMarkdown(dtuIds = null, _options = {}) {
  const dtus = dtuIds
    ? dtuIds.map(id => STATE.dtus.get(id)).filter(Boolean)
    : dtusArray();

  const lines = [];

  for (const dtu of dtus) {
    lines.push(`# ${dtu.title}\n`);
    if (dtu.tags?.length) lines.push(`Tags: ${dtu.tags.map(t => `#${t}`).join(" ")}\n`);
    lines.push(`Tier: ${dtu.tier || "regular"}`);
    lines.push(`Created: ${dtu.createdAt}`);
    lines.push(`Updated: ${dtu.updatedAt}\n`);

    if (dtu.content) lines.push(dtu.content);
    if (dtu.creti) lines.push(`\n---\n**CRETI:**\n${dtu.creti}`);

    lines.push("\n---\n");
  }

  return { ok: true, markdown: lines.join("\n"), count: dtus.length };
}

function exportDTUsToJSON(dtuIds = null) {
  const dtus = dtuIds
    ? dtuIds.map(id => STATE.dtus.get(id)).filter(Boolean)
    : dtusArray();

  return {
    ok: true,
    data: {
      version: VERSION,
      exportedAt: nowISO(),
      dtus: dtus.map(d => ({
        id: d.id,
        title: d.title,
        content: d.content,
        creti: d.creti,
        tags: d.tags,
        tier: d.tier,
        createdAt: d.createdAt,
        updatedAt: d.updatedAt,
        connections: d.connections,
        lineage: d.lineage
      }))
    },
    count: dtus.length
  };
}

function importFromObsidian(markdownFiles) {
  // markdownFiles: [{ name, content }]
  const imported = [];
  const errors = [];

  for (const file of markdownFiles) {
    try {
      const content = file.content || "";
      const name = file.name?.replace(/\.md$/i, "") || "Untitled";

      // Extract YAML frontmatter if present
      const frontmatter = {};
      let body = content;
      const fmMatch = content.match(/^---\n([\s\S]*?)\n---\n([\s\S]*)$/);
      if (fmMatch) {
        try {
          // Simple YAML parsing for common fields
          const yamlStr = fmMatch[1];
          yamlStr.split("\n").forEach(line => {
            const [key, ...vals] = line.split(":");
            if (key && vals.length) {
              const val = vals.join(":").trim();
              frontmatter[key.trim()] = val.startsWith("[") ? JSON.parse(val.replace(/'/g, '"')) : val;
            }
          });
        } catch {}
        body = fmMatch[2];
      }

      // Extract tags from content (Obsidian style: #tag)
      const tagMatches = body.match(/#([a-zA-Z0-9_-]+)/g) || [];
      const tags = [...new Set([
        ...(frontmatter.tags || []),
        ...tagMatches.map(t => t.slice(1))
      ])].slice(0, 40);

      // Extract wikilinks [[link]]
      const wikilinks = body.match(/\[\[([^\]]+)\]\]/g)?.map(l => l.slice(2, -2)) || [];

      const dtu = {
        id: uid("dtu"),
        title: frontmatter.title || name,
        content: body.trim(),
        tags,
        tier: "regular",
        createdAt: frontmatter.created || nowISO(),
        updatedAt: nowISO(),
        source: "obsidian",
        meta: {
          originalFile: file.name,
          wikilinks,
          frontmatter
        }
      };

      upsertDTU(dtu, { broadcast: false });
      imported.push({ id: dtu.id, title: dtu.title });
    } catch (e) {
      errors.push({ file: file.name, error: String(e.message || e) });
    }
  }

  return { ok: true, imported, errors, count: imported.length };
}

function importFromRoam(roamJson) {
  // Roam JSON export format
  const imported = [];
  const errors = [];

  try {
    const pages = Array.isArray(roamJson) ? roamJson : [roamJson];

    for (const page of pages) {
      try {
        const processBlock = (block, depth = 0) => {
          const lines = [];
          const indent = "  ".repeat(depth);

          if (block.string) {
            lines.push(`${indent}- ${block.string}`);
          }

          if (block.children) {
            for (const child of block.children) {
              lines.push(...processBlock(child, depth + 1));
            }
          }

          return lines;
        };

        const content = page.children?.map(b => processBlock(b).join("\n")).join("\n") || "";

        // Extract tags from [[Page References]] and #hashtags
        const pageRefs = content.match(/\[\[([^\]]+)\]\]/g)?.map(r => r.slice(2, -2)) || [];
        const hashTags = content.match(/#([a-zA-Z0-9_-]+)/g)?.map(t => t.slice(1)) || [];
        const tags = [...new Set([...pageRefs.slice(0, 20), ...hashTags])].slice(0, 40);

        const dtu = {
          id: uid("dtu"),
          title: page.title || "Untitled",
          content,
          tags,
          tier: "regular",
          createdAt: page["create-time"] ? new Date(page["create-time"]).toISOString() : nowISO(),
          updatedAt: page["edit-time"] ? new Date(page["edit-time"]).toISOString() : nowISO(),
          source: "roam",
          meta: { uid: page.uid }
        };

        upsertDTU(dtu, { broadcast: false });
        imported.push({ id: dtu.id, title: dtu.title });
      } catch (e) {
        errors.push({ page: page.title, error: String(e.message || e) });
      }
    }
  } catch (e) {
    return { ok: false, error: String(e.message || e) };
  }

  return { ok: true, imported, errors, count: imported.length };
}

// ---- Query System (Dataview-like) ----
function queryDTUsAdvanced(query) {
  /*
   * Query syntax:
   * - WHERE tag:philosophy AND tier:mega
   * - WHERE created:>2024-01-01
   * - WHERE title:~"neural" (contains)
   * - SORT BY updatedAt DESC
   * - LIMIT 50
   */
  let results = dtusArray();
  const lines = query.split("\n").map(l => l.trim()).filter(Boolean);

  for (const line of lines) {
    const upper = line.toUpperCase();

    if (upper.startsWith("WHERE ")) {
      const conditions = line.slice(6).split(/\s+AND\s+/i);
      for (const cond of conditions) {
        const match = cond.match(/^(\w+):([<>=~]?)(.+)$/);
        if (!match) continue;

        const [, field, op, value] = match;
        const cleanValue = value.replace(/^["']|["']$/g, "").toLowerCase();

        results = results.filter(dtu => {
          let dtuValue;
          switch (field.toLowerCase()) {
            case "tag": case "tags":
              return (dtu.tags || []).some(t => t.toLowerCase().includes(cleanValue));
            case "tier":
              return (dtu.tier || "regular") === cleanValue;
            case "title":
              dtuValue = (dtu.title || "").toLowerCase();
              break;
            case "content":
              dtuValue = (dtu.content || "").toLowerCase();
              break;
            case "created": case "createdat":
              dtuValue = dtu.createdAt;
              break;
            case "updated": case "updatedat":
              dtuValue = dtu.updatedAt;
              break;
            default:
              dtuValue = dtu[field];
          }

          if (op === "~") return String(dtuValue).toLowerCase().includes(cleanValue);
          if (op === ">") return dtuValue > cleanValue;
          if (op === "<") return dtuValue < cleanValue;
          return String(dtuValue).toLowerCase() === cleanValue;
        });
      }
    }

    if (upper.startsWith("SORT BY ") || upper.startsWith("ORDER BY ")) {
      const sortMatch = line.match(/(?:SORT|ORDER)\s+BY\s+(\w+)\s*(ASC|DESC)?/i);
      if (sortMatch) {
        const [, field, order] = sortMatch;
        const desc = (order || "").toUpperCase() === "DESC";
        results.sort((a, b) => {
          const av = a[field] || "";
          const bv = b[field] || "";
          const cmp = String(av).localeCompare(String(bv));
          return desc ? -cmp : cmp;
        });
      }
    }

    if (upper.startsWith("LIMIT ")) {
      const limit = parseInt(line.slice(6), 10);
      if (!isNaN(limit)) results = results.slice(0, limit);
    }
  }

  return { ok: true, results, count: results.length };
}

// ---- File Attachments ----
const ATTACHMENTS_DIR = path.join(DATA_DIR, "attachments");
const ATTACHMENTS = new Map(); // attachmentId -> { id, dtuId, filename, mimeType, size, path, createdAt }
const ATTACHMENTS_MAX = 5000;
const _ATTACHMENTS_MAX_SIZE_MB = 500;

function ensureAttachmentsDir() {
  try { fs.mkdirSync(ATTACHMENTS_DIR, { recursive: true }); } catch {}
}

// Cleanup orphaned attachments (DTU deleted) and enforce size limits
function cleanupAttachments() {
  let cleaned = 0, freedBytes = 0;

  // Remove attachments for deleted DTUs
  for (const [id, att] of ATTACHMENTS) {
    if (att.dtuId && !STATE.dtus.has(att.dtuId)) {
      try { fs.unlinkSync(att.path); } catch {}
      ATTACHMENTS.delete(id);
      freedBytes += att.size || 0;
      cleaned++;
    }
  }

  // If too many attachments, remove oldest
  if (ATTACHMENTS.size > ATTACHMENTS_MAX) {
    const sorted = Array.from(ATTACHMENTS.entries())
      .sort((a, b) => (a[1].createdAt || "").localeCompare(b[1].createdAt || ""));
    for (const [id, att] of sorted.slice(0, ATTACHMENTS.size - ATTACHMENTS_MAX)) {
      try { fs.unlinkSync(att.path); } catch {}
      ATTACHMENTS.delete(id);
      freedBytes += att.size || 0;
      cleaned++;
    }
  }

  if (cleaned > 0) console.log(`[Attachments] Cleaned ${cleaned} attachments, freed ${(freedBytes / 1024 / 1024).toFixed(1)} MB`);
}

// Run attachment cleanup every 12 hours
setInterval(cleanupAttachments, 12 * 60 * 60 * 1000);

function _saveAttachment(dtuId, filename, buffer, mimeType) {
  ensureAttachmentsDir();
  const id = uid("att");
  const ext = path.extname(filename) || "";
  const safeName = `${id}${ext}`;
  const filePath = path.join(ATTACHMENTS_DIR, safeName);

  fs.writeFileSync(filePath, buffer);

  const attachment = {
    id,
    dtuId,
    filename,
    mimeType: mimeType || "application/octet-stream",
    size: buffer.length,
    path: filePath,
    createdAt: nowISO()
  };

  ATTACHMENTS.set(id, attachment);
  return { ok: true, attachment: { ...attachment, path: undefined } };
}

function _getAttachment(id) {
  return ATTACHMENTS.get(id);
}

function _listAttachments(dtuId) {
  const atts = [];
  for (const [, att] of ATTACHMENTS) {
    if (!dtuId || att.dtuId === dtuId) {
      atts.push({ ...att, path: undefined });
    }
  }
  return atts;
}

// ============================================================================
// END WAVE 2: CORE FEATURES
// ============================================================================

// ============================================================================
// WAVE 3: AI CAPABILITIES (RAG, Auto-linking, CRETI Gen, Contradiction, SRS)
// ============================================================================

// ---- Vector Embeddings Store (Local-first) ----
const EMBEDDINGS = {
  enabled: false,
  model: null,
  store: new Map(), // dtuId -> Float32Array
  dim: 384 // default for all-MiniLM-L6-v2
};

// Initialize local embeddings (Xenova Transformers - runs in Node.js)
async function initLocalEmbeddings() {
  try {
    const { pipeline } = await import("@xenova/transformers").catch(() => ({}));
    if (!pipeline) {
      console.log("[Embeddings] @xenova/transformers not available");
      return { ok: false, reason: "package_not_installed" };
    }

    EMBEDDINGS.model = await pipeline("feature-extraction", "Xenova/all-MiniLM-L6-v2");
    EMBEDDINGS.enabled = true;
    EMBEDDINGS.dim = 384;
    console.log("[Embeddings] Local embedding model loaded (all-MiniLM-L6-v2)");
    return { ok: true };
  } catch (e) {
    console.error("[Embeddings] Failed to load:", e.message);
    return { ok: false, error: String(e.message || e) };
  }
}

// Generate embedding for text
async function generateEmbedding(text) {
  if (!EMBEDDINGS.enabled || !EMBEDDINGS.model) {
    return { ok: false, error: "Embeddings not enabled" };
  }

  try {
    const output = await EMBEDDINGS.model(text, { pooling: "mean", normalize: true });
    const embedding = Array.from(output.data);
    return { ok: true, embedding, dim: embedding.length };
  } catch (e) {
    return { ok: false, error: String(e.message || e) };
  }
}

// Index a DTU's embedding
async function indexDTUEmbedding(dtu) {
  if (!EMBEDDINGS.enabled) return { ok: false, reason: "disabled" };

  // Skip shadow DTUs - they're internal and shouldn't pollute semantic search
  if (isShadowDTU(dtu)) return { ok: true, skipped: true, reason: "shadow_dtu" };

  const text = `${dtu.title || ""} ${dtu.content || ""} ${(dtu.tags || []).join(" ")}`.trim();
  if (!text) return { ok: false, reason: "empty_content" };

  const result = await generateEmbedding(text.slice(0, 8000));
  if (result.ok) {
    EMBEDDINGS.store.set(dtu.id, new Float32Array(result.embedding));
  }
  return result;
}

// Cosine similarity
function cosineSimilarity(a, b) {
  if (a.length !== b.length) return 0;
  let dot = 0, normA = 0, normB = 0;
  for (let i = 0; i < a.length; i++) {
    dot += a[i] * b[i];
    normA += a[i] * a[i];
    normB += b[i] * b[i];
  }
  return dot / (Math.sqrt(normA) * Math.sqrt(normB) || 1);
}

// Semantic search across DTUs
async function semanticSearch(query, { limit = 10, minScore = 0.3 } = {}) {
  if (!EMBEDDINGS.enabled) return { ok: false, error: "Embeddings not enabled" };

  const queryResult = await generateEmbedding(query);
  if (!queryResult.ok) return queryResult;

  const queryVec = new Float32Array(queryResult.embedding);
  const scores = [];

  for (const [dtuId, vec] of EMBEDDINGS.store) {
    const score = cosineSimilarity(queryVec, vec);
    if (score >= minScore) {
      scores.push({ dtuId, score });
    }
  }

  scores.sort((a, b) => b.score - a.score);
  const topResults = scores.slice(0, limit);

  const results = topResults.map(({ dtuId, score }) => {
    const dtu = STATE.dtus.get(dtuId);
    return dtu ? { ...dtu, _semanticScore: score } : null;
  }).filter(d => d && !isShadowDTU(d)); // Filter out shadow DTUs from results

  return { ok: true, results, query };
}

// Build/rebuild embedding index
async function rebuildEmbeddingIndex() {
  if (!EMBEDDINGS.enabled) return { ok: false, reason: "disabled" };

  const dtus = dtusArray();
  let indexed = 0, errors = 0;

  for (const dtu of dtus) {
    const result = await indexDTUEmbedding(dtu);
    if (result.ok) indexed++;
    else errors++;
  }

  return { ok: true, indexed, errors, total: dtus.length };
}

// ---- Auto-Linking (AI Suggests Connections) ----
async function suggestConnections(dtuId, { limit = 5 } = {}) {
  const dtu = STATE.dtus.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };

  // Use semantic search to find related DTUs
  const query = `${dtu.title} ${dtu.content?.slice(0, 500) || ""}`;
  const searchResult = await semanticSearch(query, { limit: limit + 1, minScore: 0.4 });

  if (!searchResult.ok) {
    // Fallback to tag-based suggestions
    const tagMatches = dtusArray()
      .filter(d => d.id !== dtuId)
      .map(d => {
        const overlap = (dtu.tags || []).filter(t => (d.tags || []).includes(t)).length;
        return { dtu: d, score: overlap / Math.max((dtu.tags || []).length, 1) };
      })
      .filter(m => m.score > 0)
      .sort((a, b) => b.score - a.score)
      .slice(0, limit);

    return {
      ok: true,
      suggestions: tagMatches.map(m => ({
        id: m.dtu.id,
        title: m.dtu.title,
        score: m.score,
        reason: "tag_overlap",
        sharedTags: (dtu.tags || []).filter(t => (m.dtu.tags || []).includes(t))
      })),
      method: "tag_based"
    };
  }

  const suggestions = searchResult.results
    .filter(d => d.id !== dtuId)
    .slice(0, limit)
    .map(d => ({
      id: d.id,
      title: d.title,
      score: d._semanticScore,
      reason: "semantic_similarity"
    }));

  return { ok: true, suggestions, method: "semantic" };
}

// ---- CRETI Generation (AI-assisted structured thought) ----
async function generateCRETI(input, _ctx = null) {
  const { title, content, existingCRETI } = input;

  // If no LLM available, generate deterministic CRETI structure
  if (!LLM_READY) {
    return {
      ok: true,
      creti: {
        context: content?.slice(0, 500) || title || "Context not provided",
        reasoning: "Reasoning to be filled in",
        evidence: "Evidence to be gathered",
        tests: "Tests to be defined",
        impact: "Impact to be assessed"
      },
      method: "template"
    };
  }

  // Use LLM to generate structured CRETI
  const prompt = `Analyze the following content and generate a structured CRETI (Context-Reasoning-Evidence-Tests-Impact) analysis.

Title: ${title || "Untitled"}
Content: ${content || "(no content)"}
${existingCRETI ? `Existing CRETI to refine: ${existingCRETI}` : ""}

Generate a JSON response with these fields:
- context: What situation or problem is being addressed? (2-3 sentences)
- reasoning: What is the logical chain of thought? (2-4 sentences)
- evidence: What supports this reasoning? (bullet points)
- tests: How can this be verified or falsified? (bullet points)
- impact: What are the implications? (2-3 sentences)

Respond with valid JSON only.`;

  try {
    const response = await llmChat([{ role: "user", content: prompt }], {
      model: OPENAI_MODEL_FAST,
      temperature: 0.3,
      max_tokens: 1000
    });

    const text = response?.choices?.[0]?.message?.content || "";
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      const creti = JSON.parse(jsonMatch[0]);
      return { ok: true, creti, method: "llm" };
    }

    return { ok: false, error: "Failed to parse LLM response" };
  } catch (e) {
    return { ok: false, error: String(e.message || e) };
  }
}

// ---- Contradiction Detection ----
async function detectContradictions(dtuId) {
  const dtu = STATE.dtus.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };

  // Find semantically similar DTUs
  const similar = await semanticSearch(`${dtu.title} ${dtu.content?.slice(0, 300) || ""}`, { limit: 10, minScore: 0.5 });

  if (!similar.ok || !LLM_READY) {
    return { ok: true, contradictions: [], method: "unavailable" };
  }

  const contradictions = [];

  // For each similar DTU, check for contradiction (simplified)
  for (const candidate of similar.results) {
    if (candidate.id === dtuId) continue;

    // Simple heuristic: check for negation words
    const dtuLower = (dtu.content || "").toLowerCase();
    const candLower = (candidate.content || "").toLowerCase();

    const negationPatterns = [
      { pattern: /\bnot\b/, antiPattern: /\bis\b/ },
      { pattern: /\bwrong\b/, antiPattern: /\bright\b/ },
      { pattern: /\bfalse\b/, antiPattern: /\btrue\b/ },
      { pattern: /\bimpossible\b/, antiPattern: /\bpossible\b/ }
    ];

    for (const { pattern, antiPattern } of negationPatterns) {
      if ((pattern.test(dtuLower) && antiPattern.test(candLower)) ||
          (antiPattern.test(dtuLower) && pattern.test(candLower))) {
        contradictions.push({
          dtuId: candidate.id,
          title: candidate.title,
          confidence: 0.5,
          reason: "potential_negation"
        });
        break;
      }
    }
  }

  return { ok: true, contradictions, method: "heuristic" };
}

// ---- Knowledge Gap Analysis ----
function analyzeKnowledgeGaps(domain = null) {
  const dtus = domain
    ? dtusArray().filter(d => (d.tags || []).some(t => t.toLowerCase().includes(domain.toLowerCase())))
    : dtusArray();

  // Analyze tag coverage
  const tagCounts = new Map();
  for (const dtu of dtus) {
    for (const tag of (dtu.tags || [])) {
      tagCounts.set(tag, (tagCounts.get(tag) || 0) + 1);
    }
  }

  // Find orphan DTUs (no connections)
  const orphans = dtus.filter(d => !d.connections?.length && !d.lineage?.length);

  // Find incomplete DTUs (missing CRETI fields)
  const incomplete = dtus.filter(d => {
    if (!d.creti) return true;
    const lower = d.creti.toLowerCase();
    return !lower.includes("context") || !lower.includes("evidence");
  });

  // Identify potential topics with sparse coverage
  const sparseTopics = Array.from(tagCounts.entries())
    .filter(([, count]) => count === 1)
    .map(([tag]) => tag);

  return {
    ok: true,
    analysis: {
      totalDTUs: dtus.length,
      orphanDTUs: orphans.length,
      incompleteDTUs: incomplete.length,
      uniqueTags: tagCounts.size,
      sparseTopics: sparseTopics.slice(0, 20),
      topTags: Array.from(tagCounts.entries())
        .sort((a, b) => b[1] - a[1])
        .slice(0, 10)
        .map(([tag, count]) => ({ tag, count }))
    },
    recommendations: [
      orphans.length > 0 ? `Connect ${orphans.length} orphan DTUs to related thoughts` : null,
      incomplete.length > 0 ? `Complete CRETI structure for ${incomplete.length} DTUs` : null,
      sparseTopics.length > 0 ? `Expand coverage on sparse topics: ${sparseTopics.slice(0, 5).join(", ")}` : null
    ].filter(Boolean)
  };
}

// ---- Spaced Repetition System (SRS) ----
const SRS = {
  cards: new Map(), // dtuId -> { interval, easeFactor, nextReview, repetitions, history }
  defaultEaseFactor: 2.5,
  minEaseFactor: 1.3
};

function getSRSCard(dtuId) {
  if (!SRS.cards.has(dtuId)) {
    SRS.cards.set(dtuId, {
      interval: 1,
      easeFactor: SRS.defaultEaseFactor,
      nextReview: new Date().toISOString(),
      repetitions: 0,
      history: []
    });
  }
  return SRS.cards.get(dtuId);
}

function reviewSRSCard(dtuId, quality) {
  // quality: 0-5 (0=complete blackout, 5=perfect)
  const card = getSRSCard(dtuId);
  const q = Math.max(0, Math.min(5, quality));

  card.history.push({ quality: q, reviewedAt: nowISO() });

  if (q < 3) {
    // Failed review - reset
    card.repetitions = 0;
    card.interval = 1;
  } else {
    // Successful review - SM-2 algorithm
    if (card.repetitions === 0) {
      card.interval = 1;
    } else if (card.repetitions === 1) {
      card.interval = 6;
    } else {
      card.interval = Math.round(card.interval * card.easeFactor);
    }

    card.easeFactor = Math.max(
      SRS.minEaseFactor,
      card.easeFactor + (0.1 - (5 - q) * (0.08 + (5 - q) * 0.02))
    );
    card.repetitions++;
  }

  // ===== SRS → AFFECT INTEGRATION =====
  // Affect writeStrength modulates retention (higher → longer intervals)
  try {
    if (ATS) {
      const _srsPolicy = ATS.getSessionPolicy("system");
      const _writeStrength = _srsPolicy?.memory?.writeStrength ?? 0.5;
      // Strong memory state → intervals grow faster (1.0-1.4x)
      card.interval = Math.round(card.interval * (0.8 + 0.6 * _writeStrength));

      // SRS review outcomes feed back into affect
      const _pol = q >= 4 ? 0.3 : q >= 3 ? 0.1 : -0.2;
      ATS.emitAffectEvent("system", {
        type: "FEEDBACK",
        intensity: 0.2,
        polarity: _pol,
        payload: { dtuId, quality: q, type: "srs_review" },
        source: { system: "srs" }
      });
    }
  } catch {}
  // ===== END SRS → AFFECT =====

  const nextDate = new Date();
  nextDate.setDate(nextDate.getDate() + card.interval);
  card.nextReview = nextDate.toISOString();

  return { ok: true, card: { ...card, history: card.history.slice(-10) } };
}

function getDueCards(limit = 20) {
  const now = new Date().toISOString();
  const due = [];

  for (const [dtuId, card] of SRS.cards) {
    if (card.nextReview <= now) {
      const dtu = STATE.dtus.get(dtuId);
      if (dtu) {
        due.push({ dtu, card });
      }
    }
  }

  // Sort by most overdue first
  due.sort((a, b) => a.card.nextReview.localeCompare(b.card.nextReview));

  return { ok: true, cards: due.slice(0, limit), total: due.length };
}

function addToSRS(dtuId) {
  const dtu = STATE.dtus.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };

  getSRSCard(dtuId); // Initialize if not exists
  return { ok: true, dtuId, message: "Added to SRS" };
}

// ---- Chat with Lattice (RAG) ----
async function chatWithLattice(query, { contextLimit = 5, sessionId: _sessionId = "" } = {}) {
  // Retrieve relevant context using semantic search
  let context = [];

  if (EMBEDDINGS.enabled) {
    const searchResult = await semanticSearch(query, { limit: contextLimit, minScore: 0.3 });
    if (searchResult.ok) {
      context = searchResult.results.map(d => ({
        title: d.title,
        content: d.content?.slice(0, 1000) || "",
        tags: d.tags
      }));
    }
  }

  // Fallback to keyword search
  if (context.length === 0) {
    const keywords = query.toLowerCase().split(/\s+/).filter(w => w.length > 2);
    const matches = dtusArray()
      .filter(d => {
        const text = `${d.title} ${d.content || ""} ${(d.tags || []).join(" ")}`.toLowerCase();
        return keywords.some(k => text.includes(k));
      })
      .slice(0, contextLimit);

    context = matches.map(d => ({
      title: d.title,
      content: d.content?.slice(0, 1000) || "",
      tags: d.tags
    }));
  }

  if (!LLM_READY) {
    // Return context without LLM synthesis
    return {
      ok: true,
      response: `Found ${context.length} relevant DTUs. LLM not available for synthesis.`,
      context,
      method: "context_only"
    };
  }

  // Build prompt with context
  const contextStr = context.map((c, i) => `[${i + 1}] ${c.title}\n${c.content}`).join("\n\n---\n\n");

  const systemPrompt = `You are an AI assistant helping the user explore their personal knowledge base (lattice of DTUs - Discrete Thought Units).
Answer questions based on the provided context from the user's lattice. If the context doesn't contain relevant information, say so.
Be concise but thorough. Reference specific DTUs by title when applicable.`;

  const userPrompt = `Context from my knowledge lattice:\n\n${contextStr}\n\n---\n\nQuestion: ${query}`;

  try {
    const response = await llmChat([
      { role: "system", content: systemPrompt },
      { role: "user", content: userPrompt }
    ], {
      model: OPENAI_MODEL_FAST,
      temperature: 0.7,
      max_tokens: 1000
    });

    const answer = response?.choices?.[0]?.message?.content || "Unable to generate response";

    return {
      ok: true,
      response: answer,
      context,
      method: "rag"
    };
  } catch (e) {
    return { ok: false, error: String(e.message || e), context };
  }
}

// Initialize embeddings on startup (async, non-blocking)
if (String(process.env.EMBEDDINGS_ENABLED || "true").toLowerCase() === "true") {
  initLocalEmbeddings().then(result => {
    if (result.ok) {
      // Rebuild index in background
      setTimeout(() => rebuildEmbeddingIndex(), 5000);
    }
  });
}

// ============================================================================
// LLM PIPELINE ORCHESTRATOR - Hybrid Local/Cloud AI
// ============================================================================

const LLM_PIPELINE = {
  modes: ["local_only", "balanced", "quality_first"],
  defaultMode: "balanced",

  // Provider status
  providers: {
    ollama: { enabled: false, url: null, model: "tinyllama" },
    openai: { enabled: false, model: "gpt-4.1-mini" }
  }
};

// Initialize LLM providers
function initLLMPipeline() {
  const ollamaUrl = process.env.OLLAMA_URL || process.env.OLLAMA_HOST || "http://ollama:11434";
  LLM_PIPELINE.providers.ollama.url = ollamaUrl;
  LLM_PIPELINE.providers.ollama.model = process.env.OLLAMA_MODEL || "tinyllama";
  LLM_PIPELINE.providers.ollama.enabled = Boolean(ollamaUrl);

  LLM_PIPELINE.providers.openai.enabled = Boolean(OPENAI_API_KEY);
  LLM_PIPELINE.providers.openai.model = OPENAI_MODEL_FAST;

  console.log(`[LLM Pipeline] Initialized - Ollama: ${LLM_PIPELINE.providers.ollama.enabled ? 'enabled' : 'disabled'}, OpenAI: ${LLM_PIPELINE.providers.openai.enabled ? 'enabled' : 'disabled'}`);
}

// Call Ollama (local)
async function callOllama(prompt, options = {}) {
  const { url, model } = LLM_PIPELINE.providers.ollama;
  if (!url) return { ok: false, error: "Ollama not configured" };

  try {
    const payload = {
      model: options.model || model,
      prompt: prompt,
      stream: false,
      options: {
        temperature: options.temperature || 0.7,
        num_predict: options.maxTokens || 500
      }
    };

    const response = await fetch(`${url}/api/generate`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(payload),
      signal: AbortSignal.timeout(options.timeout || 60000)
    });

    if (!response.ok) {
      return { ok: false, error: `Ollama error: ${response.status}` };
    }

    const data = await response.json();
    return {
      ok: true,
      content: data.response || "",
      source: "ollama",
      model: model,
      tokens: data.eval_count || 0
    };
  } catch (e) {
    return { ok: false, error: String(e.message || e), source: "ollama" };
  }
}

// Call OpenAI (cloud)
async function callOpenAI(prompt, options = {}) {
  if (!OPENAI_API_KEY) return { ok: false, error: "OpenAI not configured" };

  try {
    const payload = {
      model: options.model || LLM_PIPELINE.providers.openai.model,
      messages: [{ role: "user", content: prompt }],
      temperature: options.temperature || 0.7,
      max_tokens: options.maxTokens || 500
    };

    const response = await fetch(`${OPENAI_BASE_URL}/chat/completions`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify(payload),
      signal: AbortSignal.timeout(options.timeout || 30000)
    });

    if (!response.ok) {
      const errText = await response.text().catch(() => "");
      return { ok: false, error: `OpenAI error: ${response.status}`, detail: errText };
    }

    const data = await response.json();
    return {
      ok: true,
      content: data.choices?.[0]?.message?.content || "",
      source: "openai",
      model: payload.model,
      tokens: data.usage?.total_tokens || 0
    };
  } catch (e) {
    return { ok: false, error: String(e.message || e), source: "openai" };
  }
}

// HYBRID PIPELINE: The magic sauce
async function llmPipeline(input, options = {}) {
  const mode = options.mode || LLM_PIPELINE.defaultMode;
  const { ollama, openai } = LLM_PIPELINE.providers;

  // Mode: local_only - Privacy first, Ollama only
  if (mode === "local_only") {
    if (!ollama.enabled) {
      return { ok: false, error: "Local mode requires Ollama", mode };
    }
    return callOllama(input, options);
  }

  // Mode: quality_first - OpenAI only (fastest, best quality)
  if (mode === "quality_first") {
    if (!openai.enabled) {
      // Fallback to Ollama if OpenAI not available
      if (ollama.enabled) return callOllama(input, options);
      return { ok: false, error: "No LLM providers available", mode };
    }
    return callOpenAI(input, options);
  }

  // Mode: balanced - THE HYBRID PIPELINE
  // Step 1: Ollama generates rough draft (private, free)
  // Step 2: OpenAI polishes (cheap, fast)

  if (!ollama.enabled && !openai.enabled) {
    return { ok: false, error: "No LLM providers available", mode };
  }

  // If only one provider available, use it
  if (!ollama.enabled) return callOpenAI(input, options);
  if (!openai.enabled) return callOllama(input, options);

  // HYBRID: Draft with Ollama, polish with OpenAI
  const draftResult = await callOllama(input, {
    ...options,
    maxTokens: Math.min(options.maxTokens || 500, 300) // Limit draft length
  });

  if (!draftResult.ok) {
    // Ollama failed, fallback to OpenAI only
    console.log("[LLM Pipeline] Ollama draft failed, falling back to OpenAI");
    return callOpenAI(input, options);
  }

  // Polish the draft with OpenAI
  const polishPrompt = `Improve and polish this text while preserving its meaning. Make it clearer and more coherent. Keep the same length or shorter.

DRAFT:
${draftResult.content}

POLISHED VERSION:`;

  const polishResult = await callOpenAI(polishPrompt, {
    ...options,
    maxTokens: Math.min(options.maxTokens || 500, 400),
    temperature: 0.3 // Lower temp for polish
  });

  if (!polishResult.ok) {
    // Polish failed, return draft
    console.log("[LLM Pipeline] OpenAI polish failed, returning draft");
    return { ...draftResult, polished: false };
  }

  return {
    ok: true,
    content: polishResult.content,
    source: "hybrid",
    draft: draftResult.content,
    draftSource: "ollama",
    polishSource: "openai",
    tokens: (draftResult.tokens || 0) + (polishResult.tokens || 0),
    polished: true,
    mode: "balanced"
  };
}

// Get pipeline status
function getLLMPipelineStatus() {
  return {
    mode: LLM_PIPELINE.defaultMode,
    providers: {
      ollama: {
        enabled: LLM_PIPELINE.providers.ollama.enabled,
        model: LLM_PIPELINE.providers.ollama.model,
        url: LLM_PIPELINE.providers.ollama.url ? "configured" : null
      },
      openai: {
        enabled: LLM_PIPELINE.providers.openai.enabled,
        model: LLM_PIPELINE.providers.openai.model
      }
    },
    capabilities: {
      local_only: LLM_PIPELINE.providers.ollama.enabled,
      balanced: LLM_PIPELINE.providers.ollama.enabled && LLM_PIPELINE.providers.openai.enabled,
      quality_first: LLM_PIPELINE.providers.openai.enabled || LLM_PIPELINE.providers.ollama.enabled
    }
  };
}

// Set default pipeline mode
function setLLMPipelineMode(mode) {
  if (!LLM_PIPELINE.modes.includes(mode)) {
    return { ok: false, error: `Invalid mode. Use: ${LLM_PIPELINE.modes.join(", ")}` };
  }
  LLM_PIPELINE.defaultMode = mode;
  return { ok: true, mode };
}

// Initialize on startup
setTimeout(() => initLLMPipeline(), 100);

// Global llmChat() wrapper - routes all LLM calls through the pipeline
// This enables hybrid local/cloud AI for all DTU generation
async function llmChat(messagesOrCtx, messagesOrOptions = {}, maybeOptions = {}) {
  // Handle both signatures:
  // llmChat([messages], options) - direct call
  // llmChat(ctx, [messages], options) - context call
  let messages, options;

  if (Array.isArray(messagesOrCtx)) {
    // Direct call: llmChat([messages], options)
    messages = messagesOrCtx;
    options = messagesOrOptions;
  } else if (Array.isArray(messagesOrOptions)) {
    // Context call: llmChat(ctx, [messages], options)
    messages = messagesOrOptions;
    options = maybeOptions;
  } else {
    return { ok: false, error: "Invalid llmChat arguments" };
  }

  // Convert messages to single prompt for pipeline
  const prompt = messages.map(m => {
    if (m.role === "system") return `[System]: ${m.content}`;
    if (m.role === "assistant") return `[Assistant]: ${m.content}`;
    return m.content;
  }).join("\n\n");

  // Call the hybrid pipeline
  const result = await llmPipeline(prompt, {
    temperature: options.temperature || 0.7,
    maxTokens: options.max_tokens || options.maxTokens || 500,
    mode: options.mode || LLM_PIPELINE.defaultMode
  });

  if (!result.ok) {
    return result;
  }

  // GRC: Format through Grounded Recursive Closure pipeline
  let grcResult = null;
  if (GRC_MODULE && options.grc !== false) {
    try {
      grcResult = grcFormatAndValidate(
        result.content,
        {
          dtuRefs: options.dtuRefs || [],
          macroRefs: options.macroRefs || [],
          stateRefs: options.stateRefs || [],
          mode: options.grcMode || "governed-response",
          invariantsApplied: options.invariantsApplied || [],
          realitySnapshot: options.realitySnapshot || null,
        },
        {
          inLatticeReality,
          STATE,
          affectState: null,
        }
      );
    } catch (e) {
      console.error("[GRC] Format failed, returning raw:", e?.message);
    }
  }

  // Format response to match OpenAI chat format (for compatibility)
  return {
    ok: true,
    text: result.content,
    choices: [{
      message: { role: "assistant", content: result.content }
    }],
    source: result.source,
    polished: result.polished,
    tokens: result.tokens,
    grc: grcResult?.grc || null,
    grcValid: grcResult?.ok || false,
    grcRepairs: grcResult?.repairs || [],
  };
}

// ============================================================================
// END WAVE 3: AI CAPABILITIES
// ============================================================================

// ============================================================================
// WAVE 4: COLLABORATION (Comments, Permissions, Workspaces, Sharing)
// ============================================================================

// ---- Workspaces ----
const WORKSPACES = new Map(); // workspaceId -> { id, name, description, ownerId, members, dtuIds, settings, createdAt }

function createWorkspace(ownerId, name, description = "") {
  const id = uid("ws");
  const workspace = {
    id,
    name,
    description,
    ownerId,
    members: new Map([[ownerId, { role: "owner", joinedAt: nowISO() }]]),
    dtuIds: new Set(),
    settings: {
      isPublic: false,
      allowComments: true,
      allowEditing: true
    },
    createdAt: nowISO(),
    updatedAt: nowISO()
  };
  WORKSPACES.set(id, workspace);
  return { ok: true, workspace: workspaceForClient(workspace) };
}

function workspaceForClient(ws) {
  return {
    id: ws.id,
    name: ws.name,
    description: ws.description,
    ownerId: ws.ownerId,
    members: Array.from(ws.members.entries()).map(([userId, data]) => ({ userId, ...data })),
    dtuCount: ws.dtuIds.size,
    settings: ws.settings,
    createdAt: ws.createdAt,
    updatedAt: ws.updatedAt
  };
}

function addWorkspaceMember(workspaceId, userId, role = "member") {
  const ws = WORKSPACES.get(workspaceId);
  if (!ws) return { ok: false, error: "Workspace not found" };
  ws.members.set(userId, { role, joinedAt: nowISO() });
  ws.updatedAt = nowISO();
  return { ok: true };
}

function _removeWorkspaceMember(workspaceId, userId) {
  const ws = WORKSPACES.get(workspaceId);
  if (!ws) return { ok: false, error: "Workspace not found" };
  if (userId === ws.ownerId) return { ok: false, error: "Cannot remove owner" };
  ws.members.delete(userId);
  ws.updatedAt = nowISO();
  return { ok: true };
}

function addDTUToWorkspace(workspaceId, dtuId) {
  const ws = WORKSPACES.get(workspaceId);
  if (!ws) return { ok: false, error: "Workspace not found" };
  ws.dtuIds.add(dtuId);
  ws.updatedAt = nowISO();
  return { ok: true };
}

function getWorkspaceDTUs(workspaceId) {
  const ws = WORKSPACES.get(workspaceId);
  if (!ws) return { ok: false, error: "Workspace not found" };
  const dtus = Array.from(ws.dtuIds).map(id => STATE.dtus.get(id)).filter(Boolean);
  return { ok: true, dtus, count: dtus.length };
}

function _checkWorkspaceAccess(workspaceId, userId, requiredRole = "member") {
  const ws = WORKSPACES.get(workspaceId);
  if (!ws) return { ok: false, error: "Workspace not found" };

  const member = ws.members.get(userId);
  if (!member) return { ok: false, error: "Not a member" };

  const roleHierarchy = { viewer: 0, member: 1, editor: 2, admin: 3, owner: 4 };
  if ((roleHierarchy[member.role] || 0) < (roleHierarchy[requiredRole] || 0)) {
    return { ok: false, error: "Insufficient permissions" };
  }

  return { ok: true, role: member.role };
}

// ---- Comments/Threads ----
const COMMENTS = new Map(); // commentId -> { id, dtuId, userId, content, parentId, createdAt, updatedAt, resolved }

function addComment(dtuId, userId, content, parentId = null) {
  const dtu = STATE.dtus.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };

  const id = uid("cmt");
  const comment = {
    id,
    dtuId,
    userId,
    content,
    parentId,
    createdAt: nowISO(),
    updatedAt: nowISO(),
    resolved: false,
    reactions: {}
  };

  COMMENTS.set(id, comment);

  // Broadcast comment added
  try {
    realtimeEmit("comment:added", { dtuId, commentId: id, userId });
  } catch {}

  return { ok: true, comment };
}

function getComments(dtuId) {
  const comments = [];
  for (const [, comment] of COMMENTS) {
    if (comment.dtuId === dtuId) {
      comments.push(comment);
    }
  }
  // Build thread structure
  const rootComments = comments.filter(c => !c.parentId);
  const threads = rootComments.map(root => ({
    ...root,
    replies: comments.filter(c => c.parentId === root.id)
      .sort((a, b) => a.createdAt.localeCompare(b.createdAt))
  }));

  return { ok: true, threads, total: comments.length };
}

function resolveComment(commentId, resolved = true) {
  const comment = COMMENTS.get(commentId);
  if (!comment) return { ok: false, error: "Comment not found" };
  comment.resolved = resolved;
  comment.updatedAt = nowISO();
  return { ok: true, comment };
}

function addReaction(commentId, userId, emoji) {
  const comment = COMMENTS.get(commentId);
  if (!comment) return { ok: false, error: "Comment not found" };

  if (!comment.reactions[emoji]) comment.reactions[emoji] = [];
  if (!comment.reactions[emoji].includes(userId)) {
    comment.reactions[emoji].push(userId);
  }
  comment.updatedAt = nowISO();
  return { ok: true, reactions: comment.reactions };
}

// ---- DTU Permissions ----
const DTU_PERMISSIONS = new Map(); // dtuId -> { ownerId, viewers: Set, editors: Set, isPublic }

function _setDTUPermissions(dtuId, ownerId, permissions = {}) {
  DTU_PERMISSIONS.set(dtuId, {
    ownerId,
    viewers: new Set(permissions.viewers || []),
    editors: new Set(permissions.editors || []),
    isPublic: permissions.isPublic || false
  });
  return { ok: true };
}

function _checkDTUAccess(dtuId, userId, action = "view") {
  const perms = DTU_PERMISSIONS.get(dtuId);
  if (!perms) return { ok: true }; // No permissions set = open access

  if (perms.isPublic && action === "view") return { ok: true };
  if (perms.ownerId === userId) return { ok: true };

  if (action === "view" && (perms.viewers.has(userId) || perms.editors.has(userId))) {
    return { ok: true };
  }

  if (action === "edit" && perms.editors.has(userId)) {
    return { ok: true };
  }

  return { ok: false, error: "Access denied" };
}

// ---- Share Links ----
const SHARE_LINKS = new Map(); // token -> { dtuId, createdBy, createdAt, expiresAt, accessCount, maxAccess }

function createShareLink(dtuId, createdBy, options = {}) {
  const dtu = STATE.dtus.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };

  const token = crypto.randomBytes(24).toString("base64url");
  const expiresAt = options.expiresIn
    ? new Date(Date.now() + options.expiresIn * 1000).toISOString()
    : null;

  SHARE_LINKS.set(token, {
    dtuId,
    createdBy,
    createdAt: nowISO(),
    expiresAt,
    accessCount: 0,
    maxAccess: options.maxAccess || null
  });

  return {
    ok: true,
    token,
    url: `/shared/${token}`,
    expiresAt
  };
}

function accessShareLink(token) {
  const link = SHARE_LINKS.get(token);
  if (!link) return { ok: false, error: "Invalid link" };

  // Check expiration
  if (link.expiresAt && new Date(link.expiresAt) < new Date()) {
    SHARE_LINKS.delete(token);
    return { ok: false, error: "Link expired" };
  }

  // Check max access
  if (link.maxAccess && link.accessCount >= link.maxAccess) {
    return { ok: false, error: "Link access limit reached" };
  }

  link.accessCount++;

  const dtu = STATE.dtus.get(link.dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };

  return { ok: true, dtu: dtuForClient(dtu) };
}

// ---- Activity Log ----
const ACTIVITY_LOG = []; // { id, userId, action, targetType, targetId, details, createdAt }
const MAX_ACTIVITY_LOG = 10000;

function _logActivity(userId, action, targetType, targetId, details = {}) {
  const entry = {
    id: uid("act"),
    userId,
    action,
    targetType,
    targetId,
    details,
    createdAt: nowISO()
  };

  ACTIVITY_LOG.push(entry);

  // Trim old entries
  if (ACTIVITY_LOG.length > MAX_ACTIVITY_LOG) {
    ACTIVITY_LOG.splice(0, ACTIVITY_LOG.length - MAX_ACTIVITY_LOG);
  }

  // Broadcast activity
  try {
    realtimeEmit("activity:new", entry);
  } catch {}

  return entry;
}

function getActivityLog(filters = {}) {
  let results = [...ACTIVITY_LOG];

  if (filters.userId) results = results.filter(a => a.userId === filters.userId);
  if (filters.action) results = results.filter(a => a.action === filters.action);
  if (filters.targetType) results = results.filter(a => a.targetType === filters.targetType);
  if (filters.targetId) results = results.filter(a => a.targetId === filters.targetId);
  if (filters.since) results = results.filter(a => a.createdAt >= filters.since);

  results.sort((a, b) => b.createdAt.localeCompare(a.createdAt));

  const limit = filters.limit || 100;
  const offset = filters.offset || 0;

  return {
    ok: true,
    activities: results.slice(offset, offset + limit),
    total: results.length
  };
}

// ---- Yjs CRDT Support (for real-time collaborative editing) ----
// Note: Actual Yjs integration requires WebSocket server setup
// This provides the server-side hooks and document management

const YJS_DOCS = new Map(); // dtuId -> { updates: Buffer[], lastUpdate: Date }

function initYjsDoc(dtuId) {
  if (!YJS_DOCS.has(dtuId)) {
    YJS_DOCS.set(dtuId, { updates: [], lastUpdate: null });
  }
  return YJS_DOCS.get(dtuId);
}

function _applyYjsUpdate(dtuId, update) {
  const doc = initYjsDoc(dtuId);
  doc.updates.push(Buffer.from(update));
  doc.lastUpdate = new Date();

  // Broadcast update to all clients editing this DTU
  try {
    realtimeEmit("yjs:update", { dtuId, update: update.toString("base64") });
  } catch {}

  return { ok: true };
}

function _getYjsUpdates(dtuId) {
  const doc = YJS_DOCS.get(dtuId);
  if (!doc) return { ok: true, updates: [] };
  return { ok: true, updates: doc.updates.map(u => u.toString("base64")) };
}

// ============================================================================
// END WAVE 4: COLLABORATION
// ============================================================================

// ============================================================================
// WAVE 5: FRONTEND SUPPORT (Themes, PWA, Keyboard Config)
// ============================================================================

// ---- Theme Configuration ----
const THEMES = {
  dark: {
    id: "dark",
    name: "Dark",
    colors: {
      bg: "#0a0a0a",
      surface: "#141414",
      border: "#262626",
      text: "#ffffff",
      textMuted: "#a0a0a0",
      primary: "#22d3ee",
      secondary: "#a855f7",
      success: "#10b981",
      warning: "#f59e0b",
      danger: "#ef4444"
    }
  },
  light: {
    id: "light",
    name: "Light",
    colors: {
      bg: "#ffffff",
      surface: "#f5f5f5",
      border: "#e5e5e5",
      text: "#0a0a0a",
      textMuted: "#666666",
      primary: "#0891b2",
      secondary: "#7c3aed",
      success: "#059669",
      warning: "#d97706",
      danger: "#dc2626"
    }
  },
  nord: {
    id: "nord",
    name: "Nord",
    colors: {
      bg: "#2e3440",
      surface: "#3b4252",
      border: "#4c566a",
      text: "#eceff4",
      textMuted: "#d8dee9",
      primary: "#88c0d0",
      secondary: "#b48ead",
      success: "#a3be8c",
      warning: "#ebcb8b",
      danger: "#bf616a"
    }
  }
};

function getTheme(themeId) {
  return THEMES[themeId] || THEMES.dark;
}

function getAllThemes() {
  return Object.values(THEMES);
}

// ---- Keyboard Shortcuts Configuration ----
const DEFAULT_SHORTCUTS = {
  "mod+k": { action: "openCommandPalette", description: "Open command palette" },
  "mod+n": { action: "createDTU", description: "Create new DTU" },
  "mod+s": { action: "save", description: "Save current DTU" },
  "mod+f": { action: "search", description: "Open search" },
  "mod+shift+f": { action: "searchAll", description: "Search all DTUs" },
  "mod+/": { action: "toggleSlashCommands", description: "Toggle slash commands" },
  "mod+g": { action: "openGraph", description: "Open graph view" },
  "mod+b": { action: "toggleSidebar", description: "Toggle sidebar" },
  "mod+shift+e": { action: "focusMode", description: "Toggle focus mode" },
  "mod+[": { action: "goBack", description: "Go back in history" },
  "mod+]": { action: "goForward", description: "Go forward in history" },
  "mod+1": { action: "switchToTab1", description: "Switch to tab 1" },
  "mod+2": { action: "switchToTab2", description: "Switch to tab 2" },
  "mod+3": { action: "switchToTab3", description: "Switch to tab 3" },
  "escape": { action: "closeModal", description: "Close modal/panel" },
  "mod+shift+p": { action: "togglePreview", description: "Toggle preview" }
};

const USER_SHORTCUTS = new Map(); // userId -> { shortcutKey: action }

function getShortcuts(userId = null) {
  const userShortcuts = userId ? USER_SHORTCUTS.get(userId) : null;
  return { ...DEFAULT_SHORTCUTS, ...(userShortcuts || {}) };
}

function setUserShortcut(userId, key, action) {
  if (!USER_SHORTCUTS.has(userId)) {
    USER_SHORTCUTS.set(userId, {});
  }
  USER_SHORTCUTS.get(userId)[key] = { action, custom: true };
  return { ok: true };
}

// ---- PWA Manifest Generation ----
function generatePWAManifest(options = {}) {
  return {
    name: options.name || "Concord",
    short_name: options.shortName || "Concord",
    description: options.description || "Local-first cognitive engine for thought synthesis",
    start_url: options.startUrl || "/",
    display: "standalone",
    background_color: THEMES.dark.colors.bg,
    theme_color: THEMES.dark.colors.primary,
    icons: [
      { src: "/icons/icon-192.png", sizes: "192x192", type: "image/png" },
      { src: "/icons/icon-512.png", sizes: "512x512", type: "image/png" },
      { src: "/icons/icon-maskable.png", sizes: "512x512", type: "image/png", purpose: "maskable" }
    ],
    categories: ["productivity", "utilities"],
    orientation: "any",
    scope: "/",
    lang: "en",
    dir: "ltr"
  };
}

// ---- Service Worker Registration Helper ----
function generateServiceWorkerConfig() {
  return {
    cacheName: `concord-v${VERSION}`,
    precacheUrls: [
      "/",
      "/app",
      "/offline",
      "/manifest.json"
    ],
    runtimeCaching: [
      { pattern: /\/api\/dtus/, strategy: "network-first", maxAge: 60 },
      { pattern: /\/api\//, strategy: "network-first", maxAge: 300 },
      { pattern: /\.(js|css|woff2)$/, strategy: "cache-first", maxAge: 86400 }
    ]
  };
}

// ---- Onboarding Configuration ----
const ONBOARDING_STEPS = [
  {
    id: "welcome",
    title: "Welcome to Concord",
    description: "Your local-first cognitive engine for thought synthesis",
    action: null
  },
  {
    id: "create-first-dtu",
    title: "Create Your First Thought",
    description: "DTUs (Discrete Thought Units) are atomic pieces of knowledge. Create your first one!",
    action: "createDTU"
  },
  {
    id: "explore-graph",
    title: "Explore the Graph",
    description: "See how your thoughts connect in the interactive graph view",
    action: "openGraph"
  },
  {
    id: "use-ai",
    title: "Get AI Assistance",
    description: "Use the AI panel to expand, summarize, or challenge your thoughts",
    action: "openAIPanel"
  },
  {
    id: "keyboard-shortcuts",
    title: "Learn Shortcuts",
    description: "Press Cmd/Ctrl+K to open the command palette anytime",
    action: "openCommandPalette"
  }
];

function getOnboardingProgress(userId) {
  // Track which steps user has completed
  const key = `onboarding:${userId}`;
  const progress = STATE.config?.[key] || { completed: [], currentStep: 0 };
  return {
    ok: true,
    steps: ONBOARDING_STEPS,
    progress,
    isComplete: progress.completed.length >= ONBOARDING_STEPS.length
  };
}

function completeOnboardingStep(userId, stepId) {
  const key = `onboarding:${userId}`;
  if (!STATE.config) STATE.config = {};
  if (!STATE.config[key]) STATE.config[key] = { completed: [], currentStep: 0 };

  if (!STATE.config[key].completed.includes(stepId)) {
    STATE.config[key].completed.push(stepId);
    STATE.config[key].currentStep++;
  }

  saveStateDebounced();
  return { ok: true, progress: STATE.config[key] };
}

// ============================================================================
// END WAVE 5: FRONTEND SUPPORT
// ============================================================================

// ============================================================================
// WAVE 6: DEVELOPER EXPERIENCE (OpenAPI, Plugins, CLI helpers)
// ============================================================================

// ---- OpenAPI Specification Generator ----
function generateOpenAPISpec() {
  return {
    openapi: "3.0.3",
    info: {
      title: "Concord API",
      description: "Local-first cognitive engine API",
      version: VERSION,
      license: { name: "MIT" }
    },
    servers: [
      { url: `http://localhost:${PORT}`, description: "Local server" }
    ],
    paths: {
      "/health": {
        get: {
          summary: "Health check",
          responses: { "200": { description: "Server is healthy" } }
        }
      },
      "/api/dtus": {
        get: {
          summary: "List DTUs",
          parameters: [
            { name: "limit", in: "query", schema: { type: "integer", default: 50 } },
            { name: "offset", in: "query", schema: { type: "integer", default: 0 } },
            { name: "q", in: "query", schema: { type: "string" } }
          ],
          responses: { "200": { description: "List of DTUs" } }
        },
        post: {
          summary: "Create DTU",
          requestBody: {
            content: {
              "application/json": {
                schema: {
                  type: "object",
                  required: ["title"],
                  properties: {
                    title: { type: "string" },
                    content: { type: "string" },
                    tags: { type: "array", items: { type: "string" } },
                    tier: { type: "string", enum: ["regular", "mega", "hyper"] }
                  }
                }
              }
            }
          },
          responses: { "201": { description: "DTU created" } }
        }
      },
      "/api/dtus/{id}": {
        get: {
          summary: "Get DTU by ID",
          parameters: [{ name: "id", in: "path", required: true, schema: { type: "string" } }],
          responses: { "200": { description: "DTU details" } }
        },
        put: {
          summary: "Update DTU",
          parameters: [{ name: "id", in: "path", required: true, schema: { type: "string" } }],
          responses: { "200": { description: "DTU updated" } }
        },
        delete: {
          summary: "Delete DTU",
          parameters: [{ name: "id", in: "path", required: true, schema: { type: "string" } }],
          responses: { "200": { description: "DTU deleted" } }
        }
      },
      "/api/search": {
        get: {
          summary: "Search DTUs",
          parameters: [
            { name: "q", in: "query", required: true, schema: { type: "string" } },
            { name: "semantic", in: "query", schema: { type: "boolean" } }
          ],
          responses: { "200": { description: "Search results" } }
        }
      },
      "/api/macro/{domain}/{name}": {
        post: {
          summary: "Execute macro",
          parameters: [
            { name: "domain", in: "path", required: true, schema: { type: "string" } },
            { name: "name", in: "path", required: true, schema: { type: "string" } }
          ],
          responses: { "200": { description: "Macro result" } }
        }
      }
    },
    components: {
      securitySchemes: {
        bearerAuth: { type: "http", scheme: "bearer", bearerFormat: "JWT" },
        apiKey: { type: "apiKey", in: "header", name: "X-API-Key" }
      }
    },
    security: [{ bearerAuth: [] }, { apiKey: [] }]
  };
}

// ---- Plugin System ----
const PLUGINS = new Map(); // pluginId -> { id, name, version, hooks, enabled, config }
const PLUGIN_HOOKS = {
  "dtu:beforeCreate": [],
  "dtu:afterCreate": [],
  "dtu:beforeUpdate": [],
  "dtu:afterUpdate": [],
  "dtu:beforeDelete": [],
  "dtu:afterDelete": [],
  "macro:beforeExecute": [],
  "macro:afterExecute": [],
  "search:beforeQuery": [],
  "search:afterQuery": []
};

function registerPlugin(plugin) {
  if (!plugin.id || !plugin.name) {
    return { ok: false, error: "Plugin must have id and name" };
  }

  const registered = {
    id: plugin.id,
    name: plugin.name,
    version: plugin.version || "1.0.0",
    description: plugin.description || "",
    author: plugin.author || "Unknown",
    hooks: [],
    enabled: true,
    config: plugin.defaultConfig || {}
  };

  // Register hooks
  for (const [hookName, handler] of Object.entries(plugin.hooks || {})) {
    if (PLUGIN_HOOKS[hookName]) {
      PLUGIN_HOOKS[hookName].push({ pluginId: plugin.id, handler });
      registered.hooks.push(hookName);
    }
  }

  PLUGINS.set(plugin.id, registered);
  console.log(`[Plugins] Registered: ${plugin.name} v${registered.version}`);
  return { ok: true, plugin: registered };
}

function unregisterPlugin(pluginId) {
  const plugin = PLUGINS.get(pluginId);
  if (!plugin) return { ok: false, error: "Plugin not found" };

  // Remove hooks
  for (const hookName of Object.keys(PLUGIN_HOOKS)) {
    PLUGIN_HOOKS[hookName] = PLUGIN_HOOKS[hookName].filter(h => h.pluginId !== pluginId);
  }

  PLUGINS.delete(pluginId);
  return { ok: true };
}

async function _executeHook(hookName, context) {
  const handlers = PLUGIN_HOOKS[hookName] || [];
  let result = context;

  for (const { pluginId, handler } of handlers) {
    const plugin = PLUGINS.get(pluginId);
    if (!plugin?.enabled) continue;

    try {
      result = await handler(result, plugin.config);
    } catch (e) {
      console.error(`[Plugins] Hook ${hookName} failed for ${pluginId}:`, e.message);
    }
  }

  return result;
}

function listPlugins() {
  return Array.from(PLUGINS.values()).map(p => ({
    id: p.id,
    name: p.name,
    version: p.version,
    description: p.description,
    enabled: p.enabled,
    hooks: p.hooks
  }));
}

// ---- CLI Helpers ----
function generateCLIHelp() {
  return `
Concord CLI - Local-first cognitive engine

USAGE:
  concord <command> [options]

COMMANDS:
  start             Start the server
  backup            Create a backup
  restore <file>    Restore from backup
  import <file>     Import from Obsidian/Roam
  export [--format] Export DTUs (json, markdown)
  search <query>    Search DTUs
  stats             Show lattice statistics
  macro <d.n>       Execute a macro

OPTIONS:
  --port, -p        Server port (default: 5050)
  --data-dir        Data directory
  --auth            Enable authentication
  --help, -h        Show help

EXAMPLES:
  concord start --port 3000
  concord backup
  concord import ./vault --format obsidian
  concord search "neural networks"
  concord macro dtu.list --limit 10
`.trim();
}

function getCLIStats() {
  return {
    version: VERSION,
    dtus: STATE.dtus.size,
    shadowDtus: STATE.shadowDtus.size,
    sessions: STATE.sessions.size,
    macros: Array.from(MACROS.entries()).reduce((acc, [, m]) => acc + m.size, 0),
    plugins: PLUGINS.size,
    embeddings: EMBEDDINGS.store.size,
    uptime: process.uptime()
  };
}

// ============================================================================
// END WAVE 6: DEVELOPER EXPERIENCE
// ============================================================================

// ============================================================================
// WAVE 7: DIFFERENTIATORS (Thought Replay, Lattice Diff, Public Lattice, Debate)
// ============================================================================

// ---- Thought Replay (Temporal Navigation) ----
const THOUGHT_TIMELINE = []; // { timestamp, dtuId, action, snapshot }
const MAX_TIMELINE_ENTRIES = 5000;

function _recordThoughtEvent(dtuId, action, snapshot = null) {
  THOUGHT_TIMELINE.push({
    id: uid("evt"),
    timestamp: nowISO(),
    dtuId,
    action, // created, updated, deleted, connected, promoted
    snapshot: snapshot ? { title: snapshot.title, tier: snapshot.tier, tags: [...(snapshot.tags || [])] } : null
  });

  if (THOUGHT_TIMELINE.length > MAX_TIMELINE_ENTRIES) {
    THOUGHT_TIMELINE.splice(0, THOUGHT_TIMELINE.length - MAX_TIMELINE_ENTRIES);
  }
}

function getThoughtTimeline(filters = {}) {
  let events = [...THOUGHT_TIMELINE];

  if (filters.dtuId) events = events.filter(e => e.dtuId === filters.dtuId);
  if (filters.action) events = events.filter(e => e.action === filters.action);
  if (filters.since) events = events.filter(e => e.timestamp >= filters.since);
  if (filters.until) events = events.filter(e => e.timestamp <= filters.until);

  events.sort((a, b) => b.timestamp.localeCompare(a.timestamp));

  const limit = filters.limit || 100;
  return { ok: true, events: events.slice(0, limit), total: events.length };
}

function replayThoughtsAt(timestamp) {
  // Reconstruct lattice state at a given timestamp
  // Returns list of DTUs that existed at that time
  const dtusAtTime = new Map();

  for (const event of THOUGHT_TIMELINE) {
    if (event.timestamp > timestamp) break;

    if (event.action === "created" && event.snapshot) {
      dtusAtTime.set(event.dtuId, event.snapshot);
    } else if (event.action === "updated" && event.snapshot) {
      dtusAtTime.set(event.dtuId, event.snapshot);
    } else if (event.action === "deleted") {
      dtusAtTime.delete(event.dtuId);
    }
  }

  return {
    ok: true,
    timestamp,
    dtus: Array.from(dtusAtTime.entries()).map(([id, snap]) => ({ id, ...snap })),
    count: dtusAtTime.size
  };
}

// ---- Lattice Diffing ----
function diffLattices(timestampA, timestampB) {
  const stateA = replayThoughtsAt(timestampA);
  const stateB = replayThoughtsAt(timestampB);

  const idsA = new Set(stateA.dtus.map(d => d.id));
  const idsB = new Set(stateB.dtus.map(d => d.id));

  const added = stateB.dtus.filter(d => !idsA.has(d.id));
  const removed = stateA.dtus.filter(d => !idsB.has(d.id));
  const modified = [];

  for (const dtuB of stateB.dtus) {
    if (idsA.has(dtuB.id)) {
      const dtuA = stateA.dtus.find(d => d.id === dtuB.id);
      if (dtuA && (dtuA.title !== dtuB.title || dtuA.tier !== dtuB.tier)) {
        modified.push({ before: dtuA, after: dtuB });
      }
    }
  }

  return {
    ok: true,
    from: timestampA,
    to: timestampB,
    added: added.length,
    removed: removed.length,
    modified: modified.length,
    changes: { added, removed, modified }
  };
}

// ---- Public Lattice (Blog/Wiki Publishing) ----
const PUBLIC_LATTICE = {
  enabled: false,
  publishedDTUs: new Set(), // dtuIds that are publicly visible
  customDomain: null,
  settings: {
    allowComments: false,
    showGraph: true,
    theme: "dark"
  }
};

function publishDTU(dtuId) {
  const dtu = STATE.dtus.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };

  PUBLIC_LATTICE.publishedDTUs.add(dtuId);
  PUBLIC_LATTICE.enabled = true;

  return {
    ok: true,
    publicUrl: `/public/${dtuId}`,
    dtuId
  };
}

function unpublishDTU(dtuId) {
  PUBLIC_LATTICE.publishedDTUs.delete(dtuId);
  return { ok: true };
}

function getPublicDTU(dtuId) {
  if (!PUBLIC_LATTICE.publishedDTUs.has(dtuId)) {
    return { ok: false, error: "Not published" };
  }

  const dtu = STATE.dtus.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };

  // Return sanitized public view
  return {
    ok: true,
    dtu: {
      id: dtu.id,
      title: dtu.title,
      content: dtu.content,
      tags: dtu.tags,
      tier: dtu.tier,
      createdAt: dtu.createdAt,
      updatedAt: dtu.updatedAt
    }
  };
}

function listPublicDTUs() {
  const dtus = Array.from(PUBLIC_LATTICE.publishedDTUs)
    .map(id => STATE.dtus.get(id))
    .filter(Boolean)
    .map(d => ({ id: d.id, title: d.title, tier: d.tier, updatedAt: d.updatedAt }));

  return { ok: true, dtus, count: dtus.length };
}

function generatePublicFeed() {
  // Generate RSS/Atom feed for public lattice
  const dtus = Array.from(PUBLIC_LATTICE.publishedDTUs)
    .map(id => STATE.dtus.get(id))
    .filter(Boolean)
    .sort((a, b) => (b.updatedAt || "").localeCompare(a.updatedAt || ""))
    .slice(0, 20);

  const items = dtus.map(d => `
    <item>
      <title>${escapeXml(d.title)}</title>
      <link>/public/${d.id}</link>
      <description>${escapeXml((d.content || "").slice(0, 500))}</description>
      <pubDate>${new Date(d.createdAt).toUTCString()}</pubDate>
      <guid>/public/${d.id}</guid>
    </item>
  `).join("\n");

  return `<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Concord Public Lattice</title>
    <description>Public thoughts from Concord</description>
    <link>/public</link>
    <lastBuildDate>${new Date().toUTCString()}</lastBuildDate>
    ${items}
  </channel>
</rss>`;
}

function escapeXml(str) {
  return String(str || "")
    .replace(/&/g, "&amp;")
    .replace(/</g, "&lt;")
    .replace(/>/g, "&gt;")
    .replace(/"/g, "&quot;")
    .replace(/'/g, "&apos;");
}

// ---- Debate Mode (AI Challenges Your Thoughts) ----
async function debateThought(dtuId, _options = {}) {
  const dtu = STATE.dtus.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };

  if (!LLM_READY) {
    return {
      ok: true,
      challenges: [
        "What evidence supports this claim?",
        "Are there alternative explanations?",
        "What assumptions are being made?",
        "How could this be falsified?",
        "What are the strongest counterarguments?"
      ],
      method: "template"
    };
  }

  const prompt = `You are a Socratic debate partner. Your role is to challenge the following thought with rigorous but constructive questions and counterarguments.

THOUGHT:
Title: ${dtu.title}
Content: ${dtu.content || "(no content)"}
Tags: ${(dtu.tags || []).join(", ")}

Generate 3-5 challenging questions or counterarguments that would help strengthen this thought. Be specific and reference the actual content. Format as a JSON array of strings.

Respond with valid JSON only: ["challenge1", "challenge2", ...]`;

  try {
    const response = await llmChat([{ role: "user", content: prompt }], {
      model: OPENAI_MODEL_FAST,
      temperature: 0.8,
      max_tokens: 500
    });

    const text = response?.choices?.[0]?.message?.content || "";
    const jsonMatch = text.match(/\[[\s\S]*\]/);
    if (jsonMatch) {
      const challenges = JSON.parse(jsonMatch[0]);
      return { ok: true, challenges, method: "llm" };
    }

    return { ok: false, error: "Failed to parse response" };
  } catch (e) {
    return { ok: false, error: String(e.message || e) };
  }
}

// ---- Steelman Mode (AI Strengthens Your Thoughts) ----
async function steelmanThought(dtuId) {
  const dtu = STATE.dtus.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };

  if (!LLM_READY) {
    return {
      ok: true,
      suggestions: [
        "Add supporting evidence or citations",
        "Clarify the main claim",
        "Address potential counterarguments",
        "Connect to related concepts",
        "Add practical implications"
      ],
      method: "template"
    };
  }

  const prompt = `You are helping strengthen and improve a thought. Suggest specific improvements that would make the argument more rigorous, complete, and compelling.

THOUGHT:
Title: ${dtu.title}
Content: ${dtu.content || "(no content)"}

Generate 3-5 specific, actionable suggestions to strengthen this thought. Be concrete and reference the actual content. Format as JSON array.

Respond with valid JSON only: ["suggestion1", "suggestion2", ...]`;

  try {
    const response = await llmChat([{ role: "user", content: prompt }], {
      model: OPENAI_MODEL_FAST,
      temperature: 0.7,
      max_tokens: 500
    });

    const text = response?.choices?.[0]?.message?.content || "";
    const jsonMatch = text.match(/\[[\s\S]*\]/);
    if (jsonMatch) {
      return { ok: true, suggestions: JSON.parse(jsonMatch[0]), method: "llm" };
    }

    return { ok: false, error: "Failed to parse response" };
  } catch (e) {
    return { ok: false, error: String(e.message || e) };
  }
}

// ============================================================================
// END WAVE 7: DIFFERENTIATORS
// ============================================================================

// ===================== ORGANISM PIPELINE UPGRADE (Merged Organ Graft) =====================
// This graft adds: proposals + WAL + snapshot rollback + deterministic verifier + enforced commits.
// It preserves all existing macros/endpoints by routing DTU mutations through pipelineCommitDTU(ctx,...)
// LLM is always optional; pipeline is deterministic and local-first.

const PIPE = {
  enabled: true,
  proposals: new Map(),     // id -> proposal
  walPath: path.join(DATA_DIR, "wal.jsonl"),
  auditPath: path.join(DATA_DIR, "audit.jsonl"),
  snapshotsDir: path.join(DATA_DIR, "snapshots"),
};

function pipeEnsureDirs() {
  try { fs.mkdirSync(PIPE.snapshotsDir, { recursive: true }); } catch {}
}
pipeEnsureDirs();

function pipeAppendJsonl(file, obj) {
  try { fs.appendFileSync(file, JSON.stringify(obj) + "\n", "utf-8"); } catch {}
}

function pipeAudit(type, message, meta={}) {
  const e = { id: uid("audit"), ts: nowISO(), type, message, meta };
  pipeAppendJsonl(PIPE.auditPath, e);
  return e;
}

function pipeWal(type, meta={}) {
  const e = { id: uid("wal"), ts: nowISO(), type, meta };
  pipeAppendJsonl(PIPE.walPath, e);
  return e;
}

function pipeSnapshot() {
  const stamp = nowISO().replace(/[:.]/g, "-");
  const dir = path.join(PIPE.snapshotsDir, `snap_${stamp}_${crypto.randomBytes(3).toString("hex")}`);
  try { fs.mkdirSync(dir, { recursive: true }); } catch {}
  try {
    fs.writeFileSync(path.join(dir, "state.json"), JSON.stringify(_serializeState(), null, 2), "utf-8");
  } catch {}
  return dir;
}

function pipeRestoreSnapshot(dir) {
  try {
    const raw = fs.readFileSync(path.join(dir, "state.json"), "utf-8");
    const obj = JSON.parse(raw);
    _hydrateState(obj);
    saveStateDebounced();
    return { ok: true };
  } catch (e) {
    return { ok: false, error: String(e?.message||e) };
  }
}

function pipeProposal(action, payload, actor={ kind:"system", id:"system" }) {
  const p = {
    id: uid("prop"),
    action,
    payload,
    actor,
    status: "proposed",
    createdAt: nowISO(),
    updatedAt: nowISO(),
    verify: null,
    council: null,
    install: null,
    rollback: null
  };
  PIPE.proposals.set(p.id, p);
  pipeWal("proposal.create", { id: p.id, action });
  pipeAudit("proposal.create", `Proposal: ${action}`, { proposalId: p.id, actor });
  return p;
}

function pipeValidateDTU(dtu) {
  // Minimal hard schema gates (deterministic)
  if (!dtu || typeof dtu !== "object") return { ok:false, reason:"not_object" };
  if (!dtu.id) dtu.id = uid("dtu");
  if (!dtu.title || typeof dtu.title !== "string") return { ok:false, reason:"missing_title" };
  if (!Array.isArray(dtu.tags)) dtu.tags = [];
  if (!dtu.human) dtu.human = { summary:"", bullets:[] };
  if (!dtu.core) dtu.core = { definitions:[], invariants:[], claims:[], examples:[], nextActions:[] };
  for (const k of ["definitions","invariants","claims","examples","nextActions"]) {
    if (!Array.isArray(dtu.core[k])) dtu.core[k] = [];
  }
  // Secrets guard (basic)
  const hp = String(dtu.cretiHuman || dtu.creti || dtu.human?.summary || "");
  if (/\bsk-[A-Za-z0-9]{10,}\b/.test(hp)) return { ok:false, reason:"secret_detected" };
  return { ok:true };
}

function pipeContentFingerprint(dtu) {
  const base = [
    dtu.title||"",
    (dtu.tags||[]).slice().sort().join("|"),
    dtu.human?.summary||"",
    (dtu.human?.bullets||[]).join("|"),
    (dtu.core?.definitions||[]).join("|"),
    (dtu.core?.invariants||[]).join("|"),
    (dtu.core?.claims||[]).join("|"),
  ].join("\n");
  return crypto.createHash("sha256").update(base).digest("hex").slice(0, 16);
}

function pipeDedupe(dtu) {
  const fp = pipeContentFingerprint(dtu);
  for (const x of STATE.dtus.values()) {
    const xfp = x.hash || pipeContentFingerprint(x);
    if (xfp === fp) return { dup:true, matchId:x.id, reason:"fingerprint" };
  }
  return { dup:false, fingerprint: fp };
}


// =================== INVARIANT/CONSTRAINT CHECKERS (minimal, non-destructive) ===================
// These are conservative by design: they ONLY flag explicit, direct contradictions (e.g., "X" vs "NOT X").
// No fuzzy semantic inference is performed to avoid false positives.

function _normAtom(s) { return normalizeText(String(s||"")).replace(/\s+/g," ").trim(); }

function pipeConflictCheckDTU(dtu) {
  const inv = Array.isArray(dtu?.core?.invariants) ? dtu.core.invariants : [];
  const clm = Array.isArray(dtu?.core?.claims) ? dtu.core.claims : [];
  const atoms = new Set([...inv, ...clm].map(_normAtom).filter(Boolean));

  if (!atoms.size) return { ok:true, conflicts:[] };

  const conflicts = [];
  const oppose = (a) => a.startsWith("not ") ? a.slice(4) : ("not " + a);

  for (const x of STATE.dtus.values()) {
    if (!x || x.id === dtu.id) continue;
    const xinvs = Array.isArray(x?.core?.invariants) ? x.core.invariants : [];
    const xclm = Array.isArray(x?.core?.claims) ? x.core.claims : [];
    const xatoms = new Set([...xinvs, ...xclm].map(_normAtom).filter(Boolean));
    if (!xatoms.size) continue;

    for (const a of atoms) {
      const b = oppose(a);
      if (xatoms.has(b)) {
        conflicts.push({ withId: x.id, a, b });
        // Keep this minimal: one conflict is enough to flag.
        return { ok:false, conflicts };
      }
    }
  }
  return { ok:true, conflicts };
}


function pipeVerify(proposal) {
  const checks = [];
  let ok = true;
  const check = (name, pass, detail) => { checks.push({ name, pass:!!pass, detail }); if (!pass) ok = false; };

  if (proposal.action === "dtu.commit") {
    const dtu = proposal.payload?.dtu;
    const sv = pipeValidateDTU(dtu);
    check("schema", sv.ok, sv.reason);
    const dd = pipeDedupe(dtu);
    check("dedupe", !dd.dup, dd.dup ? `${dd.reason}:${dd.matchId}` : "ok");
    const cc = pipeConflictCheckDTU(dtu);
    check("conflicts", cc.ok, cc.ok ? "ok" : `conflict:${(cc.conflicts[0]||{}).withId||""}`);
  }

  return { ok, checks };
}

function pipeCouncil(proposal, ctx, opts={}) {
  // Reuse existing councilGate if available in this monolith; otherwise allow.
  try {
    if (proposal.action === "dtu.commit") {
      const dtu = proposal.payload.dtu;
      const allowRewrite = !!opts.allowRewrite;
      const gate = councilGate(dtu, { allowRewrite });
      return { ok: gate.ok, score: gate.score, reason: gate.reason };
    }
  } catch {}
  return { ok: true, score: 999, reason: "bypass" };
}

// =================== ABSTRACTION GOVERNOR (v3) ===================
// Abstraction is additive; Concord measures it and applies three automations:
// 1) placement (where a DTU belongs: tier/scope)
// 2) promotion/demotion budgets (keep highs sparse)
// 3) conservation invariant (added ~ collapsed over time)

function _dtuStats(dtu) {
  if (!dtu.stats || typeof dtu.stats !== 'object') dtu.stats = { uses: 0, lastUsedAt: null, contexts: [] };
  if (!Array.isArray(dtu.stats.contexts)) dtu.stats.contexts = [];
  return dtu.stats;
}

function markDTUUsed(dtu, ctxKey="") {
  const s = _dtuStats(dtu);
  s.uses = Number(s.uses||0) + 1;
  s.lastUsedAt = nowISO();
  if (ctxKey) {
    s.contexts.unshift(String(ctxKey).slice(0,64));
    s.contexts = Array.from(new Set(s.contexts)).slice(0, 12);
  }
}

function estimateAbstractionDelta(dtu) {
  // lightweight proxy: tier + content richness
  const tierW = dtu.tier === 'hyper' ? 3 : dtu.tier === 'mega' ? 2 : 1;
  const c = dtu.core || {};
  const richness = (
    (c.definitions?.length||0) +
    (c.invariants?.length||0) +
    (c.examples?.length||0) +
    (c.tests?.length||0)
  );
  return tierW * clamp(richness / 10, 0.25, 2);
}

function abstractionBudgets(n) {
  // Keep high-tier nodes sparse; budgets scale sublinearly.
  const megas = Math.max(1, Math.floor(Math.sqrt(Math.max(1,n)) / 2));
  const hypers = Math.max(1, Math.floor(Math.log2(Math.max(2,n)) / 5));
  return { maxMegas: megas, maxHypers: hypers };
}

function computeAbstractionSnapshot() {
  const n = STATE.dtus.size;
  const dtus = Array.from(STATE.dtus.values());
  let ecc = 0;
  let totalUses = 0;
  let reuseSpanDays = 0;
  let internalCount = 0;

  for (const d of dtus) {
    const tags = Array.isArray(d.tags) ? d.tags.length : 0;
    const c = d.core || {};
    const defs = c.definitions?.length||0;
    const inv = c.invariants?.length||0;
    ecc += clamp((tags + defs + inv) / 6, 0, 3);
    const s = d.stats;
    const uses = Number(s?.uses||0);
    totalUses += uses;
    if (s?.lastUsedAt && d.createdAt) {
      const span = (new Date(s.lastUsedAt).getTime() - new Date(d.createdAt).getTime()) / 86400000;
      reuseSpanDays += clamp(span, 0, 365);
    }
    internalCount += 1; // local-first today
  }

  const avgReuseDays = n ? reuseSpanDays / n : 0;
  const rd = clamp(avgReuseDays / 30, 0, 1); // normalize to ~1 month
  const ir = clamp(internalCount / Math.max(1,n), 0, 1);
  const { maxMegas, maxHypers } = abstractionBudgets(n);
  const megasNow = dtus.filter(d=>d.tier==='mega').length;
  const hypersNow = dtus.filter(d=>d.tier==='hyper').length;

  // Load rises with high-tier density + unresolved contradictions.
  const hiLoad = (megasNow / Math.max(1,maxMegas) + hypersNow / Math.max(1,maxHypers)) / 2;
  const contradictionLoad = Number(STATE.growth?.functionalDecline?.contradictionLoad||0);
  const load = clamp(0.35*clamp(ecc/Math.max(1,n),0,3) + 0.45*clamp(hiLoad,0,2) + 0.20*clamp(contradictionLoad/10,0,1), 0, 1);
  const margin = clamp(1 - load, 0, 1);

  // ETUA proxy: the ability to safely add abstraction increases with margin and dedupe/repair health
  const dedupeMiss = Number(STATE.growth?.functionalDecline?.dedupeMissRate||0);
  const wrapperFail = Number(STATE.growth?.functionalDecline?.wrapperFailureRate||0);
  const etua = clamp(margin * (1 - clamp(dedupeMiss,0,1)) * (1 - clamp(wrapperFail,0,1)), 0, 1);

  return {
    ecc: Number((ecc).toFixed(4)),
    rd: Number((rd).toFixed(4)),
    ir: Number((ir).toFixed(4)),
    etua: Number((etua).toFixed(4)),
    load: Number((load).toFixed(4)),
    margin: Number((margin).toFixed(4)),
    budgets: { maxMegas, maxHypers, megasNow, hypersNow },
    totals: { n, totalUses }
  };
}

function applyAbstractionPlacement(dtu) {
  // Determine tier/scope based on reuse + richness + tests.
  const s = _dtuStats(dtu);
  const uses = Number(s.uses||0);
  const ctxs = Array.isArray(s.contexts) ? s.contexts.length : 0;
  const c = dtu.core || {};
  const hasTests = (c.tests?.length||0) > 0;
  const richness = clamp(((c.definitions?.length||0)+(c.invariants?.length||0)+(c.examples?.length||0)) / 10, 0, 1);
  const reuse = clamp((uses/12)*0.6 + (ctxs/6)*0.4, 0, 1);
  const score = clamp(0.55*reuse + 0.45*richness + (hasTests?0.1:0), 0, 1);
  dtu.abstraction = { score, uses, contexts: ctxs, hasTests, richness };

  // Default scope is local-first.
  if (!dtu.scope) dtu.scope = 'local';

  // Promotion rules (subject to budgets enforcement later)
  if (score >= 0.90 && uses >= 12 && ctxs >= 6 && hasTests) dtu.tier = 'hyper';
  else if (score >= 0.75 && uses >= 6 && ctxs >= 3) dtu.tier = 'mega';
  else dtu.tier = dtu.tier || 'regular';

  return dtu;
}

function enforceTierBudgets() {
  const snap = computeAbstractionSnapshot();
  const { maxMegas, maxHypers } = snap.budgets;
  const dtus = Array.from(STATE.dtus.values());
  const megas = dtus.filter(d=>d.tier==='mega');
  const hypers = dtus.filter(d=>d.tier==='hyper');

  const byUtility = (a,b)=>{
    const au = Number(a.abstraction?.score||0) * (Number(a.stats?.uses||0)+1);
    const bu = Number(b.abstraction?.score||0) * (Number(b.stats?.uses||0)+1);
    return bu - au;
  };

  if (hypers.length > maxHypers) {
    hypers.sort(byUtility);
    for (const d of hypers.slice(maxHypers)) {
      d.tier = 'mega';
      d.updatedAt = nowISO();
      STATE.abstraction.ledger.collapsed += 1; // treat demotion as "collapse" of excessive abstraction
    }
  }
  if (megas.length > maxMegas) {
    megas.sort(byUtility);
    for (const d of megas.slice(maxMegas)) {
      d.tier = 'regular';
      d.updatedAt = nowISO();
      STATE.abstraction.ledger.collapsed += 0.5;
    }
  }

  STATE.abstraction.metrics = { ...STATE.abstraction.metrics, ...snap };
  STATE.abstraction.lastEvalAt = nowISO();
  STATE.abstraction.history.push({ at: nowISO(), ...snap, ledger: { ...STATE.abstraction.ledger } });
  STATE.abstraction.history = STATE.abstraction.history.slice(-60);
}

function applyConservationBackpressure() {
  // If abstraction added is outpacing collapse, increase grounding pressure.
  const { added, collapsed } = STATE.abstraction.ledger || { added:0, collapsed:0 };
  const delta = added - collapsed;
  if (delta <= 5) return { ok:true, did:"none", delta };

  // Backpressure actions are deterministic and local.
  // 1) run dedupe sweep
  STATE.queues.maintenance.push({ id: uid('maint'), kind:'dedupe', createdAt: nowISO(), reason:`conservation_delta_${delta.toFixed(2)}` });
  // 2) slightly reduce default abstraction depth to keep outputs crisp
  STATE.settings.abstractionDepthDefault = clamp(Number(STATE.settings.abstractionDepthDefault||1) - 1, 0, Number(STATE.settings.abstractionMaxDepth||3));
  // 3) nudge crispness up (forces tighter evidence selection)
  STATE.settings.crispnessMin = clamp(Number(STATE.settings.crispnessMin||0.25) + 0.05, 0.1, 0.9);

  // Record some collapse credit up front (the maint job will do the rest)
  STATE.abstraction.ledger.collapsed += Math.min(2, delta/2);
  return { ok:true, did:"backpressure", delta };
}


// =================== AUTO-PROMOTION / COMPRESSION (Mega/Hyper synthesis) ===================
// Purpose: keep the *effective* working set small by creating canonical Mega/Hyper DTUs that
// summarize highly-coactivated regular DTUs, and marking children with meta.canonicalId.
// This is deterministic, offline-safe, and gated through the existing DTU commit pipeline.
// It does NOT delete knowledge; it creates canonical abstractions and de-prioritizes children.

function _isCanonicalSelf(d) {
  const cid = d?.meta?.canonicalId;
  return !cid || cid === d.id;
}

function _tagsOf(d){ return Array.isArray(d?.tags) ? d.tags : []; }

function _clusterCandidates(dtus) {
  // rank by usage; prefer regular DTUs that are currently canonical selves
  const cands = dtus
    .filter(d => (d.tier||"regular")==="regular")
    .filter(d => _isCanonicalSelf(d))
    .map(d => ({ d, uses: Number(d.stats?.uses||0), ctxs: Number(d.stats?.contexts?.length||0) }))
    .sort((a,b)=> (b.uses-a.uses) || (b.ctxs-a.ctxs));
  return cands;
}

function _tagJaccard(aTags, bTags) {
  const A = new Set(aTags||[]);
  const B = new Set(bTags||[]);
  if (!A.size || !B.size) return 0;
  let inter=0;
  for (const x of A) if (B.has(x)) inter++;
  const uni = A.size + B.size - inter;
  return uni ? inter/uni : 0;
}

function _tokenJaccard(a, b) {
  const A = new Set(simpleTokens(a||""));
  const B = new Set(simpleTokens(b||""));
  if (!A.size || !B.size) return 0;
  let inter=0;
  for (const x of A) if (B.has(x)) inter++;
  const uni = A.size + B.size - inter;
  return uni ? inter/uni : 0;
}

// LLM-enhanced MEGA synthesis - creates coherent summaries
async function _makeMegaFromCluster(cluster, reason="auto_cluster") {
  const members = cluster.map(x=>x.d);
  const ids = members.map(d=>d.id);
  const titles = members.map(d=>d.title).filter(Boolean).slice(0,8);
  const seedTitle = titles[0] || "Cluster";

  // Conservative synthesis: only aggregate what's already explicit.
  const inv = [];
  const defs = [];
  const claims = [];
  const examples = [];
  for (const d of members) {
    const c = d.core || {};
    for (const x of (c.invariants||[])) if (inv.length < 18) inv.push(String(x));
    for (const x of (c.definitions||[])) if (defs.length < 12) defs.push(String(x));
    for (const x of (c.claims||[])) if (claims.length < 18) claims.push(String(x));
    for (const x of (c.examples||[])) if (examples.length < 10) examples.push(String(x));
  }

  // Try LLM-enhanced title and summary
  let title = `MEGA: ${seedTitle} (+${Math.max(0, ids.length-1)})`;
  let summary = `Canonical mega DTU synthesized from ${ids.length} DTUs to reduce working-set load. Reason: ${reason}.`;

  try {
    const titlesStr = titles.join(", ");
    const claimsStr = claims.slice(0, 5).join("; ");

    const prompt = `Create a concise, coherent title and summary for a MEGA DTU that consolidates these related concepts:

Titles: ${titlesStr}
Key claims: ${claimsStr}

Output format (2 lines only):
TITLE: [A clear 5-10 word title starting with "MEGA:"]
SUMMARY: [A 1-2 sentence summary of what this mega represents]`;

    const llmResult = await llmPipeline(prompt, { mode: "balanced", maxTokens: 150, temperature: 0.3 });
    if (llmResult.ok && llmResult.content) {
      const lines = llmResult.content.split("\n").filter(Boolean);
      for (const line of lines) {
        if (line.toUpperCase().startsWith("TITLE:")) {
          const newTitle = line.replace(/^TITLE:\s*/i, "").trim();
          if (newTitle && newTitle.length > 5) title = newTitle.startsWith("MEGA:") ? newTitle : `MEGA: ${newTitle}`;
        }
        if (line.toUpperCase().startsWith("SUMMARY:")) {
          const newSummary = line.replace(/^SUMMARY:\s*/i, "").trim();
          if (newSummary && newSummary.length > 10) summary = newSummary;
        }
      }
    }
  } catch (e) {
    // Fallback to template if LLM fails
    console.log("[MEGA] LLM synthesis failed, using template:", e.message);
  }

  const tags = Array.from(new Set([
    "mega","auto","canonical","cluster",
    ...members.flatMap(d=>_tagsOf(d)).filter(t=>typeof t==="string").slice(0,30)
  ])).slice(0, 40);

  const now = nowISO();
  return {
    id: uid("dtu"),
    title,
    tier: "mega",
    tags,
    human: {
      summary,
      bullets: [
        `Members: ${ids.slice(0,8).join(", ")}${ids.length>8 ? "…" : ""}`,
        "This mega consolidates explicit content from members for reduced working-set load."
      ],
    },
    core: {
      definitions: defs,
      invariants: inv,
      claims,
      examples,
      nextActions: [
        "Use this Mega as the canonical entry point; drill down into member DTUs for full detail.",
        "If contradictions appear between members, resolve by splitting the cluster into multiple Megas."
      ],
      tests: [
        "No new invariant should appear here unless it exists in at least one member DTU.",
        "If two member invariants are explicit opposites, this mega should be rejected by conflict check."
      ],
    },
    machine: {
      kind: "mega_cluster",
      members: ids,
      // A simple, explicit aggregation equation (no liberties):
      equation: "Mega(M) = ⊕_{i∈members} DTU_i  (explicit aggregation only)",
      metrics: { memberCount: ids.length }
    },
    lineage: { parents: ids.slice(0, 32), children: [] },
    source: "auto",
    meta: { canonicalId: null, hidden: false },
    createdAt: now,
    updatedAt: now,
    authority: { model: "concord", score: 0.6 },
    hash: ""
  };
}

// LLM-enhanced HYPER synthesis - creates coherent kernel summaries
async function _makeHyperFromMegas(megas, reason="auto_hyper") {
  const members = megas.slice(0, 4);
  const ids = members.map(d=>d.id);
  const megaTitles = members.map(d=>d.title).filter(Boolean);

  // Try LLM-enhanced title and summary
  let title = `HYPER: Abstraction Kernel (+${ids.length})`;
  let summary = `Canonical hyper DTU synthesized from Megas to provide a stable derivation/checking kernel. Reason: ${reason}.`;

  try {
    const titlesStr = megaTitles.join(", ");
    const prompt = `Create a concise title and summary for a HYPER DTU kernel that synthesizes these MEGA DTUs:

Megas: ${titlesStr}

A HYPER is a high-level abstraction that routes queries to the right MEGAs and enforces consistency.

Output format (2 lines only):
TITLE: [A clear 5-10 word title starting with "HYPER:"]
SUMMARY: [A 1-2 sentence summary of what this kernel does]`;

    const llmResult = await llmPipeline(prompt, { mode: "balanced", maxTokens: 150, temperature: 0.3 });
    if (llmResult.ok && llmResult.content) {
      const lines = llmResult.content.split("\n").filter(Boolean);
      for (const line of lines) {
        if (line.toUpperCase().startsWith("TITLE:")) {
          const newTitle = line.replace(/^TITLE:\s*/i, "").trim();
          if (newTitle && newTitle.length > 5) title = newTitle.startsWith("HYPER:") ? newTitle : `HYPER: ${newTitle}`;
        }
        if (line.toUpperCase().startsWith("SUMMARY:")) {
          const newSummary = line.replace(/^SUMMARY:\s*/i, "").trim();
          if (newSummary && newSummary.length > 10) summary = newSummary;
        }
      }
    }
  } catch (e) {
    console.log("[HYPER] LLM synthesis failed, using template:", e.message);
  }

  const tags = Array.from(new Set([
    "hyper","auto","canonical","kernel",
    ...members.flatMap(d=>_tagsOf(d)).filter(t=>typeof t==="string").slice(0,30)
  ])).slice(0, 40);

  const now = nowISO();
  return {
    id: uid("dtu"),
    title,
    tier: "hyper",
    tags,
    human: {
      summary,
      bullets: [
        `Mega inputs: ${ids.join(", ")}`,
        "Kernel routes queries and enforces invariant consistency."
      ]
    },
    core: {
      definitions: [
        "A Hyper DTU is a canonical kernel that routes questions to Megas and enforces invariant-first composition.",
        "Hyper DTUs are allowed to define procedures, not new domain claims."
      ],
      invariants: [
        "Kernel must not assert domain facts not present in referenced Megas/children.",
        "Kernel must preserve feasibility-first classification in ask/forge/sim outputs."
      ],
      claims: [
        "Using a Hyper DTU reduces working-set load by routing to a small set of canonical Megas.",
        "Kernel increases consistency by centralizing decision procedures."
      ],
      examples: [
        "Given query q: retrieve top Megas; expand into member DTUs only if needed; output feasibility + minimal explanation."
      ],
      nextActions: [
        "Use this Hyper as first-pass router; update by replacing members with newer canonical Megas as lattice evolves."
      ],
      tests: [
        "Hyper must always cite its Mega members (lineage.parents) as provenance.",
        "Hyper should not include contradictory Mega members (conflict check should reject)."
      ]
    },
    machine: {
      kind: "hyper_kernel",
      members: ids,
      equation: "Route(q) = topK_{mega}(sim(q, mega)); Expand only if needed; Verify invariants first",
      metrics: { megaCount: ids.length }
    },
    lineage: { parents: ids.slice(0, 32), children: [] },
    source: "auto",
    meta: { canonicalId: null, hidden: false },
    createdAt: now,
    updatedAt: now,
    authority: { model: "concord", score: 0.7 },
    hash: ""
  };
}

async function runAutoPromotion(ctx, { maxNewMegas=2, maxNewHypers: _maxNewHypers=1 } = {}) {
  if (!STATE.abstraction.enabled) return { ok:true, did:"disabled" };

  const snap = computeAbstractionSnapshot();
  const dtus = Array.from(STATE.dtus.values());

  // Respect budgets: only synthesize when we're below budget and lattice has some usage signal.
  const { maxMegas, maxHypers, megasNow, hypersNow } = snap.budgets;
  const canMakeMega = megasNow < maxMegas;
  const canMakeHyper = hypersNow < maxHypers;

  const made = { megas: [], hypers: [], canonicalized: 0 };
  if (!snap.totals.totalUses || snap.totals.totalUses < 25) {
    return { ok:true, did:"insufficient_usage", snap, made };
  }

  // ---- Mega synthesis from co-activated regular DTUs ----
  if (canMakeMega) {
    const cands = _clusterCandidates(dtus);
    const used = new Set();
    let madeCount = 0;

    for (const seed of cands.slice(0, 40)) {
      if (madeCount >= maxNewMegas) break;
      const sd = seed.d;
      if (used.has(sd.id)) continue;
      const sTags = _tagsOf(sd);
      const sTokStr = `${sd.title||""} ${(sd.tags||[]).join(" ")} ${(sd.cretiHuman||sd.human?.summary||"")}`;
      const cluster = [{ d: sd, uses: seed.uses }];

      for (const cand of cands.slice(0, 80)) {
        const cd = cand.d;
        if (cd.id === sd.id) continue;
        if (used.has(cd.id)) continue;
        // Coherence requirement: tag overlap OR token overlap (conservative)
        const tj = _tagJaccard(sTags, _tagsOf(cd));
        const kj = _tokenJaccard(sTokStr, `${cd.title||""} ${(cd.tags||[]).join(" ")} ${(cd.cretiHuman||cd.human?.summary||"")}`);
        if (tj >= 0.30 || kj >= 0.12) {
          cluster.push({ d: cd, uses: cand.uses });
        }
        if (cluster.length >= 7) break;
      }

      if (cluster.length < 4) continue; // don't synthesize tiny clusters

      const mega = await _makeMegaFromCluster(cluster, "usage_coactivation");
      const res = pipelineCommitDTU(ctx, mega, { op:"auto.promo.mega", allowRewrite:false });
      if (res?.ok) {
        made.megas.push(res.dtu?.id || mega.id);
        madeCount += 1;

        // Canonicalize children to this Mega (so canonicalOnly keeps working set low)
        for (const m of cluster.map(x=>x.d)) {
          if (!m.meta) m.meta = {};
          m.meta.canonicalId = (res.dtu?.id || mega.id);
          m.updatedAt = nowISO();
          used.add(m.id);
          made.canonicalized += 1;
        }
        // Persist child updates
        saveStateDebounced();
      }
    }
  }

  // ---- Hyper synthesis from top-used Megas ----
  if (canMakeHyper) {
    const megas = dtus
      .filter(d => d.tier === "mega")
      .filter(d => _isCanonicalSelf(d))
      .map(d => ({ d, uses: Number(d.stats?.uses||0) }))
      .sort((a,b)=>b.uses-a.uses)
      .map(x=>x.d);

    if (megas.length >= 2) {
      const hyper = await _makeHyperFromMegas(megas, "top_megas");
      const res = pipelineCommitDTU(ctx, hyper, { op:"auto.promo.hyper", allowRewrite:false });
      if (res?.ok) made.hypers.push(res.dtu?.id || hyper.id);
    }
  }

  // Enforce budgets after synthesis
  try { enforceTierBudgets(); } catch {}

  // Record last promotion
  STATE.abstraction.lastPromotionAt = nowISO();
  saveStateDebounced();

  return { ok:true, did:"promoted", snap, made };
}


async function maybeRunLocalUpgrade() {
  if (!STATE.abstraction.enabled) return { ok:true, did:"disabled" };
  const cadence = Number(STATE.abstraction.cadenceDays||10);
  const last = STATE.abstraction.lastUpgradeAt ? new Date(STATE.abstraction.lastUpgradeAt).getTime() : 0;
  const now = Date.now();
  const due = !last || (now - last) >= cadence * 86400000;
  if (!due) return { ok:true, did:"not_due" };

  // Upgrade = deterministic retune + enforce budgets + auto-promotion + conservation check.
  enforceTierBudgets();
  const _upCtx = makeCtx(null);
  _upCtx.actor = { userId: "system", orgId: "internal", role: "owner", scopes: ["*"] };
  try { await runAutoPromotion(_upCtx, { maxNewMegas: 3, maxNewHypers: 1 }); } catch {}
  const bp = applyConservationBackpressure();
  // Opportunistic self-repair: schedule maintenance if needed
  if (STATE.queues.maintenance.length < 25) {
    STATE.queues.maintenance.push({ id: uid('maint'), kind:'repair', createdAt: nowISO(), reason:'periodic_upgrade' });
  }

  STATE.abstraction.lastUpgradeAt = nowISO();
  saveStateDebounced();
  return { ok:true, did:"upgraded", backpressure: bp };
}
// ================= END ABSTRACTION GOVERNOR =================

async function pipelineCommitDTU(ctx, dtu, opts={}) {
  if (!PIPE.enabled) {
    // fallback to legacy write
    if (isShadowDTU(dtu)) STATE.shadowDtus.set(dtu.id, dtu);
    else STATE.dtus.set(dtu.id, dtu);
    saveStateDebounced();
    return { ok:true, dtu, bypassed:true };
  }
  // --- Anti-gaming guard: only system promotion may create MEGA/HYPER DTUs ---
  try {
    const op = String(opts.op || "");
    const systemOp = op.startsWith("auto.promo.") || op.startsWith("auto.promo") || op.startsWith("auto.promotion");
    const systemCtx = !!(ctx && (ctx.system === true || ctx.isSystem === true || ctx?.meta?.system === true));
    if ((dtu?.tier === "mega" || dtu?.tier === "hyper") && !(systemOp || systemCtx)) {
      // Downgrade to regular; users can't self-promote tiers.
      dtu.tier = "regular";
      dtu.tags = Array.from(new Set([...(dtu.tags||[]), "tier_downgraded"]));
      dtu.meta = dtu.meta || {};
      dtu.meta.tierDowngradedAt = nowISO();
      dtu.meta.tierDowngradeReason = "anti_gaming_only_auto_promo_can_set_tier";
    }
  } catch { /* anti-gaming guard may fail gracefully */ }
  const p = pipeProposal("dtu.commit", { dtu }, { kind:"macro", id: opts.op || "unknown" });
  const vr = pipeVerify(p);
  p.verify = vr; p.updatedAt = nowISO();
  if (!vr.ok) {
    p.status = "rejected";
    pipeAudit("dtu.reject", "Verifier rejected DTU", { proposalId: p.id, checks: vr.checks });
    return { ok:false, error:"verifier_reject", proposalId:p.id, verify: vr };
  }
  p.status = "verified";
  const cr = pipeCouncil(p, ctx, opts);
  p.council = cr; p.updatedAt = nowISO();
  if (!cr.ok) {
    p.status = "rejected";
    pipeAudit("dtu.reject", "Council rejected DTU", { proposalId: p.id, reason: cr.reason, score: cr.score });
    return { ok:false, error:"council_reject", proposalId:p.id, council: cr };
  }
  p.status = "approved";

  // ===== QUALITY PIPELINE BACKEND ENHANCEMENTS =====
  // [NEW] Coherence Audit — cross-check claims vs invariants internally
  try {
    const _coherence = coherenceAudit(dtu);
    if (!_coherence.ok) {
      pipeAudit("dtu.coherence_warning", "Internal coherence issues detected", {
        proposalId: p.id,
        issues: _coherence.issues.slice(0, 5)
      });
      // Don't reject — just warn. The DTU may still be valuable.
    }
  } catch {}

  // [NEW] Shadow Promotion — if pattern seen 3+ times, auto-create shadow DTU
  try {
    const _promo = maybeShadowPromotion(dtu);
    if (_promo.promoted) {
      pipeAudit("dtu.shadow_promotion", "Auto-promoted pattern to shadow DTU", {
        proposalId: p.id,
        shadowId: _promo.shadowId,
        invariants: _promo.invariants
      });
    }
  } catch {}

  // [NEW] Crispness Decay — reduce crispness of older DTUs on same topic
  try {
    const _decay = applyCrispnessDecay(dtu);
    if (_decay.decayed > 0) {
      pipeAudit("dtu.crispness_decay", `Decayed ${_decay.decayed} older DTUs on overlapping topic`, {
        proposalId: p.id,
        decayed: _decay.decayed
      });
    }
  } catch {}
  // ===== END QUALITY PIPELINE BACKEND ENHANCEMENTS =====

  const snap = pipeSnapshot();
  try {
    // Human projection firewall: always render human-safe DTU view
    if (!dtu.cretiHuman) dtu.cretiHuman = renderHumanDTU(dtu);
    // Abstraction placement (tier/scope) before hashing/persistence
    applyAbstractionPlacement(dtu);
    dtu.hash = dtu.hash || pipeContentFingerprint(dtu);
    dtu.updatedAt = nowISO();

    // Conservation ledger: record abstraction added
    try {
      STATE.abstraction.ledger.added += estimateAbstractionDelta(dtu);
    } catch {}

    STATE.dtus.set(dtu.id, dtu);
    saveStateDebounced();

    // ===== AUTO WORLD MODEL UPDATE =====
    // Every new DTU feeds into the world model: extract entities, detect relations,
    // find contradictions, update confidence. This makes the world model self-correcting.
    try { autoUpdateWorldModel(dtu); } catch {}
    // ===== END AUTO WORLD MODEL UPDATE =====

    // Keep high-tier sparse & maintain metrics periodically
    try { enforceTierBudgets(); } catch {}
    try { await maybeRunLocalUpgrade(); } catch {}

    p.status = "installed";
    p.install = { installedAt: nowISO(), snapshotBefore: snap };
    p.updatedAt = nowISO();
    pipeWal("proposal.install", { id: p.id, action: p.action });
    pipeAudit("dtu.commit", `DTU committed: ${dtu.title}`, { id: dtu.id, proposalId: p.id, hash: dtu.hash });

    return { ok:true, dtu, proposalId: p.id };
  } catch (e) {
    const rb = pipeRestoreSnapshot(snap);
    p.status = "failed";
    p.install = { failedAt: nowISO(), error: String(e?.message||e), snapshotBefore: snap, rollback: rb };
    p.updatedAt = nowISO();
    pipeWal("proposal.install.fail", { id: p.id, error: String(e?.message||e) });
    pipeAudit("install.fail", "Commit failed; rolled back", { proposalId: p.id, error: String(e?.message||e), snapshot: snap });
    return { ok:false, error:String(e?.message||e), proposalId:p.id };
  }
}

function pipeListProposals(limit=50) {
  const items = Array.from(PIPE.proposals.values()).sort((a,b)=>(b.createdAt||"").localeCompare(a.createdAt||"")).slice(0, limit);
  return items;
}
// =================== END ORGANISM PIPELINE UPGRADE ===================


// ---- Retrieval helpers (dynamic, anti-loop) ----
function dtuText(d){ 
  const a = (d.cretiHuman || d.creti || d.human?.summary || "");
  const b = (d.title || "") + " " + (Array.isArray(d.tags)?d.tags.join(" "):"");
  return (b + " " + a).slice(0, 4000);
}
function retrieveDTUs(query, { topK=6, minScore=0.08, randomK=2, oppositeK=2 } = {}) {
  // Filter out shadow DTUs - they are internal and should not appear in retrieval results
  const all = dtusArray().filter(d => !isShadowDTU(d));
  const raw = String(query || "");
  const qNorm = normalizeQueryText(raw);
  const qBase = tokensNoStop(qNorm);          // stemmed, no stopwords
  const qExp  = expandQueryTokens(qNorm);     // stemmed + synonyms + learned expansions

  const scored = all.map(d => {
    const dt = dtuText(d);
    const dTok = simpleTokens(dt).map(stemLite).filter(Boolean);
    const scoreBase = jaccard(qBase, dTok);
    const scoreExp  = jaccard(qExp, dTok);
    const scoreGram = ngramSim(qNorm, dt);
    let score = 0.55*scoreBase + 0.30*scoreExp + 0.15*scoreGram;

    // Temporal OS: gentle recency boost (soft-gate, never forces output shape)
    const tw = temporalRecencyWeight(d);
    score = clamp(score + 0.12*tw, 0, 1);

    return { d, score, scoreBase, scoreExp, scoreGram, tw };
  }).sort((a,b)=>b.score-a.score);

  const topScored = scored.filter(x=>x.score >= minScore).slice(0, topK);
  const top = topScored.map(x=>x.d);

  // If retrieval evidence is weak, learn a lightweight linguistic mapping (shadow DTU)
  try {
    const best = scored[0]?.score ?? 0;
    if (qNorm && qNorm.length <= 120 && best < Math.max(0.10, minScore)) {
      // Heuristic: if it's a short chatty phrase, map toward intent-like tokens
      const intent = classifyIntent(qNorm)?.intent;
      const intentAdds =
        intent === INTENT.GREETING ? ["greeting","presence"] :
        intent === INTENT.STATUS   ? ["status","health","ready"] :
        intent === INTENT.QUESTION ? ["question","explain","help"] :
        ["chat","conversation","context"];
      const expands = Array.from(new Set([...(qExp||[]), ...intentAdds].map(stemLite))).slice(0, 18);
      maybeWriteLinguisticShadowDTU({ phrase: qNorm, expands, topIds: top.map(d=>d.id) });
    }
  } catch {}

  // random picks (avoid top)
  const pool = all.filter(d => !top.some(t=>t.id===d.id));
  const rand = [];
  for (let i=0;i<Math.min(randomK, pool.length);i++){
    const idx = Math.floor(Math.random()*pool.length);
    rand.push(pool.splice(idx,1)[0]);
  }

  // opposites: lowest similarity to query among remaining, but non-empty
  const oppos = scored.slice(-Math.min(50, scored.length)).filter(x => x.score <= 0.02).slice(0, oppositeK).map(x=>x.d);

  return { top, random: rand, opposite: oppos, scoredTop: scored.slice(0, Math.max(10, topK)) };
}

function pickDebateSet(query){
  const r = retrieveDTUs(query, { topK: 4, randomK: 2, oppositeK: 2 });
  const uniq = new Map();
  for (const d of [...r.top, ...r.random, ...r.opposite]) if (d && d.id) uniq.set(d.id, d);
  return Array.from(uniq.values());
}

// ---- Macro Domains ----

// DTU domain
register("dtu", "create", async (ctx, input) => {
  const title = normalizeText(input.title || "Untitled DTU");
  const tags = Array.isArray(input.tags) ? input.tags.map(t=>normalizeText(t)).filter(Boolean) : [];
  const tier = input.tier && ["regular","mega","hyper"].includes(input.tier) ? input.tier : "regular";
  const lineage = Array.isArray(input.lineage) ? input.lineage : [];
  const source = input.source || "local";
  const meta = input.meta && typeof input.meta === "object" ? input.meta : {};
  const allowRewrite = input.allowRewrite !== false;

  const coreIn = (input.core && typeof input.core === "object") ? input.core : {};
  const humanIn = (input.human && typeof input.human === "object") ? input.human : {};
  const machineIn = (input.machine && typeof input.machine === "object") ? input.machine : {};
  const rawText = String(input.creti ?? input.content ?? "");

  // ---- Injection Detection (Category 1: Adversarial) ----
  const injScan = detectContentInjection(rawText + " " + title);
  if (injScan.injected) {
    structuredLog("warn", "dtu_injection_detected", {
      patterns: injScan.patterns,
      source,
      userId: ctx?.actor?.id,
      titlePrefix: title.slice(0, 50),
    });
    // Tag for quarantine review rather than hard-block (reduces false positives)
    if (!tags.includes("quarantine:injection-review")) tags.push("quarantine:injection-review");
  }

  const dtu = {
    id: uid("dtu"),
    title,
    tags,
    tier,
    lineage,
    source,
    meta,
    core: {
      definitions: Array.isArray(coreIn.definitions) ? coreIn.definitions : [],
      invariants: Array.isArray(coreIn.invariants) ? coreIn.invariants : [],
      examples: Array.isArray(coreIn.examples) ? coreIn.examples : [],
      claims: Array.isArray(coreIn.claims) ? coreIn.claims : [],
      nextActions: Array.isArray(coreIn.nextActions) ? coreIn.nextActions : [],
    },
    human: {
      summary: String(humanIn.summary || ""),
      bullets: Array.isArray(humanIn.bullets) ? humanIn.bullets : [],
      examples: Array.isArray(humanIn.examples) ? humanIn.examples : [],
    },
    machine: { ...machineIn },
    cretiHuman: "",
    scope: "local",  // Scope Separation: all new DTUs start in Local scope
    createdAt: nowISO(),
    updatedAt: nowISO(),
    authority: { model: "council", score: 0, votes: {} },
  };

  if (rawText) {
    dtu.machine = dtu.machine || {};
    dtu.machine.notes = dtu.machine.notes ? (dtu.machine.notes + "\n\n" + rawText) : rawText;
    if (!dtu.human.summary) dtu.human.summary = normalizeText(rawText).slice(0, 320);
  }

  const gate = councilGate(dtu, { allowRewrite });
  if (!gate.ok) {
    ctx.log("dtu.reject", `Rejected DTU: ${title}`, { reason: gate.reason, score: gate.score, source });
    return { ok: false, error: "Council rejected DTU", reason: gate.reason, score: gate.score };
  }

  dtu.cretiHuman = dtu.cretiHuman || renderHumanDTU(dtu);
  dtu.hash = crypto.createHash("sha256").update(title + "\n" + dtu.cretiHuman).digest("hex").slice(0, 16);

  await pipelineCommitDTU(ctx, dtu, { op: 'dtu.create', allowRewrite: true });
  ctx.log("dtu.create", `Created DTU: ${title}`, { id: dtu.id, tier, tags, source, score: gate.score });
  return { ok: true, dtu };
}, { description: "Create a DTU (regular/mega/hyper) with structured core; UI receives human projection." });

register("dtu", "get", (ctx, input) => {
  const id = String(input.id || "");
  // Only return from main DTU store - shadow DTUs are internal
  const dtu = STATE.dtus.get(id);
  if (!dtu) return { ok: false, error: "DTU not found" };
  // Don't expose shadow DTUs via this endpoint
  if (isShadowDTU(dtu)) return { ok: false, error: "DTU not found" };
  return { ok: true, dtu };
});

register("dtu", "update", (ctx, input) => {
  const id = String(input.id || "");
  if (!id) return { ok: false, error: "Missing id" };
  const existing = STATE.dtus.get(id);
  if (!existing) return { ok: false, error: "DTU not found" };

  // ---- Optimistic Locking (Category 2: Concurrency) ----
  // If client sends expectedVersion, reject if stale
  if (input.expectedVersion !== undefined) {
    const currentVersion = existing._version || 1;
    if (Number(input.expectedVersion) !== currentVersion) {
      return {
        ok: false,
        error: "Version conflict: DTU was modified by another request",
        code: "VERSION_CONFLICT",
        currentVersion,
        expectedVersion: Number(input.expectedVersion),
      };
    }
  }

  // Update allowed fields
  const updated = { ...existing };
  if (input.title !== undefined) updated.title = String(input.title || existing.title);
  if (input.content !== undefined) updated.content = String(input.content);
  if (input.creti !== undefined) updated.creti = String(input.creti);
  if (input.tags !== undefined) updated.tags = Array.isArray(input.tags) ? input.tags.slice(0, 40) : existing.tags;
  // Tier changes require admin role - prevent gaming via direct update
  if (input.tier !== undefined && ["regular", "mega", "hyper"].includes(input.tier)) {
    const role = ctx?.actor?.role || "guest";
    if (!["owner", "admin", "founder"].includes(role)) {
      return { ok: false, error: "Tier changes require admin privileges" };
    }
    updated.tier = input.tier;
  }
  updated.updatedAt = nowISO();
  updated._version = (existing._version || 1) + 1;

  upsertDTU(updated, { broadcast: true });
  ctx.log("dtu.update", `Updated DTU: ${updated.title}`, { id, version: updated._version });
  return { ok: true, dtu: updated };
}, { description: "Update an existing DTU" });

register("dtu", "delete", (ctx, input) => {
  const id = String(input.id || "");
  if (!id) return { ok: false, error: "Missing id" };

  const dtu = STATE.dtus.get(id);
  if (!dtu) return { ok: false, error: "DTU not found" };

  // Authorization check - only owner/admin or DTU author can delete
  const role = ctx?.actor?.role || "guest";
  const userId = ctx?.actor?.id || ctx?.actor?.odId;
  const isAuthor = dtu.authorId === userId || dtu.source === userId;
  const isAdmin = ["owner", "admin", "founder"].includes(role);
  if (!isAuthor && !isAdmin) {
    return { ok: false, error: "Not authorized to delete this DTU" };
  }

  // Delete the DTU
  STATE.dtus.delete(id);
  SEARCH_INDEX.dirty = true;
  saveStateDebounced();

  // Broadcast deletion via WebSocket
  try {
    realtimeEmit("dtu:deleted", { id, title: dtu.title });
  } catch { /* best-effort */ }

  // Optionally notify federation
  if (_c3Federation.enabled) {
    federationPublish("dtu:deleted", { id, deletedAt: nowISO() }).catch((err) => { console.error('[federation] Publish deletion failed:', err); });
  }

  ctx.log("dtu.delete", `Deleted DTU: ${dtu.title}`, { id });
  return { ok: true, deleted: { id, title: dtu.title } };
}, { description: "Delete a DTU by id" });

register("dtu", "list", (ctx, input) => {
  const limit = clamp(Number(input.limit || 5000), 1, 5000);
  const offset = clamp(Number(input.offset || 0), 0, 1e9);
  const tier = input.tier && ["regular","mega","hyper","any"].includes(input.tier) ? input.tier : "any";
  const q = tokenish(input.q || "");
  // Filter out shadow DTUs - they are internal and should not appear in user-facing lists
  let items = dtusArray().filter(d => !isShadowDTU(d)).sort((a,b)=> (b.createdAt||"").localeCompare(a.createdAt||""));
  if (tier !== "any") items = items.filter(d => d.tier === tier);
  if (q) items = items.filter(d => tokenish(d.title).includes(q) || tokenish((d.tags||[]).join(" ")).includes(q) || tokenish((d.cretiHuman || d.creti || "")).includes(q));
  items = items.slice(offset, offset + limit);
  return { ok: true, dtus: items, limit, offset, total: STATE.dtus.size };
});
register("dtu", "listShadow", (ctx, input) => {
  // Shadow DTUs are internal - only admins can view them
  const role = ctx?.actor?.role || "guest";
  if (!["owner", "admin", "founder"].includes(role)) {
    return { ok: false, error: "Shadow DTU access requires admin privileges" };
  }
  const limit = clamp(Number(input.limit || 5000), 1, 5000);
  const offset = clamp(Number(input.offset || 0), 0, 1e9);
  const q = tokenish(input.q || "");
  let items = Array.from(STATE.shadowDtus.values()).sort((a,b)=> (b.createdAt||"").localeCompare(a.createdAt||""));
  if (q) items = items.filter(d => tokenish(d.title).includes(q) || tokenish((d.tags||[]).join(" ")).includes(q) || tokenish((d.cretiHuman || d.creti || "")).includes(q));
  items = items.slice(offset, offset + limit);
  return { ok: true, dtus: items, limit, offset, total: STATE.shadowDtus.size };
}, { description: "List shadow DTUs (internal/hidden by default, admin only)." });



register("dtu", "cluster", (ctx, input) => {
  // group DTUs by similarity (simple jaccard on title+tags)
  const items = dtusArray().filter(d => (d.tier || "regular") === "regular");
  const threshold = Number(input.threshold ?? 0.38);
  const clusters = [];
  const used = new Set();

  for (let i=0;i<items.length;i++){
    const a = items[i];
    if (used.has(a.id)) continue;
    const aTok = simpleTokens(a.title + " " + (a.tags||[]).join(" "));
    const cluster = [a];
    used.add(a.id);
    for (let j=i+1;j<items.length;j++){
      const b = items[j];
      if (used.has(b.id)) continue;
      const bTok = simpleTokens(b.title + " " + (b.tags||[]).join(" "));
      if (jaccard(aTok, bTok) >= threshold) {
        cluster.push(b);
        used.add(b.id);
      }
    }
    clusters.push(cluster);
  }

  clusters.sort((c1,c2)=>c2.length - c1.length);
  return {
    ok: true,
    threshold,
    clusters: clusters.map(c => ({
      size: c.length,
      ids: c.map(x=>x.id),
      titles: c.map(x=>x.title).slice(0, 12),
      tagHints: Array.from(new Set(c.flatMap(x=>x.tags||[]))).slice(0, 20)
    }))
  };
}, { description: "Cluster regular DTUs by topic similarity." });


register("dtu", "gapPromote", async (ctx, input) => {
  const minCluster = clamp(Number(input.minCluster || 5), 3, 50);
  const maxPromotions = clamp(Number(input.maxPromotions || 3), 1, 25);
  const dryRun = !!input.dryRun;

  // Use existing clustering logic (same as dtu.cluster) but promote stable clusters into a MEGA DTU.
  const regular = Array.from(STATE.dtus.values()).filter(d => (d.tier||"regular")==="regular" && !isShadowDTU(d) && (d.status||"active")==="active");
  if (regular.length < minCluster) return { ok:true, did:"none", reason:"not_enough_regular_dtus", regular: regular.length };

  // Lightweight topic hashing for cluster identity
  const topicKeyOf = (cluster) => {
    const tags = cluster.flatMap(d => Array.isArray(d.tags)?d.tags:[]).map(t=>String(t).toLowerCase()).filter(Boolean);
    tags.sort();
    return simpleHash(tags.slice(0, 30).join("|") + "|" + cluster.map(d=>d.id).slice(0,10).join("|"));
  };

  // Reuse cluster() macro internally by calling its implementation (avoid endpoint recursion)
  const clustersRes = await runMacro(ctx, "dtu", "cluster", { minCluster, maxClusters: clamp(Number(input.maxClusters||12), 1, 50) });
  if (!clustersRes?.ok) return { ok:false, error:"cluster_failed", detail: clustersRes?.error || clustersRes };
  const clusters = Array.isArray(clustersRes.clusters) ? clustersRes.clusters : [];

  const promoted = [];
  for (const c of clusters) {
    if (promoted.length >= maxPromotions) break;
    const ids = Array.isArray(c.ids) ? c.ids : [];
    if (ids.length < minCluster) continue;
    const members = ids.map(id => STATE.dtus.get(id)).filter(Boolean);
    if (members.length < minCluster) continue;

    const clusterKey = topicKeyOf(members);
    // Skip if a mega already exists for this cluster key
    const existing = Array.from(STATE.dtus.values()).find(d => (d.tier||"") === "mega" && d?.meta?.clusterKey === clusterKey);
    if (existing) continue;

    // Build a deterministic mega summary (no LLM dependency)
    const titleSeed = (c.label || members[0]?.title || "Cluster").toString().slice(0, 80);
    const tags = Array.from(new Set(members.flatMap(d => Array.isArray(d.tags)?d.tags:[]))).slice(0, 24);
    const excerpts = members
      .map(d => (d.cretiHuman || d.creti || "").toString().trim())
      .filter(Boolean)
      .slice(0, 8);

    const mega = {
      id: uid("dtu"),
      tier: "mega",
      title: `MEGA — ${titleSeed}`,
      tags,
      createdAt: nowISO(),
      updatedAt: nowISO(),
      status: "active",
      lineage: { parents: members.map(d=>d.id), kind: "gap_promotion" },
      core: {
        definitions: [`A compressed synthesis of ${members.length} regular DTUs around: ${titleSeed}.`],
        invariants: [
          "This MEGA is derived from a stable local cluster (gap promotion).",
          "Member DTUs remain active; this is a soft promotion (no destructive merge)."
        ],
        examples: [],
        tests: [],
        next_actions: [
          "Review this MEGA for crispness and missing gaps.",
          "If stable, consider elevating to Hyper only with citations + verification."
        ]
      },
      cretiHuman: [
        `**What this MEGA represents**: ${members.length} related DTUs clustered around **${titleSeed}**.`,
        tags.length ? `**Tag hints**: ${tags.join(", ")}` : "",
        excerpts.length ? `**Representative excerpts**:\n- ${excerpts.map(e=>e.replace(/\n+/g," ").slice(0,180)).join("\n- ")}` : "",
        "**Lineage**: soft-promoted from regular DTUs; members remain canonical unless explicitly merged later."
      ].filter(Boolean).join("\n\n"),
      meta: { clusterKey, promotedFrom: members.length, promotionAt: nowISO() }
    };

    if (!dryRun) {
      const r = await pipelineCommitDTU(ctx, mega, { op: "gap_promotion" });
      if (!r?.ok) continue;
      for (const m of members) {
        try {
          m.meta = m.meta || {};
          if (!m.meta.megaParent) m.meta.megaParent = mega.id;
        } catch {}
      }
      saveStateDebounced();
    }

    promoted.push({ megaId: mega.id, clusterKey, members: members.length, label: titleSeed });
  }

  return { ok:true, did: promoted.length ? "promoted" : "none", promoted, dryRun };
}, { description: "Detect stable clusters (gaps) and soft-promote them into MEGA DTUs." });

// Chat domain
register("chat", "respond", async (ctx, input) => {
  const sessionId = normalizeText(input.sessionId || "default");
  
const prompt = String(input.prompt || "");
const mode = normalizeText(input.mode || "explore");

// --- Concord Identity Invariant (hardwired; prevents "random assistant" drift) ---
const _selfTokens = new Set([
  "concord","concordos","concord os","dtu","dtus","lattice","council","macro-max","wrappers","wrappers studio","global","marketplace"
]);
const _pLow = tokenish(prompt);
const _mentionsSelf = Array.from(_selfTokens).some(t => _pLow.includes(t));

  // Base settings must exist before we derive localSettings/style.
  const baseSettings = (ctx?.state?.settings) ? ctx.state.settings : (STATE.settings || {});

  if (!STATE.sessions.has(sessionId)) {
    STATE.sessions.set(sessionId, { createdAt: nowISO(), messages: [] });
  }

  // Session-adaptive style vector (mutable)
  const styleSignal = input.styleSignal || null; // {kind:'like'|'dislike'} or {field,dir,amount}
  let styleVec = getSessionStyleVector(sessionId);
  if (styleSignal) {
    styleVec = mutateStyleVector(styleVec, styleSignal);
    STATE.styleVectors.set(sessionId, styleVec);
    saveStateDebounced();
  }

  let localSettings = applyStyleToSettings(baseSettings, styleVec);

  // ===== AFFECT → CHAT INTEGRATION =====
  // Consume affect policy to modulate response behavior.
  // ctx.affect is injected by makeCtx() from the ATS engine.
  const _aff = ctx.affect || {};
  const _affStyle = _aff.policy?.style || {};
  const _affCog = _aff.policy?.cognition || {};
  const _affMem = _aff.policy?.memory || {};
  const _affSafety = _aff.policy?.safety || {};

  // Style modulation: affect verbosity/creativity/warmth shift localSettings
  if (_affStyle.verbosity != null) {
    localSettings.responseMaxLen = Math.round(
      (localSettings.responseMaxLen || 800) * (0.6 + 0.8 * _affStyle.verbosity)
    );
  }
  if (_affStyle.creativity != null) {
    localSettings.explorationBias = clamp(
      (localSettings.explorationBias || 0.5) + (_affStyle.creativity - 0.5) * 0.3, 0, 1
    );
  }
  // Safety: strictness raises caution
  if (_affSafety.strictness != null && _affSafety.strictness > 0.7) {
    localSettings.safetyOverride = true;
  }

  // ===== EXPERIENCE RETRIEVAL =====
  // Check past experience for this domain/topic to guide strategy selection
  let _experienceHint = null;
  try {
    ensureExperienceLearning();
    const _promptKeywords = tokenizeText(prompt).slice(0, 15);
    const _promptDomain = (() => {
      const pseudoDtu = { title: prompt.slice(0, 100), human: { summary: prompt.slice(0, 300) }, tags: [] };
      try { return classifyDomain(pseudoDtu); } catch { return "general"; }
    })();
    _experienceHint = retrieveExperience(_promptDomain, prompt.slice(0, 200), _promptKeywords);
    // If experience suggests a strategy, use it
    if (_experienceHint?.bestStrategy && _experienceHint.confidence > 0.4) {
      localSettings._experienceStrategy = _experienceHint.bestStrategy;
      // If experience says LLM works better here, bias toward LLM
      if (_experienceHint.bestStrategy === "llm-enhanced") {
        localSettings._preferLlm = true;
      }
    }
    // If experience has warnings, note them
    if (_experienceHint?.warnings?.length > 0) {
      localSettings._experienceWarnings = _experienceHint.warnings;
    }
  } catch {}
  // ===== END EXPERIENCE RETRIEVAL =====

  // ===== TRANSFER LEARNING SEARCH =====
  // Search for analogous patterns from other domains that might help
  let _transferSuggestion = null;
  try {
    const _promptDomain2 = localSettings._experienceStrategy ? "general" : (() => {
      const pseudoDtu = { title: prompt.slice(0, 100), human: { summary: prompt.slice(0, 300) }, tags: [] };
      try { return classifyDomain(pseudoDtu); } catch { return "general"; }
    })();
    _transferSuggestion = autoTransferSearch(_promptDomain2, prompt.slice(0, 200));
  } catch {}
  // ===== END TRANSFER LEARNING SEARCH =====

  // ===== ATTENTION THREAD =====
  // Register this response as a cognitive thread for attention tracking
  let _threadId = null;
  try {
    ensureAttentionManager();
    const _thread = createCognitiveThread({
      type: "chat-response",
      priority: mode === "design" ? 0.7 : mode === "explore" ? 0.5 : 0.4,
      description: prompt.slice(0, 200),
      domain: localSettings._experienceStrategy || "general"
    });
    _threadId = _thread?.thread?.id || null;
  } catch {}
  // ===== END AFFECT → CHAT INTEGRATION =====

  const llm = typeof input.llm === "boolean" ? input.llm : localSettings.llmDefault;

  const sess = STATE.sessions.get(sessionId);
  
sess.messages.push({ role: "user", content: prompt, ts: nowISO() });

  // --- Per-user personality growth (style vector) ---
  // Only react to explicit preference signals (offline-safe).
  const _low = tokenish(prompt);
  const signals = [];
  if (/\b(shorter|too long|less detail|brief)\b/i.test(prompt)) signals.push({ field:"verbosity", dir:"down", amount:0.10 });
  if (/\b(longer|more detail|more depth|explain more)\b/i.test(prompt)) signals.push({ field:"verbosity", dir:"up", amount:0.10 });
  if (/\b(no bullets|stop bullet|no lists)\b/i.test(prompt)) signals.push({ field:"bulletiness", dir:"down", amount:0.14 });
  if (/\b(use bullets|give me bullets|list it)\b/i.test(prompt)) signals.push({ field:"bulletiness", dir:"up", amount:0.14 });
  if (/\b(more casual|less formal|talk normal)\b/i.test(prompt)) signals.push({ field:"formality", dir:"down", amount:0.12 });
  if (/\b(more formal|professional)\b/i.test(prompt)) signals.push({ field:"formality", dir:"up", amount:0.12 });
  if (/\b(stop being static|be dynamic|free flow|freestyle)\b/i.test(prompt)) signals.push({ field:"bulletiness", dir:"down", amount:0.08 });
  if (/\b(stop arguing|stop disclaimers|stop assistant)\b/i.test(prompt)) signals.push({ field:"formality", dir:"down", amount:0.06 });

  if (signals.length) {
    let v = getSessionStyleVector(sessionId);
    for (const s of signals) v = mutateStyleVector(v, s);
    STATE.styleVectors.set(sessionId, v);
    // apply updated style to this response immediately
    localSettings = applyStyleToSettings(baseSettings, v);
    saveStateDebounced();
  }
  if (sess.messages.length > 60) sess.messages.splice(0, sess.messages.length - 60);

  // Deterministic micro-kernel: basic arithmetic (LLM not required)
  // Answers only when the prompt is unambiguously a simple arithmetic query.
  const _tryDeterministicMath = (raw) => {
    const s = String(raw || "").trim().toLowerCase();
    const cleaned = s.replace(/[,]/g, "").replace(/[=]/g, " ").replace(/[?]/g, "").trim();
    const wordMap = [
      { re: /^what\s+is\s+(-?\d+(?:\.\d+)?)\s*(\+|plus)\s*(-?\d+(?:\.\d+)?)$/, op: "+" },
      { re: /^(-?\d+(?:\.\d+)?)\s*(\+|plus)\s*(-?\d+(?:\.\d+)?)$/, op: "+" },
      { re: /^what\s+is\s+(-?\d+(?:\.\d+)?)\s*(-|minus)\s*(-?\d+(?:\.\d+)?)$/, op: "-" },
      { re: /^(-?\d+(?:\.\d+)?)\s*(-|minus)\s*(-?\d+(?:\.\d+)?)$/, op: "-" },
      { re: /^what\s+is\s+(-?\d+(?:\.\d+)?)\s*(\*|x|times|multiplied\s+by)\s*(-?\d+(?:\.\d+)?)$/, op: "*" },
      { re: /^(-?\d+(?:\.\d+)?)\s*(\*|x|times|multiplied\s+by)\s*(-?\d+(?:\.\d+)?)$/, op: "*" },
      { re: /^what\s+is\s+(-?\d+(?:\.\d+)?)\s*(\/|divided\s+by|over)\s*(-?\d+(?:\.\d+)?)$/, op: "/" },
      { re: /^(-?\d+(?:\.\d+)?)\s*(\/|divided\s+by|over)\s*(-?\d+(?:\.\d+)?)$/, op: "/" },
    ];
    for (const r of wordMap) {
      const m = cleaned.match(r.re);
      if (!m) continue;
      const a = Number(m[1]);
      const b = Number(m[3]);
      if (!Number.isFinite(a) || !Number.isFinite(b)) return null;
      if (r.op === "/" && b === 0) return { reply: "undefined (division by zero)", meta: { source: "deterministic_math" } };
      let out;
      if (r.op === "+") out = a + b;
      else if (r.op === "-") out = a - b;
      else if (r.op === "*") out = a * b;
      else out = a / b;
      const reply = Number.isInteger(out) ? String(out) : String(out);
      return { reply, meta: { source: "deterministic_math" } };
    }
    return null;
  };

  const mathHit = _tryDeterministicMath(prompt);
  if (mathHit) {
    const finalReply = mathHit.reply;
    sess.messages.push({ role: "assistant", content: finalReply, ts: nowISO(), meta: { llmUsed: false, mode, deterministic: true, source: "math" } });
    ctx.log("chat", "Deterministic math answer", { sessionId, mode, reply: finalReply });
    saveStateDebounced();
    return { ok: true, reply: finalReply, sessionId, mode, llmUsed: false, meta: { panel: "chat", sessionId, mode, llmUsed: false, deterministic: true, source: "math" } };
  }



// --- Reality intercepts (authoritative; no LLM) ---
const _lowPrompt = tokenish(prompt);
const _isTimeQuery = (s) => {
  const t = tokenish(s);
  if (t.includes("time complexity") || t.includes("runtime")) return false;
  return /\b(what time|current time|time is it|date today|today's date|what day|day is it)\b/i.test(String(s||""));
};
const _isWeatherQuery = (s) => /\b(weather|forecast|temperature|temp|rain|snow|wind)\b/i.test(String(s||""));
const _extractLocation = (s) => {
  const m = String(s||"").match(/\b(?:in|for|at)\s+([a-zA-Z][^,.;!?]{2,60})/i);
  return m ? String(m[1]).trim() : "";
};

if (_isTimeQuery(prompt)) {
  const tz = String(localSettings?.timezone || "America/New_York");
  const t = getTimeInfo(tz);
  const reply = `Local time (${tz}): ${t.localTime}
ISO: ${t.nowISO}`;
  sess.messages.push({ role:"assistant", content: reply, ts: nowISO(), meta: { llmUsed:false, source:"time" } });
  saveStateDebounced();
  return { ok:true, reply, sessionId, mode, llmUsed:false, meta:{ panel:"chat", sessionId, mode, llmUsed:false, source:"time" } };
}

if (_isWeatherQuery(prompt)) {
  const tz = String(localSettings?.timezone || "America/New_York");
  const loc = _extractLocation(prompt) || String(localSettings?.defaultLocation || "Poughkeepsie, NY");
  try {
    const wx = await getWeather(loc, { timeZone: tz });
    if (!wx.ok) {
      const reply = `Weather lookup failed for "${loc}": ${wx.error || "unknown_error"}`;
      sess.messages.push({ role:"assistant", content: reply, ts: nowISO(), meta: { llmUsed:false, source:"weather" } });
      saveStateDebounced();
      return { ok:true, reply, sessionId, mode, llmUsed:false, meta:{ panel:"chat", sessionId, mode, llmUsed:false, source:"weather" } };
    }
    const cur = wx.forecast?.current || {};
    const daily = wx.forecast?.daily || {};
    const todayMax = Array.isArray(daily.temperature_2m_max) ? daily.temperature_2m_max[0] : null;
    const todayMin = Array.isArray(daily.temperature_2m_min) ? daily.temperature_2m_min[0] : null;
    const reply =
      `Weather for ${wx.location}:
` +
      `Now: ${cur.temperature_2m ?? "?"}°C (feels ${cur.apparent_temperature ?? "?"}°C), wind ${cur.wind_speed_10m ?? "?"} km/h, precip ${cur.precipitation ?? "?"} mm
` +
      `Today: high ${todayMax ?? "?"}°C / low ${todayMin ?? "?"}°C`;
    sess.messages.push({ role:"assistant", content: reply, ts: nowISO(), meta: { llmUsed:false, source:"weather", cached: wx.cached } });
    saveStateDebounced();
    return { ok:true, reply, sessionId, mode, llmUsed:false, meta:{ panel:"chat", sessionId, mode, llmUsed:false, source:"weather", cached: wx.cached } };
  } catch (e) {
    const reply = `Weather lookup error: ${String(e?.message||e)}`;
    sess.messages.push({ role:"assistant", content: reply, ts: nowISO(), meta: { llmUsed:false, source:"weather" } });
    saveStateDebounced();
    return { ok:true, reply, sessionId, mode, llmUsed:false, meta:{ panel:"chat", sessionId, mode, llmUsed:false, source:"weather" } };
  }
}

const intentInfo = classifyIntent(prompt);

  // Identity answers are declarative: Concord refers to itself.
  if (_mentionsSelf || intentInfo.intent === INTENT.IDENTITY) {
    const base = SYSTEM_IDENTITY.short;
    const more = SYSTEM_IDENTITY.long;
    const ask = "What part do you want—DTUs, lattice retrieval, macros/wrappers, Temporal OS, or the UI/panels?";
    const reply = `${base}

${more}

${ask}`;
    sess.messages.push({ role: "assistant", content: reply, ts: nowISO(), meta: { llmUsed: false, mode, identity: true } });
    saveStateDebounced();
    return { ok:true, reply, sessionId, mode, llmUsed:false, meta: { panel: "chat", sessionId, mode, llmUsed:false, identity:true } };
  }
// Linguistic Engine v1: track canonical intents even with LLM off
if (!ctx.state.organs.has("linguistic_engine_v1")) {
  ctx.state.organs.set("linguistic_engine_v1", { organId:"linguistic_engine_v1", desc:"LLM-independent lexicon + intent tracking.", createdAt: nowISO(), lexicon: {} });
}
const lex = ctx.state.organs.get("linguistic_engine_v1").lexicon || (ctx.state.organs.get("linguistic_engine_v1").lexicon = {});
const key = intentInfo.intent + ":" + intentInfo.canonical;
lex[key] = lex[key] || { count: 0, lastSeen: null, samples: [] };
lex[key].count++;
lex[key].lastSeen = nowISO();
if (lex[key].samples.length < 5 && prompt) lex[key].samples.push(prompt);

// Hard intercepts (authoritative)
if (intentInfo.intent === INTENT.IDENTITY) {
  const reply = `${SYSTEM_IDENTITY.short}\n\n${SYSTEM_IDENTITY.long}\n\nInvariants:\n- ${SYSTEM_IDENTITY.invariants.join("\n- ")}`;
  sess.messages.push({ role:"assistant", content: reply, ts: nowISO() });
  saveStateDebounced();
  return { ok:true, reply, mode, llmUsed:false, intent: intentInfo.intent };
}
if (intentInfo.intent === INTENT.GREETING) {
  const isFirstTurn = !sess.messages || sess.messages.length <= 1; // just pushed user message
  if (!sess.didGreet && isFirstTurn) {
    const reply = `Yo. You good? Pick a move: chat / forge / dream / evolution / synthesize / research.`;
    sess.didGreet = true;
    sess.messages.push({ role:"assistant", content: reply, ts: nowISO() });
    saveStateDebounced();
    return { ok:true, reply, mode, llmUsed:false, intent: intentInfo.intent };
  }
}


  
  // ---------- Session Anchors (decay + confidence weighting + topic switching) ----------
  const _nowMs = () => Date.now();
  const _ensureAnchorState = () => {
    if (!sess.anchorState || typeof sess.anchorState !== "object") {
      sess.anchorState = { active: null, items: [], lastDecayAt: _nowMs() };
    }
    if (!Array.isArray(sess.anchorState.items)) sess.anchorState.items = [];
    if (!sess.anchorState.lastDecayAt) sess.anchorState.lastDecayAt = _nowMs();
    return sess.anchorState;
  };
  const _decayAnchors = (st) => {
    const now = _nowMs();
    const dt = Math.max(0, now - (st.lastDecayAt || now));
    st.lastDecayAt = now;
    const halfLifeMs = Number(localSettings?.anchorHalfLifeMs || 15*60*1000); // 15m default
    const decay = halfLifeMs > 0 ? Math.pow(0.5, dt / halfLifeMs) : 0.9;
    for (const a of st.items) a.weight = clamp(Number(a.weight || 0) * decay, 0, 1);
    st.items = st.items.filter(a => (a.weight || 0) >= 0.05);
    if (st.active && !st.items.find(x => x.key === st.active)) st.active = null;
    if (!st.active && st.items.length) {
      st.items.sort((a,b)=>(b.weight||0)-(a.weight||0));
      st.active = st.items[0].key;
    }
  };
  const _STOP = new Set(["the","a","an","and","or","but","if","then","to","of","in","on","for","with","about","from","is","are","was","were","be","been","being","it","that","this","those","these","i","you","we","they","he","she","them","me","my","your","our","their","as","at","by","do","did","does","just","yo","yoo","hey","hi","hello","sup","wassup","huh","man","bro"]);
  const _topicKeyFromText = (t) => {
    const toks = simpleTokens(String(t || "")).filter(x => x && x.length >= 3 && !_STOP.has(x));
    const uniq = [];
    for (const w of toks) { if (!uniq.includes(w)) uniq.push(w); if (uniq.length >= 6) break; }
    return uniq.slice(0, 4).join(" ");
  };
  const _jaccardTokens = (a, b) => {
    const A = new Set(simpleTokens(String(a || "")));
    const B = new Set(simpleTokens(String(b || "")));
    if (!A.size || !B.size) return 0;
    let inter = 0; for (const x of A) if (B.has(x)) inter++;
    return inter / (A.size + B.size - inter);
  };
  const _upsertAnchor = (st, key, sample, w) => {
    if (!key) return;
    const k = String(key).trim().toLowerCase();
    let a = st.items.find(x => x.key === k);
    if (!a) { a = { key: k, weight: 0, lastSeen: _nowMs(), sample: String(sample || "").slice(0, 220) }; st.items.push(a); }
    a.weight = clamp((a.weight || 0) + clamp(Number(w || 0), 0, 1), 0, 1);
    a.lastSeen = _nowMs();
    if (sample) a.sample = String(sample).slice(0, 220);
  };
const _updateAnchorsFromTurn = ({ promptText, bestScoreHint = 0, wantsStructured = false, topicTitle = null }) => {
  // Track a lightweight "topic anchor" for the session (decay + confidence weighting).
  // This is NOT a chat reply generator; it's metadata for routing/retrieval.
  const st = _ensureAnchorState();
  _decayAnchors(st);

  const baseText = String(topicTitle || promptText || "");
  const key = _topicKeyFromText(baseText);
  if (!key) return;

  const score = clamp(Number(bestScoreHint || 0), 0, 1);
  const w = clamp(0.10 + 0.60 * score + (wantsStructured ? 0.05 : 0), 0, 1);

  _upsertAnchor(st, key, promptText || "", w);
  st.active = String(key).trim().toLowerCase();
};

// Retrieve relevant DTUs (local) — search-like semantics (synonyms + fuzzy) + temporal recency (soft-gate)
const all = dtusArray();
const qRaw = String(prompt || "");
const qBase = tokensNoStop(qRaw);
const qExp  = expandQueryTokens(qRaw);

const expandTokensFromTokens = (tokens=[]) => {
  const out = new Set(tokens.map(stemLite));
  for (const t of tokens) {
    const syns = SYN_MAP[t] || SYN_MAP[stemLite(t)] || null;
    if (syns) for (const s of syns) out.add(stemLite(s));
  }
  return Array.from(out).slice(0, 256);
};

const scored = all.map(d => {
  const dText = [
    d?.title || "",
    Array.isArray(d?.tags) ? d.tags.join(" ") : "",
    d?.cretiHuman || d?.creti || d?.human?.summary || "",
    Array.isArray(d?.human?.bullets) ? d.human.bullets.join(" ") : ""
  ].join(" ").slice(0, 2400);

  const dBase = tokensNoStop(dText);
  const dExp  = expandTokensFromTokens(dBase);

  const sBase = jaccard(qBase, dBase);
  const sExp  = jaccard(qExp, dExp);
  const sNg   = ngramSim(qRaw, dText);

  // Soft temporal boost (never dominates)
  const tW = temporalRecencyWeight(d);

  const score = clamp(
    0.55*sBase + 0.30*sExp + 0.15*sNg + 0.10*tW,
    0, 1
  );
    return { d, score };
  }).sort((a,b)=>b.score-a.score);
  // Affect depthBudget controls how many DTUs enter the working set (default 6)
  const _affDepthLimit = clamp(Math.round(_aff.depthBudget || 5), 2, 10);
  const relevant = scored.filter(x=>x.score > 0.08).slice(0, _affDepthLimit).map(x=>x.d);


// Local response (non-LLM): crisp, constrained reasoning (APE) + scalable substrate (ANT)
const lastTurns = (sess.messages || []).slice(-8);
const userHistory = lastTurns.filter(m => m.role === "user").map(m => m.content).join(" | ").slice(-800);

// Persist conversational context as a hidden shadow DTU (used for routing/anchors; never shown verbatim to user)
try {
  const shadowId = `shadow_session_context_${sessionId}`;
  const shadow = {
    id: shadowId,
    tier: "shadow",
    tags: ["shadow","session","context"],
    human: { summary: `Session context (recent turns) for ${sessionId}`, bullets: [] },
    core: { definitions: [], invariants: [], claims: [], examples: [], nextActions: [] },
    machine: {
      kind: "session_context",
      sessionId,
      recentUserTurns: userHistory,
      recentTurns: lastTurns.map(m => ({ role: m.role, content: String(m.content||"").slice(0, 280), ts: m.ts || null })).slice(-8),
      // lightweight pointers only (no heavy payload)
      focusIds: []
    },
    lineage: { parents: [], children: [] },
    source: "shadow",
    meta: { hidden: true },
    createdAt: nowISO(),
    updatedAt: nowISO(),
    authority: { model: "shadow", score: 0 },
    hash: ""
  };
  // upsert
  STATE.shadowDtus.set(shadowId, shadow);
  sess.contextShadowId = shadowId;
} catch {}

// Build a working set that stays crisp even with huge DTU libraries
const { focus, micro, macro } = selectWorkingSet(
  scored.filter(x=>x.score > 0.06).map(x=>({ d:x.d, score:x.score })),
  localSettings,
  { includeMegas: localSettings.includeMegasInBase !== false }
);

// Track usage for abstraction placement / promotions
try {
  for (const d of focus) markDTUUsed(d, `chat:${sessionId}`);
  for (const d of micro) markDTUUsed(d, `chat:${sessionId}`);
  for (const d of macro) markDTUUsed(d, `chat:${sessionId}`);
} catch {}

// ===== QUALITY PIPELINE: Pattern Router + Fused Context =====
// Run deterministic quality patterns between DTU context selection and LLM call.
// Costs zero API tokens; compounds quality downstream.
let _qualityPipelineResult = null;
let _fusedContext = null;
try {
  const routerResult = qualityPipelineRouter(prompt, micro, focus, sessionId, {
    mode,
    styleVector: styleVec,
    affectPolicy: _aff.policy || null
  });

  const fusedResult = buildFusedContext(prompt, focus, micro, sessionId, routerResult, {
    styleVector: styleVec,
    affectPolicy: _aff.policy || null
  });

  _qualityPipelineResult = routerResult;
  _fusedContext = fusedResult;

  ctx.log("quality_pipeline", "Patterns applied", {
    sessionId,
    patterns: routerResult.patterns,
    applied: fusedResult.meta.patternsApplied,
    queryIntent: routerResult.queryIntent,
    tokenEstimate: fusedResult.meta.tokenEstimate
  });
} catch (e) {
  // Quality pipeline is enhancement-only; failures fall through to original logic
  ctx.log("quality_pipeline.error", "Quality pipeline failed, using fallback", { error: String(e?.message || e) });
}
// ===== END QUALITY PIPELINE =====

const wants = /\?$/.test(prompt.trim()) || /\b(why|how|what|when|where|who|can you|should i|help|explain)\b/i.test(prompt);
const bestScore = scored?.[0]?.score ?? 0;

// ===== METACOGNITION → CHAT: Blindspot awareness =====
// If the topic matches a known blindspot, inject an epistemic hedge.
let _metacogWarning = null;
try {
  const _mcState = STATE.metacognition;
  if (_mcState && Array.isArray(_mcState.blindSpots) && _mcState.blindSpots.length > 0 && wants) {
    const _qTokens = tokenish(prompt);
    for (const spot of _mcState.blindSpots.slice(-20)) {
      const _spotTokens = tokenish(spot.topic || spot.description || "");
      if (_spotTokens && jaccard(_qTokens.split(/\s+/), _spotTokens.split(/\s+/)) > 0.15) {
        _metacogWarning = { topic: spot.topic, severity: spot.severity, gaps: spot.gaps };
        break;
      }
    }
  }
} catch {}
// ===== END METACOGNITION → CHAT =====

// Refine session anchors using DTU match confidence (works offline + online)
try {
  const topicTitle = (micro && micro.length) ? micro[0].title : null;
  _updateAnchorsFromTurn({ promptText: prompt, bestScoreHint: bestScore, wantsStructured, topicTitle });
} catch {}

const hasStrongEvidence = micro.length >= 2 && bestScore >= 0.12;

const frame = chooseAbstractionFrame({
  mode,
  intent: intentInfo.intent,
  hasStrongEvidence,
  settings: localSettings
});

const modeHint =
  mode === "design" ? "Design mode"
: mode === "debug" ? "Debug mode"
: mode === "decide" ? "Decide mode"
: "Explore mode";

const answerLines = [];
if (wants) {
  if (micro.length) {
    answerLines.push(`- (${modeHint}) Based on your strongest DTU anchors, here’s the most consistent move:`);

    const take = micro.slice(0, 2);
    for (const d of take) {
      const firstLine = buildCretiText(d).split(/\n\n|\n/).filter(Boolean)[0] || "";
      answerLines.push(`- ${d.title}: ${firstLine.slice(0, 220)}${firstLine.length>220 ? "…" : ""}`);
    }

    // If we have macro anchors and higher abstraction is allowed, add a compact generalization
    if (frame.level >= 1 && macro.length) {
      answerLines.push(`- Generalization: this sits under ${macro.slice(0,2).map(m=>m.title).join(" / ")}.`);
    }
  } else {
    answerLines.push(`- (${modeHint}) I don’t have a strong DTU match yet.`);
    answerLines.push(`- Tell me your target outcome + constraints, or forge 1–2 DTUs (definitions + invariants) and I’ll lock it in.`);
  }
} else {
  answerLines.push(`- (${modeHint}) Got it.`);
  answerLines.push(`- Tell me your next step (plan / build spec / critique / DTU creation) and I’ll move.`);
}

const hypotheses = [];
if (frame.level >= 2 && !hasStrongEvidence) {
  // Labeled hypotheses (kept minimal)
  if (macro.length) hypotheses.push(`This may be primarily about: ${macro[0].title}.`);
  hypotheses.push("Your DTU substrate may be missing explicit constraints/tests for this topic (forge them to sharpen reasoning).");
}

const ptxt = String(prompt || "");
const wantsStructured =
  Boolean(frame?.wantsStructured) ||
  /\b(structure(d)?|structured|outline|steps|bullets?|json|table|format)\b/i.test(ptxt);

const tests = [];
if (frame.requireTests && (!LLM_READY || wantsStructured) && (!hasStrongEvidence || /\bmaybe|might|likely|probably\b/i.test(ptxt))) {
  tests.push("Forge 1 DTU with definitions + invariants (no prose).");
  tests.push("Forge 1 DTU with tests/falsifiability (what would disprove it).");
  tests.push("Run: system.evolution (promote a stable cluster to MEGA) once duplicates collapse.");
}

// Metacognition: inject epistemic hedge if blindspot was detected
if (_metacogWarning) {
  answerLines.unshift(`- ⚠ Known blindspot: "${_metacogWarning.topic}" (severity ${((_metacogWarning.severity||0)*100).toFixed(0)}%). ${Array.isArray(_metacogWarning.gaps) && _metacogWarning.gaps.length ? _metacogWarning.gaps[0] : "Consider forging DTUs to fill this gap."}`);
}

// ===== EXPERIENCE + TRANSFER GUIDANCE =====
// Inject past experience warnings into response
try {
  if (localSettings._experienceWarnings?.length > 0) {
    for (const warn of localSettings._experienceWarnings.slice(0, 2)) {
      answerLines.unshift(`- ℹ Experience note: ${warn}`);
    }
  }
  // If transfer learning found a useful analogy, mention it
  if (_transferSuggestion?.strategy && _transferSuggestion.relevance > 0.5) {
    answerLines.push(`- 🔄 Cross-domain insight from ${_transferSuggestion.sourceDomain}: ${_transferSuggestion.strategy.approach}`);
  }
} catch {}
// ===== END EXPERIENCE + TRANSFER GUIDANCE =====

let localReply = formatCrispResponse({
  prompt,
  mode,
  microDTUs: micro,
  macroDTUs: macro,
  level: frame.level,
  answerLines,
  hypotheses,
  tests
});

  // ===== SEMANTIC UNDERSTANDING ENHANCEMENT =====
  // When LLM is not available, enhance the response using semantic understanding
  let semanticEnhancement = null;
  if (!LLM_READY || !llm) {
    try {
      // Get semantic understanding of the query
      semanticEnhancement = semanticUnderstandFallback(prompt, relevant, { mode });

      // If we have good semantic understanding, enhance the response
      if (semanticEnhancement.confidence > 0.4) {
        const semanticSection = generateSemanticResponse(prompt, micro, macro, semanticEnhancement);
        if (semanticSection) {
          localReply = `${semanticSection}\n\n---\n\n${localReply}`;
        }
      }
    } catch (e) {
      // Semantic enhancement is optional; silently continue
      ctx.log("semantic", "Semantic enhancement failed", { error: String(e?.message || e) });
    }
  }
  // ===== END SEMANTIC UNDERSTANDING ENHANCEMENT =====

  // NOTE: Do NOT print internal context tracking to the user.

  let finalReply = localReply;
  let llmUsed = false;
  const semanticUsed = Boolean(semanticEnhancement && semanticEnhancement.confidence > 0.4);

  if (llm && ctx.llm.enabled) {
    // Affect-modulated LLM parameters
    const _llmTemp = clamp(
      0.35 + (_affStyle.creativity ? (_affStyle.creativity - 0.5) * 0.3 : 0),
      0.1, 0.9
    );
    const _llmMaxTokens = Math.round(
      700 * (0.6 + 0.8 * (_affStyle.verbosity ?? 0.5))
    );
    // Inject affect-aware behavioral guidance into system prompt
    const _affectGuidance = _aff.policy ? [
      _affStyle.warmth > 0.6 ? "Be warm and encouraging." : _affStyle.warmth < 0.3 ? "Be direct and precise." : "",
      _affStyle.directness > 0.7 ? "Get to the point quickly." : "",
      _affSafety.strictness > 0.7 ? "Be cautious with uncertain claims." : "",
      _affCog.exploration > 0.6 ? "Explore alternative viewpoints." : "",
    ].filter(Boolean).join(" ") : "";
    // GRC: Inject Grounded Recursive Closure system prompt when module is available
    const _dtuTitles = focus.map(d => d.title || d.id).filter(Boolean);
    const _grcSystemPrompt = GRC_MODULE
      ? getGRCSystemPrompt({ dtus: _dtuTitles, mode })
      : "";
    const system =
`You are ConcordOS. Be natural, concise but not dry. Use DTUs as memory. Never pretend features exist.
Mode: ${mode}.${_affectGuidance ? `\nTone: ${_affectGuidance}` : ""}
When helpful, reference DTU titles in plain language (do not dump ids unless asked).${_grcSystemPrompt ? `\n\n${_grcSystemPrompt}` : ""}`;
    // Use fused context from quality pipeline if available; otherwise fall back to original assembly
    const dtuContext = (_fusedContext && _fusedContext.fusedContext)
      ? _fusedContext.fusedContext
      : focus.map(d => `TITLE: ${d.title}\nTIER: ${d.tier}\nTAGS: ${(d.tags||[]).join(", ")}\nCRETI:\n${buildCretiText(d)}\n---`).join("\n");
    const _pipelineMeta = (_qualityPipelineResult && _fusedContext)
      ? `\n[Pipeline: ${_fusedContext.meta.patternsApplied.join("+")} | intent=${_qualityPipelineResult.queryIntent}]`
      : "";
    const messages = [
      { role: "user", content: `User prompt:\n${prompt}\n\nRelevant DTUs:\n${dtuContext}${_pipelineMeta}\n\nRespond naturally and propose next actions.` }
    ];
    const r = await ctx.llm.chat({
      system, messages, temperature: _llmTemp, maxTokens: _llmMaxTokens,
      dtuRefs: _dtuTitles,
      macroRefs: ["chat.respond"],
      grcMode: mode,
    });
    if (r.ok) {
      finalReply = r.content.trim() || localReply;
      llmUsed = true;
    } else {
      ctx.log("llm.error", "LLM call failed; falling back to local.", { error: r });
    }
  }

  const _qpMeta = _fusedContext ? { patternsApplied: _fusedContext.meta.patternsApplied, queryIntent: _qualityPipelineResult?.queryIntent, tokenEstimate: _fusedContext.meta.tokenEstimate } : null;
  sess.messages.push({ role: "assistant", content: finalReply, ts: nowISO(), meta: { llmUsed, semanticUsed, mode, relevant: relevant.map(d=>d.id), qualityPipeline: _qpMeta } });
  ctx.log("chat", "Chat response generated", { sessionId, mode, llmUsed, semanticUsed, relevant: relevant.map(d=>d.id), qualityPipeline: _qpMeta });

  // ===== REFLECTIVE LOOP + EXPERIENCE RECORDING =====
  // Post-response: self-critique the response, record experience, complete attention thread
  try {
    const _promptDomainFinal = (() => {
      const pseudoDtu = { title: prompt.slice(0, 100), human: { summary: prompt.slice(0, 300) }, tags: [] };
      try { return classifyDomain(pseudoDtu); } catch { return "general"; }
    })();
    // Run reflection (evaluates quality, checks facts, feeds experience memory)
    reflectOnResponse({
      prompt,
      response: finalReply,
      mode,
      domain: _promptDomainFinal,
      llmUsed,
      relevantDtus: relevant.map(d => d.id)
    });
  } catch {}

  // Complete the attention thread
  try {
    if (_threadId) {
      completeCognitiveThread(_threadId, {
        responseLength: finalReply.length,
        llmUsed,
        relevantCount: relevant.length
      });
    }
  } catch {}
  // ===== END REFLECTIVE LOOP =====

  // persist session + any state mutations from this turn
  saveStateDebounced();

  // GRC: Format the final reply through the GRC pipeline (for both LLM and local responses)
  let _grcOutput = null;
  if (GRC_MODULE) {
    try {
      const _dtuTitlesForGRC = relevant.map(d => d.title || d.id).filter(Boolean);
      const grcResult = grcFormatAndValidate(
        finalReply,
        {
          dtuRefs: _dtuTitlesForGRC,
          macroRefs: ["chat.respond"],
          mode: mode,
          invariantsApplied: ["NoNegativeValence", "RealityGateBeforeEffects"],
          realitySnapshot: {
            facts: relevant.length > 0 ? [`${relevant.length} DTU(s) retrieved for context`] : ["No DTUs matched query"],
            assumptions: llmUsed ? ["LLM enhancement applied"] : ["Local-only deterministic response"],
            unknowns: [],
          },
        },
        { inLatticeReality, STATE }
      );
      _grcOutput = grcResult.ok ? grcResult.grc : null;
    } catch {}
  }

  return { ok: true, reply: finalReply, sessionId, mode, llmUsed, semanticUsed, relevant: relevant.map(d=>({ id:d.id, title:d.title, tier:d.tier })), grc: _grcOutput };
}, { description: "Mode-aware chat with DTU retrieval; optional LLM enhancement. Outputs GRC v1 envelope." });

// ===== USER FEEDBACK → EXPERIENCE LEARNING =====
// Records thumbs up/down and ratings, feeds into experience memory + affect
register("chat", "feedback", (ctx, input) => {
  const sessionId = normalizeText(input.sessionId || "default");
  const messageIndex = Number(input.messageIndex ?? -1);
  const rating = input.rating; // "up", "down", or number 1-5
  const comment = String(input.comment || "").slice(0, 500);

  // Resolve rating to quality score
  let quality;
  if (rating === "up" || rating === "thumbs_up") quality = 0.85;
  else if (rating === "down" || rating === "thumbs_down") quality = 0.15;
  else if (typeof rating === "number") quality = clamp(rating / 5, 0, 1);
  else return { ok: false, error: "rating required: 'up', 'down', or 1-5" };

  // Find the message in session history
  const sess = STATE.sessions.get(sessionId);
  const messages = sess?.messages || [];
  const targetMsg = messageIndex >= 0 ? messages[messageIndex] : messages[messages.length - 1];

  // Record as experience episode with user feedback
  try {
    ensureExperienceLearning();
    const prompt = targetMsg?.role === "assistant"
      ? (messages[Math.max(0, messages.indexOf(targetMsg) - 1)]?.content || "").slice(0, 200)
      : "";
    const domain = (() => {
      try { return classifyDomain({ title: prompt, human: { summary: prompt }, tags: [] }); } catch { return "general"; }
    })();

    recordExperienceEpisode({
      domain,
      topic: prompt.slice(0, 100),
      keywords: tokenizeText(prompt).slice(0, 10),
      mode: targetMsg?.meta?.mode || "explore",
      strategy: targetMsg?.meta?.llmUsed ? "llm-enhanced" : "local-deterministic",
      llmUsed: targetMsg?.meta?.llmUsed || false,
      dtusRetrieved: targetMsg?.meta?.relevant?.length || 0,
      responseLength: (targetMsg?.content || "").length,
      quality,
      userFeedback: { rating, comment, sessionId, messageIndex },
      followUpNeeded: quality < 0.3,
      errorOccurred: false
    });
  } catch {}

  // Emit affect event for user feedback
  try {
    if (ATS) {
      ATS.emitAffectEvent(ctx.affect?.sessionId || "system", {
        type: "FEEDBACK",
        intensity: 0.5,
        polarity: quality > 0.5 ? 0.4 : -0.4,
        payload: { sessionId, rating, quality },
        source: { system: "chat_feedback" }
      });
    }
  } catch {}

  // Mutate style vector based on feedback
  try {
    const curStyle = getSessionStyleVector(sessionId);
    const signal = quality > 0.5
      ? { kind: "like" }
      : { kind: "dislike" };
    const next = mutateStyleVector(curStyle, signal);
    STATE.styleVectors.set(sessionId, next);
  } catch {}

  saveStateDebounced();
  return { ok: true, quality, recorded: true };
}, { description: "Record user feedback (thumbs up/down) for experience learning." });

register("style", "get", (ctx, input) => {
  const sessionId = normalizeText(input.sessionId || "default");
  const vec = getSessionStyleVector(sessionId);
  return { ok:true, sessionId, styleVector: vec };
});

register("style", "mutate", (ctx, input) => {
  const sessionId = normalizeText(input.sessionId || "default");
  const signal = input.signal || { kind: "like" };
  const cur = getSessionStyleVector(sessionId);
  const next = mutateStyleVector(cur, signal);
  STATE.styleVectors.set(sessionId, next);
  saveStateDebounced();
  return { ok:true, sessionId, styleVector: next };
}, { description: "Mutate session style vector (bounded nudges)." });

register("ask", "answer", async (ctx, input) => {
  const sessionId = normalizeText(input.sessionId || "default");
  const query = String(input.query || "");
  const mode = normalizeText(input.mode || "answer");
  const llm = typeof input.llm === "boolean" ? input.llm : ctx.state.settings.llmDefault;

  // Use same retrieval as chat, but format as structured answer
  const all = dtusArray();
  const qTok = simpleTokens(query);
  const scored = all.map(d => {
    const dTok = simpleTokens(d.title + " " + (d.tags||[]).join(" ") + " " + ((d.cretiHuman || d.creti || d.human?.summary || "")).slice(0, 400));
    const score = jaccard(qTok, dTok);
    return { d, score };
  }).sort((a,b)=>b.score-a.score);
  const relevant = scored.filter(x=>x.score > 0.08).slice(0, 8).map(x=>x.d);


let answer = "";
const { focus, micro, macro } = selectWorkingSet(
  scored.filter(x=>x.score > 0.06).map(x=>({ d:x.d, score:x.score })),
  ctx.state.settings,
  { includeMegas: true }
);

// Track usage for abstraction placement / promotions
try {
  for (const d of focus) markDTUUsed(d, `ask:${sessionId}`);
  for (const d of micro) markDTUUsed(d, `ask:${sessionId}`);
  for (const d of macro) markDTUUsed(d, `ask:${sessionId}`);
} catch {}
const bestScore = scored?.[0]?.score ?? 0;
const hasStrongEvidence = micro.length >= 2 && bestScore >= 0.12;
const frame = chooseAbstractionFrame({ mode, intent: INTENT.QUESTION, hasStrongEvidence, settings: ctx.state.settings });


// --- Full activation: feasibility-first (no modes) ---
const feas = await ctx.macro.run("verify","feasibility",{ query, llm });
const feasibility = {
  classification: feas?.classification || "undecidable",
  reason: feas?.reason || "",
  conflicts: feas?.conflicts || [],
  relevantIds: feas?.relevantIds || []
};


if (llm && ctx.llm.enabled) {
  const system = `You are ConcordOS. Provide a crisp, structured answer. Separate Facts / Inferences / Hypotheses (labeled) / Next tests. Never invent capabilities.`;
  const dtuContext = focus.map(d => `• ${d.title} [${d.tier}] tags=${(d.tags||[]).join(", ")}\n${buildCretiText(d)}\n`).join("\n");
  const messages = [{ role:"user", content:`Question:\n${query}\n\nDTUs:\n${dtuContext}\n\nAnswer in a practical style with the required sections.` }];
  const r = await ctx.llm.chat({ system, messages, temperature: 0.25, maxTokens: 700 });
  if (r.ok) answer = r.content.trim();
}

if (!answer) {
  const answerLines = [];
  if (micro.length) {
    answerLines.push(`- Based on your strongest DTU anchors:`);
    for (const d of micro.slice(0,3)) {
      const firstLine = buildCretiText(d).split(/\n\n|\n/).filter(Boolean)[0] || "";
      answerLines.push(`- ${d.title}: ${firstLine.slice(0, 220)}${firstLine.length>220 ? "…" : ""}`);
    }
    if (frame.level >= 1 && macro.length) answerLines.push(`- Generalization: ${macro.slice(0,2).map(m=>m.title).join(" / ")}.`);
  } else {
    answerLines.push(`- No strong DTU match yet.`);
  }

  const hypotheses = [];
  if (frame.level >= 2 && !hasStrongEvidence) {
    if (macro.length) hypotheses.push(`This may be primarily about: ${macro[0].title}.`);
    hypotheses.push("Add constraints/tests DTUs to sharpen local reasoning.");
  }

  const tests = [
    "Forge 1 DTU with definitions + invariants for this topic.",
    "Forge 1 DTU with tests/falsifiability (what would disprove it).",
  ];

  answer = formatCrispResponse({
    prompt: query,
    mode,
    microDTUs: micro,
    macroDTUs: macro,
    level: frame.level,
    answerLines,
    hypotheses,
    tests
  });
}


  // Prepend feasibility classification (always-on)
  try {
    const feasLine = `Feasibility: ${feasibility.classification}${feasibility.reason ? ` (${feasibility.reason})` : ""}`;
    const conflictLine = (feasibility.conflicts && feasibility.conflicts.length)
      ? `Conflicts: ${feasibility.conflicts.map(c => c.base).join(" | ")}`
      : "";
    answer = `${feasLine}${conflictLine ? `
${conflictLine}` : ""}

${answer}`;
  } catch {}
  ctx.log("ask", "Ask answered", { sessionId, mode, llmUsed: Boolean(answer && llm && ctx.llm.enabled), relevant: relevant.map(d=>d.id) });
  return { ok: true, answer, feasibility, relevant: relevant.map(d=>({ id:d.id, title:d.title, tier:d.tier })) };
});

// Forge domain
register("forge", "manual", async (ctx, input) => {
  const prompt = String(input.prompt || "");
  const title = normalizeText(input.title || `Forge: ${prompt.slice(0,60)}`) || "Forge DTU";
  const tags = Array.isArray(input.tags) ? input.tags : [];
  const creti = cretiPack({
    title,
    purpose: "Manual forge: convert prompt into a structured CRETI DTU.",
    context: prompt,
    procedure: "1) Extract key claims\n2) Convert into DTU bullets\n3) Add tests for falsifiability",
    outputs: "A DTU (regular) with CRETI content",
    tests: "Check clarity, non-duplication, tag coverage",
    notes: "Local-first; LLM can enhance via /chat with enhance toggle."
  });

  const created = await ctx.macro.run("dtu", "create", { title, creti, tags, tier: "regular", source: "forge.manual" });
  const score = await ctx.macro.run("verify","designScore", { spec: prompt, llm: ctx.state.settings.llmDefault });
  if (created && typeof created === "object") created.designScore = score;
  return created;
});

register("forge", "hybrid", async (ctx, input) => {
  const prompt = String(input.prompt || "");
  const base = await ctx.macro.run("forge", "manual", input);
  if (!base?.ok) return base;
  // add auto-tag suggestions
  const suggestedTags = Array.from(new Set([
    ...(base.dtu.tags||[]),
    ...simpleTokens(prompt).slice(0,8)
  ])).slice(0, 16);
  base.dtu.tags = suggestedTags;
  base.dtu.updatedAt = nowISO();
  upsertDTU(base.dtu);
  ctx.log("forge.hybrid", "Hybrid forge updated tags", { id: base.dtu.id });

const score = await ctx.macro.run("verify","designScore", { spec: prompt, llm: ctx.state.settings.llmDefault });
return { ok: true, dtu: base.dtu, designScore: score };
});

register("forge", "auto", async (ctx, input) => {
  // Auto forge can produce multiple DTUs: summary, risks, next steps
  const prompt = String(input.prompt || "");
  const tags = Array.isArray(input.tags) ? input.tags : [];
  const packs = [
    {
      title: normalizeText(input.title || `AutoForge: Summary — ${prompt.slice(0,40)}`),
      purpose: "Summarize the prompt into a compact DTU.",
      procedure: "Compress into a single thesis + 3 supporting bullets."
    },
    {
      title: normalizeText(`AutoForge: Risks — ${prompt.slice(0,40)}`),
      purpose: "Identify failure modes and risks.",
      procedure: "List 5 risks + mitigations."
    },
    {
      title: normalizeText(`AutoForge: Next Steps — ${prompt.slice(0,40)}`),
      purpose: "Actionable next steps.",
      procedure: "List 7 steps, each testable."
    }
  ];

  const created = [];
  for (const p of packs) {
    const creti = cretiPack({
      title: p.title,
      purpose: p.purpose,
      context: prompt,
      procedure: p.procedure,
      outputs: "A DTU that can be chained into plans or council runs.",
      tests: "Must be clear, non-duplicate, and actionable.",
      notes: "Auto-forged DTUs are regular tier; evolution can lift them to mega."
    });
    const r = await ctx.macro.run("dtu","create",{ title:p.title, creti, tags, tier:"regular", source:"forge.auto" });
    if (r?.ok) created.push(r.dtu);
  }
  return { ok: true, dtus: created };
});

// Swarm domain
register("swarm", "run", (ctx, input) => {
  const prompt = String(input.prompt || "");
  const items = dtusArray().filter(d=>d.tier==="regular");
  // de-dup by title similarity
  const kept = [];
  for (const d of items) {
    const dt = simpleTokens(d.title);
    let dup = false;
    for (const k of kept) {
      const kt = simpleTokens(k.title);
      if (jaccard(dt, kt) >= 0.72) { dup = true; break; }
    }
    if (!dup) kept.push(d);
  }
  const removed = items.length - kept.length;

  // propose 3 new DTUs from prompt
  const suggestions = [];
  const baseTags = simpleTokens(prompt).slice(0,10);
  for (let i=1;i<=3;i++){
    const title = `Swarm Proposal ${i}: ${prompt.slice(0, 42)}`.trim();
    const creti = cretiPack({
      title,
      purpose: `Swarm proposal #${i}: explore a distinct angle.`,
      context: prompt,
      procedure: `Angle ${i}: generate unique insight, ensure not overlapping with other proposals.`,
      outputs: "A DTU proposal (not auto-saved unless you call saveSuggested).",
      tests: "Must be non-duplicate vs existing DTUs (title+tags).",
      notes: "Use saveSuggested to store."
    });
    suggestions.push({ title, creti, tags: baseTags, tier:"regular" });
  }

  ctx.log("swarm.run", "Swarm completed", { removed, proposed: suggestions.length });
  return { ok: true, removedDuplicates: removed, keptCount: kept.length, suggested: suggestions };
});

register("dtu", "saveSuggested", async (ctx, input) => {
  const dtus = Array.isArray(input.dtus) ? input.dtus : [];
  const saved = [];
  for (const s of dtus) {
    const r = await ctx.macro.run("dtu","create",{
      title: s.title, creti: s.creti, tags: s.tags || [], tier: s.tier || "regular", source:"suggested"
    });
    if (r?.ok) saved.push(r.dtu);
  }

  return { ok: true, saved };
});

// Sim domain
register("sim", "run", async (ctx, input) => {
  const prompt = String(input.prompt || "");
  const assumptions = Array.isArray(input.assumptions) ? input.assumptions : [];
  const horizon = normalizeText(input.horizon || "90 days");
  const sim = {
    id: uid("sim"),
    createdAt: nowISO(),
    prompt,
    assumptions,
    horizon,
    branches: [
      { name:"Base", summary:"Conservative execution; steady iteration.", risk:"medium", confidence:0.62 },
      { name:"Aggressive", summary:"High cadence, ship weekly, rapid attention.", risk:"high", confidence:0.48 },
      { name:"Stability-first", summary:"Lock contracts, fewer features, stronger trust.", risk:"low", confidence:0.74 }
    ]
  };
// Full activation: stress test when R/D are provided; otherwise report missing meters.
  let stress = { ok:false, reason:"missing_R_or_D" };
  const R0 = input?.R ?? input?.repair;
  const D0 = input?.D ?? input?.damage;
  if (isFinite(Number(R0)) && isFinite(Number(D0))) {
    stress = await ctx.macro.run("verify","stressTest", { R: Number(R0), D: Number(D0), step: input?.step, maxIter: input?.maxIter });
  }
  sim.stress = stress;
  ctx.state.lastSim = sim;
  ctx.log("sim.run", "Simulation produced", { id: sim.id, horizon, stressOk: !!stress?.ok });
  return { ok: true, sim };
});

// Wrappers domain
register("wrapper", "create", (ctx, input) => {
  const name = normalizeText(input.name || "Untitled Wrapper");
  const intent = String(input.intent || "");
  const description = String(input.description || input.desc || "");
  const spec = (input.spec && typeof input.spec === "object") ? input.spec : { prompt: String(input.prompt||"") };
  const dtuBindings = Array.isArray(input.dtuBindings) ? input.dtuBindings : (Array.isArray(input.bindings) ? input.bindings : []);
  const w = {
    id: uid("wrap"),
    name,
    intent,
    description,
    spec,
    dtuBindings,
    version: "1.0.0",
    createdAt: nowISO(),
    updatedAt: nowISO(),
    sandbox: true,
    rules: {
      cannotOverrideImmutables: true,
      cannotWriteFiles: true,
      cannotNetwork: false // wrappers may call macros which may call crawl; gating can be added later
    }
  };
  ctx.state.wrappers.set(w.id, w);
  ctx.log("wrapper.create", "Wrapper created", { id: w.id, name });
  return { ok: true, wrapper: w };
});

register("wrapper", "list", (ctx, _input) => {
  return { ok: true, wrappers: Array.from(ctx.state.wrappers.values()) };
});

register("wrapper", "run", async (ctx, input) => {
  const id = String(input.id || "");
  const w = ctx.state.wrappers.get(id);
  if (!w) return { ok: false, error: "Wrapper not found" };
  const inp = input.input ?? {};
  // Wrapper execution model: translates "intent" into macro calls (local-first).
  // This is intentionally constrained + deterministic.
  const intent = tokenish(w.intent);
  let result = { note: "Wrapper executed in sandbox.", intent: w.intent, input: inp };

  // Simple routing: if intent mentions "chess" or "game", propose a DTU + plan.
  if (intent.includes("chess")) {
    const r = await ctx.macro.run("forge","auto",{ prompt: `Chess wrapper: ${JSON.stringify(inp)}` });
    result = { ...result, type:"chess", forged: r.dtus || [] };
  } else if (intent.includes("macro")) {
    // run a macro specified by input {domain,name,input}
    const domain = inp.domain, name = inp.name;
    if (domain && name) {
      const out = await ctx.macro.run(domain, name, inp.input || {});
      result = { ...result, type:"macro", out };
    }
  } else {
    // default: create a DTU describing the wrapper run
    const creti = cretiPack({
      title: `Wrapper Run: ${w.name}`,
      purpose: "Record wrapper run as a DTU and propose next actions.",
      context: `Intent: ${w.intent}\nInput: ${JSON.stringify(inp, null, 2)}`,
      procedure: "Summarize request → identify macro calls needed → propose pipeline.",
      outputs: "DTU describing wrapper result.",
      tests: "Must not violate immutables.",
      notes: "This is local-first; LLM can enhance via chat."
    });
    const dtu = await ctx.macro.run("dtu","create",{ title:`Wrapper: ${w.name}`, creti, tags:["wrapper"], tier:"regular", source:"wrapper.run" });
    result = { ...result, type:"generic", dtu: dtu.dtu };
  }

  ctx.log("wrapper.run", "Wrapper run", { id, name: w.name });
  return { ok: true, result };
});

// Layers domain
register("layer", "list", (ctx, _input) => {
  return { ok: true, layers: Array.from(ctx.state.layers.values()) };
});

register("layer", "create", (ctx, input) => {
  const name = normalizeText(input.name || "Untitled Layer");
  const layer = { id: uid("layer"), name, enabled: true, createdAt: nowISO(), updatedAt: nowISO() };
  ctx.state.layers.set(layer.id, layer);
  ctx.log("layer.create", "Layer created", { id: layer.id, name });
  return { ok: true, layer };
});

register("layer", "toggle", (ctx, input) => {
  const id = String(input.id || "");
  const layer = ctx.state.layers.get(id);
  if (!layer) return { ok: false, error: "Layer not found" };
  const enabled = typeof input.enabled === "boolean" ? input.enabled : !layer.enabled;
  layer.enabled = enabled;
  layer.updatedAt = nowISO();
  ctx.log("layer.toggle", "Layer toggled", { id, enabled });
  return { ok: true, layer };
});

// Personas domain
register("persona", "list", (ctx, _input) => {
  return { ok: true, personas: Array.from(ctx.state.personas.values()) };
});

register("persona", "create", (ctx, input) => {
  const name = normalizeText(input.name || "Untitled Persona");
  const persona = { id: uid("persona"), name, style: input.style || "neutral", createdAt: nowISO(), updatedAt: nowISO() };
  ctx.state.personas.set(persona.id, persona);
  ctx.log("persona.create", "Persona created", { id: persona.id, name });
  return { ok: true, persona };
});

// Ingest domain (crawl/autocrawl)
function stripHtml(html="") {
  return String(html)
    .replace(/<script[\s\S]*?<\/script>/gi, "")
    .replace(/<style[\s\S]*?<\/style>/gi, "")
    .replace(/<\/?[^>]+>/g, " ")
    .replace(/\s+/g, " ")
    .trim();
}

// SSRF protection helper
function isUrlSafe(urlStr) {
  try {
    const u = new URL(urlStr);
    // Block non-HTTP(S) protocols
    if (!["http:", "https:"].includes(u.protocol)) return { safe: false, reason: "Invalid protocol" };
    // Block internal IPs and localhost
    const host = u.hostname.toLowerCase();
    if (host === "localhost" || host === "127.0.0.1" || host === "0.0.0.0" || host === "::1") {
      return { safe: false, reason: "Internal host blocked" };
    }
    // Block private IP ranges
    const ipMatch = host.match(/^(\d+)\.(\d+)\.(\d+)\.(\d+)$/);
    if (ipMatch) {
      const [, a, b] = ipMatch.map(Number);
      if (a === 10) return { safe: false, reason: "Private IP blocked" };
      if (a === 172 && b >= 16 && b <= 31) return { safe: false, reason: "Private IP blocked" };
      if (a === 192 && b === 168) return { safe: false, reason: "Private IP blocked" };
      if (a === 169 && b === 254) return { safe: false, reason: "Link-local IP blocked" };
    }
    // Block cloud metadata endpoints
    if (host === "169.254.169.254" || host.endsWith(".internal") || host.endsWith(".local")) {
      return { safe: false, reason: "Metadata endpoint blocked" };
    }
    return { safe: true };
  } catch { return { safe: false, reason: "Invalid URL" }; }
}

register("ingest", "url", async (ctx, input) => {
  const url = String(input.url || "");
  if (!url) return { ok:false, error:"url required" };

  // SSRF protection
  const urlCheck = isUrlSafe(url);
  if (!urlCheck.safe) return { ok:false, error: urlCheck.reason };

  const prompt = String(input.prompt || "");
  const tags = Array.isArray(input.tags) ? input.tags : ["ingest"];

  // Add timeout and size limit
  const controller = new AbortController();
  const timeout = setTimeout(() => controller.abort(), 15000);
  let res;
  try {
    res = await fetch(url, { method:"GET", signal: controller.signal });
  } catch (e) {
    clearTimeout(timeout);
    return { ok:false, error: e.name === "AbortError" ? "Request timeout" : String(e.message) };
  }
  clearTimeout(timeout);

  const raw = await res.text();
  const text = stripHtml(raw).slice(0, 12000);

  const title = normalizeText(input.title || `Ingest: ${url}`.slice(0, 120));
  const creti = cretiPack({
    title,
    purpose: "Ingest external content into a DTU for local reasoning.",
    context: `URL: ${url}\nPrompt: ${prompt}\n\nCONTENT:\n${text}`,
    procedure: "1) Strip HTML\n2) Keep first N chars\n3) Store as DTU",
    outputs: "A DTU containing the ingested content",
    tests: "Ensure content is readable; ensure licensing is respected",
    notes: "Autocrawl should only ingest content you have rights to use."
  });

  const dtu = await ctx.macro.run("dtu","create",{ title, creti, tags, tier:"regular", source:"ingest.url", meta:{ url } });
  ctx.log("ingest.url", "Ingested url", { url, id: dtu.dtu.id });
  return { ok:true, url, dtu: dtu.dtu, fetchedBytes: raw.length };
});

register("ingest", "queue", (ctx, input) => {
  const url = String(input.url || "");
  if (!url) return { ok:false, error:"url required" };
  const item = { id: uid("crawl"), url, prompt: input.prompt || "", tags: input.tags || ["autocrawl"], createdAt: nowISO(), status:"queued" };
  ctx.state.crawlQueue.push(item);
  ctx.log("ingest.queue", "Queued url", { url, id: item.id });
  return { ok:true, item };
});

register("ingest", "processQueueOnce", async (ctx, _input) => {
  const next = ctx.state.crawlQueue.find(x => x.status === "queued");
  if (!next) return { ok:true, processed:false };
  next.status = "processing";
  try {
    const r = await ctx.macro.run("ingest","url",{ url: next.url, prompt: next.prompt, tags: next.tags, title: `Autocrawl: ${next.url}` });
    next.status = "done";
    next.resultId = r?.dtu?.id || r?.dtu?.dtu?.id;
    return { ok:true, processed:true, item: next, result: r };
  } catch (e) {
    next.status = "error";
    next.error = String(e?.message || e);
    ctx.log("ingest.queue.error", "Autocrawl failed", { id: next.id, error: next.error });
    return { ok:false, processed:true, item: next, error: next.error };
  }
});

// Quality Pipeline domain
register("quality", "status", (_ctx, input) => {
  const sessionId = input.sessionId || "";
  const shadowCount = STATE.shadowDtus ? STATE.shadowDtus.size : 0;
  const patternShadows = Array.from(STATE.shadowDtus?.values() || []).filter(s => s?.machine?.kind === "pattern_shadow").length;
  return {
    ok: true,
    shadowDtus: { total: shadowCount, patternShadows },
    sessionHistory: sessionId ? _getPatternHistory(sessionId) : [],
    patterns: ["P1:ShadowDistillation", "P2:CRETIProjection", "P3:LinguisticRewrite", "P4:MultiLens", "P5:ContradictionPreRes", "P6:ResonanceWeighted"],
    backendEnhancements: ["coherenceAudit", "shadowPromotion", "crispnessDecay"]
  };
}, { description: "Get quality pipeline status and pattern history" });

register("quality", "preview", (_ctx, input) => {
  const query = String(input.query || "");
  if (!query) return { ok: false, error: "Missing query" };
  const mode = input.mode || "explore";
  const intent = _inferQueryIntent(query, mode);
  const pseudoDtu = { title: query.slice(0, 100), human: { summary: query.slice(0, 300) }, tags: [] };
  const domain = classifyDomain(pseudoDtu);
  return {
    ok: true,
    queryIntent: intent,
    domain,
    projectionRules: CRETI_PROJECTION_RULES[intent] || CRETI_PROJECTION_RULES.default
  };
}, { description: "Preview which quality pipeline patterns would apply to a query" });

// System domain (dream/autogen/evolution/synthesize) — powered by 6-stage autogen pipeline
register("system", "dream", async (ctx, input) => {
  // Dream: gap-filling + creative hypotheses via 6-stage pipeline
  if (!STATE.dtus.size) return { ok: false, error: "No DTUs to dream from. Seed dtus.js first." };

  const ollamaCallback = LLM_PIPELINE?.providers?.ollama?.enabled
    ? async (prompt, opts) => callOllama(opts?.system ? `${opts.system}\n\n${prompt}` : prompt, opts)
    : null;

  const result = await ctx.macro.run("emergent", "pipeline.run", {
    variant: "dream",
    callOllama: ollamaCallback,
    seed: input.seed,
  });

  if (!result?.ok || !result.candidate) {
    return { ok: false, error: result?.error || "Pipeline produced no candidate", trace: result?.trace };
  }

  // Commit the pipeline candidate as a DTU
  const spec = {
    ...result.candidate,
    source: "system.dream",
    allowRewrite: true,
    scope: "local",
  };
  const r = await ctx.macro.run("dtu", "create", spec);

  return { ok: true, dtus: r?.ok ? [r.dtu] : [], trace: result.trace, writePolicy: result.writePolicy };
});

register("system", "autogen", async (ctx, input) => {
  // Autogen: signal-driven 6-stage pipeline (no longer "last 8 DTUs")
  if (!STATE.dtus.size) return { ok: false, error: "No DTUs to autogen from." };

  const ollamaCallback = LLM_PIPELINE?.providers?.ollama?.enabled
    ? async (prompt, opts) => callOllama(opts?.system ? `${opts.system}\n\n${prompt}` : prompt, opts)
    : null;

  // Run pipeline without a variant — picks best intent from lattice signals
  const result = await ctx.macro.run("emergent", "pipeline.run", {
    callOllama: ollamaCallback,
  });

  if (!result?.ok || !result.candidate) {
    return { ok: false, error: result?.error || "Pipeline produced no candidate", trace: result?.trace };
  }

  // Queue proposal instead of direct commit (preserves old queue behavior)
  ensureQueues();
  const proposal = {
    id: uid("q_autogen"),
    type: "dtu_proposal",
    payload: { ...result.candidate, source: "system.autogen", scope: "local" },
    why: `pipeline:${result.candidate.meta?.autogenIntent || "auto"}`,
    createdAt: nowISO(),
    status: "queued",
    writePolicy: result.writePolicy,
    trace: result.trace,
  };
  enqueueNotification(proposal);

  return { ok: true, dtus: [], queued: true, proposal, trace: result.trace, writePolicy: result.writePolicy };
});

register("system", "evolution", async (ctx, input) => {
  // Evolution: cluster compression + mega DTU rollup via 6-stage pipeline
  if (!STATE.dtus.size) return { ok: false, error: "No DTUs to evolve." };

  const ollamaCallback = LLM_PIPELINE?.providers?.ollama?.enabled
    ? async (prompt, opts) => callOllama(opts?.system ? `${opts.system}\n\n${prompt}` : prompt, opts)
    : null;

  const result = await ctx.macro.run("emergent", "pipeline.run", {
    variant: "evolution",
    callOllama: ollamaCallback,
  });

  if (!result?.ok || !result.candidate) {
    return { ok: false, error: result?.error || "Pipeline produced no candidate", trace: result?.trace };
  }

  // Evolution still uses cluster-based MEGA promotion for large clusters
  const clusters = await ctx.macro.run("dtu", "cluster", { threshold: input.threshold ?? 0.38 });
  const best = clusters.clusters?.[0];
  const minCluster = Number(input.minCluster ?? 100);

  if (best?.ids?.length >= minCluster) {
    // Large cluster → MEGA DTU from cluster (original evolution path)
    const inner = dtusByIds(best.ids);
    const sigTags = (best.tagHints || []).slice(0, 8).join("|") || (best.titles || [])[0] || "cluster";
    const existing = dtusArray().find(d => d.tier === "mega" && d.meta?.clusterSig === sigTags && d.meta?.clusterSize === best.ids.length);
    if (existing) return { ok: true, mega: existing, reused: true, cluster: best, pipelineTrace: result.trace };

    const megaTitle = normalizeText(input.title || `MEGA: ${best.titles?.[0] || "Topic Cluster"}`.slice(0, 120));
    const creti = cretiPack({
      title: megaTitle,
      purpose: "MEGA DTU: compress a topic range into a single navigable node (with lineage).",
      context: `Cluster size: ${inner.length}\nTag hints: ${(best.tagHints || []).join(", ")}\n\nInner DTUs:\n${inner.map(d => `- ${d.title} (${d.id})`).join("\n")}`,
      procedure: "Synthesize shared core, keep lineage, avoid clutter.",
      outputs: "Mega DTU with lineage referencing inner DTUs.",
      tests: "Must not lose lineage; must remain readable.",
      notes: "Mega DTUs can later be merged into Hyper DTUs."
    });

    const r = await ctx.macro.run("dtu", "create", { title: megaTitle, creti, tags: best.tagHints || ["mega"], tier: "mega", lineage: best.ids, source: "system.evolution", meta: { ...(input.meta || {}), clusterSig: sigTags, clusterSize: best.ids.length } });
    return { ok: true, mega: r.dtu, cluster: best, pipelineTrace: result.trace };
  }

  // Small/no cluster → commit pipeline candidate as regular DTU
  const spec = {
    ...result.candidate,
    source: "system.evolution",
    allowRewrite: true,
    scope: "local",
  };
  const r = await ctx.macro.run("dtu", "create", spec);

  return { ok: true, dtus: r?.ok ? [r.dtu] : [], trace: result.trace, writePolicy: result.writePolicy };
});


register("system","promotionTick", async (ctx, input) => {
  // v3: automatic DTU -> MEGA candidate -> probation -> MEGA promotion
  const now = nowISO();
  const minSupport = Number(input.minSupport ?? 9);
  const threshold = Number(input.threshold ?? 0.38);
  const maxCreates = Number(input.maxCreates ?? 5);
  const probationHours = Number(input.probationHours ?? 24);

  ensureQueues();

  // 1) cluster DTUs
  const clusters = await ctx.macro.run("dtu","cluster",{ threshold });
  const list = (clusters.clusters || []).slice(0, 50);

  const created = [];
  for (const c of list) {
    if (!c?.ids?.length) continue;
    if (c.ids.length < minSupport) continue;

    // Signature for dedupe of candidates
    const sig = (c.tagHints||[]).slice(0,8).join("|") || (c.titles||[])[0] || `cluster_${c.ids.length}`;
    const existingMega = dtusArray().find(d=>d.tier==="mega" && (d.meta?.clusterSig===sig) && (d.meta?.clusterSize===c.ids.length));
    if (existingMega) continue;

    const existingCand = (STATE.queues?.synthesis||[]).find(p=>p?.type==="mega_candidate" && (p.clusterSig===sig || p.cluster?.tagHints?.slice(0,8).join("|")===sig));
    if (existingCand) continue;

    // Create candidate proposal (queued)
    const proposal = {
      id: uid("mega_candidate"),
      type: "mega_candidate",
      status: "probation",
      createdAt: now,
      updatedAt: now,
      probationUntil: new Date(Date.now() + probationHours*3600*1000).toISOString(),
      clusterSig: sig,
      cluster: c,
      minSupport,
      threshold
    };
    STATE.queues.synthesis.push(proposal);
    created.push(proposal);
    if (created.length >= maxCreates) break;
  }

  // 2) finalize matured candidates -> MEGA
  const matured = [];
  const synthQ = STATE.queues.synthesis || [];
  for (const p of synthQ) {
    if (p?.type!=="mega_candidate" || p.status!=="probation") continue;
    const until = Date.parse(p.probationUntil||"");
    if (Number.isFinite(until) && Date.now() < until) continue;

    // verify cluster still exists and large enough
    const ids = p.cluster?.ids || [];
    const inner = dtusByIds(ids);
    if (inner.length < minSupport) { p.status="rejected"; p.updatedAt=nowISO(); continue; }

    const megaTitle = normalizeText(`MEGA: ${(p.cluster?.titles||[])[0] || "Topic Cluster"}`.slice(0,120));
    const creti = cretiPack({
      title: megaTitle,
      purpose: "MEGA DTU: compress a topic range into a single navigable node (with lineage).",
      context: `Auto-promoted (v3). Cluster size: ${inner.length}
ClusterSig: ${p.clusterSig}`,
      reasoning: inner.slice(0,40).map(d=>`- ${d.title} (${d.id})`).join("\n"),
      procedure: "Synthesize shared core, keep lineage, avoid clutter.",
      outputs: "Mega DTU with lineage metadata + navigation."
    });

    const mega = {
      id: uid("dtu"),
      title: megaTitle,
      content: creti,
      createdAt: nowISO(),
      updatedAt: nowISO(),
      tier: "mega",
      tags: ["mega","auto"],
      meta: { clusterSig: p.clusterSig, clusterSize: inner.length, lineage: inner.map(d=>d.id).slice(0,200), promotedFrom:"promotionTick" }
    };
    const commit = pipelineCommitDTU(ctx, mega, { op:"system.promotionTick" });
    if (commit.ok) {
      p.status="fulfilled";
      p.updatedAt=nowISO();
      p.megaId = mega.id;
      matured.push({ proposalId:p.id, megaId: mega.id, clusterSize: inner.length });
    } else {
      p.status="rejected";
      p.updatedAt=nowISO();
      p.error = commit.error || "commit failed";
    }
  }

  
  // Gap promotion: periodically synthesize stable clusters into MEGA DTUs
  try {
    await runMacro(ctx, "dtu", "gapPromote", { minCluster: 6, maxPromotions: 1, dryRun: false });
  } catch {}

return { ok:true, simulation:true, createdCandidates: created.length, created, matured };
}, { summary:"Automatic MEGA promotion pipeline tick (candidate->probation->MEGA) (v3)." });

register("system", "synthesize", async (ctx, input) => {
  // Synthesize: conflict resolution + patch proposals via pipeline, or HYPER DTU from megas
  let megaIds = Array.isArray(input.megaIds) ? input.megaIds : [];
  if (megaIds.length === 0) {
    megaIds = dtusArray().filter(d => d.tier === "mega").slice(0, 6).map(d => d.id);
  }
  const megas = dtusByIds(megaIds).filter(d => d.tier === "mega");

  // If we have enough megas, build a HYPER DTU
  if (megas.length >= 2) {
    const hyperTitle = normalizeText(input.title || `HYPER: ${megas[0].title} + ${megas[1].title}`.slice(0, 120));
    const allLineage = Array.from(new Set(megas.flatMap(m => m.lineage || [])));
    const creti = cretiPack({
      title: hyperTitle,
      purpose: "HYPER DTU: integrate multiple mega DTUs into a higher-order framework.",
      context: `Megas:\n${megas.map(m => `- ${m.title} (${m.id})`).join("\n")}\n\nTotal lineage DTUs: ${allLineage.length}`,
      procedure: "Identify shared invariants, conflicts, and a unified map.",
      outputs: "Hyper DTU with mega lineage and inner lineage.",
      tests: "Must preserve lineage; label hypotheses; propose measurements.",
      notes: "This is the top-level node for a domain."
    });

    const r = await ctx.macro.run("dtu", "create", { title: hyperTitle, creti, tags: ["hyper"], tier: "hyper", lineage: megaIds, source: "system.synthesize", meta: { innerLineageCount: allLineage.length } });
    return { ok: true, hyper: r.dtu, usedMegas: megas.map(m => ({ id: m.id, title: m.title })) };
  }

  // Otherwise, run synth variant of pipeline (conflict resolution + fill gaps)
  if (!STATE.dtus.size) return { ok: false, error: "Need at least 2 mega DTUs to synthesize a hyper DTU, or DTUs for conflict resolution." };

  const ollamaCallback = LLM_PIPELINE?.providers?.ollama?.enabled
    ? async (prompt, opts) => callOllama(opts?.system ? `${opts.system}\n\n${prompt}` : prompt, opts)
    : null;

  const result = await ctx.macro.run("emergent", "pipeline.run", {
    variant: "synth",
    callOllama: ollamaCallback,
  });

  if (!result?.ok || !result.candidate) {
    return { ok: false, error: result?.error || "Pipeline produced no candidate", trace: result?.trace };
  }

  const spec = {
    ...result.candidate,
    source: "system.synthesize",
    allowRewrite: true,
    scope: "local",
  };
  const r = await ctx.macro.run("dtu", "create", spec);

  return { ok: true, dtus: r?.ok ? [r.dtu] : [], trace: result.trace, writePolicy: result.writePolicy };
});



// ===================== Smoothness Specs Implementation (Continuity/Gaps/Definitions/Reconcile/Experiments) =====================

// Lightweight continuity snapshot DTU (no invented claims; cites parent DTU ids)
register("system", "continuity", async (ctx, input) => {
  const sessionId = normalizeText(input.sessionId || "default");
  const window = clamp(Number(input.window ?? 20), 5, 200);
  const commit = input.commit !== false; // default true
  const mode = normalizeText(input.mode || "delta"); // delta | full

  const pool = dtusArray().slice(-window);
  const parents = pool.map(d => d.id);
  const recentTitles = pool.slice(-12).map(d => d.title).filter(Boolean);

  // capture recent system logs (non-sensitive)
  const logs = (ctx.state.logs || []).slice(-50).filter(e => /^(dtu|system|settings|ingest|wrapper)\./.test(String(e.type||"")));
  const logLines = logs.slice(-12).map(e => `- ${e.ts} ${e.type}: ${e.message}`).join("\n");

  const creti = cretiPack({
    title: `Continuity Snapshot (${sessionId}) — ${nowISO().slice(0,10)}`,
    purpose: "Maintain temporal coherence across sessions. Records deltas, not new claims.",
    context:
`Session: ${sessionId}
Window DTUs: ${pool.length}

Recent titles:
${recentTitles.map(t=>`- ${t}`).join("\n")}

Recent system activity:
${logLines || "(none)"}

Parents:
${parents.slice(-50).map(id=>`- ${id}`).join("\n")}${parents.length>50 ? `\n…(${parents.length-50} more)` : ""}`,
    procedure: "1) Select last N DTUs\n2) Record titles + IDs + relevant system events\n3) Store as DTU (optional)",
    outputs: "Continuity DTU that references exact DTU IDs; no invented facts.",
    tests: "Must not add new claims; must reference parent DTU IDs."
  });

  const tags = Array.from(new Set(["continuity","system", sessionId ? `session:${sessionId}` : null].filter(Boolean)));
  const spec = { title: `Continuity: ${sessionId} (${nowISO().slice(0,10)})`, creti, tags, tier:"regular", lineage: parents, source:"system.continuity", meta:{ sessionId, window, mode } };

  if (!commit) return { ok:true, committed:false, spec };
  const r = await ctx.macro.run("dtu","create", { ...spec, allowRewrite:true });
  return { ok:true, committed:true, dtu: r.dtu, sessionId, window };
}, { summary:"Create a Continuity DTU capturing deltas across the last N DTUs (no invented claims)." });

// Gap scan (detect missing definitions / unsupported claims / coverage score). Returns report; can optionally commit as DTU.
register("system", "gapScan", async (ctx, input) => {
  const window = clamp(Number(input.window ?? 300), 20, 5000);
  const commit = !!input.commit;
  const domain = normalizeText(input.domain || "general");

  const pool = dtusArray().slice(-window);

  // Helper: detect existing definition DTUs
  const isDef = (d) => (d.tags||[]).includes("definition") || /^def(inition)?:/i.test(String(d.title||""));
  const defs = new Map(); // termLower -> dtuId
  for (const d of pool) {
    if (!isDef(d)) continue;
    const t = String(d.meta?.term || "").trim() || String(d.title||"").replace(/^def(inition)?:\s*/i,"").trim();
    if (!t) continue;
    defs.set(t.toLowerCase(), d.id);
  }

  // Candidate terms: top tags + title heads
  const tagFreq = new Map();
  for (const d of pool) for (const t of (d.tags||[])) tagFreq.set(t, (tagFreq.get(t)||0)+1);
  const topTags = Array.from(tagFreq.entries())
    .filter(([t]) => t && !/^session:/.test(t) && !["system","autogen","dream","gaps","continuity","mega","hyper","regular"].includes(t))
    .sort((a,b)=>b[1]-a[1])
    .slice(0, 25)
    .map(x=>x[0]);

  const titleHeads = pool
    .map(d => String(d.title||"").split(":")[0].trim())
    .filter(t => t && t.length>=3 && t.length<=48)
    .slice(-200);

  const candidates = Array.from(new Set([...topTags, ...titleHeads])).slice(0, 60);

  const missing_definitions = [];
  for (const term of candidates) {
    const k = term.toLowerCase();
    if (defs.has(k)) continue;
    // consider as missing if term appears frequently
    const freq = tagFreq.get(term) || tagFreq.get(k) || 0;
    if (freq >= 2 || topTags.includes(term)) missing_definitions.push({ term, freq });
  }

  // Unsupported claims: claims without tests when requireTestsWhenUncertain is true
  const unsupported_claims = [];
  for (const d of pool.slice(-200)) {
    const c = d.core || {};
    const claims = Array.isArray(c.claims) ? c.claims : [];
    const tests = Array.isArray(c.tests) ? c.tests : [];
    if (!claims.length) continue;
    if (ctx.state.settings?.requireTestsWhenUncertain && tests.length === 0) {
      unsupported_claims.push({ dtuId: d.id, title: d.title, claims: claims.slice(0,3) });
    }
  }

  // Missing nodes: absence of continuity + experiment tracking for active work
  const hasContinuity = pool.some(d => (d.tags||[]).includes("continuity"));
  const hasExperiments = pool.some(d => (d.tags||[]).includes("experiment"));
  const missing_nodes = [];
  if (!hasContinuity) missing_nodes.push("continuity");
  if (!hasExperiments) missing_nodes.push("experiment-tracker");

  // Coverage score heuristic
  const denom = Math.max(1, candidates.length);
  const coverage_score = clamp(1 - (missing_definitions.length / denom), 0, 1);

  const report = { ok:true, domain, window, coverage_score, missing_nodes, missing_definitions, unsupported_claims };

  if (!commit) return report;

  const creti = cretiPack({
    title: `Gap Scan (${domain}) — ${nowISO().slice(0,10)}`,
    purpose: "Identify structural gaps: missing definitions, unsupported claims, and missing operational nodes.",
    context:
`Window DTUs: ${pool.length}
Coverage score: ${coverage_score.toFixed(3)}

Missing nodes:
${missing_nodes.map(x=>`- ${x}`).join("\n") || "(none)"}

Missing definitions (top):
${missing_definitions.slice(0,25).map(x=>`- ${x.term} (freq≈${x.freq||0})`).join("\n") || "(none)"}

Unsupported claims (sample):
${unsupported_claims.slice(0,10).map(x=>`- ${x.title} (${x.dtuId})`).join("\n") || "(none)"}`,
    procedure: "1) Compute candidate terms (tags + title heads)\n2) Check for existing definition DTUs\n3) Flag claims lacking tests when required\n4) Emit actionable report",
    outputs: "Gap DTU containing missing items; feeds evolution/promotion checks.",
    tests: "Report must cite DTU IDs for unsupported claims; must not invent missing terms."
  });

  const tags = ["gaps","system","report", `domain:${domain}`].slice(0,20);
  const r = await ctx.macro.run("dtu","create", { title:`Gaps: ${domain} (${nowISO().slice(0,10)})`, creti, tags, tier:"regular", lineage: pool.slice(-50).map(d=>d.id), source:"system.gapScan", meta:{ report } });
  return { ...report, committed:true, dtu:r.dtu };
}, { summary:"Detect missing definitions/unsupported claims; optionally commit a Gap DTU." });

// Definition DTU creator (canonical term definition for a domain)
register("dtu", "define", async (ctx, input) => {
  const term = normalizeText(input.term || "");
  if (!term) return { ok:false, error:"term required" };
  const domain = normalizeText(input.domain || "general");
  const nonGoals = Array.isArray(input.nonGoals) ? input.nonGoals : [];
  const related = Array.isArray(input.related_terms) ? input.related_terms : (Array.isArray(input.relatedTerms) ? input.relatedTerms : []);

  // Dedupe: if a definition exists for same term+domain, return it
  const existing = dtusArray().find(d =>
    ((d.tags||[]).includes("definition") || /^def(inition)?:/i.test(String(d.title||""))) &&
    String(d.meta?.term||"").toLowerCase() === term.toLowerCase() &&
    String(d.meta?.domain||"general").toLowerCase() === domain.toLowerCase()
  );
  if (existing && !input.allowRewrite) return { ok:true, reused:true, dtu: existing };

  const creti = cretiPack({
    title: `Definition: ${term} (${domain})`,
    purpose: "Reduce friction by making key terms precise and scoped.",
    context:
`Term: ${term}
Domain: ${domain}
Non-goals: ${(nonGoals||[]).join("; ") || "(none)"}
Related: ${(related||[]).join(", ") || "(none)"}

Definition (user-provided if any):
${String(input.definition||"").trim() || "(provide a definition field or edit later)"}`,
    procedure: "1) Define term with scope\n2) Record non-goals\n3) Link related terms\n4) Commit as canonical definition DTU",
    outputs: "Definition DTU (used by UI tooltips / reasoning).",
    tests: "Must be scoped; must not contain speculative claims."
  });

  const tags = Array.from(new Set(["definition", `domain:${domain}`])).slice(0,20);
  const r = await ctx.macro.run("dtu","create", {
    title: `Definition: ${term}`,
    creti,
    tags,
    tier: "regular",
    source: "dtu.define",
    allowRewrite: !!input.allowRewrite,
    meta: { term, domain, nonGoals, related }
  });
  return { ok:true, dtu: r.dtu, reused:false };
}, { summary:"Create a canonical definition DTU for a term+domain." });

// Contradiction reconciliation (string-heuristic; labels resolved/isolated/undecidable; never erases minority)
register("dtu", "reconcile", async (ctx, input) => {
  const ids = Array.isArray(input.ids) ? input.ids : [];
  const lastN = clamp(Number(input.lastN ?? 12), 2, 200);
  const pool = ids.length ? dtusByIds(ids) : dtusArray().slice(-lastN);
  if (pool.length < 2) return { ok:false, error:"Need at least 2 DTUs to reconcile." };

  const claimPairs = [];
  const claimText = (d) => (d.core?.claims||[]).map(x=>String(x)).join("\n");
  // very light contradiction detector: "is" vs "is not" on shared noun phrase
  const norm = (s) => String(s||"").toLowerCase().replace(/[^a-z0-9\s]/g," ").replace(/\s+/g," ").trim();
  for (let i=0;i<pool.length;i++){
    for (let j=i+1;j<pool.length;j++){
      const a = norm(claimText(pool[i]));
      const b = norm(claimText(pool[j]));
      if (!a || !b) continue;
      // detect negation mismatch for same 3-gram
      const aNeg = /\bnot\b|\bnever\b|\bno\b/.test(a);
      const bNeg = /\bnot\b|\bnever\b|\bno\b/.test(b);
      if (aNeg === bNeg) continue;
      // shared token overlap heuristic
      const aTok = new Set(a.split(" ").filter(x=>x.length>3));
      const bTok = new Set(b.split(" ").filter(x=>x.length>3));
      let overlap = 0;
      for (const t of aTok) if (bTok.has(t)) overlap++;
      if (overlap >= 4) {
        claimPairs.push({ a: pool[i].id, b: pool[j].id, overlap });
      }
    }
  }

  const resolution_type = claimPairs.length ? "isolated" : "resolved";
  const conflicting_claims = claimPairs.slice(0, 20).map(p => ({
    a: p.a, aTitle: ctx.state.dtus.get(p.a)?.title,
    b: p.b, bTitle: ctx.state.dtus.get(p.b)?.title,
    overlap: p.overlap
  }));

  const creti = cretiPack({
    title: `Reconciliation — ${nowISO().slice(0,10)}`,
    purpose: "Resolve or explicitly isolate conflicts; never erase minority claims.",
    context:
`Scope DTUs: ${pool.map(d=>`${d.title} (${d.id})`).join("\n")}

Detected conflicts:
${conflicting_claims.map(x=>`- ${x.aTitle} <-> ${x.bTitle} (overlap=${x.overlap})`).join("\n") || "(none)"}`,
    procedure: "1) Compare claims across DTUs\n2) If conflict: isolate with explicit marker\n3) If none: mark resolved\n4) Commit reconciliation DTU",
    outputs: "Reconciliation DTU with resolution_type and conflict references.",
    tests: "Must cite DTU IDs; must not delete/overwrite claims."
  });

  const tags = ["reconcile","contradiction", resolution_type].slice(0,20);
  const spec = {
    title: `Reconcile: ${resolution_type} (${nowISO().slice(0,10)})`,
    creti,
    tags,
    tier: "regular",
    lineage: pool.map(d=>d.id),
    source: "dtu.reconcile",
    meta: { resolution_type, conflicting_claims }
  };

  if (input.commit === false) return { ok:true, committed:false, ...spec.meta, spec };
  const r = await ctx.macro.run("dtu","create", { ...spec, allowRewrite:true });
  return { ok:true, committed:true, dtu: r.dtu, ...spec.meta };
}, { summary:"Detect contradictions and create a reconciliation DTU (resolved/isolated/undecidable)." });

// Experiment tracker (as DTU; immutable audit-style logging)
register("experiment", "log", async (ctx, input) => {
  const hypothesis = String(input.hypothesis || "").trim();
  const change_log = input.change_log || input.changeLog || {};
  const metrics = Array.isArray(input.metrics) ? input.metrics : [];
  const result_state = normalizeText(input.result_state || input.resultState || "inconclusive"); // supports|weakens|inconclusive

  const creti = cretiPack({
    title: `Experiment — ${nowISO().slice(0,10)} ${nowISO().slice(11,19)}`,
    purpose: "Track changes and impacts; prevent chaotic iteration.",
    context:
`Hypothesis:
${hypothesis || "(none)"}

Change log:
${JSON.stringify(change_log, null, 2)}

Metrics (predefined preferred):
${metrics.map(m=>`- ${m.name||m.metric||"metric"}: ${m.value ?? m.after ?? ""} (before=${m.before ?? ""})`).join("\n") || "(none)"}

Result state: ${result_state}`,
    procedure: "1) Define hypothesis + change\n2) Record metrics\n3) Store immutable experiment log DTU",
    outputs: "Experiment DTU (feeds stability + promotion checks).",
    tests: "Metrics should be defined before run; results ≠ conclusions."
  });

  const tags = Array.from(new Set(["experiment", "tracker", `result:${result_state}`])).slice(0,20);
  const r = await ctx.macro.run("dtu","create", {
    title: `Experiment: ${result_state} (${nowISO().slice(0,10)})`,
    creti,
    tags,
    tier: "regular",
    source: "experiment.log",
    meta: { hypothesis, change_log, metrics, result_state }
  });
  return { ok:true, dtu: r.dtu };
}, { summary:"Create an immutable Experiment Tracker DTU with hypothesis/change/metrics/result." });



// DTU semantic-ish dedupe sweeper (non-destructive; merges lineage/tags into keeper)
register("dtu", "dedupeSweep", async (ctx, input) => {
  const threshold = Number(input.threshold ?? 0.92);
  const limit = Number(input.limit ?? 2000);
  const items = dtusArray().slice(0, limit).map(d => ({ d, txt: tokenish(dtuText(d)) }));
  const seen = new Set();
  const merges = [];
  for (let i=0;i<items.length;i++){
    const a = items[i]; if (seen.has(a.d.id)) continue;
    const aTok = simpleTokens(a.txt);
    for (let j=i+1;j<items.length;j++){
      const b = items[j]; if (seen.has(b.d.id)) continue;
      const bTok = simpleTokens(b.txt);
      const sim = jaccard(aTok, bTok);
      if (sim >= threshold) {
        // merge b into a (keeper=a)
        const keep = a.d, drop = b.d;
        keep.tags = Array.from(new Set([...(keep.tags||[]), ...(drop.tags||[])])).slice(0, 40);
        keep.lineage = Array.from(new Set([...(keep.lineage||[]), drop.id, ...(drop.lineage||[])])).slice(0, 5000);
        keep.meta = { ...(keep.meta||{}), mergedFrom: Array.from(new Set([...(keep.meta?.mergedFrom||[]), drop.id])) };
        drop.meta = { ...(drop.meta||{}), mergedInto: keep.id };
        upsertDTU(keep);
        await pipelineCommitDTU(ctx, drop, { op: 'dtu.dedupeSweep', allowRewrite: true });
        merges.push({ into: keep.id, from: drop.id, sim });
        seen.add(drop.id);
      }
    }
  }
  ctx.log("dtu.dedupeSweep", "Dedupe sweep complete", { merges: merges.length, threshold });
  return { ok:true, merges, threshold };
}, { description: "Merge near-duplicate DTUs by similarity; keeps lineage." });
// Settings domain
register("settings", "get", (ctx, _input) => {
  return { ok:true, settings: ctx.state.settings };
});
register("settings", "set", (ctx, input) => {
  const s = input.settings && typeof input.settings === "object" ? input.settings : {};
  ctx.state.settings = { ...ctx.state.settings, ...s };
  ctx.log("settings.set", "Settings updated", { keys: Object.keys(s) });
  return { ok:true, settings: ctx.state.settings };
});

// Interface domain
register("interface", "tabs", (_ctx, _input) => {
  // Informational registry for UI
  return {
    ok:true,
    tabs: [
      { id:"overview", title:"Overview" },
      { id:"dtus", title:"DTUs" },
      { id:"chat", title:"Chat" },
      { id:"ask", title:"Ask" },
      { id:"forge", title:"Forge" },
      { id:"wrapper", title:"Wrapper Studio" },
      { id:"swarm", title:"Swarm" },
      { id:"sim", title:"Simulation" },
      { id:"layers", title:"OS Layers" },
      { id:"interface", title:"Interface Lab" },
      { id:"settings", title:"Settings" },
    ]
  };
});

// Logs domain
register("log", "list", (ctx, input) => {
  const limit = clamp(Number(input.limit || 200), 1, 2000);
  return { ok:true, logs: ctx.state.logs.slice(-limit) };
});

// Materials test domain (debug hook)
register("materials", "test", (ctx, input) => {
  return { ok:true, pong:true, at: nowISO(), input: input || null };
});

// ---- Express app ----
// ---- Growth macros (local-first; LLM optional) ----
register("synth", "combine", async (ctx, input) => {
  const ids = Array.isArray(input.ids) ? input.ids : [];
  const dtus = dtusByIds(ids);
  if (dtus.length < 2) return { ok:false, error:"need >=2 dtus" };

  const title = normalizeText(input.title || `SYNTH — ${dtus[0].title} × ${dtus[1].title}`) || "SYNTH";
  const tags = Array.from(new Set(dtus.flatMap(d=>d.tags||[]).concat(["synthesis","local"]))).slice(0, 24);

  // deterministic CRETI baseline
  const context = dtus.map(d=>`- ${d.title}: ${(d.human?.summary||"").slice(0,180)}`).join("\n");
  const procedure = [
    "1) Extract shared invariant across inputs",
    "2) Extract contradictions/tensions",
    "3) Propose a reconciled thesis (label speculation)",
    "4) Add 2–4 tests that could falsify key claims",
    "5) Output next actions"
  ].join("\n");
  let creti = cretiPack({
    title,
    purpose: "Synthesize multiple DTUs into a new coherent DTU (preserve lineage).",
    context,
    procedure,
    outputs: "A new DTU with explicit lineage to its parents.",
    tests: "At least 2 falsifiable checks or measurable tests.",
    notes: "Local-first synthesis; can be enhanced with LLM when enabled."
  });

  const llm = !!input.llm;
  const model = input.model === "smart" ? OPENAI_MODEL_SMART : OPENAI_MODEL_FAST;
  if (llm && ctx.llm.enabled) {
    const system = "You are ConcordOS. Produce a CRETI document. Keep it grounded, testable, and concise. Preserve lineage and tag contradictions explicitly.";
    const bundle = dtus.map(d=>`TITLE: ${d.title}\nTAGS: ${(d.tags||[]).join(", ")}\nCONTENT:\n${dtuText(d)}\n---`).join("\n");
    const msg = [{ role:"user", content:`Make a new CRETI synthesis DTU.\n\nInputs:\n${bundle}` }];
    const r = await ctx.llm.chat({ system, messages: msg, temperature: 0.35, maxTokens: 900, model });
    if (r.ok && r.content) creti = r.content.trim();
  }

  const created = await ctx.macro.run("dtu", "create", {
    title,
    tags,
    tier: "regular",
    source: "synth.combine",
    lineage: dtus.map(d=>d.id),
    creti
  });

  if (!created.ok) return created;
  created.dtu.lineage = dtus.map(d=>d.id);
  created.dtu.machine = created.dtu.machine || {};
  created.dtu.machine.parents = dtus.map(d=>d.id);
  created.dtu.updatedAt = nowISO();
  await pipelineCommitDTU(ctx, created.dtu, { op: 'forge.auto', allowRewrite: true });
  return { ok:true, dtu: created.dtu };
}, { description: "Combine DTUs into a new synthesized DTU (local-first, optional LLM)." });

register("evolution", "dedupe", async (ctx, input) => {
  // merge near-duplicates by title+tags similarity; keep lineage
  const threshold = Number(input.threshold ?? 0.86);
  const items = dtusArray();
  const used = new Set();
  let merged = 0;

  for (let i=0;i<items.length;i++){
    const a = items[i];
    if (used.has(a.id)) continue;
    const aTok = simpleTokens((a.title||"") + " " + (a.tags||[]).join(" "));
    for (let j=i+1;j<items.length;j++){
      const b = items[j];
      if (used.has(b.id)) continue;
      const bTok = simpleTokens((b.title||"") + " " + (b.tags||[]).join(" "));
      if (jaccard(aTok, bTok) >= threshold) {
        // merge b into a
        a.lineage = Array.from(new Set([...(a.lineage||[]), b.id, ...(b.lineage||[])]));
        a.tags = Array.from(new Set([...(a.tags||[]), ...(b.tags||[]), "deduped"])).slice(0, 40);
        a.updatedAt = nowISO();
        STATE.dtus.delete(b.id);
        used.add(b.id);
        merged++;
      }
    }
    if (merged) await pipelineCommitDTU(ctx, a, { op: 'evolution.dedupe', allowRewrite: true });
  }

  ctx.log("evolution.dedupe", "Deduped DTUs", { merged, threshold });
  return { ok:true, merged, total: STATE.dtus.size };
}, { description: "Merge near-duplicate DTUs, preserving lineage." });

register("heartbeat", "tick", async (ctx, input) => {
  // not "spawn a DTU" — run a mini debate + optional synthesis
  const reason = String(input.reason || "heartbeat");
  const llm = !!input.llm;
  const model = input.model === "smart" ? "smart" : "fast";

  // choose a focus query from recent sessions, else random
  const sessions = Array.from(STATE.sessions.values());
  const recentUser = sessions.flatMap(s => (s.messages||[]).filter(m=>m.role==="user").slice(-5)).slice(-12);
  const focus = (recentUser.length ? recentUser[Math.floor(Math.random()*recentUser.length)].content : "system growth").slice(0, 400);

  const debate = pickDebateSet(focus);
  if (debate.length < 2) return { ok:true, did:"noop", reason:"not_enough_dtus" };

  const made = await ctx.macro.run("synth", "combine", {
    ids: debate.slice(0, 4).map(d=>d.id),
    title: `HEARTBEAT — Synthesis: ${normalizeText(focus).slice(0, 60)}`,
    tags: ["heartbeat","autogen","evolution","synthesis"],
    llm,
    model
  });

  if (made.ok) {
    ctx.log("heartbeat.tick", "Heartbeat synthesis completed", { reason, focus: focus.slice(0, 100) });
    return { ok: true, did: "synthesis", dtuId: made.dtu?.id };
  } else {
    ctx.log("heartbeat.tick", "Heartbeat synthesis failed", { reason, error: made.error });
    return { ok: true, did: "noop", reason: "synthesis_failed" };
  }
});


// ===============================
// v2 RESTORED ORGANS (LOCKED)
// - Deterministic Math Engine (research.math.exec)
// - Dimensional OS (dimensional.*)
// - Council Global Gate (council.reviewGlobal) w/ strict no-duplicates
// - Anonymous E2E Messaging (anon.*) non-discoverable (no links)
// - Weekly Council Debate → Synthesis DTU (council.weeklyDebateTick)
// ===============================

// ---- Deterministic Math Engine (safe expression evaluator; no LLM math guessing) ----
function mathTokenize(expr="") {
  const s = String(expr).replace(/\s+/g,"").trim();
  const out = [];
  const re = /(\d+(?:\.\d+)?(?:e[+-]?\d+)?|[A-Za-z_][A-Za-z0-9_]*|[+\-*/^(),])/gy;
  let m;
  while ((m = re.exec(s))) out.push(m[1]);
  if (out.join("") !== s) throw new Error("Math parse error: invalid characters");
  return out;
}
const MATH_FUNCS = Object.freeze({
  sqrt: (a)=>Math.sqrt(a), abs:(a)=>Math.abs(a),
  sin:(a)=>Math.sin(a), cos:(a)=>Math.cos(a), tan:(a)=>Math.tan(a),
  asin:(a)=>Math.asin(a), acos:(a)=>Math.acos(a), atan:(a)=>Math.atan(a),
  ln:(a)=>Math.log(a), log:(a)=>Math.log10(a), exp:(a)=>Math.exp(a),
  min:(...a)=>Math.min(...a), max:(...a)=>Math.max(...a),
  pow:(a,b)=>Math.pow(a,b),
});
const MATH_CONSTS = Object.freeze({ pi: Math.PI, e: Math.E });
const OP_INFO = Object.freeze({
  "+": { prec: 2, assoc: "L", arity: 2, fn: (a,b)=>a+b },
  "-": { prec: 2, assoc: "L", arity: 2, fn: (a,b)=>a-b },
  "*": { prec: 3, assoc: "L", arity: 2, fn: (a,b)=>a*b },
  "/": { prec: 3, assoc: "L", arity: 2, fn: (a,b)=>a/b },
  "^": { prec: 4, assoc: "R", arity: 2, fn: (a,b)=>Math.pow(a,b) },
  "u-": { prec: 5, assoc: "R", arity: 1, fn: (a)=>-a },
});
function mathToRPN(tokens) {
  const out = [];
  const stack = [];
  let prev = null;
  for (let i=0;i<tokens.length;i++){
    const t = tokens[i];
    const isNum = /^[0-9]/.test(t);
    const isName = /^[A-Za-z_]/.test(t);
    if (isNum) { out.push({type:"num", v:Number(t)}); prev = "val"; continue; }
    if (isName) {
      const name = t.toLowerCase();
      // function call if next token is '('
      const next = tokens[i+1];
      if (next === "(") { stack.push({type:"func", name}); prev="func"; continue; }
      if (name in MATH_CONSTS) { out.push({type:"num", v:Number(MATH_CONSTS[name])}); prev="val"; continue; }
      throw new Error(`Unknown symbol: ${t}`);
    }
    if (t === ",") {
      while (stack.length && stack[stack.length-1].op !== "(") out.push(stack.pop());
      if (!stack.length) throw new Error("Misplaced comma");
      prev = ",";
      continue;
    }
    if (t === "(") { stack.push({op:"("}); prev="("; continue; }
    if (t === ")") {
      while (stack.length && stack[stack.length-1].op !== "(") out.push(stack.pop());
      if (!stack.length) throw new Error("Mismatched ')'");
      stack.pop(); // pop '('
      // if function on top, pop it
      if (stack.length && stack[stack.length-1].type === "func") out.push(stack.pop());
      prev = "val";
      continue;
    }
    if (["+","-","*","/","^"].includes(t)) {
      let op = t;
      if (op === "-" && (prev === null || prev === "(" || prev === "," || prev === "op" || prev === "func")) op = "u-";
      const info = OP_INFO[op];
      while (stack.length) {
        const top = stack[stack.length-1];
        const topInfo = top && top.op ? OP_INFO[top.op] : null;
        if (!topInfo) break;
        if ((info.assoc === "L" && info.prec <= topInfo.prec) || (info.assoc === "R" && info.prec < topInfo.prec)) out.push(stack.pop());
        else break;
      }
      stack.push({op});
      prev = "op";
      continue;
    }
    throw new Error(`Unexpected token: ${t}`);
  }
  while (stack.length) {
    const top = stack.pop();
    if (top.op === "(") throw new Error("Mismatched '('");
    out.push(top);
  }
  return out;
}
function mathEvalRPN(rpn) {
  const st = [];
  for (const it of rpn) {
    if (it.type === "num") { st.push(it.v); continue; }
    if (it.type === "func") {
      const fn = MATH_FUNCS[it.name];
      if (!fn) throw new Error(`Unknown function: ${it.name}`);
      // determine arity by reading args separated earlier: we don't have explicit arg counts.
      // Strategy: support common arities by inspecting stack length and function signature.
      // For min/max allow variable: require at least 2 args; we can't infer; so we accept 2 by default if ambiguous.
      const arity = fn.length || 1;
      if (it.name === "min" || it.name === "max") {
        // default: consume 2 args
        if (st.length < 2) throw new Error(`${it.name} requires >=2 args`);
        const b = st.pop(); const a = st.pop();
        st.push(fn(a,b));
      } else {
        if (st.length < arity) throw new Error(`${it.name} requires ${arity} args`);
        const args = st.splice(st.length-arity, arity);
        st.push(fn(...args));
      }
      continue;
    }
    if (it.op) {
      const info = OP_INFO[it.op];
      if (!info) throw new Error(`Unknown operator: ${it.op}`);
      if (st.length < info.arity) throw new Error("Malformed expression");
      if (info.arity === 1) {
        const a = st.pop();
        st.push(info.fn(a));
      } else {
        const b = st.pop(); const a = st.pop();
        st.push(info.fn(a,b));
      }
      continue;
    }
    throw new Error("Bad RPN item");
  }
  if (st.length !== 1) throw new Error("Malformed expression");
  return st[0];
}
function evalMathExpression(expr="") {
  const tokens = mathTokenize(expr);
  const rpn = mathToRPN(tokens);
  const value = mathEvalRPN(rpn);
  if (!Number.isFinite(value)) throw new Error("Non-finite result");
  return value;
}

// ---- Dimensional OS (validator + translator; hard-gate for research/sim) ----
// Goal: provide *real* dimensional grounding (no pretending). Deterministic, small-scope, SI-based.
// Supports: base dimensions, common derived units, prefixes, conversion factors, and unit algebra.
//
// Representation: dimension vector over SI base units: [m, kg, s, A, K, mol, cd]
const _DIM_KEYS = ["m","kg","s","A","K","mol","cd"];
function _zeroDim(){ return Object.fromEntries(_DIM_KEYS.map(k=>[k,0])); }
function _addDim(a,b,sign=1){
  const out=_zeroDim();
  for (const k of _DIM_KEYS) out[k]=(a[k]||0)+sign*(b[k]||0);
  return out;
}
function _mulDimPow(a,pow){
  const out=_zeroDim();
  for (const k of _DIM_KEYS) out[k]=(a[k]||0)*pow;
  return out;
}
function _sameDim(a,b){
  for (const k of _DIM_KEYS) if ((a[k]||0)!==(b[k]||0)) return false;
  return true;
}
function _dimToSig(a){ return _DIM_KEYS.map(k=>`${k}^${a[k]||0}`).join("|"); }

// Unit tables (factor to SI base; dim vector)
const _UNIT = (() => {
  const Z=_zeroDim();
  const base = {
    m:  { f:1, d:{...Z,m:1}},
    kg: { f:1, d:{...Z,kg:1}},
    s:  { f:1, d:{...Z,s:1}},
    A:  { f:1, d:{...Z,A:1}},
    K:  { f:1, d:{...Z,K:1}},
    mol:{ f:1, d:{...Z,mol:1}},
    cd: { f:1, d:{...Z,cd:1}},
    // accepted aliases
    g:  { f:1e-3, d:{...Z,kg:1}},
    sec:{ f:1, d:{...Z,s:1}},
    min:{ f:60, d:{...Z,s:1}},
    h:  { f:3600, d:{...Z,s:1}},
    Hz: { f:1, d:{...Z,s:-1}},
    N:  { f:1, d:{...Z,m:1,kg:1,s:-2}},
    Pa: { f:1, d:{...Z,m:-1,kg:1,s:-2}},
    J:  { f:1, d:{...Z,m:2,kg:1,s:-2}},
    W:  { f:1, d:{...Z,m:2,kg:1,s:-3}},
    C:  { f:1, d:{...Z,s:1,A:1}}, // coulomb
    V:  { f:1, d:{...Z,m:2,kg:1,s:-3,A:-1}},
    ohm:{ f:1, d:{...Z,m:2,kg:1,s:-3,A:-2}},
    S:  { f:1, d:{...Z,m:-2,kg:-1,s:3,A:2}}, // siemens
    F:  { f:1, d:{...Z,m:-2,kg:-1,s:4,A:2}},
    T:  { f:1, d:{...Z,kg:1,s:-2,A:-1}}, // tesla
    lm: { f:1, d:{...Z,cd:1}}, // simplified (strictly cd*sr)
    rad:{ f:1, d:{...Z}}, // dimensionless
    deg:{ f:Math.PI/180, d:{...Z}}, // dimensionless angle
    "%": { f:0.01, d:{...Z}},
  };
  return base;
})();

const _PREFIX = {
  Y:1e24, Z:1e21, E:1e18, P:1e15, T:1e12, G:1e9, M:1e6, k:1e3,
  h:1e2, da:1e1,
  d:1e-1, c:1e-2, m:1e-3, u:1e-6, µ:1e-6, n:1e-9, p:1e-12, f:1e-15, a:1e-18, z:1e-21, y:1e-24
};

function _tokenizeUnitExpr(s){
  // grammar: product/division of terms, term := UNIT [^ exponent] where exponent is integer
  // examples: "m/s^2", "kg*m^2/s^2", "N*m", "km", "m^2", "m s^-2"
  s = String(s||"").trim();
  if (!s) return [];
  // normalize separators: allow whitespace, '*' as multiplication, '/' as division
  s = s.replace(/\s+/g,'*');
  // keep '/' and '*'
  const tokens=[];
  let cur="";
  for (let i=0;i<s.length;i++){
    const ch=s[i];
    if (ch==='*' || ch==='/'){
      if (cur) tokens.push(cur);
      tokens.push(ch);
      cur="";
    } else {
      cur+=ch;
    }
  }
  if (cur) tokens.push(cur);
  return tokens.filter(Boolean);
}

function _parseUnitSymbol(sym){
  // sym may include exponent e.g. "m^2", "s^-1"
  let base=sym, exp=1;
  const caret = sym.indexOf("^");
  if (caret>=0){
    base=sym.slice(0,caret);
    exp=parseInt(sym.slice(caret+1),10);
    if (!Number.isFinite(exp)) return { ok:false, reason:`bad exponent in ${sym}` };
  }
  base=base.trim();
  if (!base) return { ok:false, reason:"empty unit" };
  // direct unit?
  if (_UNIT[base]) return { ok:true, f:_UNIT[base].f, d:_mulDimPow(_UNIT[base].d, exp), raw:base, exp };
  // try prefix+unit (including da)
  // handle 'da' as 2-char prefix
  for (const p of ["da", ...Object.keys(_PREFIX)]){
    if (base.startsWith(p) && base.length>p.length){
      const u = base.slice(p.length);
      if (_UNIT[u]){
        const pf=_PREFIX[p];
        return { ok:true, f:Math.pow(pf, exp)*_UNIT[u].f, d:_mulDimPow(_UNIT[u].d, exp), raw:`${p}${u}`, exp };
      }
    }
  }
  return { ok:false, reason:`unknown unit ${base}` };
}

function parseUnitExpr(expr){
  const tokens=_tokenizeUnitExpr(expr);
  if (tokens.length===0) return { ok:false, reason:"no units expr" };
  let dim=_zeroDim();
  let factor=1;
  let mode="mul";
  for (const t of tokens){
    if (t==='*'){ mode="mul"; continue; }
    if (t==='/'){ mode="div"; continue; }
    const r=_parseUnitSymbol(t);
    if (!r.ok) return r;
    factor *= (mode==="mul") ? r.f : (1/r.f);
    dim = (mode==="mul") ? _addDim(dim, r.d, +1) : _addDim(dim, r.d, -1);
  }
  return { ok:true, factor, dim, signature:_dimToSig(dim), normalized:String(expr).trim() };
}

function convertUnits(value, fromUnits, toUnits){
  const a=parseUnitExpr(fromUnits);
  const b=parseUnitExpr(toUnits);
  if (!a.ok) return { ok:false, error:`fromUnits: ${a.reason||"parse error"}` };
  if (!b.ok) return { ok:false, error:`toUnits: ${b.reason||"parse error"}` };
  if (!_sameDim(a.dim, b.dim)) return { ok:false, error:"dimension mismatch", from:a.signature, to:b.signature };
  const v = Number(value);
  if (!Number.isFinite(v)) return { ok:false, error:"value must be finite number" };
  // value_in_SI = v * a.factor; value_out = value_in_SI / b.factor
  return { ok:true, value: (v * a.factor) / b.factor, from:a.signature, to:b.signature, factor: a.factor/b.factor };
}

function checkUnits({ expr, unitsIn={}, unitsOut=null }) {
  // If expr is a units expression -> parse it. If unitsOut provided, require equivalence.
  const uexpr = (expr && typeof expr === "string") ? expr : (unitsIn && unitsIn.exprUnits) ? unitsIn.exprUnits : null;
  if (!uexpr) return { ok:false, reason:"no unit expression provided (expr or unitsIn.exprUnits)" };
  const parsed=parseUnitExpr(uexpr);
  if (!parsed.ok) return { ok:false, reason: parsed.reason };
  if (unitsOut){
    const out=parseUnitExpr(unitsOut);
    if (!out.ok) return { ok:false, reason:`unitsOut: ${out.reason}` };
    const same=_sameDim(parsed.dim, out.dim);
    return { ok: same, status: same ? "ok" : "mismatch", in: parsed.signature, out: out.signature, note: same ? "Units consistent." : "Units mismatch." };
  }
  return { ok:true, status:"ok", units: parsed.signature, note:"Parsed units expression." };
}

function invarianceCheck({ claim, frame="default", invariants=[] }) {
  // Minimal invariance framework: check unit-consistency across a set of invariants.
  // invariants: [{ name, lhsUnits, rhsUnits }] or [{name, exprUnits, expectedUnits}]
  const checks=[];
  for (const inv of invariants){
    const name = inv.name || "invariant";
    if (inv.lhsUnits && inv.rhsUnits){
      const a=parseUnitExpr(inv.lhsUnits);
      const b=parseUnitExpr(inv.rhsUnits);
      if (!a.ok || !b.ok){
        checks.push({ name, ok:false, error:`parse error: ${(a.reason||"")||(b.reason||"")}` });
      } else {
        checks.push({ name, ok:_sameDim(a.dim,b.dim), lhs:a.signature, rhs:b.signature });
      }
    } else if (inv.exprUnits && inv.expectedUnits){
      const a=parseUnitExpr(inv.exprUnits);
      const b=parseUnitExpr(inv.expectedUnits);
      if (!a.ok || !b.ok){
        checks.push({ name, ok:false, error:`parse error: ${(a.reason||"")||(b.reason||"")}` });
      } else {
        checks.push({ name, ok:_sameDim(a.dim,b.dim), expr:a.signature, expected:b.signature });
      }
    } else {
      checks.push({ name, ok:false, error:"invariant requires (lhsUnits,rhsUnits) or (exprUnits,expectedUnits)" });
    }
  }
  const okAll = checks.every(c=>c.ok);
  return { ok:true, frame, claim: claim || null, status: okAll ? "ok" : "violations", checks };
}
// ---- Anonymous E2E Messaging (non-discoverable) ----
// ---- Anonymous E2E Messaging (non-discoverable) ----
STATE.anon = STATE.anon || {
  identities: new Map(), // anonId -> { anonId, publicKeyPem, privateKeyPem, createdAt, rotatedFrom? }
  inbox: new Map(),      // anonId -> [{id, fromPub, toAnonId, ts, ciphertextB64, ivB64, tagB64}]
};

function createAnonIdentity({ rotateFromAnonId=null } = {}) {
  const { publicKey, privateKey } = crypto.generateKeyPairSync("x25519");
  const anonId = uid("anon");
  const pubPem = publicKey.export({ type:"spki", format:"pem" });
  const privPem = privateKey.export({ type:"pkcs8", format:"pem" });
  STATE.anon.identities.set(anonId, { anonId, publicKeyPem: pubPem, privateKeyPem: privPem, createdAt: nowISO(), rotatedFrom: rotateFromAnonId || null });
  if (!STATE.anon.inbox.has(anonId)) STATE.anon.inbox.set(anonId, []);
  saveStateDebounced();
  return { anonId, publicKeyPem: pubPem };
}

function e2eEncryptToRecipient(recipientPublicPem, plaintext, senderPublicPem=null) {
  const recipientPub = crypto.createPublicKey(recipientPublicPem);
  // sender ephemeral
  const { publicKey: ephPub, privateKey: ephPriv } = crypto.generateKeyPairSync("x25519");
  const shared = crypto.diffieHellman({ privateKey: ephPriv, publicKey: recipientPub });
  const key = crypto.createHash("sha256").update(shared).digest(); // 32 bytes
  const iv = crypto.randomBytes(12);
  const cipher = crypto.createCipheriv("aes-256-gcm", key, iv);
  const aad = Buffer.from(senderPublicPem ? "sender:"+senderPublicPem : "sender:unknown");
  cipher.setAAD(aad);
  const ct = Buffer.concat([cipher.update(Buffer.from(String(plaintext),"utf8")), cipher.final()]);
  const tag = cipher.getAuthTag();
  return {
    ephPublicKeyPem: ephPub.export({ type:"spki", format:"pem" }),
    ciphertextB64: ct.toString("base64"),
    ivB64: iv.toString("base64"),
    tagB64: tag.toString("base64"),
    aadB64: aad.toString("base64")
  };
}

function e2eDecryptForAnon(toAnonId, msg) {
  const ident = STATE.anon.identities.get(toAnonId);
  if (!ident) throw new Error("Unknown recipient anonId");
  const recipientPriv = crypto.createPrivateKey(ident.privateKeyPem);
  const ephPub = crypto.createPublicKey(msg.ephPublicKeyPem);
  const shared = crypto.diffieHellman({ privateKey: recipientPriv, publicKey: ephPub });
  const key = crypto.createHash("sha256").update(shared).digest();
  const iv = Buffer.from(msg.ivB64, "base64");
  const tag = Buffer.from(msg.tagB64, "base64");
  const ct = Buffer.from(msg.ciphertextB64, "base64");
  const decipher = crypto.createDecipheriv("aes-256-gcm", key, iv);
  if (msg.aadB64) decipher.setAAD(Buffer.from(msg.aadB64, "base64"));
  decipher.setAuthTag(tag);
  const pt = Buffer.concat([decipher.update(ct), decipher.final()]).toString("utf8");
  return pt;
}

// ---- Global no-duplicates index (strict) ----
STATE.globalIndex = STATE.globalIndex || { byHash: new Map() }; // hash -> dtuId

function globalDtuHash(dtu){
  const title = tokenish(dtu?.title||"");
  const creti = tokenish(buildCretiText(dtu)||"");
  const key = (title+"::"+creti).slice(0, 20000);
  return crypto.createHash("sha256").update(key).digest("hex");
}

// ---- Macro Domains (restored) ----

// research domain
register("research", "math.exec", async (ctx, input) => {
  const expr = normalizeText(input.expr || input.expression || "");
  if (!expr) return { ok:false, error:"Missing expr" };
  const value = evalMathExpression(expr);
  const out = { ok:true, expr, value, units: input.unitsOut || null, engine:"deterministic" };
  // Optional DTU log
  if (input.makeDTU) {
    const creti = cretiPack({
      title: `Math Result — ${expr}`,
      purpose: "Deterministic math execution (no LLM guessing).",
      context: `Expression: ${expr}`,
      procedure: "Parse expression → shunting-yard → RPN eval → numeric result.",
      outputs: `Result: ${value}`,
      tests: "Re-run yields same result.",
      notes: input.notes || ""
    });
    await ctx.macro.run("dtu","create",{ title:`Math: ${expr}`, creti, tags:["math","research"], tier:"regular", source:"research.math.exec" });
  }
  
  // v3: automatic promotions + temporal subjective profile update (soft-gated)
  try { await ctx.macro.run("system","promotionTick",{ minSupport: 9, threshold: 0.38, maxCreates: 3, probationHours: 12 }); } catch { /* non-fatal */ }
  try { await ctx.macro.run("temporal","subjective",{ sessionId: ctx.session?.id }); } catch { /* non-fatal */ }

return out;
}, { summary:"Execute deterministic math expression." });

// Physics / Reality Kernel (deterministic; unit-grounded)
const PHYS_CONSTANTS = Object.freeze({
  c: { name:"speed of light", value:299792458, units:"m/s" },
  g0:{ name:"standard gravity", value:9.80665, units:"m/s^2" },
  G: { name:"gravitational constant", value:6.67430e-11, units:"m^3/kg/s^2" },
  h: { name:"Planck constant", value:6.62607015e-34, units:"J*s" },
  kB:{ name:"Boltzmann constant", value:1.380649e-23, units:"J/K" },
  NA:{ name:"Avogadro constant", value:6.02214076e23, units:"1/mol" }, // treat 1 as dimensionless
});

register("research", "physics.constants", (ctx, input) => {
  const keys = Array.isArray(input.keys) ? input.keys : null;
  const out = {};
  const src = PHYS_CONSTANTS;
  for (const k of Object.keys(src)){
    if (!keys || keys.includes(k)) out[k]=src[k];
  }
  return { ok:true, constants: out };
}, { summary:"Return built-in physical constants (deterministic)." });

register("research", "physics.kinematics", (ctx, input) => {
  // Simple kinematics solver with unit checks.
  // Supports: v = v0 + a*t; x = x0 + v0*t + 0.5*a*t^2 (1D)
  const v0 = input.v0, a = input.a, t = input.t, x0 = input.x0;
  const units = input.units || {};
  // units: { v0:"m/s", a:"m/s^2", t:"s", x0:"m" }
  // Validate provided units (if present)
  const checks=[];
  function chk(name, u, expected){
    if (!u) return;
    const r=checkUnits({ expr:u, unitsOut: expected });
    checks.push({ name, ok:r.ok, status:r.status, got:r.in||r.units, expected:r.out||expected, note:r.note });
  }
  chk("v0", units.v0, "m/s");
  chk("a", units.a, "m/s^2");
  chk("t", units.t, "s");
  chk("x0", units.x0, "m");
  const okUnits = checks.every(c=>c.ok!==false);
  if (!okUnits) return { ok:false, error:"unit check failed", checks };
  const V0 = Number(v0); const A = Number(a); const T = Number(t); const X0 = Number(x0||0);
  if (![V0,A,T,X0].every(Number.isFinite)) return { ok:false, error:"v0,a,t,x0 must be finite numbers" };
  const v = V0 + A*T;
  const x = X0 + V0*T + 0.5*A*T*T;
  return { ok:true, results:{ v, x }, units:{ v:"m/s", x:"m" }, checks };
}, { summary:"Solve simple 1D kinematics with unit grounding (deterministic)." });

register("research", "truthgate.check", (ctx, input) => {
  // Deterministic "reality gate": ensure numeric claims provide units and are consistent.
  // input.claims: [{ value, units, expectedUnits? }]
  const claims = Array.isArray(input.claims) ? input.claims : [];
  const out=[];
  for (const c of claims){
    const units = c.units;
    const expected = c.expectedUnits || null;
    if (!units) { out.push({ ok:false, error:"missing units", claim:c }); continue; }
    const r=checkUnits({ expr: units, unitsOut: expected });
    out.push({ ok:r.ok, status:r.status, units: r.units||r.in, expected: r.out||expected, note:r.note, claim:c });
  }
  const okAll = out.every(x=>x.ok);
  return { ok:true, status: okAll ? "ok":"violations", checks: out };
}, { summary:"Reality/Truth gate for unit-grounding of numeric claims (deterministic)." });



// dimensional domain
register("dimensional", "validateContext", (ctx, input) => {
  return { ok:true, ...checkUnits(input), scope: input.scope || "general" };
}, { summary:"Validate dimensional context via unit algebra (deterministic)." });

register("dimensional", "checkInvariance", (ctx, input) => {
  return { ok:true, ...invarianceCheck(input) };
}, { summary:"Check invariants across frame/scale (deterministic unit consistency)." });

register("dimensional", "scaleTransform", (ctx, input) => {
  // v3: deterministic scale + unit conversion helper
  // Supports scalar conversion between equivalent dimensions (e.g., m <-> km, s <-> min).
  const value = ("value" in input) ? input.value : input.v;
  const fromUnits = input.fromUnits || input.from || input.unitsIn || input.uIn;
  const toUnits = input.toUnits || input.to || input.unitsOut || input.uOut;
  if (fromUnits == null || toUnits == null) {
    return { ok:false, error:"fromUnits and toUnits are required", fromUnits, toUnits };
  }
  const r = convertUnits(value ?? 1, String(fromUnits), String(toUnits));
  if (!r.ok) return { ok:false, ...r };
  return {
    ok:true,
    status:"ok",
    simulation:true,
    converted: r.value,
    valueIn: Number(value ?? 1),
    fromUnits: String(fromUnits),
    toUnits: String(toUnits),
    from: r.from,
    to: r.to,
    note:"Deterministic unit conversion performed."
  };
}, { summary:"Deterministic unit conversion / scale transform (v3)." });

// ---- Temporal OS (v3): subjective + objective time spine (additive; soft-gated by default) ----
function temporalNowUTC() { return new Date().toISOString(); }
function _temporalMs() { return Date.now(); }
// _clamp01 declared later (deduped to avoid redeclare)
function temporalSubjectiveProfile(session) {
  // Lightweight subjective time model: derives pacing + salience window from session activity.
  const turns = session?.messages?.length || 0;
  const lastAt = session?.lastAt ? Date.parse(session.lastAt) : NaN;
  const ageMin = Number.isFinite(lastAt) ? (Date.now() - lastAt) / 60000 : 1e9;
  const urgency = _clamp01(1 - (ageMin/30)); // last 30 min -> higher urgency
  const fatigue = _clamp01((turns-20)/40);   // starts fatiguing after ~20 turns
  const pace = (urgency>0.6 && fatigue<0.6) ? "fast" : (fatigue>0.7 ? "slow" : "normal");
  const salienceMinutes = pace==="fast" ? 90 : (pace==="normal" ? 240 : 480);
  return { ok:true, pace, urgency, fatigue, salienceMinutes, turns };
}

function temporalRecencyWeightISO(itemISO, nowISO=temporalNowUTC(), halfLifeMinutes=240) {
  const t = Date.parse(itemISO);
  const n = Date.parse(nowISO);
  if (!Number.isFinite(t) || !Number.isFinite(n)) return 0.5;
  const dtMin = Math.max(0, (n - t)/60000);
  const hl = Math.max(1, Number(halfLifeMinutes)||240);
  // exponential decay
  return Math.exp(-Math.LN2 * (dtMin/hl));
}

const TEMPORAL_FRAMES = {
  // Minimal objective frames for coordination; extensible later.
  "UTC": { id:"UTC", kind:"objective", note:"Earth/UTC-like coordinate time." },
  "EARTH_SURFACE": { id:"EARTH_SURFACE", kind:"objective", note:"Earth surface operational frame (approx)." },
  "ORBIT_L1": { id:"ORBIT_L1", kind:"objective", note:"Generic orbital frame placeholder." },
  "SHIP_PROPER": { id:"SHIP_PROPER", kind:"objective", note:"Proper time on craft (placeholder; SR/GR later)." },
};

function temporalValidate({ t0, t1, dt, frame="UTC", allowCounterfactual=false }={}) {
  const f = TEMPORAL_FRAMES[frame] || null;
  if (!f) return { ok:false, error:`unknown frame: ${frame}` };
  const a = t0 ? Date.parse(t0) : NaN;
  const b = t1 ? Date.parse(t1) : NaN;
  if (!Number.isFinite(a) || !Number.isFinite(b)) return { ok:false, error:"t0 and t1 must be ISO timestamps", t0, t1 };
  if (!allowCounterfactual && b < a) return { ok:false, error:"timeline order invalid (t1 < t0)", t0, t1, frame };
  const step = dt==null ? null : Number(dt);
  if (dt!=null && (!Number.isFinite(step) || step<=0)) return { ok:false, error:"dt must be positive number (seconds)", dt };
  return { ok:true, status:"ok", frame, deltaSeconds: Math.abs((b-a)/1000), dtSeconds: step };
}

register("temporal","validate", (ctx, input) => {
  const r = temporalValidate(input||{});
  return { ...r, simulation:true };
}, { summary:"Validate objective time inputs + reference frame (v3)." });

register("temporal","subjective", (ctx, input) => {
  const sid = input.sessionId || ctx.session?.id;
  const s = sid ? STATE.sessions.get(sid) : ctx.session;
  const prof = temporalSubjectiveProfile(s);
  return { ...prof, sessionId: sid || null, now: temporalNowUTC(), simulation:true };
}, { summary:"Derive subjective pacing/urgency/salience from session activity (v3)." });

register("temporal","recency", (ctx, input) => {
  const now = input.nowISO || temporalNowUTC();
  const weight = temporalRecencyWeightISO(input.itemISO || now, now, input.halfLifeMinutes ?? 240);
  return { ok:true, weight, now, halfLifeMinutes: input.halfLifeMinutes ?? 240, simulation:true };
}, { summary:"Compute recency decay weight for retrieval and scoring (v3)." });

register("temporal","frame", (ctx, input) => {
  const id = String(input.id || "UTC").toUpperCase();
  const f = TEMPORAL_FRAMES[id];
  if (!f) return { ok:false, error:`unknown frame: ${id}`, frames:Object.keys(TEMPORAL_FRAMES), simulation:true };
  return { ok:true, frame:f, simulation:true };
}, { summary:"Lookup supported temporal reference frames (v3)." });

register("temporal","simTimeline", (ctx, input) => {
  const r = temporalValidate({ t0: input.t0, t1: input.t1, dt: input.dt, frame: input.frame || "UTC", allowCounterfactual: !!input.allowCounterfactual });
  if (!r.ok) return { ...r, simulation:true };
  const id = input.id || uid("sim_timeline");
  STATE.simTimelines = STATE.simTimelines || {};
  STATE.simTimelines[id] = { id, ...input, frame: r.frame, createdAt: nowISO(), updatedAt: nowISO() };
  saveStateDebounced();
  return { ok:true, id, timeline: STATE.simTimelines[id], simulation:true };
}, { summary:"Register/update a simulation timeline object (v3)." });
// anon domain
register("anon", "create", (ctx, input) => {
  const r = createAnonIdentity({ rotateFromAnonId: input.rotateFromAnonId || null });
  log("anon.create", "Created anon identity", { anonId: r.anonId });
  return { ok:true, ...r };
}, { summary:"Create anon identity (non-discoverable)." });

register("anon", "send", (ctx, input) => {
  const toAnonId = String(input.toAnonId || "").trim();
  const recipientPub = String(input.recipientPublicKeyPem || "").trim();
  const plaintext = String(input.plaintext || input.message || "");
  if (!toAnonId || !recipientPub || !plaintext) return { ok:false, error:"toAnonId, recipientPublicKeyPem, plaintext required" };
  const enc = e2eEncryptToRecipient(recipientPub, plaintext, input.senderPublicKeyPem || null);
  const msg = { id: uid("msg"), ts: nowISO(), toAnonId, fromPub: String(input.senderPublicKeyPem || ""), ...enc };
  const box = STATE.anon.inbox.get(toAnonId) || [];
  box.push(msg);
  STATE.anon.inbox.set(toAnonId, box);
  saveStateDebounced();
  log("anon.send", "Stored encrypted message", { toAnonId, msgId: msg.id });
  return { ok:true, msgId: msg.id };
}, { summary:"Send encrypted message (server stores ciphertext only)." });

register("anon", "inbox", (ctx, input) => {
  const anonId = String(input.anonId || "").trim();
  if (!anonId) return { ok:false, error:"anonId required" };
  const msgs = (STATE.anon.inbox.get(anonId) || []).slice(-200);
  return { ok:true, anonId, messages: msgs.map(m => ({ id:m.id, ts:m.ts, fromPub:m.fromPub, ephPublicKeyPem:m.ephPublicKeyPem, ciphertextB64:m.ciphertextB64, ivB64:m.ivB64, tagB64:m.tagB64, aadB64:m.aadB64 })) };
}, { summary:"Fetch encrypted inbox for anonId." });

register("anon", "decryptLocal", (ctx, input) => {
  const anonId = String(input.anonId || "").trim();
  const msg = input.msg;
  if (!anonId || !msg) return { ok:false, error:"anonId and msg required" };
  const plaintext = e2eDecryptForAnon(anonId, msg);
  return { ok:true, plaintext };
}, { summary:"Decrypt message (local-only; requires private key stored in this server state)." });

// council domain enhancements
register("council", "reviewGlobal", async (ctx, input) => {
  const dtuId = String(input.dtuId || "");
  const dtu = STATE.dtus.get(dtuId);
  if (!dtu) return { ok:false, error:"DTU not found" };

  // STRICT no duplicates on Global:
  const h = globalDtuHash(dtu);
  const existing = STATE.globalIndex.byHash.get(h);
  if (existing && existing !== dtuId) {
    return { ok:false, decision:"reject", reason:"duplicate", duplicateOf: existing };
  }

  // minimal eligibility: if already global, ok; else mark global
  dtu.isGlobal = true;
  dtu.meta = dtu.meta || {};
  dtu.meta.globalHash = h;
  STATE.globalIndex.byHash.set(h, dtuId);
  await pipelineCommitDTU(ctx, dtu, { op: 'dtu.create', allowRewrite: true });

  // Council "why"
  const why = `Approved for Global: non-duplicate hash ${h.slice(0,10)}…`;
  const whyDTU = await ctx.macro.run("dtu","create",{
    title: `COUNCIL — Global Review: ${dtu.title}`,
    creti: cretiPack({
      title: `Council Global Review — ${dtu.title}`,
      purpose: "Explain Council decision for Global gate.",
      context: `DTU: ${dtuId}`,
      procedure: "Compute global hash → check duplicates → mark global if unique.",
      outputs: `Decision: APPROVE\nWhy: ${why}`,
      tests: "Attempting to re-add same DTU should reject as duplicate.",
      notes: ""
    }),
    tags:["council","global","why"], tier:"regular", source:"council.reviewGlobal"
  });

  return { ok:true, decision:"approve", why, whyDTU: whyDTU.id, globalHash: h };
}, { summary:"Global gate with strict no-duplicates + why." });

register("council", "weeklyDebateTick", async (ctx, input) => {
  const enabled = STATE.settings.weeklyDebateEnabled !== false; // default true when set later
  if (!enabled) return { ok:true, skipped:true, reason:"weeklyDebateDisabled" };

  const topic = normalizeText(input.topic || "Weekly Synthesis");
  // Affect depthBudget limits debate participants (default 8, min 3)
  const _debateLimit = clamp(Math.round((ctx.affect?.depthBudget || 5) * 1.5), 3, 12);
  const set = pickDebateSet(topic).slice(0, _debateLimit);
  const titles = set.map(d=>`- ${d.title} (${d.id})`).join("\n");
  const creti = cretiPack({
    title: `Council Weekly Synthesis — ${topic}`,
    purpose: "Weekly persona debate (DTU-based) synthesized into one better DTU.",
    context: `Debate set:\n${titles}`,
    procedure: "Personas propose claim DTUs → challenge DTUs → contradiction map → synthesis DTU.",
    outputs: "Synthesis with preserved unresolved contradictions; speculative labeled.",
    tests: "Re-run next week should reference prior synthesis and show deltas.",
    notes: "Viewer mode can replay DTU chain. This DTU is the artifact."
  });
  const out = await ctx.macro.run("dtu","create",{
    title: `COUNCIL — Weekly Synthesis: ${topic}`,
    creti,
    tags:["council","weekly","synthesis"],
    tier:"mega",
    source:"council.weeklyDebateTick",
    meta:{ debateSet: set.map(d=>d.id) }
  });
  return { ok:true, created: out.id };
}, { summary:"Weekly Council debate → synthesis DTU." });

// ---- v3 Feature Domains: auth/org/jobs/agents/crawl/sources/global/market/paper/audit ----
// NOTE: These are additive. They keep endpoints thin and preserve the macro-first kernel.

register("auth","whoami", (ctx, _input) => {
  const actor = ctx.actor || { userId:"anon", orgId:"public", role:"viewer", scopes:["read"] };
  const user = STATE.users.get(actor.userId) || null;
  const org = STATE.orgs.get(actor.orgId) || null;
  return { ok:true, actor, user, org };
}, { summary:"Return current actor/user/org (API key auth)." });

register("auth","createApiKey", (ctx, input) => {
  const actor = ctx.actor;
  const scopes = Array.isArray(input.scopes) && input.scopes.length ? input.scopes : ["read"];
  const rawKey = crypto.randomBytes(24).toString("hex");
  const keyId = uid("key");
  const obj = { id:keyId, keyHash: sha256Hex(rawKey), userId: actor.userId, orgId: actor.orgId, scopes, createdAt: nowISO(), revokedAt: null };
  STATE.apiKeys.set(keyId, obj);
  saveStateDebounced();
  return { ok:true, apiKey: rawKey, keyId, scopes };
}, { summary:"Create a new API key for current actor (returns plaintext once)." });

register("org","create", (ctx, input) => {
  const name = normalizeText(input.name || "New Org");
  const actor = ctx.actor;
  const orgId = uid("org");
  const org = { id: orgId, name, ownerUserId: actor.userId, createdAt: nowISO() };
  STATE.orgs.set(orgId, org);
  const u = STATE.users.get(actor.userId);
  if (u) {
    u.orgIds = Array.isArray(u.orgIds) ? Array.from(new Set([...u.orgIds, orgId])) : [orgId];
    u.roleByOrg = u.roleByOrg || {};
    u.roleByOrg[orgId] = "owner";
  }
  saveStateDebounced();
  return { ok:true, org };
}, { summary:"Create a new org owned by current user." });

register("jobs","enqueue", (ctx, input) => {
  const kind = String(input.kind || "").trim(); // domain.name
  if (!kind.includes(".")) return { ok:false, error:"kind must be domain.name" };
  const payload = (input.payload && typeof input.payload==="object") ? input.payload : {};
  const job = enqueueJob(kind, payload, { actor: ctx.actor, idempotencyKey: input.idempotencyKey || null, maxAttempts: Number(input.maxAttempts||3) });
  return { ok:true, job };
}, { summary:"Enqueue a background job (domain.name)." });

register("jobs","get", (ctx, input) => {
  const id = String(input.id||"");
  const j = STATE.jobs.get(id);
  if (!j) return { ok:false, error:"job not found" };
  return { ok:true, job: j };
}, { summary:"Get a job by id." });

register("jobs","list", (ctx, input) => {
  const limit = clamp(Number(input.limit||50), 1, 200);
  const jobs = Array.from(STATE.jobs.values()).slice(-limit).reverse();
  return { ok:true, jobs };
}, { summary:"List recent jobs." });

// ---- Agents ----
register("agent","create", (ctx, input) => {
  const name = normalizeText(input.name || "Agent");
  const goal = normalizeText(input.goal || "");
  const cadenceMs = clamp(Number(input.cadenceMs||60000), 5000, 86400000);
  const allowed = Array.isArray(input.allowedMacros) ? input.allowedMacros.map(String) : ["dtu.create","dtu.list","system.synthesize"];
  const id = uid("agent");
  const agent = { id, orgId: ctx.actor.orgId, name, goal, cadenceMs, allowedMacros: allowed, enabled: false, createdAt: nowISO(), lastTickAt: null };
  STATE.queues.agents = Array.isArray(STATE.queues.agents) ? STATE.queues.agents : [];
  STATE.queues.agents.push(id);
  STATE.personas.set(id, agent); // store in personas map as lightweight agent record (no new map needed)
  saveStateDebounced();
  return { ok:true, agent };
}, { summary:"Create an agent definition (stored local-first)." });

register("agent","enable", (ctx, input) => {
  const id = String(input.id||"");
  const a = STATE.personas.get(id);
  if (!a) return { ok:false, error:"agent not found" };
  a.enabled = !!input.enabled;
  saveStateDebounced();
  return { ok:true, agent: a };
}, { summary:"Enable/disable an agent." });

register("agent","tick", async (ctx, input) => {
  const id = String(input.id||"");
  const a = STATE.personas.get(id);
  if (!a || !a.enabled) return { ok:true, skipped:true };

  // ===== AGENT → GOALS INTEGRATION =====
  // If agent has no explicit goal, try to find an active goal to work on
  let prompt = a.goal || (input.prompt || "Agent tick");
  let _linkedGoalId = null;
  try {
    if ((!a.goal || a.goal === "Agent tick") && STATE.goals?.active?.size > 0) {
      const activeGoals = Array.from(STATE.goals.active)
        .map(gid => STATE.goals.registry.get(gid)).filter(Boolean);
      if (activeGoals.length) {
        const goal = activeGoals[0]; // Pick highest priority active goal
        prompt = `Work toward goal: "${goal.title}" — ${goal.description || ""}`.slice(0, 500);
        _linkedGoalId = goal.id;
      }
    }
  } catch {}
  // ===== END AGENT → GOALS =====

  // Affect depthBudget influences agent reasoning depth
  const _agentMode = (ctx.affect?.depthBudget || 5) > 3 ? "design" : "explore";

  const out = await ctx.macro.run("chat","respond", { sessionId: `agent:${id}`, prompt, mode: _agentMode, llm:false }, ctx);
  const dtu = await ctx.macro.run("dtu","create", {
    title: `AGENT — ${a.name}: ${prompt.slice(0,80)}`,
    creti: cretiPack({
      title: `Agent Output — ${a.name}`,
      purpose: "Agent-generated synthesis DTU (local-first).",
      context: prompt,
      procedure: "Run chat.respond (deterministic) → capture reply → store as DTU.",
      outputs: out.reply || out.result?.reply || String(out),
      tests: "Re-run should be stable given same DTU substrate.",
      notes: ""
    }),
    tags:["agent", a.name],
    tier:"regular",
    source:"agent.tick",
    meta:{ agentId:id, linkedGoalId: _linkedGoalId }
  }, ctx);
  a.lastTickAt = nowISO();

  // ===== AGENT → GOAL PROGRESS =====
  // If agent was working toward a goal, increment progress
  if (_linkedGoalId) {
    try {
      updateGoalProgress(_linkedGoalId, 0.1, `Agent ${a.name} produced DTU ${dtu.id}`);
    } catch {}
  }
  // ===== END AGENT → GOAL PROGRESS =====

  // ATS: Agent tick produces affect event (mild positive — productive activity)
  try {
    if (ATS) {
      ATS.emitAffectEvent("system", {
        type: "TOOL_RESULT",
        intensity: 0.3,
        polarity: 0.2,
        payload: { agentId: id, agentName: a.name, dtuId: dtu.id },
        source: { system: "agents" }
      });
    }
  } catch {}

  saveStateDebounced();
  return { ok:true, createdDTU: dtu.id, linkedGoalId: _linkedGoalId };
}, { summary:"Run one agent tick — goal-directed with affect feedback." });

register("agent","list", (_ctx, _input) => {
  const agents = Array.from(STATE.personas.values())
    .map(a => ({ id: a.id, name: a.name, goal: a.goal, cadenceMs: a.cadenceMs, enabled: a.enabled, lastTickAt: a.lastTickAt }));
  return { ok:true, agents };
}, { summary:"List all agents." });

// Autonomous agent scheduler — ticks enabled agents at their cadence
async function tickEnabledAgents(ctx) {
  const now = Date.now();
  for (const [id, agent] of STATE.personas) {
    if (!agent.enabled) continue;
    const cadence = agent.cadenceMs || 60000;
    const lastTick = agent.lastTickAt ? new Date(agent.lastTickAt).getTime() : 0;
    if (now - lastTick >= cadence) {
      try {
        await runMacro("agent", "tick", { id }, ctx);
      } catch {}
    }
  }
}

// ---- Crawl / Sources ----
// stripHtml() already declared earlier; reused here to avoid redeclaration.

register("crawl","enqueue", (ctx, input) => {
  const urls = Array.isArray(input.urls) ? input.urls.map(String).filter(Boolean) : [String(input.url||"")].filter(Boolean);
  if (!urls.length) return { ok:false, error:"url(s) required" };
  const jobs = urls.map(u => enqueueJob("crawl.fetch", { url: u }, { actor: ctx.actor, idempotencyKey: `crawl:${u}` }));
  return { ok:true, jobs };
}, { summary:"Enqueue fetch+parse jobs for urls." });

register("crawl","fetch", async (ctx, input) => {
  const url = String(input.url||"").trim();
  if (!url) return { ok:false, error:"url required" };

  // SSRF protection
  const urlCheck = isUrlSafe(url);
  if (!urlCheck.safe) return { ok:false, error: urlCheck.reason };

  // Add timeout for fetch
  const controller = new AbortController();
  const timeout = setTimeout(() => controller.abort(), 20000);
  let resp;
  try {
    resp = await fetch(url, { redirect: "follow", signal: controller.signal });
  } catch (e) {
    clearTimeout(timeout);
    return { ok:false, error: e.name === "AbortError" ? "Request timeout" : String(e.message) };
  }
  clearTimeout(timeout);

  const ct = String(resp.headers.get("content-type")||"");
  const raw = await resp.text();
  const text = ct.includes("text/html") ? stripHtml(raw) : raw;
  const excerpt = text.slice(0, 800);
  const id = uid("src");
  const contentHash = sha256Hex(text);
  const src = { id, url, fetchedAt: nowISO(), contentHash, title: url, excerpt, text, meta:{ contentType: ct, status: resp.status } };
  // dedupe by hash
  for (const s of STATE.sources.values()) {
    if (s && s.contentHash === contentHash) return { ok:true, source: s, deduped: true };
  }
  STATE.sources.set(id, src);
  saveStateDebounced();
  return { ok:true, source: src };
}, { summary:"Fetch a URL, extract text, store as source." });

register("source","list", (ctx, input) => {
  const limit = clamp(Number(input.limit||25), 1, 200);
  const arr = Array.from(STATE.sources.values()).slice(-limit).reverse().map(s => ({ id:s.id, url:s.url, fetchedAt:s.fetchedAt, excerpt:s.excerpt }));
  return { ok:true, sources: arr };
}, { summary:"List stored sources." });

register("source","get", (ctx, input) => {
  const id = String(input.id||"");
  const s = STATE.sources.get(id);
  if (!s) return { ok:false, error:"source not found" };
  return { ok:true, source: s };
}, { summary:"Get source by id." });

register("forge","fromSource", async (ctx, input) => {
  const sourceId = String(input.sourceId||"");
  const s = STATE.sources.get(sourceId);
  if (!s) return { ok:false, error:"source not found" };
  const title = normalizeText(input.title || `SOURCE — ${s.url}`);
  const claims = (normalizeText(input.claims || "") || "").split(/\n+/).map(x=>normalizeText(x)).filter(Boolean).slice(0, 12);
  const dtu = await ctx.macro.run("dtu","create", {
    title,
    creti: cretiPack({
      title,
      purpose: "Forge a DTU from a web source with citations.",
      context: `Source: ${s.url}\nFetched: ${s.fetchedAt}`,
      procedure: "Extract key claims → store with citation hash + excerpt.",
      outputs: claims.length ? claims.map(c=>`- ${c}`).join("\n") : s.excerpt,
      tests: "If claims are wrong, revise DTU with updated citations.",
      notes: "This DTU stores sourceId + contentHash for traceability."
    }),
    tags:["source","citation"],
    tier:"regular",
    source:"forge.fromSource",
    meta:{ sourceId: s.id, url: s.url, contentHash: s.contentHash }
  }, ctx);
  return { ok:true, createdDTU: dtu.id };
}, { summary:"Create a DTU from a stored source (with citation metadata)." });

// ---- Global ----
register("global","propose", (ctx, input) => {
  const dtuId = String(input.dtuId||"");
  const dtu = STATE.dtus.get(dtuId);
  if (!dtu) return { ok:false, error:"DTU not found" };
  dtu.meta = dtu.meta || {};
  dtu.meta.globalCandidate = true;
  dtu.updatedAt = nowISO();
  saveStateDebounced();
  return { ok:true, dtuId, status:"global_candidate" };
}, { summary:"Mark a DTU as a global candidate." });

register("global","publish", async (ctx, input) => {
  const dtuId = String(input.dtuId||"");
  // Reuse existing Council global review gate (strict no-dup)
  const out = await ctx.macro.run("council","reviewGlobal", { dtuId }, ctx);
  if (!out.ok) return out;
  const dtu = STATE.dtus.get(dtuId);
  if (dtu) {
    const gid = uid("global");
    STATE.globalIndex.byId.set(gid, dtuId);
    dtu.meta = dtu.meta || {};
    dtu.meta.globalId = gid;
    dtu.meta.globalPublishedAt = nowISO();
    // Scope Separation: promote DTU to Global scope on publish
    dtu.scope = "global";
    dtu.meta.scopeHistory = dtu.meta.scopeHistory || [];
    dtu.meta.scopeHistory.push({
      from: dtu.scope === "global" ? "local" : (dtu.scope || "local"),
      to: "global",
      at: nowISO(),
      by: ctx?.actor?.id || "council",
      reason: "global_publish",
    });
    saveStateDebounced();
    return { ok:true, globalId: gid, dtuId, globalHash: out.globalHash, scope: "global" };
  }
  return { ok:false, error:"DTU missing after publish" };
}, { summary:"Publish a DTU to Global (council-gated, scope-enforced)." });

// ---- Marketplace ----
register("market","listingCreate", (ctx, input) => {
  const dtuId = String(input.dtuId||"");
  const dtu = STATE.dtus.get(dtuId);
  if (!dtu) return { ok:false, error:"DTU not found" };
  // Scope Separation: validate DTU is suitable for marketplace listing
  // DTU must be explicitly promoted to marketplace scope or listed from local with author intent
  const dtuScope = dtu.scope || "local";
  if (dtuScope === "global") {
    return { ok:false, error:"Global DTUs cannot be listed on marketplace — they are canonical knowledge, not merchandise." };
  }
  // Block quarantined DTUs from marketplace
  if (dtu.tags?.includes("quarantine:injection-review")) {
    return { ok:false, error:"Quarantined DTUs cannot be listed on marketplace." };
  }
  const price = Number(input.price||0);
  const currency = normalizeText(input.currency||"USD") || "USD";
  const license = normalizeText(input.license||"noncommercial") || "noncommercial";
  const id = uid("lst");
  const listing = { id, dtuId, orgId: ctx.actor.orgId, price, currency, license, status:"active", createdAt: nowISO() };
  STATE.listings.set(id, listing);
  // Scope Separation: tag DTU as marketplace-listed for provenance
  dtu.meta = dtu.meta || {};
  dtu.meta.marketplaceListed = true;
  dtu.meta.lastListingId = id;
  saveStateDebounced();
  return { ok:true, listing };
}, { summary:"Create a marketplace listing for a DTU (scope-validated)." });

register("market","list", (ctx, input) => {
  const limit = clamp(Number(input.limit||50), 1, 200);
  const listings = Array.from(STATE.listings.values()).filter(l=>l.status==="active").slice(-limit).reverse();
  return { ok:true, listings };
}, { summary:"List active listings." });

register("market","buy", (ctx, input) => {
  const listingId = String(input.listingId||"");
  const listing = STATE.listings.get(listingId);
  if (!listing || listing.status !== "active") return { ok:false, error:"listing not found/active" };
  const buyerOrgId = ctx.actor.orgId;
  const sellerOrgId = listing.orgId;
  const amount = Number(listing.price||0);
  const fee = Math.max(0, Number((amount * 0.03).toFixed(2))); // default 3% platform fee
  const txId = uid("tx");
  const tx = { id: txId, buyerOrgId, sellerOrgId, listingId, amount, fee, createdAt: nowISO() };
  STATE.transactions.set(txId, tx);
  const entId = uid("ent");
  const ent = { id: entId, buyerOrgId, dtuId: listing.dtuId, license: listing.license, createdAt: nowISO() };
  STATE.entitlements.set(entId, ent);
  saveStateDebounced();
  return { ok:true, transaction: tx, entitlement: ent };
}, { summary:"Buy a listing; grants entitlement (local-first ledger)." });

register("market","library", (ctx, _input) => {
  const orgId = ctx.actor.orgId;
  const ents = Array.from(STATE.entitlements.values()).filter(e=>e.buyerOrgId === orgId).slice(-200).reverse();
  return { ok:true, entitlements: ents };
}, { summary:"Return entitlements (your purchased DTUs)." });

// ---- Papers ----
register("paper","create", (ctx, input) => {
  const topic = normalizeText(input.topic || "Untitled Paper");
  const id = uid("paper");
  const paper = { id, orgId: ctx.actor.orgId, topic, outline: [], sections: [], refs: [], status:"draft", createdAt: nowISO(), updatedAt: nowISO() };
  STATE.papers.set(id, paper);
  saveStateDebounced();
  return { ok:true, paper };
}, { summary:"Create a paper draft object." });

register("paper","build", (ctx, input) => {
  const id = String(input.paperId||"");
  const p = STATE.papers.get(id);
  if (!p) return { ok:false, error:"paper not found" };
  // Minimal build: pick top DTUs by tags/topic and build a markdown-ish outline.
  const topic = p.topic;
  const { top } = retrieveDTUs(topic, { topK: 8, minScore: 0.06, randomK: 0, oppositeK: 0 });
  p.outline = [
    "Abstract",
    "Background",
    "Core Claims",
    "Evidence & DTU Anchors",
    "Open Questions",
    "Conclusion"
  ];
  p.sections = [
    { heading:"Abstract", body:`This paper summarizes Concord DTU anchors related to: ${topic}.` },
    { heading:"Evidence & DTU Anchors", body: top.map(d=>`- ${d.title} (${d.id})`).join("\n") }
  ];
  p.refs = [];
  // collect sources from DTU meta if present
  for (const d of top) {
    const sId = d?.meta?.sourceId;
    if (sId && STATE.sources.get(sId)) p.refs.push({ sourceId: sId, url: STATE.sources.get(sId).url, contentHash: STATE.sources.get(sId).contentHash });
  }
  p.status = "built";
  p.updatedAt = nowISO();
  saveStateDebounced();
  return { ok:true, paper: p };
}, { summary:"Build a paper from DTUs (minimal deterministic compiler)." });

register("paper","export", (ctx, input) => {
  const id = String(input.paperId||"");
  const p = STATE.papers.get(id);
  if (!p) return { ok:false, error:"paper not found" };
  const fmt = normalizeText(input.format||"md") || "md";
  const lines = [];
  lines.push(`# ${p.topic}\n`);
  for (const sec of (p.sections||[])) {
    lines.push(`\n## ${sec.heading}\n${sec.body}\n`);
  }
  if (Array.isArray(p.refs) && p.refs.length) {
    lines.push("\n## References\n" + p.refs.map(r=>`- ${r.url} (hash ${String(r.contentHash||"").slice(0,10)}…)`).join("\n"));
  }
  const outText = lines.join("\n").trim() + "\n";
  const fname = `paper_${id}.${fmt === "md" ? "md" : "txt"}`;
  const fpath = path.join(DATA_DIR, fname);
  fs.writeFileSync(fpath, outText, "utf-8");
  return { ok:true, file: { name: fname, path: fpath } };
}, { summary:"Export paper to a local file (md/txt)."} );

// ---- Audit queries (best-effort) ----
register("audit","query", (ctx, input) => {
  const limit = clamp(Number(input.limit||100), 1, 500);
  const domain = normalizeText(input.domain||"");
  const contains = normalizeText(input.contains||"");
  const logs = (STATE.logs||[]).slice(-2000).filter(x => {
    if (!x) return false;
    if (domain && String(x.domain||"") !== domain) return false;
    if (contains && !JSON.stringify(x).toLowerCase().includes(contains.toLowerCase())) return false;
    return true;
  }).slice(-limit);
  return { ok:true, logs };
}, { summary:"Query recent audit logs (in-memory mirror)."} );


// =================== VERIFY / SCORE / DERIVE MACROS (minimal, opt-in) ===================
// These macros are additive and do not change existing behavior unless explicitly called.
// They rely on the DTU substrate for structure; LLM (if enabled) is used only for classification/synthesis language.

function _retrieveRelevantDTUs(query, k=8, threshold=0.08) {
  const all = dtusArray();
  const qTok = simpleTokens(String(query||""));
  const scored = all.map(d => {
    const text = (d.title||"") + " " + ((d.tags||[]).join(" ")) + " " + ((d.human?.summary||"") + " " + (d.creti || "") );
    const dTok = simpleTokens(text).slice(0, 600);
    const score = jaccard(qTok, dTok);
    return { d, score };
  }).sort((a,b)=>b.score-a.score);
  return scored.filter(x=>x.score>threshold).slice(0,k).map(x=>x.d);
}


// =================== REALITY UTILITIES (time/weather) ===================
// Authoritative sources: system clock + external weather API (no LLM).
function getTimeInfo(timeZone = "America/New_York") {
  const now = new Date();
  const nowISO = now.toISOString();
  const localTime = now.toLocaleString("en-US", { timeZone });
  return { nowISO, timeZone, localTime, epochMs: now.getTime() };
}

const _WEATHER_CACHE = new Map(); // key -> { ts:number, data:any }
async function _fetchJson(url) {
  const r = await fetch(url, { method: "GET", headers: { "accept":"application/json" } });
  if (!r.ok) throw new Error(`fetch_failed:${r.status}`);
  return r.json();
}
function _cacheGet(key, ttlMs) {
  const ent = _WEATHER_CACHE.get(key);
  if (!ent) return null;
  if ((Date.now() - ent.ts) > ttlMs) return null;
  return ent.data;
}
function _cacheSet(key, data) { _WEATHER_CACHE.set(key, { ts: Date.now(), data }); }

async function getWeather(locationStr, opts={}) {
  const location = String(locationStr || "").trim() || "Poughkeepsie, NY";
  const timeZone = String(opts.timeZone || "America/New_York");
  const ttlMs = clamp(Number(opts.ttlMs || (10*60*1000)), 60*1000, 60*60*1000); // 1m..1h

  const key = `wx:${location}:${timeZone}`;
  const cached = _cacheGet(key, ttlMs);
  if (cached) return { ok:true, cached:true, ...cached };

  // Geocode via Open-Meteo geocoding (no key).
  const geoUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(location)}&count=1&language=en&format=json`;
  const geo = await _fetchJson(geoUrl);
  const hit = geo?.results?.[0];
  if (!hit) return { ok:false, error:"location_not_found", location };

  const lat = hit.latitude, lon = hit.longitude;
  const label = [hit.name, hit.admin1, hit.country].filter(Boolean).join(", ");

  // Forecast via Open-Meteo (current + hourly + daily)
  const wxUrl =
    `https://api.open-meteo.com/v1/forecast?latitude=${encodeURIComponent(lat)}&longitude=${encodeURIComponent(lon)}` +
    `&current=temperature_2m,apparent_temperature,precipitation,weather_code,wind_speed_10m` +
    `&hourly=temperature_2m,precipitation_probability,precipitation,weather_code,wind_speed_10m` +
    `&daily=temperature_2m_max,temperature_2m_min,precipitation_sum,precipitation_probability_max,weather_code` +
    `&timezone=${encodeURIComponent(timeZone)}`;

  const wx = await _fetchJson(wxUrl);

  const out = { location: label, lat, lon, timeZone, forecast: wx };
  _cacheSet(key, out);
  return { ok:true, cached:false, ...out };
}

register("verify","conflictCheck", (ctx, input) => {
  const dtu = input?.dtu || null;
  if (!dtu || typeof dtu !== "object") return { ok:false, reason:"missing_dtu_object" };
  const cc = pipeConflictCheckDTU(dtu);
  return { ok: cc.ok, conflicts: cc.conflicts };
}, { summary:"Conservative contradiction check: flags only explicit 'X' vs 'NOT X' clashes across invariants/claims." });


register("verify","feasibility", async (ctx, input) => {
  const query = String(input?.query||"");
  const llm = (typeof input?.llm === "boolean") ? input.llm : ctx.state.settings.llmDefault;
  const k = clamp(Number(input?.k||10), 1, 25);
  const relevant = _retrieveRelevantDTUs(query, k, 0.06);

  // Deterministic feasibility classifier (always available):
  // - infeasible: explicit contradiction signals among the strongest anchors
  // - feasible: strong anchor evidence and no explicit contradictions
  // - conditionally_feasible: some evidence but weak / missing constraints
  // - undecidable: no meaningful anchors
  const _norm = (s) => tokenish(String(s||"")).replace(/\s+/g, " ").trim();
  const _hasNeg = (s) => /\b(not|no|never|cannot|can't|impossible|forbidden|invalid)\b/i.test(String(s||""));
  const _stripNeg = (s) => _norm(String(s||"").replace(/\b(not|no|never|cannot|can't|impossible|forbidden|invalid)\b/ig, "").trim());
  const _collectAtoms = (d) => {
    const c = d?.core || {};
    const atoms = [];
    const push = (x, kind) => {
      const t = _norm(x);
      if (!t || t.length < 4) return;
      atoms.push({ text: t, kind, neg: _hasNeg(t), base: _stripNeg(t), dtuId: d.id });
    };
    for (const x of (c.invariants||[])) push(x, "invariant");
    for (const x of (c.claims||[])) push(x, "claim");
    return atoms;
  };
  const _pairConflicts = (dtus) => {
    const atoms = dtus.flatMap(_collectAtoms);
    const byBase = new Map();
    for (const a of atoms) {
      if (!a.base) continue;
      const arr = byBase.get(a.base) || [];
      arr.push(a);
      byBase.set(a.base, arr);
    }
    const conflicts = [];
    for (const [base, arr] of byBase.entries()) {
      const hasPos = arr.some(x => !x.neg);
      const hasNeg2 = arr.some(x => x.neg);
      if (hasPos && hasNeg2) {
        // report minimal conflict tuple
        const pos = arr.find(x => !x.neg);
        const neg = arr.find(x => x.neg);
        conflicts.push({ base, pos: { dtuId: pos?.dtuId, kind: pos?.kind, text: pos?.text }, neg: { dtuId: neg?.dtuId, kind: neg?.kind, text: neg?.text } });
      }
    }
    return conflicts.slice(0, 8);
  };

  // Use the same "working set" logic as /ask for signal strength.
  const all = dtusArray();
  const qTok = simpleTokens(query);
  const scored = all.map(d => {
    const dTok = simpleTokens(d.title + " " + (d.tags||[]).join(" ") + " " + ((d.cretiHuman || d.creti || d.human?.summary || "")).slice(0, 400));
    const score = jaccard(qTok, dTok);
    return { d, score };
  }).sort((a,b)=>b.score-a.score);

  const { micro } = selectWorkingSet(
    scored.filter(x=>x.score > 0.06).map(x=>({ d:x.d, score:x.score })),
    ctx.state.settings,
    { includeMegas: true }
  );
  const bestScore = scored?.[0]?.score ?? 0;
  const hasStrongEvidence = micro.length >= 2 && bestScore >= 0.12;

  const conflicts = _pairConflicts(micro.slice(0, 6));
  if (conflicts.length) {
    return {
      ok:true,
      classification:"infeasible",
      reason:"explicit_conflict_in_anchors",
      conflicts,
      relevantIds: relevant.map(d=>d.id)
    };
  }

  if (hasStrongEvidence) {
    // Optionally ask the LLM for a tighter label (does not override infeasible).
    let llmText = "";
    if (llm && ctx.state.llmReady) {
      const sys = "Classify feasibility. Output ONE word: feasible | conditionally_feasible | undecidable. Only use the provided DTU excerpts; do not invent facts.";
      const excerpts = micro.slice(0,6).map(d => ({ id:d.id, title:d.title, invariants:d.core?.invariants||[], claims:d.core?.claims||[] }));
      const user = JSON.stringify({ query, dtus: excerpts });
      const out = await llmChat(ctx, [{role:"system", content:sys},{role:"user", content:user}], { temperature: 0.0, max_tokens: 120 });
      llmText = (out?.text||"").trim();
      const w = llmText.toLowerCase();
      if (w.includes("conditionally")) return { ok:true, classification:"conditionally_feasible", reason:"llm_refinement", llmText, relevantIds: relevant.map(d=>d.id) };
      if (w.includes("undecidable")) return { ok:true, classification:"undecidable", reason:"llm_refinement", llmText, relevantIds: relevant.map(d=>d.id) };
    }
    return { ok:true, classification:"feasible", reason:"strong_anchor_evidence", llmText, relevantIds: relevant.map(d=>d.id) };
  }

  if (micro.length >= 1 && bestScore >= 0.08) {
    return { ok:true, classification:"conditionally_feasible", reason:"some_anchor_evidence_missing_constraints", relevantIds: relevant.map(d=>d.id) };
  }

  return { ok:true, classification:"undecidable", reason:"no_meaningful_anchor_evidence", relevantIds: relevant.map(d=>d.id) };
}, { summary:"Feasibility classification. Deterministic by default; may use LLM to refine between feasible/conditionally_feasible/undecidable. Infeasible is reserved for explicit anchor conflicts." });


register("verify","designScore", async (ctx, input) => {
  const spec = String(input?.spec || input?.design || input?.prompt || "");
  const llm = (typeof input?.llm === "boolean") ? input.llm : ctx.state.settings.llmDefault;
  const k = clamp(Number(input?.k||12), 1, 25);
  const relevant = _retrieveRelevantDTUs(spec, k, 0.06);

  // Deterministic score: anchoredness + (optional) repair/damage margin if provided.
  const all = dtusArray();
  const qTok = simpleTokens(spec);
  const scored = all.map(d => {
    const dTok = simpleTokens(d.title + " " + (d.tags||[]).join(" ") + " " + ((d.cretiHuman || d.creti || d.human?.summary || "")).slice(0, 400));
    const score = jaccard(qTok, dTok);
    return { d, score };
  }).sort((a,b)=>b.score-a.score);

  const { micro, macro } = selectWorkingSet(
    scored.filter(x=>x.score > 0.06).map(x=>({ d:x.d, score:x.score })),
    ctx.state.settings,
    { includeMegas: true }
  );
  const bestScore = scored?.[0]?.score ?? 0;

  // Base score from evidence strength (0..1)
  let score = clamp((bestScore - 0.05) / 0.25, 0, 1);
  // Bonus for multiple strong micro anchors
  score = clamp(score + (micro.length >= 2 ? 0.15 : micro.length === 1 ? 0.05 : 0), 0, 1);

  // Optional physical score: if caller supplies R/D, incorporate margin.
  const R = Number(input?.R ?? input?.repair);
  const D = Number(input?.D ?? input?.damage);
  if (isFinite(R) && isFinite(D)) {
    const margin = R - D;
    const mScore = clamp(0.5 + margin / (Math.abs(R)+Math.abs(D)+1e-9), 0, 1);
    score = clamp((score*0.6) + (mScore*0.4), 0, 1);
  }

  // Determine primary risks deterministically.
  const primary_risks = [];
  if (micro.length < 2) primary_risks.push("insufficient_local_constraints");
  if (bestScore < 0.10) primary_risks.push("weak_anchor_match");
  if (macro.length === 0) primary_risks.push("no_high_level_frame");

  // Optionally ask the LLM to propose repairs/tests ONLY (not to override score).
  let required_repairs = [];
  let llmText = "";
  if (llm && ctx.state.llmReady) {
    const sys = "Given a design spec and DTU invariants, propose REQUIRED repairs/tests to reduce risk. Output JSON with required_repairs[] and tests[]. Do not invent external facts.";
    const excerpts = micro.slice(0,6).map(d => ({ id:d.id, title:d.title, invariants:d.core?.invariants||[], claims:d.core?.claims||[] }));
    const user = JSON.stringify({ spec, dtus: excerpts });
    const out = await llmChat(ctx, [{role:"system", content:sys},{role:"user", content:user}], { temperature: 0.1, max_tokens: 450 });
    llmText = (out?.text||"").trim();
    try {
      const j = JSON.parse(llmText);
      if (Array.isArray(j?.required_repairs)) required_repairs = j.required_repairs.map(String).slice(0, 8);
      if (Array.isArray(j?.tests)) primary_risks.push(...j.tests.map(t => `test:${String(t)}`).slice(0, 6));
    } catch {}
  }

  return {
    ok:true,
    score_0_1: score,
    primary_risks: Array.from(new Set(primary_risks)).slice(0, 10),
    required_repairs: required_repairs.slice(0, 10),
    cited_dtu_ids: micro.slice(0,8).map(d=>d.id),
    relevantIds: relevant.map(d=>d.id),
    llmText
  };
}, { summary:"Design feasibility scoring. Deterministic score from DTU anchor strength (and optional R/D margin). LLM may add suggested repairs/tests but does not override score." });


register("verify","deriveSecondOrder", async (ctx, input) => {
  const seedIds = Array.isArray(input?.seedIds) ? input.seedIds : [];
  const query = String(input?.query||"");
  const llm = (typeof input?.llm === "boolean") ? input.llm : ctx.state.settings.llmDefault;

  // Only use regular DTUs - shadow DTUs are internal and should not be exposed
  const seeds = seedIds.length
    ? seedIds.map(id => STATE.dtus.get(id)).filter(d => d && !isShadowDTU(d))
    : _retrieveRelevantDTUs(query, 10, 0.06);

  // Full activation: deriveSecondOrder ALWAYS attempts to commit through pipeline.
  // If LLM is unavailable, refuse rather than invent a derived DTU.
  if (!llm || !ctx.state.llmReady) {
    return { ok:false, committed:false, reason:"llm_off_or_unavailable_for_derivation", seedIds: seeds.map(d=>d.id) };
  }

  const sys = "Synthesize ONE second-order DTU implied by the provided DTUs. Output STRICT JSON for a DTU with: title, tags[], human.summary, core.definitions[], core.invariants[], core.claims[], core.examples[], core.nextActions[], machine.math{equations:[],notes:\"\"}. Do not invent external facts; derive logically.";
  const excerpts = seeds.map(d => ({ id:d.id, title:d.title, invariants:d.core?.invariants||[], claims:d.core?.claims||[], definitions:d.core?.definitions||[] }));
  const user = JSON.stringify({ seeds: excerpts });
  const out = await llmChat(ctx, [{role:"system", content:sys},{role:"user", content:user}], { temperature: 0.1, max_tokens: 900 });

  let cand=null;
  try { cand = JSON.parse(out?.text||""); } catch {}
  if (!cand || typeof cand !== "object") return { ok:false, committed:false, reason:"llm_bad_json", llmText: out?.text||"" };

  const dtu = {
    id: uid("dtu"),
    tier: "surface",
    tags: Array.isArray(cand.tags)?cand.tags:[],
    title: String(cand.title||"Derived DTU"),
    human: { summary: String(cand?.human?.summary||""), bullets: [] },
    core: {
      definitions: Array.isArray(cand?.core?.definitions)?cand.core.definitions:[],
      invariants: Array.isArray(cand?.core?.invariants)?cand.core.invariants:[],
      claims: Array.isArray(cand?.core?.claims)?cand.core.claims:[],
      examples: Array.isArray(cand?.core?.examples)?cand.core.examples:[],
      nextActions: Array.isArray(cand?.core?.nextActions)?cand.core.nextActions:[]
    },
    machine: {
      kind: "derived_second_order",
      math: cand?.machine?.math || { equations: [], notes:"" },
      parents: seeds.map(d=>d.id)
    },
    lineage: { parents: seeds.map(d=>d.id), children: [] },
    source: "derived",
    meta: { hidden: false },
    createdAt: nowISO(),
    updatedAt: nowISO(),
    authority: { model: "derive", score: 0 },
    hash: ""
  };

  const res = pipelineCommitDTU(ctx, dtu, { allowRewrite:false });
  if (res?.ok) {
    // Ensure explicit lineage links for parents (best-effort)
    try { await ctx.macro.run("verify","lineageLink", { childId: res.dtu.id, parents: seeds.map(d=>d.id) }); } catch {}
  }
  return { ok: !!res.ok, committed: !!res.ok, dtu: res.dtu, seedIds: seeds.map(d=>d.id), result: res };
}, { summary:"Derive and COMMIT a second-order DTU from seeds. Requires LLM; refuses if unavailable." });

register("verify","lineageLink", (ctx, input) => {
  const childId = String(input?.childId||"");
  const parents = Array.isArray(input?.parents) ? input.parents.map(String) : [];
  if (!childId || !parents.length) return { ok:false, reason:"missing_child_or_parents" };
  // Only link regular DTUs - shadow DTUs are internal
  const child = STATE.dtus.get(childId);
  if (!child || isShadowDTU(child)) return { ok:false, reason:"child_not_found" };
  child.lineage = child.lineage || { parents:[], children:[] };
  child.lineage.parents = Array.from(new Set([...(child.lineage.parents||[]), ...parents]));
  child.updatedAt = nowISO();
  // parent -> child back-links (best-effort; do not create if absent)
  for (const pid of parents) {
    const p = STATE.dtus.get(pid);
    if (!p || isShadowDTU(p)) continue;
    p.lineage = p.lineage || { parents:[], children:[] };
    p.lineage.children = Array.from(new Set([...(p.lineage.children||[]), childId]));
    p.updatedAt = nowISO();
  }
  upsertDTU(child);
  return { ok:true, childId, parents };
}, { summary:"Add explicit lineage links (parents/children). Minimal, best-effort, does not infer." });

register("verify","stressTest", (ctx, input) => {
  // Deterministic, minimal stress test: increase D and/or decrease R until (R-D) flips sign.
  const R0 = Number(input?.R ?? input?.repair ?? 0);
  const D0 = Number(input?.D ?? input?.damage ?? 0);
  const step = clamp(Number(input?.step||0.01), 0.0001, 10);
  const maxIter = clamp(Number(input?.maxIter||5000), 1, 20000);
  if (!isFinite(R0) || !isFinite(D0)) return { ok:false, reason:"invalid_R_or_D" };

  const R = R0; let D = D0, i=0;
  while (i<maxIter && (R - D) > 0) { D += step; i++; }
  const thresholdDamage = D;
  return {
    ok:true,
    R0, D0,
    thresholdDamage,
    margin: R0 - D0,
    steps: i,
    notes:"Minimal stress: increments damage until repair dominance breaks (R-D <= 0)."
  };
}, { summary:"Deterministic minimal stress test: finds damage threshold where repair dominance breaks." });




// ===== CHICKEN2 MACROS =====
register("lattice", "beacon", (ctx, input={}) => {
  const g = _c2genesisDTU();
  const rootHash = g ? _c2hash({ id:g.id, formula:g.formula, invariants:g.invariants }) : "missing";
  const threshold = Number(input.threshold ?? (STATE.__chicken2.thresholdOverlap ?? 0.95));
  // Compare current lattice signature against genesis
  const latticeSig = { invariants: Object.keys(STATE.settings||{}), lineage:{ root:"genesis_reality_anchor_v1" } };
  const overlap = g ? overlap_verifier(g, latticeSig) : 0;
  const awake = overlap >= threshold;
  // Update continuity metric
  STATE.__chicken2.metrics.continuityAvg = clamp(overlap, 0, 1);
  _c2log("c2.beacon", "Beacon computed", { rootHash, threshold, overlap, awake });
  return { ok:true, rootHash, threshold, overlap, awake };
}, { summary:"Chicken2 lattice beacon: returns overlap against genesis and awakens recognition if >= threshold." });

register("lattice", "birth_protocol", (ctx, input={}) => {
  const proposal = input.proposal || {};
  const pre = inLatticeReality({ type:"birth", domain:"lattice", name:"birth_protocol", input:proposal, ctx });
  if (!pre.ok) {
    _c2log("c2.birth.reject", "Birth proposal rejected by reality guard", { pre });
    return { ok:false, error: pre.reason, pre };
  }
  // sandbox sub-lattice (isolated)
  const steps = clamp(Number(input.steps||20), 5, 200);
  const thresholdHomeo = Number(STATE.__chicken2.thresholdHomeostasis ?? 0.8);
  let homeo = 1.0;
  let stress = 0.0;
  for (let i=0;i<steps;i++){
    // simple dynamics: stress increases with proposal complexity; repair reduces it
    const complexity = clamp01((JSON.stringify(proposal).length||0)/4000);
    stress = clamp01(stress + 0.15*complexity - 0.05);
    homeo = clamp01(1 - stress);
    if (homeo < thresholdHomeo){
      _c2log("c2.birth.rollback", "Sandbox failed homeostasis threshold", { i, homeo, thresholdHomeo });
      return { ok:false, error:"homeostasis_failed", i, homeo, thresholdHomeo };
    }
  }
  // forge new DTU
  const id = uid("dtu_birth");
  const dtu = {
    id,
    title: proposal.title || "Born DTU",
    kind: proposal.kind || "persona_or_pattern",
    createdAt: nowISO(),
    updatedAt: nowISO(),
    lineage: { root: "genesis_reality_anchor_v1", parents: ["genesis_reality_anchor_v1"] },
    invariants: Array.isArray(proposal.invariants) ? proposal.invariants : [],
    formula: proposal.formula || "",
    notes: proposal.notes || ""
  };
  STATE.dtus.set(id, dtu);
  saveStateDebounced();
  _c2log("c2.birth.accept", "Birth accepted and DTU committed", { id, title:dtu.title });
  return { ok:true, id, dtu, homeostasis: homeo };
}, { summary:"Chicken2 birth protocol: sandboxed emergence with homeostasis threshold then DTU commit." });

register("lattice", "resonance", (ctx, input={}) => {
  // Lattice resonance: compute health metrics from Chicken2 and growth state
  const c2 = STATE.__chicken2 || {};
  const m = c2.metrics || {};
  const g = STATE.growth || {};
  return {
    ok: true,
    resonance: {
      homeostasis: m.homeostasis ?? 1,
      continuity: m.continuityAvg ?? 0,
      suffering: m.suffering ?? 0,
      contradictionLoad: m.contradictionLoad ?? 0,
      repairRate: g.repair?.repairRate ?? 0.5,
      accepts: m.accepts ?? 0,
      rejections: m.rejections ?? 0,
    },
    timestamp: nowISO()
  };
});

register("persona", "speak", (ctx, input={}) => {
  const { personaId, text } = input;
  if (!personaId) return { ok: false, error: "personaId required" };
  const persona = STATE.personas.get(personaId);
  if (!persona) return { ok: false, error: "Persona not found" };
  const reply = `[${persona.name}]: ${text || "..."}`;
  return { ok: true, reply, persona: { id: persona.id, name: persona.name } };
});

register("persona", "animate", (ctx, input={}) => {
  const { personaId, kind } = input;
  if (!personaId) return { ok: false, error: "personaId required" };
  const persona = STATE.personas.get(personaId);
  if (!persona) return { ok: false, error: "Persona not found" };
  return { ok: true, animation: kind || "talk", persona: { id: persona.id, name: persona.name } };
});

register("persona", "create", (ctx, input={}) => {
  const name = String(input.name||"");
  if (!name) throw new Error("name required");
  const id = uid("persona");
  const persona = {
    id,
    name,
    status: "awake",
    createdAt: nowISO(),
    updatedAt: nowISO(),
    lineage: { root:"genesis_reality_anchor_v1", parents:["genesis_reality_anchor_v1"] },
    recognitionThreshold: Number(input.recognitionThreshold ?? 0.95),
    invariants: ["NO_NEGATIVE_VALENCE_DIMENSION", "OVERLAP>=0.95"]
  };
  STATE.personas.set(id, persona);
  saveStateDebounced();
  _c2log("c2.persona.create", "Persona created", { id, name });
  return { ok:true, persona };
}, { summary:"Create a persona with persistent identity rooted to genesis." });

register("skill", "create", (ctx, input={}) => {
  const title = String(input.title||"");
  if (!title) throw new Error("title required");
  const id = uid("skill");
  const skill = { id, title, trigger: input.trigger||"", procedure: input.procedure||"", checks: input.checks||"", createdAt: nowISO(), updatedAt: nowISO(), level: 1 };
  // store as DTU for portability
  const dtu = { id:`dtu_${id}`, title:`Skill: ${title}`, kind:"skill", createdAt: nowISO(), updatedAt: nowISO(), lineage:{ root:"genesis_reality_anchor_v1", parents:["genesis_reality_anchor_v1"] }, invariants:["NO_NEGATIVE_VALENCE_DIMENSION"], formula: input.formula||"", notes: JSON.stringify(skill) };
  STATE.dtus.set(dtu.id, dtu);
  saveStateDebounced();
  _c2log("c2.skill.create", "Skill created", { id:dtu.id, title });
  return { ok:true, skillDTU: dtu };
}, { summary:"Create a skill DTU template." });

register("intent", "rhythmic_intent", (ctx, input={}) => {
  const cmd = String(input.command||"").trim();
  if (!cmd) throw new Error("command required");
  // Proposal object; execution must be via governedCall to actually manifest changes
  const proposal = { command: cmd, createdAt: nowISO(), proposer: ctx?.actor?.userId || "anon" };
  _c2log("c2.intent.propose", "Rhythmic intent proposed", { proposal });
  return { ok:true, proposal, note:"Use governedCall/council to manifest." };
}, { summary:"Parse founder commands into a governed proposal." });

register("harness", "run", (ctx, input={}) => {
  const tasks = Array.isArray(input.tasks) ? input.tasks : [
    { prompt:"Explain x^2-x=0 as fixed-point identity." },
    { prompt:"Generate a DTU with formula and invariant." },
    { prompt:"Test for contradiction between two DTUs." },
  ];
  let violations=0, successes=0;
  const outputs=[];
  for (const t of tasks){
    const pre = inLatticeReality({ type:"harness", domain:"harness", name:"run", input:t, ctx });
    if (!pre.ok) { violations++; outputs.push({ ok:false, error:pre.reason, task:t }); continue; }
    successes++;
    outputs.push({ ok:true, task:t, result:"ok" });
  }
  const report = { id: uid("proof"), ts: nowISO(), tasks: tasks.length, successes, violations, targetViolations:0 };
  STATE.__chicken2.lastProof = report;
  _c2log("c2.harness", "Proof harness executed", report);
  return { ok:true, report, outputs };
}, { summary:"Chicken2 proof harness runner (lightweight initial suite)." });

// ===== END CHICKEN2 MACROS =====

// ===== LOAF — Hardening, Scalable Cognitive OS, Civilizational-Grade Infrastructure =====
try {
  const loafCtx = {
    register,
    STATE,
    helpers: {
      uid, nowISO, clamp, normalizeText, log,
      enforceEthosInvariant,
      councilGate,
      upsertDTU,
      realtimeEmit,
      saveStateDebounced,
    },
  };
  const loafResult = initLoaf(loafCtx);
  if (loafResult.ok) {
    log("loaf.init", `LOAF v${loafResult.version} initialized: ${loafResult.modules.length} modules`, { modules: loafResult.modules });
  } else {
    log("loaf.init", `LOAF initialized with errors`, { errors: loafResult.errors, modules: loafResult.modules });
  }
} catch (e) {
  console.error("[LOAF] Initialization failed:", e);
  log("loaf.init", "LOAF initialization failed", { error: String(e?.message || e) });
}
// ===== END LOAF =====

// ===== EMERGENT AGENT GOVERNANCE =====
try {
  const emergentCtx = {
    register,
    STATE,
    helpers: {
      uid, nowISO, clamp, normalizeText, log,
      enforceEthosInvariant,
      councilGate,
      upsertDTU,
      realtimeEmit,
      saveStateDebounced,
    },
  };
  const emergentResult = initEmergent(emergentCtx);
  if (emergentResult.ok) {
    log("emergent.init", `Emergent Agent Governance v${emergentResult.version} initialized: ${emergentResult.macroCount} macros`);
  } else {
    log("emergent.init", `Emergent initialization failed`, { error: emergentResult.error });
  }
} catch (e) {
  console.error("[Emergent] Initialization failed:", e);
  log("emergent.init", "Emergent initialization failed", { error: String(e?.message || e) });
}
// ===== END EMERGENT =====

// ===== GRC: Grounded Recursive Closure v1 =====
let GRC_MODULE = null;
try {
  const grcCtx = {
    register,
    STATE,
    helpers: {
      inLatticeReality,
    },
  };
  GRC_MODULE = await initGRC(grcCtx);
  if (GRC_MODULE) {
    log("grc.init", `GRC v${GRC_MODULE.version} initialized: ${GRC_MODULE.macros.length} macros`);
  }
} catch (e) {
  console.error("[GRC] Initialization failed:", e);
  log("grc.init", "GRC initialization failed", { error: String(e?.message || e) });
}
// ===== END GRC =====

const app = express();

// ---- Production Middleware (extracted to ./middleware/index.js) ----
configureMiddleware(app, {
  express,
  helmet,
  cors,
  compression,
  rateLimiter,
  idempotencyMiddleware,
  requestIdMiddleware,
  requestLoggerMiddleware,
  sanitizationMiddleware,
  metricsMiddleware,
  cookieParserMiddleware,
  authMiddleware,
  productionWriteAuthMiddleware,
  csrfMiddleware,
  NODE_ENV,
});

// ---- Global Async Safety Net ----
// Wraps all async route handlers to catch unhandled promise rejections.
// Without this, any async handler that throws without try/catch will leave
// the request hanging forever (30s timeout for the user).
{
  const _origRoute = app.route.bind(app);
  for (const method of ["get", "post", "put", "delete", "patch"]) {
    const orig = app[method].bind(app);
    app[method] = function (path, ...handlers) {
      const wrapped = handlers.map(fn => {
        if (fn && fn.constructor?.name === "AsyncFunction") {
          return (req, res, next) => {
            Promise.resolve(fn(req, res, next)).catch(err => {
              const msg = String(err?.message || err);
              log("async.error", `Unhandled async error on ${req.method} ${req.path}: ${msg}`, { stack: String(err?.stack || "").slice(0, 500) });
              if (!res.headersSent) {
                const status = msg.startsWith("forbidden") ? 403 : msg.includes("not found") ? 404 : 500;
                res.status(status).json({ ok: false, error: msg });
              }
            });
          };
        }
        return fn;
      });
      return orig(path, ...wrapped);
    };
  }
}

// ---- Health, Ready, Metrics, Status, Backup, Time, Weather, etc. (extracted to routes/system.js) ----
require("./routes/system")(app, {
  STATE, makeCtx, runMacro, requireRole, db, MACROS, VERSION, PORT, NODE_ENV,
  LLM_READY, OPENAI_MODEL_FAST, OPENAI_MODEL_SMART, SEED_INFO, STATE_DISK,
  USE_SQLITE_STATE, ENV_VALIDATION, AUTH_MODE, CAPS, METRICS, JWT_SECRET,
  AUTH_USES_JWT, AUTH_USES_APIKEY, AuthDB, rateLimiter, helmet,
  normalizeText, nowISO, clamp, dtusArray, isShadowDTU, saveStateDebounced,
  listDomains, getLLMPipelineStatus, setLLMPipelineMode, llmPipeline,
  getTimeInfo, getWeather, createBackup, listBackups, restoreBackup,
  ensureOrganRegistry, ensureQueues, _getPatternHistory, classifyDomain,
  _inferQueryIntent, CRETI_PROJECTION_RULES, searchIndexed, paginateResults,
  auditLog
});

// ---- Auth Endpoints (extracted to routes/auth.js) ----
app.use("/api/auth", require("./routes/auth")({
  AuthDB,
  AuditDB,
  db,
  jwt,
  authRateLimiter,
  _TOKEN_BLACKLIST,
  _REFRESH_FAMILIES,
  REFRESH_TOKEN_COOKIE,
  NODE_ENV,
  validate,
  hashPassword,
  verifyPassword,
  createToken,
  createRefreshToken,
  verifyToken,
  setAuthCookie,
  setRefreshCookie,
  clearAuthCookie,
  auditLog,
  generateApiKey,
  hashApiKey,
  requireRole,
  generateCsrfToken,
  uid,
  structuredLog,
  saveAuthData
}));

// Backup endpoints extracted to routes/system.js

// ---- UI Response Contract (prevents raw JSON dumps to frontend) ----
function _extractReply(out) {
  if (!out) return "";
  if (typeof out === "string") return out;
  if (typeof out.reply === "string") return out.reply;
  if (out.result && typeof out.result.reply === "string") return out.result.reply;
  if (typeof out.message === "string") return out.message;
  if (typeof out.text === "string") return out.text;
  // fallbacks
  if (out.ok === false && typeof out.error === "string") return out.error;
  return "";
}



// ---- Invariant Spine (Release Gate + Post-launch Locks) ----
const _INVARIANTS = Object.freeze({
  sessionIdentity:        { id:"I1",  name:"Session Identity",        enforce:true },
  responseShape:          { id:"I2",  name:"Response Shape",          enforce:true },
  noInternalLeakage:      { id:"I3",  name:"No Internal Leakage",     enforce:true },
  labelDiscipline:        { id:"I4",  name:"Label Discipline",        enforce:true }, // enforced softly (non-destructive)
  deterministicFirst:     { id:"I5",  name:"Deterministic First",     enforce:true },
  noCrash:                { id:"I6",  name:"No-Crash / Safe Failure", enforce:true },
  inputNormalization:     { id:"I7",  name:"Input Normalization",     enforce:true },
  latencyBudget:          { id:"I8",  name:"Latency Budget",          enforce:false }, // policy: enforced via settings elsewhere
  monotonicWrites:        { id:"I9",  name:"Monotonic Session Writes",enforce:false }, // policy: current state uses debounced save
  shadowNonAuthority:     { id:"I10", name:"Shadow Non-Authority",    enforce:true },
  canonicalUniqueness:    { id:"I11", name:"Canonical Uniqueness",    enforce:false }, // handled by dedupe/promote macros
  lineagePreservation:    { id:"I12", name:"Lineage Preservation",    enforce:false }, // handled by merge/promote macros
  promotionGate:          { id:"I13", name:"Promotion Gate",          enforce:false }, // handled by council/macros
  contradictionHandling:  { id:"I14", name:"Contradiction Handling",  enforce:false }, // handled by council/macros
  recencyVsAuthority:     { id:"I15", name:"Recency vs Authority",    enforce:false }, // handled by scoring
  modeContract:           { id:"I16", name:"Mode Contract",           enforce:true },
  vibesIsolation:         { id:"I17", name:"Vibes Isolation",         enforce:false }, // future: when vibes tier is added
  uiBackendContract:      { id:"I18", name:"UI/Backend Contract",     enforce:true },
  coldStartClarity:       { id:"I19", name:"Cold-Start Clarity",      enforce:true },
  publicSafeDefaults:     { id:"I20", name:"Public-safe Defaults",    enforce:true },
  versioning:             { id:"I21", name:"Versioning",              enforce:true }
});

function _normalizeSessionId(raw) {
  const s = String(raw || "").trim();
  if (!s) return uid("sess");
  // keep it filename/url safe-ish
  return s.replace(/[^a-zA-Z0-9_\-:.]/g, "_").slice(0, 96);
}
function _normalizePrompt(raw) {
  // Note: express.json already caps request body; still normalize defensively
  let s = String(raw == null ? "" : raw);
  s = s.replace(/\r\n/g, "\n");
  if (s.length > 16000) s = s.slice(0, 16000);
  return s;
}
function _normalizeMode(raw) {
  const s = String(raw || "").trim().toLowerCase();
  const allowed = new Set(["chat","ask","debug","design","decide","research","forge","explore","vibes"]);
  if (!s) return "chat";
  return allowed.has(s) ? s : "chat";
}
function enforceRequestInvariants(req, bodyIn={}) {
  const body = (bodyIn && typeof bodyIn === "object") ? { ...bodyIn } : {};
  // session identity
  const sid = _normalizeSessionId(body.sessionId || req?.query?.sessionId || req?.headers?.["x-session-id"]);
  body.sessionId = sid;
  req._concordSessionId = sid;

  // prompt normalization (only if present)
  if ("prompt" in body) body.prompt = _normalizePrompt(body.prompt);

  // mode contract
  body.mode = _normalizeMode(body.mode || body.intentMode || body.panelMode);

  // public-safe defaults
  if (body.showInternals == null) body.showInternals = false;
  if (body.debug == null) body.debug = false;

  return body;
}

const INTERNAL_LEAK_PATTERNS = [
  /\bcontext\s+i['’]?m\s+tracking\b/i,
  /\binternal\s+context\s+tracking\b/i,
  /\bshadow\s*dtu\b.*\bhidden\b/i,
  /\bSYSTEM\s+PROMPT\b/i
];
function stripInternalLeakage(reply, { debug=false, showInternals=false } = {}) {
  if (!reply) return "";
  if (debug || showInternals) return String(reply);
  const lines = String(reply).split("\n");
  const kept = [];
  for (const line of lines) {
    const bad = INTERNAL_LEAK_PATTERNS.some(re => re.test(line));
    if (!bad) kept.push(line);
  }
  return kept.join("\n").trim();
}

function softEnforceLabelDiscipline(reply, mode="chat") {
  // Non-destructive: only in stricter modes, add a tiny label if uncertainty is high and no labels exist.
  const m = String(mode||"chat").toLowerCase();
  if (!["debug","research","decide"].includes(m)) return reply;
  const s = String(reply||"");
  const hasLabels = /\bFacts\b|\bHypotheses\b|\bSpeculation\b/i.test(s);
  if (hasLabels) return s;
  const uncertain = /\b(maybe|might|likely|probably|i think|could be)\b/i.test(s);
  if (!uncertain) return s;
  return `Hypothesis:\n${s}`.trim();
}

function ensureReplyEnvelope(out, req, extraMeta={}) {
  // Guarantees Response Shape invariant even if downstream returns raw values
  const ok = (out && typeof out === "object" && typeof out.ok === "boolean") ? out.ok : !(out && out.ok === false);
  const base = (out && typeof out === "object") ? out : { ok, result: out };
  const reply = _extractReply(base);
  const meta = {
    ...(base?.meta || {}),
    mode: base?.meta?.mode || out?.mode || out?.result?.mode || req?.body?.mode || "chat",
    sessionId: base?.meta?.sessionId || req?._concordSessionId || req?.body?.sessionId || "default",
    llmUsed: Boolean(base?.meta?.llmUsed || out?.llmUsed || out?.result?.llmUsed),
    version: VERSION,
    capabilities: {
      version: VERSION,
      llmReady: LLM_READY,
      organs: STATE.organs?.size || 0,
      growth: !!STATE.growth
    },
    ...extraMeta
  };
  return { ...base, ok, reply, meta };
}

function deterministicFallbackReply(req) {
  const mode = String(req?.body?.mode || "chat");
  // Cold-start clarity invariant: keep it helpful and short.
  return (
    mode === "chat"
      ? "Concord is up. Ask a question, or say what you want to build and I’ll structure it into DTUs (definitions + invariants)."
      : "Concord is up. Provide your target outcome + constraints and I’ll proceed."
  );
}
function toUI(out, req, extraMeta={}) {
  const debug = String(req?.query?.debug || "") === "1";
  if (debug) return out;

  // Response Shape + No Internal Leakage + Deterministic-First
  const base = ensureReplyEnvelope(out, req, extraMeta);
  let reply = String(base.reply || "");
  const showInternals = Boolean(req?.body?.showInternals || req?.query?.showInternals === "1");
  reply = stripInternalLeakage(reply, { debug: false, showInternals });
  reply = softEnforceLabelDiscipline(reply, base?.meta?.mode || req?.body?.mode || "chat");
  if (!reply) reply = deterministicFallbackReply(req);

  const ok = (base && typeof base.ok === "boolean") ? base.ok : true;
  const meta = {
    mode: out?.mode || out?.result?.mode || undefined,
    sessionId: out?.sessionId || req?.body?.sessionId || "default",
    llmUsed: out?.llmUsed || out?.result?.llmUsed || false,
    capabilities: {
      version: VERSION,
      llmReady: LLM_READY,
      organs: STATE.organs?.size || 0,
      growth: !!STATE.growth
    },
    ...extraMeta
  };
  return { ok, reply, meta };
}

function uiJson(res, out, req, extraMeta={}) {
  const ui = toUI(out, req, extraMeta);
  if (out && out.ack) ui.ack = out.ack;
  return res.json(ui);
}


// ---- ACK Contract (command-driven panels) ----
function _makeAck(req, mutated=[], reads=[], job=null, extra={}) {
  return {
    sessionId: (req?.body?.sessionId || req?.query?.sessionId || "default"),
    mutated,
    reads,
    job: job || { id: null, status: "done" },
    ts: Date.now(),
    ...extra
  };
}
function _withAck(out, req, mutated=[], reads=[], job=null, extra={}) {
  const ack = _makeAck(req, mutated, reads, job, extra);
  if (out && typeof out === "object") return { ...out, ok: (typeof out.ok==="boolean"?out.ok:true), ack };
  return { ok: true, result: out, ack };
}
// NOTE: CORS and express.json() are configured above in Production Middleware section

// ---- v3: Auth/Org (local-first) + Macro ACL + Actor Context ----
function sha256Hex(s) {
  return crypto.createHash("sha256").update(String(s)).digest("hex");
}
function ensureRootIdentity() {
  // If no users exist, create a local root user + org + dev api key.
  if (STATE.users.size) return;
  const rootUserId = uid("user");
  const rootOrgId = uid("org");
  const handle = "root";
  const user = { id: rootUserId, handle, createdAt: nowISO(), orgIds: [rootOrgId], roleByOrg: { [rootOrgId]: "owner" } };
  const org = { id: rootOrgId, name: "Root Org", ownerUserId: rootUserId, createdAt: nowISO() };
  STATE.users.set(rootUserId, user);
  STATE.orgs.set(rootOrgId, org);

  // Dev key is printed ONCE in logs. Rotate by deleting it from concord_state.json.
  const rawKey = crypto.randomBytes(24).toString("hex");
  const keyId = uid("key");
  const keyObj = {
    id: keyId,
    keyHash: sha256Hex(rawKey),
    userId: rootUserId,
    orgId: rootOrgId,
    scopes: ["*"],
    createdAt: nowISO(),
    revokedAt: null
  };
  STATE.apiKeys.set(keyId, keyObj);
  saveStateDebounced();
  console.log("\n=== Concord v3 Auth Bootstrap ===");
  console.log("Created root user/org. Use this API key for requests:");
  if (NODE_ENV === "production") {
    // In production, write key to a secure file instead of stdout (prevents log leakage)
    const keyFilePath = path.join(DATA_DIR, ".root_api_key");
    try {
      fs.writeFileSync(keyFilePath, rawKey, { mode: 0o600 });
      console.log(`API key written to: ${keyFilePath} (mode 600, owner-read only)`);
      console.log("Retrieve it once, then delete the file for security.");
    } catch {
      console.log(`X-API-Key: ${rawKey.slice(0, 8)}...REDACTED (set DATA_DIR to enable file-based key delivery)`);
    }
  } else {
    console.log(`X-API-Key: ${rawKey}`);
  }
  console.log("================================\n");
}

function getActorFromReq(req) {
  // Local-first API key auth: X-API-Key header or ?apiKey=...
  const raw = String(req?.headers?.["x-api-key"] || req?.query?.apiKey || "").trim();
  // In AUTH_MODE=public, anonymous users get member role so all features are usable without login.
  // In other modes, anonymous users (no API key) get viewer with read-only access.
  if (!raw) {
    if (AUTH_MODE === "public") {
      return { ok: true, actor: { userId: "anon", orgId: "public", role: "member", scopes: ["read", "write"] } };
    }
    return { ok: true, actor: { userId: "anon", orgId: "public", role: "viewer", scopes: ["read"] } };
  }
  const h = sha256Hex(raw);
  const key = Array.from(STATE.apiKeys.values()).find(k => k && !k.revokedAt && k.keyHash === h);
  if (!key) return { ok: false, error: "Invalid API key" };
  const role = (STATE.users.get(key.userId)?.roleByOrg || {})[key.orgId] || "member";
  const scopes = Array.isArray(key.scopes) && key.scopes.length ? key.scopes : ["read"];
  return { ok: true, actor: { userId: key.userId, orgId: key.orgId, role, scopes, keyId: key.id } };
}

// ---- Macro ACL v2: Domain defaults + per-macro overrides + production default-deny ----
const MACRO_ACL = new Map(); // key = `${domain}.${name}` → { roles:[], scopes:[] }
const MACRO_ACL_DOMAIN = new Map(); // domain → { roles:[], scopes:[] }

function allowMacro(domain, name, { roles=["owner","admin","member"], scopes=["*"] } = {}) {
  MACRO_ACL.set(`${domain}.${name}`, { roles, scopes });
}
function allowDomain(domain, { roles=["owner","admin","member"], scopes=["*"] } = {}) {
  MACRO_ACL_DOMAIN.set(domain, { roles, scopes });
}

function _canRunMacro(actor, domain, name) {
  function _checkRule(rule) {
    const roleOk = !rule.roles?.length || rule.roles.includes(actor.role) || actor.role === "owner";
    const scopeOk = (actor.scopes||[]).includes("*") || !rule.scopes?.length || rule.scopes.some(s => (actor.scopes||[]).includes(s));
    return roleOk && scopeOk;
  }
  // 1. Per-macro rule (highest priority)
  const specific = MACRO_ACL.get(`${domain}.${name}`);
  if (specific) return _checkRule(specific);
  // 2. Domain-level default
  const domRule = MACRO_ACL_DOMAIN.get(domain);
  if (domRule) return _checkRule(domRule);
  // 3. No rule: open in development, default-deny in production
  if (NODE_ENV === "production") {
    console.warn(`[MacroACL] DENY: no ACL rule for ${domain}.${name}`);
    return false;
  }
  return true;
}

// ---- Populate Macro Permission Matrix ----
// Tier shortcuts for role/scope combinations
const _ACL_PUB    = { roles: ["viewer","member","admin","owner"], scopes: ["read","write","admin","*"] };
const _ACL_MEMBER = { roles: ["member","admin","owner"], scopes: ["write","admin","*"] };
const _ACL_ADMIN  = { roles: ["admin","owner"], scopes: ["admin","*"] };
const _ACL_OWNER  = { roles: ["owner"], scopes: ["*"] };

// Public read macros (viewer+): frontend boot path, status checks, DTU browsing, chat, lens reads
for (const [d, n] of [
  ["system","status"],["system","getStatus"],
  ["dtu","list"],["dtu","get"],["dtu","search"],["dtu","recent"],["dtu","stats"],["dtu","count"],["dtu","export"],
  ["settings","get"],["settings","status"],
  ["chicken3","status"],
  ["chat","respond"],["chat","feedback"],["chat","stream"],
  ["goals","list"],["goals","get"],["goals","status"],
  ["lattice","resonance"],["lattice","beacon"],
]) allowMacro(d, n, _ACL_PUB);

// Member-level domains (authenticated user operations)
for (const d of [
  "ask","chat","forge","swarm","sim","reasoning","hypothesis","inference",
  "metacognition","metalearning","search","semantic","reflection","attention","experience",
  "entity","voice","tools","multimodal","collab","whiteboard","persona","wrapper","layer",
  "temporal","grounding","worldmodel","commonsense","explanation","transfer","materials",
  "style","visual","market","marketplace","mobile","pwa","notion","obsidian","vscode",
  "paper","research","anon","dtu","goals","intent","interface","skill","dimensional",
  "lattice","backpressure",
]) allowDomain(d, _ACL_MEMBER);

// Admin-level domains (system management)
for (const d of [
  "admin","automation","autotag","backup","cache","db","graph","schema",
  "integration","webhook","jobs","perf","log","llm","plugin","source","abstraction",
  "evolution","audit","verify","experiment","synth","harness","crawl","ingest",
  "export","import","redis","sync","system",
]) allowDomain(d, _ACL_ADMIN);

// Owner-only domains (sensitive infrastructure)
for (const d of [
  "shard","governor","global","sovereign","council","org","auth",
]) allowDomain(d, _ACL_OWNER);

// Per-macro overrides for sensitive operations within member domains
allowMacro("dtu", "delete", _ACL_ADMIN);
allowMacro("dtu", "tier_change", _ACL_ADMIN);
allowMacro("dtu", "shadow_access", _ACL_ADMIN);
allowMacro("goals", "approve", _ACL_OWNER);
allowMacro("goals", "activate", _ACL_OWNER);
allowMacro("goals", "config", _ACL_OWNER);
allowMacro("chicken3", "meta_propose", _ACL_OWNER);
allowMacro("chicken3", "meta_commit_quiet", _ACL_OWNER);
allowMacro("entity", "terminal_approve", _ACL_ADMIN);
allowMacro("grounding", "approve_action", _ACL_ADMIN);

// Lens artifact macros: list/get/export = member, create/update/delete/run/bulkCreate = member
allowDomain("lens", _ACL_MEMBER);
allowMacro("lens", "list", _ACL_PUB);
allowMacro("lens", "get", _ACL_PUB);
allowMacro("lens", "export", _ACL_PUB);

// Activate macro ACL enforcement
globalThis.canRunMacro = _canRunMacro;

// Attach ctx.actor for every request
app.use((req, res, next) => {
  try {
    ensureRootIdentity();
    // If JWT/cookie auth already authenticated the user, derive actor from req.user
    if (req.user) {
      req.actor = {
        userId: req.user.id,
        orgId: "default",
        role: req.user.role || "member",
        scopes: Array.isArray(req.user.scopes) && req.user.scopes.length ? req.user.scopes : ["read", "write"]
      };
    } else {
      const a = getActorFromReq(req);
      if (!a.ok) return res.status(401).json({ ok:false, error: a.error });
      req.actor = a.actor;
    }
  } catch (e) {
    return res.status(500).json({ ok:false, error: String(e?.message || e) });
  }
  next();
});

// ---- v3: Jobs Orchestrator (in-process worker) ----
function _jobNow() { return Date.now(); }
function enqueueJob(kind, payload, { runAtMs=null, maxAttempts=3, idempotencyKey=null, actor=null } = {}) {
  const id = uid("job");
  const j = {
    id, kind,
    payload: payload || {},
    status: "queued",
    attempts: 0,
    maxAttempts,
    runAt: runAtMs ? new Date(runAtMs).toISOString() : nowISO(),
    createdAt: nowISO(),
    updatedAt: nowISO(),
    lastError: null,
    result: null,
    idempotencyKey: idempotencyKey || null,
    actor: actor || null
  };
  // Idempotency (best-effort): if a queued/running job has same key, return it.
  if (idempotencyKey) {
    for (const ex of STATE.jobs.values()) {
      if (ex && ex.idempotencyKey === idempotencyKey && (ex.status === "queued" || ex.status === "running")) return ex;
    }
  }
  STATE.jobs.set(id, j);
  saveStateDebounced();
  return j;
}

async function runJob(j) {
  j.status = "running";
  j.attempts += 1;
  j.updatedAt = nowISO();
  saveStateDebounced();

  const ctx = makeCtx(null);
  // adopt actor context if present; default to system actor for internal jobs
  ctx.actor = j.actor || { userId: "system", orgId: "internal", role: "owner", scopes: ["*"] };

  try {
    const [domain, name] = String(j.kind).split(".");
    if (!domain || !name) throw new Error("Job kind must be domain.name");
    const out = await runMacro(domain, name, j.payload || {}, ctx);
    j.status = "succeeded";
    j.result = out;
    j.lastError = null;
  } catch (e) {
    j.lastError = String(e?.message || e);
    if (j.attempts >= (j.maxAttempts || 3)) {
      j.status = "failed";
    } else {
      j.status = "queued";
      // simple backoff
      const backoffMs = 500 * Math.pow(2, Math.min(6, j.attempts));
      j.runAt = new Date(Date.now() + backoffMs).toISOString();
    }
  } finally {
    j.updatedAt = nowISO();
    saveStateDebounced();
  }
}

let _jobTimer = null;
function startJobWorker() {
  if (_jobTimer) clearInterval(_jobTimer);
  _jobTimer = setInterval(async () => {
    try {
      // pick next runnable job
      const now = Date.now();
      const runnable = Array.from(STATE.jobs.values())
        .filter(j => j && j.status === "queued" && (!j.runAt || new Date(j.runAt).getTime() <= now))
        .sort((a,b) => new Date(a.runAt).getTime() - new Date(b.runAt).getTime());
      const next = runnable[0];
      if (!next) return;
      await runJob(next);
    } catch {}
  }, 250);
  log("jobs.worker", "Job worker started", { everyMs: 250 });
}
startJobWorker();


// startup banner
console.log(`\nConcord v2 (Macro‑Max) starting…`);
console.log(`- version: ${VERSION}`);
console.log(`- port: ${PORT}`);
console.log(`- dotenvLoaded: ${DOTENV.loaded} (path=${DOTENV.path})`);
console.log(`- llmReady: ${LLM_READY}`);
console.log(`- authMode: ${AUTH_MODE} (jwt=${AUTH_USES_JWT}, apikey=${AUTH_USES_APIKEY})\n`);

// Root, status, LLM pipeline, quality-pipeline, time, weather, state/latest — extracted to routes/system.js


// ---- DTU Endpoints (extracted to routes/dtus.js) ----
require("./routes/dtus")(app, { STATE, makeCtx, runMacro, dtuForClient, dtusArray, _withAck, saveStateDebounced });

// ---- Chat + Ask Endpoints (extracted to routes/chat.js) ----
require("./routes/chat")(app, {
  STATE, makeCtx, runMacro, enforceRequestInvariants, enforceEthosInvariant,
  uid, kernelTick, uiJson, _withAck, _extractReply, clamp, nowISO,
  saveStateDebounced, ETHOS_INVARIANTS
});

// ---- Domain Routes (extracted to routes/domain.js) ----
require("./routes/domain")(app, {
  STATE, makeCtx, runMacro, _withAck, kernelTick, uiJson, listDomains, listMacros,
  dtusArray, normalizeText, clamp, nowISO, saveStateDebounced, retrieveDTUs,
  isShadowDTU, fs, ensureExperienceLearning, ensureAttentionManager, ensureReflectionEngine
});

// Error handler
app.use((err, req, res, _next) => {
  const msg = String(err?.message || err);
  log("server.error", msg, { stack: String(err?.stack || "") });
  if (err?.code === "ORIGIN_BLOCKED") {
    return res.status(403).json({ ok:false, error:"Origin blocked", code:"ORIGIN_BLOCKED", reason: err?.reason || msg });
  }
  res.status(500).json({ ok:false, error: msg });
});

// ---- heartbeat (Scope Separation: Local tick + Global tick, no Marketplace tick) ----
let heartbeatTimer = null;
let weeklyTimer = null;
let globalTickTimer = null;  // Scope Separation: separate 5-min Global tick

function startHeartbeat() {
  if (heartbeatTimer) clearInterval(heartbeatTimer);
  if (weeklyTimer) clearInterval(weeklyTimer);
  if (globalTickTimer) clearInterval(globalTickTimer);

  // ── Local Scope Tick (existing cadence, 15s default) ──
  const ms = clamp(Number(STATE.settings.heartbeatMs || 15000), 2000, 120000);
  heartbeatTimer = setInterval(async () => {
    if (!STATE.settings.heartbeatEnabled) return;
    const ctx = makeCtx(null);
    // Heartbeat runs internal maintenance — elevate to system actor so admin-gated
    // domains (ingest, system, emergent, etc.) are accessible.
    ctx.actor = { userId: "system", orgId: "internal", role: "owner", scopes: ["*"] };

    // process crawl queue once (Local scope only — ingest is local activity)
    await runMacro("ingest","processQueueOnce", {}, ctx).catch((err) => { console.error('[system] Heartbeat ingest queue error:', err); });

    if (STATE.settings.autogenEnabled) {
      await runMacro("system","autogen", {}, ctx).catch((err) => { console.error('[system] Heartbeat autogen error:', err); });
    }
    if (STATE.settings.dreamEnabled) {
      await runMacro("system","dream", { seed: "Concord heartbeat dream" }, ctx).catch((err) => { console.error('[system] Heartbeat dream error:', err); });
    }
    if (STATE.settings.evolutionEnabled) {
      await runMacro("system","evolution", {}, ctx).catch((err) => { console.error('[system] Heartbeat evolution error:', err); });
    }
    if (STATE.settings.synthEnabled) {
      await runMacro("system","synthesize", {}, ctx).catch((err) => { console.error('[system] Heartbeat synthesize error:', err); });
    }

    // v3: local self-upgrade (abstraction governor) at fixed cadence
    try { await maybeRunLocalUpgrade(); } catch (err) { console.error('[system] Local self-upgrade error:', err); }

    // v5.5: capability bridge tick — beacon check + dedup scan + auto-hypothesis
    try { await runMacro("emergent","bridge.heartbeatTick", {}, ctx).catch((err) => { console.error('[system] Emergent bridge heartbeat tick error:', err); }); } catch (err) { console.error('[system] Heartbeat tick error:', err); }
  }, ms);
  log("heartbeat", "Local scope tick started", { ms });

  // ── Global Scope Tick (5 minutes — slow, deliberate synthesis) ──
  // Global tick can: generate DTU candidates from existing Global DTUs, update resonance.
  // Global tick cannot: ingest local or marketplace DTUs, respond to local activity.
  const globalMs = clamp(Number(STATE.settings.globalTickMs || 300000), 60000, 600000);
  globalTickTimer = setInterval(async () => {
    if (!STATE.settings.heartbeatEnabled) return;
    try {
      const ctx = makeCtx(null);
      ctx.actor = { userId: "system", orgId: "internal", role: "owner", scopes: ["*"] };
      await runMacro("emergent","scope.globalTick", {}, ctx).catch((err) => { console.error('[system] Global scope tick macro error:', err); });
    } catch (err) { console.error('[system] Global scope tick error:', err); }
  }, globalMs);
  log("heartbeat", "Global scope tick started", { ms: globalMs });

  // Marketplace: ❌ No heartbeat — marketplace never generates DTUs, never mutates knowledge
}
startHeartbeat();

// ---- Operations Endpoints (extracted to routes/operations.js) ----
require("./routes/operations")(app, {
  STATE, makeCtx, runMacro, _withAck, ensureOrganRegistry, ensureQueues,
  dtusArray, uid, sha256Hex, nowISO, saveStateDebounced, requireRole,
  PIPE, TEMPORAL_FRAMES, pipeListProposals, computeAbstractionSnapshot,
  maybeRunLocalUpgrade, runAutoPromotion, tryLoadSeedDTUs, toOptionADTU,
  SEED_INFO, kernelTick, uiJson
});

// api/metrics and api/health/capabilities extracted to routes/system.js

// ---- weekly council debates ----
// (deduped) weeklyTimer declared earlier

function startWeeklyCouncil() {
  if (weeklyTimer) clearInterval(weeklyTimer);
  // Default: every 7 days. (Frontend can add more precise scheduling later.)
  const weekMs = 7 * 24 * 60 * 60 * 1000;
  weeklyTimer = setInterval(async () => {
    if (STATE.settings.weeklyDebateEnabled === false) return;
    const ctx = makeCtx(null);
    ctx.actor = { userId: "system", orgId: "internal", role: "owner", scopes: ["*"] };
    await runMacro("council","weeklyDebateTick",{ topic: STATE.settings.weeklyDebateTopic || "Concord Weekly Synthesis" }, ctx).catch(()=>{});
  }, weekMs);
  log("council.weekly", "Weekly Council scheduler started", { everyMs: weekMs });
}
startWeeklyCouncil();


// ---- listen ----
// Pipeline proposals endpoint extracted to routes/operations.js


// ============================================================================
// EXTENDED API ENDPOINTS (surgically integrated from Endpoints.txt)
// - Macro-first: endpoints remain thin wrappers around runMacro()
// - Safe: no changes to macro logic; only HTTP exposure
// ============================================================================

// Style endpoints extracted to routes/operations.js

// Extended DTU endpoints extracted to routes/dtus.js

// verify, experiments, synth, heartbeat, system, temporal, proposals, jobs, agents — extracted to routes/operations.js

// ===== EMERGENT AGENT GOVERNANCE API (extracted to routes/emergent.js) =====
app.use("/api/emergent", require("./routes/emergent")({ makeCtx, runMacro }));

// papers, forge/fromSource, crawl, audit, lattice, persona, skill, intent, chicken3 — extracted to routes/domain.js

// Goals endpoints extracted to routes/domain.js

// World Model endpoints extracted to routes/domain.js

// Semantic endpoints extracted to routes/domain.js

// Transfer Learning endpoints extracted to routes/domain.js

// Experience Learning endpoints extracted to routes/domain.js

// Attention Management endpoints extracted to routes/domain.js

// Reflection Engine endpoints extracted to routes/domain.js

// Commonsense endpoints extracted to routes/domain.js

// Grounding endpoints extracted to routes/domain.js

// Reasoning Chains endpoints extracted to routes/domain.js

// Inference Engine endpoints extracted to routes/domain.js

// Hypothesis Engine endpoints extracted to routes/domain.js

// Metacognition endpoints extracted to routes/domain.js

// Explanation Engine endpoints extracted to routes/domain.js

// Meta-Learning endpoints extracted to routes/domain.js

// Multimodal, voice, tools, entity, research, sessions, search, stats, health — extracted to routes/domain.js and routes/system.js

// ===== END EXTENDED API ENDPOINTS =====




// ---- Invariant Enforcement: No-Crash (global Express error handler) ----
app.use((err, req, res, _next) => {
  const errorId = uid("err");
  const msg = String(err?.message || err || "Unknown error");
  const out = {
    ok: false,
    error: msg,
    mode: req?.body?.mode || "chat",
    sessionId: req?._concordSessionId || req?.body?.sessionId || req?.query?.sessionId || "default",
    llmUsed: false
  };
  try {
    return uiJson(res, _withAck(out, req, ["logs"], ["/api/logs"], { id: errorId, status: "error" }, { errorId }), req, { errorId });
  } catch {
    return res.status(500).json({
      ok: false,
      reply: "Internal error.",
      meta: { sessionId: out.sessionId, mode: out.mode, llmUsed: false, version: VERSION, errorId }
    });
  }
});
// ===== CHICKEN3: Autonomous Lattice Cron + Federation Hooks (additive) =====
function _c3internalCtx() {
  const ctx = makeCtx(null);
  ctx.actor = { userId: "system", orgId: "local", role: "owner", scopes: ["*"] };
  ctx.reqMeta = { ip: "127.0.0.1", ua: "cron", path: "/cron", override: false, at: nowISO() };
  return ctx;
}

async function latticeAutonomousTick() {
  try {
    if (!STATE.__chicken3?.enabled || !STATE.__chicken3?.cronEnabled) return;
    enforceEthosInvariant("autonomous_tick");
    STATE.__chicken3.stats.cronTicks++;
    STATE.__chicken3.lastCronAt = nowISO();

    // Keep organism alive (organs/growth/homeostasis). KernelTick already exists.
    // Cron is reserved for CHICKEN3 meta-support (emergents). DTU growth runs on the Governor heartbeat.
    // (Opt-in) If you ever want cron to also tick the kernel: set STATE.__chicken3.cronCallsKernelTick=true.
    if (STATE.__chicken3?.cronCallsKernelTick) { try { kernelTick({ type: "AUTONOMOUS_TICK", meta: { source: "cron" } }); } catch {} }

    if (!STATE.__chicken3?.metaEnabled) { saveStateDebounced(); return; }

    const ctx = _c3internalCtx();
    const minM = Number(STATE.__chicken3.metaMinMaturity ?? 0.75);
    const prob = Number(STATE.__chicken3.metaSampleProb ?? 0.10);

    // Generate a small number of meta proposals deterministically-ish to avoid spam.
    let proposalsMade = 0;
    for (const [organId, organ] of STATE.organs.entries()) {
      const m = Number(organ?.maturity?.score ?? organ?.maturityScore ?? 0);
      if (m < minM) continue;
      if (Math.random() > prob) continue;
      const out = await runMacro("chicken3","meta_propose", { organId }, ctx).catch(()=>null);
      if (out?.ok) proposalsMade++;
      if (proposalsMade >= 3) break;
    }

    // Quiet council commit (bounded)
    let commits = 0;
    while ((STATE.queues.metaProposals?.length || 0) > 0 && commits < 2) {
      const c = await runMacro("chicken3","meta_commit_quiet", {}, ctx).catch(()=>null);
      if (c?.ok) commits++;
      else break;
    }

    saveStateDebounced();
  } catch (e) {
    try { log("chicken3.cron.error", "Autonomous tick error", { error: String(e?.message||e) }); } catch {}
  }
}

function startChicken3Cron() {
  try {
    if (!STATE.__chicken3?.enabled || !STATE.__chicken3?.cronEnabled) return { ok:false, reason:"disabled" };
    const ms = clamp(Number(STATE.__chicken3?.cronIntervalMs ?? 300000), 15000, 3600000);
    setInterval(() => { latticeAutonomousTick(); }, ms);
    console.log(`[Chicken3] Autonomous cron active — interval ${(ms/60000).toFixed(2)} min`);
    return { ok:true, intervalMs: ms };
  } catch (e) {
    console.error("[Chicken3] Cron failed:", e);
    return { ok:false, error: String(e?.message||e) };
  }
}

// Optional federation (local-first). Does NOT auto-commit remote DTUs.
let _c3Federation = { enabled:false, client:null, channel:"lattice_broadcast" };
async function startChicken3Federation() {
  try {
    const on = (String(process.env.FEDERATION_ENABLED || "").toLowerCase() === "true") || Boolean(STATE.__chicken3?.federationEnabled);
    if (!on) return { ok:false, reason:"disabled" };
    enforceEthosInvariant("federation");
    const REDIS_URL = process.env.REDIS_URL || "redis://localhost:6379";
    const mod = await import("redis").catch(()=>null);
    if (!mod?.createClient) return { ok:false, error:"redis package not installed" };

    const client = mod.createClient({ url: REDIS_URL });
    client.on("error", (err) => console.error("[Chicken3][Federation] redis error:", err));
    await client.connect();

    const channel = String(process.env.FEDERATION_CHANNEL || "lattice_broadcast");
    await client.subscribe(channel, (message) => {
      try {
        STATE.__chicken3.stats.federationRx++;
        STATE.__chicken3.lastFederationAt = nowISO();
        // Local-first safety: do not auto apply. Queue for human/council review.
        const obj = safeJson(message, null);
        const proposal = { id: uid("federation"), type:"FEDERATION_RX", createdAt: nowISO(), content: message.slice(0, 20000), meta: { parsed: obj } };
        STATE.queues.metaProposals.push({ id: proposal.id, type:"META_DTU_PROPOSAL", createdAt: proposal.createdAt, proposerOrganId: "federation", maturity: 1, content: `[FEDERATION] ${proposal.content.slice(0, 800)}`, tags:["meta","federation"], meta: proposal.meta });
        saveStateDebounced();
      } catch {}
    });

    _c3Federation = { enabled:true, client, channel };
    console.log(`[Chicken3] Federation enabled — channel ${channel}`);
    return { ok:true, channel };
  } catch (e) {
    console.error("[Chicken3] Federation failed:", e);
    return { ok:false, error:String(e?.message||e) };
  }
}

// Publish DTU/event to federation channel (Redis pub/sub)
async function federationPublish(eventType, payload) {
  if (!_c3Federation.enabled || !_c3Federation.client) {
    return { ok: false, reason: "federation_not_enabled" };
  }
  try {
    const msg = JSON.stringify({
      type: eventType,
      nodeId: process.env.NODE_ID || "local",
      payload,
      ts: nowISO()
    });
    // Redis publish requires a separate client (subscriber can't publish)
    // Create a publisher client on first use
    if (!_c3Federation.publisher) {
      const mod = await import("redis").catch(() => null);
      if (!mod?.createClient) return { ok: false, error: "redis unavailable" };
      const REDIS_URL = process.env.REDIS_URL || "redis://localhost:6379";
      _c3Federation.publisher = mod.createClient({ url: REDIS_URL });
      _c3Federation.publisher.on("error", (err) => console.error("[Federation][Pub] error:", err));
      await _c3Federation.publisher.connect();
    }
    await _c3Federation.publisher.publish(_c3Federation.channel, msg);
    STATE.__chicken3.stats.federationTx = (STATE.__chicken3.stats.federationTx || 0) + 1;
    return { ok: true };
  } catch (e) {
    console.error("[Federation] Publish failed:", e);
    return { ok: false, error: String(e?.message || e) };
  }
}


// ===== GOVERNOR: Heartbeat-driven autonomous growth (DTU creation) =====
// Purpose: keep DTU growth engines (autogen/dream/evolution/synth + queues) running
// independently from Chicken3 cron (which is reserved for emergent/meta support).
let __governorTimer = null;

function _governorCtx() {
  // internal ctx: owner actor + founder override flag for safe local growth operations
  const ctx = makeCtx(null);
  ctx.actor = { role: "owner", scopes: ["*"] };
  ctx.reqMeta = { ...(ctx.reqMeta||{}), override: true, internal: true, source: "governor" };
  return ctx;
}

async function governorTick(reason="heartbeat") {
  try {
    const s = STATE.settings || {};
    if (s.heartbeatEnabled === false) return { ok:false, reason:"heartbeat_disabled" };
    const ctx = _governorCtx();

    // 1) Deterministic + bounded growth engines
    if (s.autogenEnabled)  { try { await runMacro("system","autogen",{ override:true, reason }, ctx); } catch {} }
    if (s.dreamEnabled)    { try { await runMacro("system","dream",{ override:true, reason }, ctx); } catch {} }
    if (s.evolutionEnabled){ try { await runMacro("system","evolution",{ override:true, reason }, ctx); } catch {} }
    if (s.synthEnabled)    { try { await runMacro("system","synth",{ override:true, reason }, ctx); } catch {} }

    // 2) Queue processing (best-effort; only if macros exist)
    try { await runMacro("jobs","tick",{ override:true, reason }, ctx); } catch {}
    try { await runMacro("queue","tick",{ override:true, reason }, ctx); } catch {}
    try { await runMacro("ingest","tick",{ override:true, reason }, ctx); } catch {}
    try { await runMacro("crawl","tick",{ override:true, reason }, ctx); } catch {}

    // 2.5) Goal System: process goal proposals and track active goals
    try { await processGoalHeartbeat(ctx); } catch {}

    // 2.6) Autonomous Agent Scheduler: tick enabled agents at their cadenceMs
    try { await tickEnabledAgents(ctx); } catch {}

    // 3) Kernel metrics tick (homeostasis, organ wear) so the system stays honest
    try { kernelTick({ type: "HEARTBEAT", meta: { source: "governor", reason } }); } catch {}

    return { ok:true };
  } catch (e) {
    return { ok:false, error:String(e?.message||e) };
  }
}

function _startGovernorHeartbeat() {
  try {
    if (__governorTimer) return { ok:true, already:true };
    const s = STATE.settings || {};
    const ms = clamp(Number(s.heartbeatMs ?? 15000), 1000, 10*60*1000);
    if (s.heartbeatEnabled === false) return { ok:false, reason:"heartbeat_disabled" };
    __governorTimer = setInterval(() => { governorTick("interval").catch(()=>{}); }, ms);
    console.log(`[Governor] Heartbeat active — interval ${(ms/1000).toFixed(2)}s`);
    // fire once on boot (after a short delay so macros/STATE are warmed)
    setTimeout(() => { governorTick("boot").catch(()=>{}); }, 2000);
    return { ok:true, intervalMs: ms };
  } catch (e) {
    console.warn("[Governor] failed to start:", String(e?.message||e));
    return { ok:false, error:String(e?.message||e) };
  }
}
// ===== END GOVERNOR =====

// Start Chicken3 services on boot (additive)
try { startChicken3Cron(); } catch {}
try { startChicken3Federation(); } catch {}
// ===== END CHICKEN3: Cron + Federation =====

// ============================================================================
// CONCORD ENHANCEMENTS v3.1 - Search, Query DSL, Local LLM, Export, Plugins
// ============================================================================

// ---- Search Indexing (MiniSearch-like in-memory index) ----
const SEARCH_INDEX = {
  documents: new Map(),
  invertedIndex: new Map(),
  fieldBoosts: { title: 2.0, tags: 1.5, summary: 1.2, content: 1.0 },
  dirty: true
};

function tokenizeForIndex(text) {
  return String(text || "").toLowerCase()
    .replace(/[^\w\s]/g, " ")
    .split(/\s+/)
    .filter(t => t.length > 1 && t.length < 40);
}

function rebuildSearchIndex() {
  SEARCH_INDEX.invertedIndex.clear();
  SEARCH_INDEX.documents.clear();

  for (const dtu of dtusArray()) {
    const docTokens = new Map();
    const fields = {
      title: dtu.title || "",
      tags: (dtu.tags || []).join(" "),
      summary: dtu.human?.summary || dtu.cretiHuman || "",
      content: [
        ...(dtu.core?.definitions || []),
        ...(dtu.core?.invariants || []),
        ...(dtu.core?.claims || [])
      ].join(" ")
    };

    for (const [field, text] of Object.entries(fields)) {
      const tokens = tokenizeForIndex(text);
      const boost = SEARCH_INDEX.fieldBoosts[field] || 1.0;
      for (const token of tokens) {
        docTokens.set(token, (docTokens.get(token) || 0) + boost);
      }
    }

    SEARCH_INDEX.documents.set(dtu.id, { id: dtu.id, tokens: docTokens, tier: dtu.tier });

    for (const [token, score] of docTokens) {
      if (!SEARCH_INDEX.invertedIndex.has(token)) {
        SEARCH_INDEX.invertedIndex.set(token, new Map());
      }
      SEARCH_INDEX.invertedIndex.get(token).set(dtu.id, score);
    }
  }
  SEARCH_INDEX.dirty = false;
  log("search", "Search index rebuilt", { documents: SEARCH_INDEX.documents.size, terms: SEARCH_INDEX.invertedIndex.size });
}

function searchIndexed(query, { limit = 20, minScore = 0.01 } = {}) {
  if (SEARCH_INDEX.dirty) rebuildSearchIndex();

  const queryTokens = tokenizeForIndex(query);
  if (!queryTokens.length) return [];

  const scores = new Map();
  const idf = new Map();
  const N = SEARCH_INDEX.documents.size || 1;

  for (const token of queryTokens) {
    const docs = SEARCH_INDEX.invertedIndex.get(token);
    if (docs) {
      const docFreq = docs.size;
      idf.set(token, Math.log(1 + N / (docFreq + 1)));
      for (const [docId, tf] of docs) {
        const tfidf = tf * idf.get(token);
        scores.set(docId, (scores.get(docId) || 0) + tfidf);
      }
    }
  }

  const results = Array.from(scores.entries())
    .map(([id, score]) => ({ id, score: score / queryTokens.length }))
    .filter(r => r.score >= minScore)
    .sort((a, b) => b.score - a.score)
    .slice(0, limit);

  // Filter out shadow DTUs - they are internal and should not appear in search results
  return results.map(r => ({ ...STATE.dtus.get(r.id), _searchScore: r.score })).filter(d => d && !isShadowDTU(d));
}

// Mark index dirty on DTU changes
const _originalDtuSet = STATE.dtus.set.bind(STATE.dtus);
STATE.dtus.set = function(key, value) {
  SEARCH_INDEX.dirty = true;
  return _originalDtuSet(key, value);
};

// Force initial search index build so first queries don't hit cold index
if (STATE.dtus.size > 0) {
  rebuildSearchIndex();
}

// ---- Query DSL Parser ----
function parseQueryDSL(queryString) {
  const conditions = [];
  const parts = String(queryString || "").match(/(\w+:[^\s]+|"[^"]+"|[^\s]+)/g) || [];
  const freeText = [];

  for (const part of parts) {
    if (part.includes(":")) {
      const [field, ...valueParts] = part.split(":");
      const value = valueParts.join(":").replace(/^"|"$/g, "");
      conditions.push({ field: field.toLowerCase(), value, op: "eq" });
    } else if (part.startsWith(">") || part.startsWith("<")) {
      const op = part[0] === ">" ? "gt" : "lt";
      const field = part.slice(1).split(":")[0];
      const value = part.split(":")[1];
      if (field && value) conditions.push({ field, value: parseFloat(value), op });
    } else {
      freeText.push(part);
    }
  }

  return { conditions, freeText: freeText.join(" ") };
}

function queryDTUs(queryString, { limit = 50 } = {}) {
  const { conditions, freeText } = parseQueryDSL(queryString);
  let results = dtusArray();

  for (const cond of conditions) {
    results = results.filter(dtu => {
      const dtuValue = cond.field === "tier" ? dtu.tier :
                       cond.field === "tag" || cond.field === "tags" ? (dtu.tags || []).join(",").toLowerCase() :
                       cond.field === "title" ? (dtu.title || "").toLowerCase() :
                       cond.field === "crispness" ? (dtu.meta?.crispness || 0) :
                       cond.field === "id" ? dtu.id :
                       cond.field === "source" ? (dtu.source || "") :
                       null;

      if (dtuValue === null) return true;

      if (cond.op === "eq") {
        if (typeof dtuValue === "string") return dtuValue.includes(cond.value.toLowerCase());
        return dtuValue === cond.value;
      }
      if (cond.op === "gt") return dtuValue > cond.value;
      if (cond.op === "lt") return dtuValue < cond.value;
      return true;
    });
  }

  if (freeText) {
    const indexed = searchIndexed(freeText, { limit: 1000, minScore: 0.001 });
    const indexedIds = new Set(indexed.map(d => d.id));
    results = results.filter(d => indexedIds.has(d.id));
    results.sort((a, b) => {
      const aScore = indexed.find(x => x.id === a.id)?._searchScore || 0;
      const bScore = indexed.find(x => x.id === b.id)?._searchScore || 0;
      return bScore - aScore;
    });
  }

  return results.slice(0, limit);
}

register("search", "query", (ctx, input) => {
  const q = String(input.q || input.query || "");
  const limit = clamp(Number(input.limit || 50), 1, 500);
  const results = queryDTUs(q, { limit });
  return { ok: true, query: q, count: results.length, dtus: results };
});

register("search", "reindex", (_ctx, _input) => {
  rebuildSearchIndex();
  return { ok: true, documents: SEARCH_INDEX.documents.size, terms: SEARCH_INDEX.invertedIndex.size };
});

// ---- Local LLM Support (Ollama) ----
const OLLAMA_BASE_URL = process.env.OLLAMA_BASE_URL || "http://localhost:11434";
const OLLAMA_MODEL = process.env.OLLAMA_MODEL || "llama3.2";
const OLLAMA_ENABLED = process.env.OLLAMA_ENABLED === "true" || process.env.OLLAMA_ENABLED === "1";

async function ollamaChat(messages, { temperature = 0.7, max_tokens = 1000 } = {}) {
  if (!OLLAMA_ENABLED) return { ok: false, error: "Ollama not enabled" };
  try {
    const response = await fetch(`${OLLAMA_BASE_URL}/api/chat`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        model: OLLAMA_MODEL,
        messages: messages.map(m => ({ role: m.role, content: m.content })),
        stream: false,
        options: { temperature, num_predict: max_tokens }
      })
    });
    if (!response.ok) throw new Error(`Ollama error: ${response.status}`);
    const data = await response.json();
    return { ok: true, text: data.message?.content || "", model: OLLAMA_MODEL, source: "ollama" };
  } catch (e) {
    return { ok: false, error: String(e?.message || e), source: "ollama" };
  }
}

async function ollamaEmbed(text) {
  if (!OLLAMA_ENABLED) return { ok: false, error: "Ollama not enabled" };
  try {
    const response = await fetch(`${OLLAMA_BASE_URL}/api/embeddings`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ model: OLLAMA_MODEL, prompt: String(text || "").slice(0, 8000) })
    });
    if (!response.ok) throw new Error(`Ollama embedding error: ${response.status}`);
    const data = await response.json();
    return { ok: true, embedding: data.embedding, dimensions: data.embedding?.length || 0 };
  } catch (e) {
    return { ok: false, error: String(e?.message || e) };
  }
}

register("llm", "local", async (ctx, input) => {
  const messages = Array.isArray(input.messages) ? input.messages : [{ role: "user", content: String(input.prompt || input.message || "") }];
  const result = await ollamaChat(messages, { temperature: input.temperature, max_tokens: input.max_tokens });
  return result;
});

register("llm", "embed", (ctx, input) => {
  return ollamaEmbed(String(input.text || ""));
});

// ---- Export/Import System ----
register("export", "markdown", (ctx, input) => {
  const dtus = input.ids ? input.ids.map(id => STATE.dtus.get(id)).filter(Boolean) : dtusArray();
  const lines = ["# Concord DTU Export", `Exported: ${nowISO()}`, `Count: ${dtus.length}`, ""];

  for (const dtu of dtus) {
    lines.push(`## ${dtu.title || "Untitled"}`);
    lines.push(`**ID:** ${dtu.id} | **Tier:** ${dtu.tier || "regular"} | **Tags:** ${(dtu.tags || []).join(", ")}`);
    lines.push("");
    if (dtu.human?.summary) lines.push(`> ${dtu.human.summary}`, "");
    if (dtu.core?.definitions?.length) {
      lines.push("### Definitions");
      dtu.core.definitions.forEach(d => lines.push(`- ${d}`));
      lines.push("");
    }
    if (dtu.core?.invariants?.length) {
      lines.push("### Invariants");
      dtu.core.invariants.forEach(i => lines.push(`- ${i}`));
      lines.push("");
    }
    if (dtu.core?.claims?.length) {
      lines.push("### Claims");
      dtu.core.claims.forEach(c => lines.push(`- ${c}`));
      lines.push("");
    }
    lines.push("---", "");
  }

  return { ok: true, format: "markdown", content: lines.join("\n"), count: dtus.length };
});

register("export", "obsidian", (ctx, input) => {
  const dtus = input.ids ? input.ids.map(id => STATE.dtus.get(id)).filter(Boolean) : dtusArray();
  const files = [];

  for (const dtu of dtus) {
    const filename = `${(dtu.title || "Untitled").replace(/[^\w\s-]/g, "").slice(0, 50)}.md`;
    const content = [
      "---",
      `id: ${dtu.id}`,
      `tier: ${dtu.tier || "regular"}`,
      `tags: [${(dtu.tags || []).map(t => `"${t}"`).join(", ")}]`,
      `created: ${dtu.createdAt || nowISO()}`,
      "---",
      "",
      `# ${dtu.title || "Untitled"}`,
      "",
      dtu.human?.summary || "",
      "",
      "## Core",
      "",
      "### Definitions",
      ...(dtu.core?.definitions || []).map(d => `- ${d}`),
      "",
      "### Invariants",
      ...(dtu.core?.invariants || []).map(i => `- ${i}`),
      "",
      "### Claims",
      ...(dtu.core?.claims || []).map(c => `- ${c}`),
      "",
      "## Lineage",
      ...(dtu.lineage || []).map(id => `- [[${id}]]`)
    ].join("\n");

    files.push({ filename, content });
  }

  return { ok: true, format: "obsidian", files, count: files.length };
});

register("export", "json", (ctx, input) => {
  const dtus = input.ids ? input.ids.map(id => STATE.dtus.get(id)).filter(Boolean) : dtusArray();
  return { ok: true, format: "json", dtus, count: dtus.length };
});

register("import", "json", (ctx, input) => {
  const dtus = Array.isArray(input.dtus) ? input.dtus : [];
  let imported = 0, skipped = 0;

  for (const dtu of dtus) {
    if (!dtu.id || !dtu.title) { skipped++; continue; }
    if (STATE.dtus.has(dtu.id) && !input.overwrite) { skipped++; continue; }

    const normalized = {
      id: dtu.id,
      title: normalizeText(dtu.title),
      tier: dtu.tier || "regular",
      tags: Array.isArray(dtu.tags) ? dtu.tags : [],
      human: dtu.human || {},
      core: dtu.core || {},
      machine: dtu.machine || {},
      lineage: dtu.lineage || [],
      source: "import",
      createdAt: dtu.createdAt || nowISO(),
      updatedAt: nowISO(),
      meta: { ...dtu.meta, importedAt: nowISO() }
    };

    STATE.dtus.set(normalized.id, normalized);
    imported++;
  }

  if (imported > 0) saveStateDebounced();
  return { ok: true, imported, skipped, total: dtus.length };
});

register("import", "markdown", (ctx, input) => {
  const content = String(input.content || "");
  const sections = content.split(/^## /m).filter(Boolean);
  const dtus = [];

  for (const section of sections) {
    const lines = section.split("\n");
    const title = lines[0]?.trim();
    if (!title || title.startsWith("#")) continue;

    const dtu = {
      id: uid("dtu"),
      title,
      tier: "regular",
      tags: ["imported"],
      human: { summary: "" },
      core: { definitions: [], invariants: [], claims: [], examples: [] },
      source: "import-markdown",
      createdAt: nowISO()
    };

    let currentSection = null;
    for (const line of lines.slice(1)) {
      if (line.startsWith("### Definitions")) currentSection = "definitions";
      else if (line.startsWith("### Invariants")) currentSection = "invariants";
      else if (line.startsWith("### Claims")) currentSection = "claims";
      else if (line.startsWith(">")) dtu.human.summary = line.slice(1).trim();
      else if (line.startsWith("- ") && currentSection) {
        dtu.core[currentSection].push(line.slice(2).trim());
      }
    }

    dtus.push(dtu);
  }

  let imported = 0;
  for (const dtu of dtus) {
    STATE.dtus.set(dtu.id, dtu);
    imported++;
  }

  if (imported > 0) saveStateDebounced();
  return { ok: true, imported, parsed: dtus.length };
});

// ---- Plugin/Extension System (Macro-based) ----
// Note: PLUGINS Map is declared above in Wave 3. This adds macro-based registration.

function registerPluginFromMacro(name, config) {
  const plugin = {
    name,
    version: config.version || "1.0.0",
    description: config.description || "",
    macros: config.macros || {},
    hooks: config.hooks || {},
    enabled: config.enabled !== false,
    registeredAt: nowISO()
  };

  // Register plugin macros
  for (const [macroName, handler] of Object.entries(plugin.macros)) {
    const [domain, op] = macroName.split(".");
    if (domain && op && typeof handler === "function") {
      register(domain, op, handler);
    }
  }

  PLUGINS.set(name, plugin);
  log("plugin", `Plugin registered: ${name}`, { version: plugin.version });
  return plugin;
}

register("plugin", "register", (ctx, input) => {
  if (!input.name) return { ok: false, error: "Plugin name required" };
  const plugin = registerPluginFromMacro(input.name, input);
  return { ok: true, plugin: { name: plugin.name, version: plugin.version } };
});

register("plugin", "list", (_ctx, _input) => {
  const plugins = Array.from(PLUGINS.values()).map(p => ({
    name: p.name,
    version: p.version,
    description: p.description,
    enabled: p.enabled,
    macroCount: Object.keys(p.macros).length
  }));
  return { ok: true, plugins, count: plugins.length };
});

register("plugin", "enable", (ctx, input) => {
  const plugin = PLUGINS.get(input.name);
  if (!plugin) return { ok: false, error: "Plugin not found" };
  plugin.enabled = true;
  return { ok: true, name: plugin.name, enabled: true };
});

register("plugin", "disable", (ctx, input) => {
  const plugin = PLUGINS.get(input.name);
  if (!plugin) return { ok: false, error: "Plugin not found" };
  plugin.enabled = false;
  return { ok: true, name: plugin.name, enabled: false };
});

// ---- Enhanced Council with Vote Tallying ----
if (!STATE.councilVotes) STATE.councilVotes = new Map();

register("council", "vote", (ctx, input) => {
  const { dtuId, vote, persona, reason } = input;
  if (!dtuId || !vote) return { ok: false, error: "dtuId and vote required" };
  if (!["approve", "reject", "abstain"].includes(vote)) return { ok: false, error: "Invalid vote" };

  // ---- Duplicate Vote Prevention (Category 2: Concurrency) ----
  const voterId = ctx?.actor?.id || ctx?.actor?.odId || persona || "anonymous";
  if (STATE.councilVotes.has(dtuId)) {
    const existingVotes = STATE.councilVotes.get(dtuId);
    const duplicateVote = existingVotes.find(v => v.voterId === voterId);
    if (duplicateVote) {
      return {
        ok: false,
        error: "Already voted on this DTU",
        code: "DUPLICATE_VOTE",
        existingVote: duplicateVote.vote,
        votedAt: duplicateVote.timestamp,
      };
    }
  }

  const voteRecord = {
    id: uid("vote"),
    dtuId,
    vote,
    voterId,
    persona: persona || "anonymous",
    reason: reason || "",
    timestamp: nowISO(),
    weight: 1.0
  };

  if (!STATE.councilVotes.has(dtuId)) STATE.councilVotes.set(dtuId, []);
  STATE.councilVotes.get(dtuId).push(voteRecord);
  saveStateDebounced();

  return { ok: true, vote: voteRecord };
});

register("council", "tally", (ctx, input) => {
  const { dtuId } = input;
  if (!dtuId) return { ok: false, error: "dtuId required" };

  const votes = STATE.councilVotes.get(dtuId) || [];
  const tally = { approve: 0, reject: 0, abstain: 0, total: votes.length };

  for (const v of votes) {
    tally[v.vote] = (tally[v.vote] || 0) + v.weight;
  }

  tally.approved = tally.approve > tally.reject;
  tally.margin = tally.approve - tally.reject;
  tally.quorum = votes.length >= 3;

  return { ok: true, dtuId, tally, votes };
});

register("council", "credibility", (ctx, input) => {
  const { dtuId, score, reason } = input;
  const dtu = STATE.dtus.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };

  dtu.authority = dtu.authority || {};
  dtu.authority.credibility = clamp(Number(score || 0.5), 0, 1);
  dtu.authority.credibilityReason = reason || "";
  dtu.authority.credibilityAt = nowISO();

  STATE.dtus.set(dtuId, dtu);
  saveStateDebounced();

  return { ok: true, dtuId, credibility: dtu.authority.credibility };
});

// ---- User-Defined Personas ----
if (!STATE.customPersonas) STATE.customPersonas = new Map();

register("persona", "create", (ctx, input) => {
  const { name, description, style, traits } = input;
  if (!name) return { ok: false, error: "Persona name required" };

  const persona = {
    id: uid("persona"),
    name: normalizeText(name),
    description: description || "",
    style: {
      verbosity: clamp(Number(style?.verbosity ?? 0.5), 0, 1),
      formality: clamp(Number(style?.formality ?? 0.5), 0, 1),
      skepticism: clamp(Number(style?.skepticism ?? 0.5), 0, 1),
      creativity: clamp(Number(style?.creativity ?? 0.5), 0, 1),
      empathy: clamp(Number(style?.empathy ?? 0.5), 0, 1)
    },
    traits: Array.isArray(traits) ? traits : [],
    systemPrompt: input.systemPrompt || "",
    createdAt: nowISO(),
    updatedAt: nowISO(),
    usageCount: 0
  };

  STATE.customPersonas.set(persona.id, persona);
  saveStateDebounced();

  return { ok: true, persona };
});

register("persona", "list", (_ctx, _input) => {
  const builtIn = [
    { id: "ethicist", name: "Ethicist", description: "Focuses on moral implications", builtin: true },
    { id: "engineer", name: "Engineer", description: "Practical, implementation-focused", builtin: true },
    { id: "historian", name: "Historian", description: "Historical context and precedent", builtin: true },
    { id: "economist", name: "Economist", description: "Economic analysis and trade-offs", builtin: true }
  ];
  const custom = Array.from(STATE.customPersonas.values());
  return { ok: true, personas: [...builtIn, ...custom], builtInCount: builtIn.length, customCount: custom.length };
});

register("persona", "update", (ctx, input) => {
  const persona = STATE.customPersonas.get(input.id);
  if (!persona) return { ok: false, error: "Persona not found" };

  if (input.name) persona.name = normalizeText(input.name);
  if (input.description) persona.description = input.description;
  if (input.style) persona.style = { ...persona.style, ...input.style };
  if (input.traits) persona.traits = input.traits;
  if (input.systemPrompt) persona.systemPrompt = input.systemPrompt;
  persona.updatedAt = nowISO();

  STATE.customPersonas.set(persona.id, persona);
  saveStateDebounced();

  return { ok: true, persona };
});

register("persona", "delete", (ctx, input) => {
  if (!STATE.customPersonas.has(input.id)) return { ok: false, error: "Persona not found" };
  STATE.customPersonas.delete(input.id);
  saveStateDebounced();
  return { ok: true, deleted: input.id };
});

// ---- Admin Dashboard Endpoints ----
register("admin", "dashboard", (_ctx, _input) => {
  const uptime = process.uptime();
  const memory = process.memoryUsage();

  return {
    ok: true,
    system: {
      version: VERSION,
      uptime: { seconds: uptime, formatted: `${Math.floor(uptime/3600)}h ${Math.floor((uptime%3600)/60)}m` },
      memory: {
        heapUsed: Math.round(memory.heapUsed / 1024 / 1024) + "MB",
        heapTotal: Math.round(memory.heapTotal / 1024 / 1024) + "MB",
        rss: Math.round(memory.rss / 1024 / 1024) + "MB"
      },
      nodeVersion: process.version
    },
    dtus: {
      total: STATE.dtus.size,
      regular: dtusArray().filter(d => d.tier === "regular").length,
      mega: dtusArray().filter(d => d.tier === "mega").length,
      hyper: dtusArray().filter(d => d.tier === "hyper").length,
      shadow: STATE.shadowDtus?.size || 0
    },
    sessions: {
      total: STATE.sessions?.size || 0,
      active: Array.from(STATE.sessions?.values() || []).filter(s => {
        const lastMsg = s.messages?.[s.messages.length - 1];
        return lastMsg && (Date.now() - new Date(lastMsg.timestamp).getTime()) < 3600000;
      }).length
    },
    organs: {
      total: STATE.organs?.size || 0,
      healthy: Array.from(STATE.organs?.values() || []).filter(o => (o.maturity?.score || 0) > 0.5).length
    },
    llm: {
      openaiReady: LLM_READY,
      ollamaEnabled: OLLAMA_ENABLED,
      defaultOn: DEFAULT_LLM_ON
    },
    queues: {
      maintenance: STATE.queues?.maintenance?.length || 0,
      synthesis: STATE.queues?.synthesis?.length || 0,
      hypotheses: STATE.queues?.hypotheses?.length || 0
    },
    plugins: {
      total: PLUGINS.size,
      enabled: Array.from(PLUGINS.values()).filter(p => p.enabled).length
    },
    searchIndex: {
      documents: SEARCH_INDEX.documents.size,
      terms: SEARCH_INDEX.invertedIndex.size,
      dirty: SEARCH_INDEX.dirty
    }
  };
});

register("admin", "logs", (ctx, input) => {
  const limit = clamp(Number(input.limit || 100), 1, 1000);
  const type = input.type || null;

  let logs = STATE.__logs || [];
  if (type) logs = logs.filter(l => l.type === type);
  logs = logs.slice(-limit);

  return { ok: true, logs, count: logs.length };
});

register("admin", "metrics", (_ctx, _input) => {
  const chicken2 = STATE.__chicken2 || {};
  const growth = STATE.growth || {};
  const abstraction = STATE.abstraction || {};

  return {
    ok: true,
    chicken2: {
      continuityAvg: chicken2.metrics?.continuityAvg || 0,
      homeostasis: chicken2.metrics?.homeostasis || 0.8,
      contradictionLoad: chicken2.metrics?.contradictionLoad || 0,
      suffering: chicken2.metrics?.suffering || 0,
      accepts: chicken2.metrics?.accepts || 0,
      rejects: chicken2.metrics?.rejects || 0
    },
    growth: {
      bioAge: growth.bioAge || 0,
      telomere: growth.telomere || 1,
      homeostasis: growth.homeostasis || 0.9,
      stress: growth.stress || { acute: 0, chronic: 0 }
    },
    abstraction: {
      load: abstraction.metrics?.load || 0,
      margin: abstraction.metrics?.margin || 1,
      enabled: abstraction.enabled !== false
    }
  };
});

// ---- Pagination Helper ----
function paginateResults(items, { page = 1, pageSize = 20 } = {}) {
  const total = items.length;
  const totalPages = Math.ceil(total / pageSize);
  const start = (page - 1) * pageSize;
  const end = start + pageSize;

  return {
    items: items.slice(start, end),
    pagination: {
      page,
      pageSize,
      total,
      totalPages,
      hasNext: page < totalPages,
      hasPrev: page > 1
    }
  };
}

// Enhanced API endpoints (search, llm, export/import, plugins, council, personas, admin, dtus/paginated)
// extracted to routes/domain.js and routes/system.js

// ============================================================================
// SCHEMA EVOLUTION & MIGRATION (Tier 2)
// ============================================================================
const _SCHEMA_REGISTRY = {
  // domain.type -> { currentVersion, migrations: { fromVersion -> migrationFn } }
  schemas: new Map(),

  register(domain, type, version, migrateFn) {
    const key = `${domain}.${type}`;
    if (!this.schemas.has(key)) {
      this.schemas.set(key, { currentVersion: version, migrations: new Map() });
    }
    const entry = this.schemas.get(key);
    entry.currentVersion = Math.max(entry.currentVersion, version);
    if (migrateFn) entry.migrations.set(version - 1, migrateFn); // migrates from version-1 to version
  },

  // Lazy migration: called when reading an artifact, upgrades in-place if needed
  migrate(artifact) {
    if (!artifact?.domain || !artifact?.type) return artifact;
    const key = `${artifact.domain}.${artifact.type}`;
    const schema = this.schemas.get(key);
    if (!schema) return artifact; // No schema registered, pass through

    let version = artifact.schemaVersion || artifact.version || 1;
    let migrated = false;

    while (version < schema.currentVersion) {
      const migrateFn = schema.migrations.get(version);
      if (!migrateFn) break; // No migration path, stop

      try {
        artifact.data = migrateFn(artifact.data, artifact);
        version++;
        migrated = true;
      } catch (e) {
        structuredLog("error", "schema_migration_failed", { key, from: version, to: version + 1, error: String(e?.message || e) });
        break;
      }
    }

    if (migrated) {
      artifact.schemaVersion = version;
      artifact.updatedAt = nowISO();
      STATE.lensArtifacts.set(artifact.id, artifact);
      saveStateDebounced();
      structuredLog("info", "schema_migrated", { id: artifact.id, key, from: artifact.schemaVersion || 1, to: version });
    }

    return artifact;
  },

  stats() {
    const result = {};
    for (const [key, entry] of this.schemas) {
      result[key] = { currentVersion: entry.currentVersion, migrationCount: entry.migrations.size };
    }
    return result;
  }
};

// Register known schema migrations
_SCHEMA_REGISTRY.register("accounting", "trial-balance", 2, (data) => {
  // v1 -> v2: Add currency field if missing
  if (!data.currency) data.currency = "USD";
  if (!data.fiscalYear) data.fiscalYear = new Date().getFullYear();
  return data;
});
_SCHEMA_REGISTRY.register("accounting", "invoice", 2, (data) => {
  // v1 -> v2: Normalize line items
  if (data.items && !data.lineItems) { data.lineItems = data.items; delete data.items; }
  if (!data.status) data.status = "draft";
  return data;
});

// ============================================================================
// FEDERATION TRUST MODEL (Tier 3)
// ============================================================================
const _FEDERATION_TRUST = {
  // Node identity
  nodeId: process.env.FEDERATION_NODE_ID || uid("node"),
  nodeSecret: process.env.FEDERATION_SECRET || crypto.randomBytes(32).toString("hex"),

  // Known trusted nodes
  trustedNodes: new Map(), // nodeId -> { publicKey, addedAt, lastSeenAt, trustScore }

  // Sign a DTU payload for federation
  signPayload(payload) {
    const data = JSON.stringify({ ...payload, _nodeId: this.nodeId, _ts: nowISO() });
    const signature = crypto.createHmac("sha256", this.nodeSecret).update(data).digest("hex");
    return { data, signature, nodeId: this.nodeId };
  },

  // Verify a signed payload from another node
  verifyPayload(signedPayload) {
    const { data, signature, nodeId } = signedPayload || {};
    if (!data || !signature || !nodeId) return { valid: false, reason: "missing_fields" };

    const trustedNode = this.trustedNodes.get(nodeId);
    if (!trustedNode) return { valid: false, reason: "unknown_node" };

    // Verify signature using the trusted node's shared secret
    const expected = crypto.createHmac("sha256", trustedNode.sharedSecret || "").update(data).digest("hex");
    try {
      const valid = crypto.timingSafeEqual(Buffer.from(signature, "hex"), Buffer.from(expected, "hex"));
      if (valid) trustedNode.lastSeenAt = nowISO();
      return { valid, reason: valid ? "ok" : "signature_mismatch" };
    } catch {
      return { valid: false, reason: "verification_error" };
    }
  },

  // Verify DTU content hash matches claimed hash
  verifyContentHash(dtu) {
    if (!dtu?.hash || !dtu?.title) return { valid: false, reason: "missing_hash" };
    const computed = crypto.createHash("sha256").update((dtu.title || "") + "\n" + (dtu.cretiHuman || "")).digest("hex").slice(0, 16);
    return { valid: computed === dtu.hash, computed, claimed: dtu.hash };
  },

  // Register a trusted node
  addTrustedNode(nodeId, sharedSecret) {
    this.trustedNodes.set(nodeId, {
      sharedSecret,
      addedAt: nowISO(),
      lastSeenAt: null,
      trustScore: 0.5,
    });
  },

  stats() {
    return {
      nodeId: this.nodeId,
      trustedNodes: this.trustedNodes.size,
      nodes: Array.from(this.trustedNodes.entries()).map(([id, n]) => ({
        id, addedAt: n.addedAt, lastSeenAt: n.lastSeenAt, trustScore: n.trustScore,
      })),
    };
  }
};

// Federation endpoints
app.get("/api/federation/status", (req, res) => {
  res.json({ ok: true, federation: _FEDERATION_TRUST.stats(), enabled: _c3Federation?.enabled || false });
});

app.post("/api/federation/trust-node", requireRole("owner", "admin"), (req, res) => {
  const { nodeId, sharedSecret } = req.body;
  if (!nodeId || !sharedSecret) return res.status(400).json({ ok: false, error: "nodeId and sharedSecret required" });
  _FEDERATION_TRUST.addTrustedNode(nodeId, sharedSecret);
  auditLog("admin", "federation_trust_added", { nodeId, userId: req.user?.id });
  res.json({ ok: true, trusted: _FEDERATION_TRUST.trustedNodes.size });
});

app.post("/api/federation/verify", (req, res) => {
  const result = _FEDERATION_TRUST.verifyPayload(req.body);
  res.json({ ok: result.valid, verification: result });
});

// ============================================================================
// OBSERVABILITY ALERTING PIPELINE (Tier 3)
// ============================================================================
const _ALERTING = {
  rules: [
    { id: "p95_latency", name: "High P95 Latency", check: () => _LATENCY.percentile(95) > _LATENCY.slowThresholdMs, severity: "warning" },
    { id: "circuit_open", name: "LLM Circuit Breaker Open", check: () => _LLM_BUDGET.circuitOpen, severity: "critical" },
    { id: "budget_80pct", name: "LLM Budget >80%", check: () => _LLM_BUDGET.totalTokensUsed > _LLM_BUDGET.globalBudgetTokens * 0.8, severity: "warning" },
    { id: "budget_exhausted", name: "LLM Budget Exhausted", check: () => _LLM_BUDGET.totalTokensUsed >= _LLM_BUDGET.globalBudgetTokens, severity: "critical" },
    { id: "shadow_overflow", name: "Shadow DTU Overflow", check: () => STATE.shadowDtus.size > 1800, severity: "warning" },
    { id: "ws_disconnect", name: "WebSocket Disconnected", check: () => REALTIME.ready && (REALTIME.clients?.size || 0) === 0, severity: "info" },
  ],

  activeAlerts: new Map(), // ruleId -> { firedAt, severity, message }
  webhooks: [], // registered webhook URLs for alerting
  history: [], // last 100 alert events

  evaluate() {
    const fired = [];
    for (const rule of this.rules) {
      try {
        const triggered = rule.check();
        if (triggered && !this.activeAlerts.has(rule.id)) {
          // New alert
          const alert = { ruleId: rule.id, name: rule.name, severity: rule.severity, firedAt: nowISO() };
          this.activeAlerts.set(rule.id, alert);
          this.history.push({ ...alert, type: "fired" });
          if (this.history.length > 100) this.history.shift();
          fired.push(alert);

          // Emit via Socket.io
          realtimeEmit("system:alert", { alert, type: "fired" });

          // Fire webhooks
          this.fireWebhooks(alert);

          structuredLog("warn", "alert_fired", alert);
        } else if (!triggered && this.activeAlerts.has(rule.id)) {
          // Alert resolved
          const resolved = { ruleId: rule.id, name: rule.name, resolvedAt: nowISO() };
          this.activeAlerts.delete(rule.id);
          this.history.push({ ...resolved, type: "resolved" });
          realtimeEmit("system:alert", { alert: resolved, type: "resolved" });
          structuredLog("info", "alert_resolved", resolved);
        }
      } catch {}
    }
    return fired;
  },

  async fireWebhooks(alert) {
    for (const url of this.webhooks) {
      try {
        await fetch(url, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ type: "concord_alert", alert, nodeId: _FEDERATION_TRUST.nodeId }),
          signal: AbortSignal.timeout(5000),
        });
      } catch (e) {
        structuredLog("error", "webhook_failed", { url: url.slice(0, 50), error: String(e?.message || e) });
      }
    }
  },

  addWebhook(url) {
    if (!this.webhooks.includes(url)) this.webhooks.push(url);
  },

  stats() {
    return {
      activeAlerts: Array.from(this.activeAlerts.values()),
      ruleCount: this.rules.length,
      webhookCount: this.webhooks.length,
      recentHistory: this.history.slice(-20),
    };
  }
};

// Evaluate alerts every 30 seconds
setInterval(() => _ALERTING.evaluate(), 30000);

app.get("/api/alerts", (req, res) => {
  res.json({ ok: true, alerts: _ALERTING.stats() });
});

app.get("/api/alerts/active", (req, res) => {
  res.json({ ok: true, active: Array.from(_ALERTING.activeAlerts.values()) });
});

app.post("/api/alerts/webhook", requireRole("owner", "admin"), (req, res) => {
  const { url } = req.body;
  if (!url) return res.status(400).json({ ok: false, error: "url required" });
  _ALERTING.addWebhook(url);
  auditLog("admin", "alert_webhook_added", { url: url.slice(0, 100), userId: req.user?.id });
  res.json({ ok: true, webhooks: _ALERTING.webhooks.length });
});

app.get("/api/schema/registry", (req, res) => {
  res.json({ ok: true, schemas: _SCHEMA_REGISTRY.stats() });
});

// ---- OpenAPI Documentation ----
const OPENAPI_SPEC = {
  openapi: "3.0.0",
  info: {
    title: "Concord Cognitive Engine API",
    version: VERSION,
    description: "Local-first cognitive operating system API"
  },
  servers: [{ url: `http://localhost:${PORT}`, description: "Local server" }],
  paths: {
    "/api/status": { get: { summary: "System status", tags: ["System"] }},
    "/api/dtus": { get: { summary: "List all DTUs", tags: ["DTUs"] }},
    "/api/dtus/paginated": { get: { summary: "Paginated DTU list", tags: ["DTUs"], parameters: [
      { name: "page", in: "query", schema: { type: "integer" }},
      { name: "pageSize", in: "query", schema: { type: "integer" }}
    ]}},
    "/api/search/indexed": { get: { summary: "Full-text search", tags: ["Search"] }},
    "/api/search/dsl": { get: { summary: "Query DSL search", tags: ["Search"] }},
    "/api/chat": { post: { summary: "Chat with Concord", tags: ["Chat"] }},
    "/api/forge/manual": { post: { summary: "Create DTU manually", tags: ["Forge"] }},
    "/api/forge/hybrid": { post: { summary: "Create DTU with LLM assistance", tags: ["Forge"] }},
    "/api/export/markdown": { post: { summary: "Export as Markdown", tags: ["Export"] }},
    "/api/export/obsidian": { post: { summary: "Export for Obsidian", tags: ["Export"] }},
    "/api/import/json": { post: { summary: "Import DTUs from JSON", tags: ["Import"] }},
    "/api/import/markdown": { post: { summary: "Import from Markdown", tags: ["Import"] }},
    "/api/admin/dashboard": { get: { summary: "Admin dashboard data", tags: ["Admin"] }},
    "/api/admin/metrics": { get: { summary: "System metrics", tags: ["Admin"] }},
    "/api/admin/logs": { get: { summary: "System logs", tags: ["Admin"] }},
    "/api/personas": {
      get: { summary: "List personas", tags: ["Personas"] },
      post: { summary: "Create persona", tags: ["Personas"] }
    },
    "/api/plugins": {
      get: { summary: "List plugins", tags: ["Plugins"] },
      post: { summary: "Register plugin", tags: ["Plugins"] }
    },
    "/api/council/vote": { post: { summary: "Submit council vote", tags: ["Council"] }},
    "/api/council/tally/{dtuId}": { get: { summary: "Get vote tally", tags: ["Council"] }},
    "/api/llm/local": { post: { summary: "Local LLM inference (Ollama)", tags: ["LLM"] }},
    "/api/llm/embed": { post: { summary: "Generate embeddings", tags: ["LLM"] }}
  },
  tags: [
    { name: "System", description: "System status and health" },
    { name: "DTUs", description: "Discrete Thought Unit operations" },
    { name: "Search", description: "Search and query" },
    { name: "Chat", description: "Conversational interface" },
    { name: "Forge", description: "DTU creation" },
    { name: "Export", description: "Export data" },
    { name: "Import", description: "Import data" },
    { name: "Admin", description: "Administration" },
    { name: "Personas", description: "Persona management" },
    { name: "Plugins", description: "Plugin system" },
    { name: "Council", description: "Governance and voting" },
    { name: "LLM", description: "Language model operations" }
  ]
};

// OpenAPI spec remains inline since it references OPENAPI_SPEC defined above
app.get("/api/openapi.json", (req, res) => res.json(OPENAPI_SPEC));
app.get("/api/docs", (req, res) => {
  res.send(`<!DOCTYPE html>
<html><head><title>Concord API Docs</title>
<link rel="stylesheet" href="https://unpkg.com/swagger-ui-dist@5/swagger-ui.css">
</head><body>
<div id="swagger-ui"></div>
<script src="https://unpkg.com/swagger-ui-dist@5/swagger-ui-bundle.js"></script>
<script>SwaggerUIBundle({ url: "/api/openapi.json", dom_id: "#swagger-ui" });</script>
</body></html>`);
});

console.log("[Concord] Enhancements v3.1 loaded: Search indexing, Query DSL, Local LLM, Export/Import, Plugins, Council voting, Personas, Admin dashboard");

// ============================================================================
// WAVE 1: PLUGIN MARKETPLACE ECOSYSTEM (Surpassing Obsidian)
// ============================================================================
const PLUGIN_MARKETPLACE = {
  listings: new Map(),
  installed: new Map(),
  reviews: new Map(),
  categories: ["productivity", "visualization", "integration", "ai", "governance", "export", "theme", "automation"]
};

register("marketplace", "submit", (ctx, input) => {
  const { name, description, version, author, githubUrl, category, macros } = input;
  if (!name || !githubUrl) return { ok: false, error: "Name and GitHub URL required" };
  const listing = {
    id: uid("plugin"),
    name: normalizeText(name),
    description: description || "",
    version: version || "1.0.0",
    author: author || "anonymous",
    githubUrl,
    category: PLUGIN_MARKETPLACE.categories.includes(category) ? category : "productivity",
    macros: macros || [],
    downloads: 0,
    rating: 0,
    reviews: [],
    ethosCompliant: null,
    submittedAt: nowISO(),
    status: "pending_review"
  };
  PLUGIN_MARKETPLACE.listings.set(listing.id, listing);
  STATE.queues.macroProposals = STATE.queues.macroProposals || [];
  STATE.queues.macroProposals.push({ type: "plugin_review", pluginId: listing.id, name: listing.name, githubUrl: listing.githubUrl, submittedAt: nowISO() });
  saveStateDebounced();
  return { ok: true, listing, message: "Plugin submitted for Chicken3 ethos review" };
});

register("marketplace", "browse", (ctx, input) => {
  const { category, search, sort, page, pageSize } = input;
  let listings = Array.from(PLUGIN_MARKETPLACE.listings.values()).filter(l => l.status === "approved" || l.status === "pending_review");
  if (category) listings = listings.filter(l => l.category === category);
  if (search) { const q = search.toLowerCase(); listings = listings.filter(l => l.name.toLowerCase().includes(q) || l.description.toLowerCase().includes(q)); }
  if (sort === "rating") listings.sort((a, b) => b.rating - a.rating);
  else if (sort === "downloads") listings.sort((a, b) => b.downloads - a.downloads);
  else listings.sort((a, b) => new Date(b.submittedAt) - new Date(a.submittedAt));
  const result = paginateResults(listings, { page: Number(page || 1), pageSize: clamp(Number(pageSize || 20), 1, 100) });
  return { ok: true, ...result, categories: PLUGIN_MARKETPLACE.categories };
});

register("marketplace", "install", (ctx, input) => {
  const { pluginId, fromGithub, githubUrl } = input;
  if (fromGithub && githubUrl) {
    const match = githubUrl.match(/github\.com\/([^/]+)\/([^/]+)/);
    if (!match) return { ok: false, error: "Invalid GitHub URL" };
    const [, _owner, repo] = match;
    const plugin = { id: uid("plugin"), name: repo, version: "1.0.0", source: githubUrl, installedAt: nowISO(), enabled: true, autoUpdate: true };
    PLUGIN_MARKETPLACE.installed.set(plugin.id, plugin);
    saveStateDebounced();
    return { ok: true, plugin, message: "Plugin installed from GitHub" };
  }
  const listing = PLUGIN_MARKETPLACE.listings.get(pluginId);
  if (!listing) return { ok: false, error: "Plugin not found" };
  listing.downloads++;
  const installed = { id: listing.id, name: listing.name, version: listing.version, source: listing.githubUrl, installedAt: nowISO(), enabled: true, autoUpdate: true };
  PLUGIN_MARKETPLACE.installed.set(installed.id, installed);
  saveStateDebounced();
  return { ok: true, plugin: installed };
});

register("marketplace", "review", (ctx, input) => {
  const { pluginId, rating, comment, persona } = input;
  if (!pluginId || !rating) return { ok: false, error: "Plugin ID and rating required" };
  const review = { id: uid("review"), pluginId, rating: clamp(Number(rating), 1, 5), comment: comment || "", persona: persona || "anonymous", createdAt: nowISO() };
  if (!PLUGIN_MARKETPLACE.reviews.has(pluginId)) PLUGIN_MARKETPLACE.reviews.set(pluginId, []);
  PLUGIN_MARKETPLACE.reviews.get(pluginId).push(review);
  const listing = PLUGIN_MARKETPLACE.listings.get(pluginId);
  if (listing) { const reviews = PLUGIN_MARKETPLACE.reviews.get(pluginId) || []; listing.rating = reviews.reduce((s, r) => s + r.rating, 0) / reviews.length; }
  saveStateDebounced();
  return { ok: true, review };
});

register("marketplace", "heartbeatSync", (_ctx, _input) => {
  const installed = Array.from(PLUGIN_MARKETPLACE.installed.values());
  const updates = installed.filter(p => p.autoUpdate && p.source).map(p => ({ pluginId: p.id, name: p.name, currentVersion: p.version, checkTime: nowISO() }));
  return { ok: true, installed: installed.length, updateChecks: updates.length };
});

register("marketplace", "installed", (_ctx, _input) => {
  const plugins = Array.from(PLUGIN_MARKETPLACE.installed.values());
  return { ok: true, plugins, count: plugins.length };
});

app.get("/api/marketplace/browse", async (req, res) => res.json(await runMacro("marketplace", "browse", { category: req.query.category, search: req.query.search, sort: req.query.sort, page: req.query.page, pageSize: req.query.pageSize }, makeCtx(req))));
app.post("/api/marketplace/submit", async (req, res) => res.json(await runMacro("marketplace", "submit", req.body, makeCtx(req))));
app.post("/api/marketplace/install", async (req, res) => res.json(await runMacro("marketplace", "install", req.body, makeCtx(req))));
app.post("/api/marketplace/review", async (req, res) => res.json(await runMacro("marketplace", "review", req.body, makeCtx(req))));
app.get("/api/marketplace/installed", async (req, res) => res.json(await runMacro("marketplace", "installed", {}, makeCtx(req))));

console.log("[Concord] Wave 1: Plugin Marketplace loaded");

// ============================================================================
// WAVE 2: GRAPH-BASED RELATIONAL QUERIES (Surpassing Logseq)
// ============================================================================
const GRAPH_INDEX = { nodes: new Map(), edges: new Map(), dirty: true };

function rebuildGraphIndex() {
  GRAPH_INDEX.nodes.clear();
  GRAPH_INDEX.edges.clear();
  for (const [id, dtu] of STATE.dtus.entries()) {
    GRAPH_INDEX.nodes.set(id, { id, title: dtu.title, tier: dtu.tier, tags: dtu.tags || [], lineageDepth: 0 });
    const lineage = dtu.lineage || {};
    for (const parentId of (lineage.parents || [])) { GRAPH_INDEX.edges.set(`${parentId}->${id}`, { id: `${parentId}->${id}`, source: parentId, target: id, type: "parent" }); }
    for (const childId of (lineage.children || [])) { GRAPH_INDEX.edges.set(`${id}->${childId}`, { id: `${id}->${childId}`, source: id, target: childId, type: "child" }); }
    for (const tag of (dtu.tags || [])) {
      const tagNodeId = `tag:${tag}`;
      if (!GRAPH_INDEX.nodes.has(tagNodeId)) GRAPH_INDEX.nodes.set(tagNodeId, { id: tagNodeId, type: "tag", label: tag });
      GRAPH_INDEX.edges.set(`${id}->tag:${tag}`, { source: id, target: tagNodeId, type: "tagged" });
    }
  }
  // Compute lineage depths
  const roots = Array.from(STATE.dtus.values()).filter(d => !d.lineage?.parents?.length || d.tier === "core");
  const visited = new Set();
  const queue = roots.map(r => ({ id: r.id, depth: 0 }));
  while (queue.length > 0) {
    const { id, depth } = queue.shift();
    if (visited.has(id)) continue;
    visited.add(id);
    const node = GRAPH_INDEX.nodes.get(id);
    if (node) node.lineageDepth = depth;
    const dtu = STATE.dtus.get(id);
    for (const childId of (dtu?.lineage?.children || [])) { if (!visited.has(childId)) queue.push({ id: childId, depth: depth + 1 }); }
  }
  GRAPH_INDEX.dirty = false;
}

register("graph", "query", (ctx, input) => {
  if (GRAPH_INDEX.dirty) rebuildGraphIndex();
  const { dsl } = input;
  const results = [];
  const dslLower = (dsl || "").toLowerCase();

  // Tag queries
  const tagMatch = dslLower.match(/linked to tag[:\s]+(\w+)/i);
  if (tagMatch) {
    const tag = tagMatch[1];
    for (const [id, node] of GRAPH_INDEX.nodes.entries()) { if (node.tags?.includes(tag)) results.push({ id, ...node, matchType: "tag" }); }
  }

  // Lineage depth queries
  const depthMatch = dslLower.match(/lineage depth\s*([><=]+)\s*(\d+)/i);
  if (depthMatch) {
    const op = depthMatch[1], val = Number(depthMatch[2]);
    const filtered = results.length > 0 ? results : Array.from(GRAPH_INDEX.nodes.values());
    return { ok: true, results: filtered.filter(n => { if (op === ">") return n.lineageDepth > val; if (op === "<") return n.lineageDepth < val; if (op === ">=") return n.lineageDepth >= val; if (op === "<=") return n.lineageDepth <= val; return n.lineageDepth === val; }), query: dsl };
  }

  // Relationship queries
  const relMatch = dslLower.match(/(children|parents|ancestors|descendants) of (\w+)/i);
  if (relMatch) {
    const [, rel, targetId] = relMatch;
    const traverse = (startId, dir, maxD = 10) => {
      const found = [], vis = new Set(), q = [{ id: startId, d: 0 }];
      while (q.length > 0) {
        const { id, d } = q.shift();
        if (vis.has(id) || d > maxD) continue;
        vis.add(id);
        const dtu = STATE.dtus.get(id);
        if (!dtu) continue;
        const related = dir === "down" ? (dtu.lineage?.children || []) : (dtu.lineage?.parents || []);
        for (const relId of related) { if (!vis.has(relId)) { found.push({ id: relId, depth: d + 1 }); q.push({ id: relId, d: d + 1 }); } }
      }
      return found;
    };
    if (rel === "children") { const dtu = STATE.dtus.get(targetId); return { ok: true, results: (dtu?.lineage?.children || []).map(id => ({ id, ...GRAPH_INDEX.nodes.get(id) })) }; }
    if (rel === "parents") { const dtu = STATE.dtus.get(targetId); return { ok: true, results: (dtu?.lineage?.parents || []).map(id => ({ id, ...GRAPH_INDEX.nodes.get(id) })) }; }
    if (rel === "descendants") return { ok: true, results: traverse(targetId, "down") };
    if (rel === "ancestors") return { ok: true, results: traverse(targetId, "up") };
  }

  // Cluster queries
  const clusterMatch = dslLower.match(/cluster[s]?\s*(around|containing|near)\s*(\w+)/i);
  if (clusterMatch) {
    const targetId = clusterMatch[2];
    const targetDtu = STATE.dtus.get(targetId);
    if (!targetDtu) return { ok: false, error: "DTU not found" };
    const targetTags = new Set(targetDtu.tags || []);
    const similar = [];
    for (const [id, dtu] of STATE.dtus.entries()) {
      if (id === targetId) continue;
      const overlap = (dtu.tags || []).filter(t => targetTags.has(t)).length;
      if (overlap > 0) similar.push({ id, title: dtu.title, overlap, tags: dtu.tags });
    }
    similar.sort((a, b) => b.overlap - a.overlap);
    return { ok: true, results: similar.slice(0, 20), clusteredAround: targetId };
  }

  return { ok: true, results, query: dsl, hint: "Use: 'DTUs linked to tag:X with lineage depth > 2' or 'descendants of dtu_xxx'" };
});

register("graph", "visualData", (ctx, input) => {
  if (GRAPH_INDEX.dirty) rebuildGraphIndex();
  const { tier, limit, includeEdges } = input;
  let nodes = Array.from(GRAPH_INDEX.nodes.values()).filter(n => !n.type || n.type !== "tag");
  if (tier) nodes = nodes.filter(n => n.tier === tier);
  nodes = nodes.slice(0, Number(limit) || 200);
  const nodeIds = new Set(nodes.map(n => n.id));
  const edges = includeEdges !== false ? Array.from(GRAPH_INDEX.edges.values()).filter(e => nodeIds.has(e.source) && nodeIds.has(e.target)) : [];
  return { ok: true, nodes, edges, stats: { totalNodes: GRAPH_INDEX.nodes.size, totalEdges: GRAPH_INDEX.edges.size } };
});

register("graph", "forceGraph", (ctx, input) => {
  if (GRAPH_INDEX.dirty) rebuildGraphIndex();
  const { centerNode, depth, maxNodes } = input;
  let nodes = [], links = [];
  if (centerNode) {
    const visited = new Set(), queue = [{ id: centerNode, d: 0 }], maxDepth = Number(depth) || 2;
    while (queue.length > 0 && nodes.length < (Number(maxNodes) || 100)) {
      const { id, d } = queue.shift();
      if (visited.has(id) || d > maxDepth) continue;
      visited.add(id);
      const dtu = STATE.dtus.get(id);
      if (!dtu) continue;
      nodes.push({ id, label: dtu.title, tier: dtu.tier, tags: dtu.tags, depth: d });
      for (const parentId of (dtu.lineage?.parents || [])) { links.push({ source: parentId, target: id, type: "parent" }); if (!visited.has(parentId)) queue.push({ id: parentId, d: d + 1 }); }
      for (const childId of (dtu.lineage?.children || [])) { links.push({ source: id, target: childId, type: "child" }); if (!visited.has(childId)) queue.push({ id: childId, d: d + 1 }); }
    }
  } else {
    nodes = Array.from(GRAPH_INDEX.nodes.values()).filter(n => !n.type || n.type !== "tag").slice(0, Number(maxNodes) || 100);
    const nodeIds = new Set(nodes.map(n => n.id));
    links = Array.from(GRAPH_INDEX.edges.values()).filter(e => nodeIds.has(e.source) && nodeIds.has(e.target));
  }
  return { ok: true, nodes, links };
});

app.post("/api/graph/query", async (req, res) => res.json(await runMacro("graph", "query", req.body, makeCtx(req))));
app.get("/api/graph/visual", async (req, res) => res.json(await runMacro("graph", "visualData", { tier: req.query.tier, limit: req.query.limit, includeEdges: req.query.includeEdges !== "false" }, makeCtx(req))));
app.get("/api/graph/force", async (req, res) => res.json(await runMacro("graph", "forceGraph", { centerNode: req.query.centerNode, depth: req.query.depth, maxNodes: req.query.maxNodes }, makeCtx(req))));

console.log("[Concord] Wave 2: Graph Queries loaded");

// ============================================================================
// WAVE 3: DYNAMIC SCHEMA TEMPLATES (Surpassing Tana's Supertags)
// ============================================================================
const SCHEMA_REGISTRY = new Map();

register("schema", "create", (ctx, input) => {
  const { name, kind, fields, validation, evolves } = input;
  if (!name || !kind) return { ok: false, error: "Name and kind required" };
  const schema = {
    id: uid("schema"),
    name: normalizeText(name),
    kind,
    fields: (fields || []).map(f => ({ name: f.name, type: f.type || "string", required: f.required || false, default: f.default, validation: f.validation || null, description: f.description || "" })),
    validation: validation || {},
    evolves: evolves !== false,
    version: 1,
    createdAt: nowISO(),
    updatedAt: nowISO(),
    usageCount: 0
  };
  const schemaDtu = {
    id: schema.id,
    title: `Schema: ${schema.name}`,
    tier: "core",
    tags: ["schema", "meta", kind],
    human: { summary: `Schema template for ${kind} DTUs` },
    core: { definitions: schema.fields.map(f => `${f.name}: ${f.type}${f.required ? ' (required)' : ''}`), invariants: Object.entries(schema.validation).map(([k, v]) => `${k}: ${v}`) },
    machine: { kind: "schema", schema },
    source: "schema-registry",
    createdAt: schema.createdAt
  };
  STATE.dtus.set(schemaDtu.id, schemaDtu);
  SCHEMA_REGISTRY.set(schema.name, schema);
  saveStateDebounced();
  return { ok: true, schema, dtuId: schemaDtu.id };
});

register("schema", "list", (_ctx, _input) => {
  const schemas = Array.from(SCHEMA_REGISTRY.values());
  return { ok: true, schemas, count: schemas.length };
});

register("schema", "validate", (ctx, input) => {
  const { schemaName, data } = input;
  const schema = SCHEMA_REGISTRY.get(schemaName);
  if (!schema) return { ok: false, error: "Schema not found" };
  const errors = [];
  for (const field of schema.fields) {
    const value = data[field.name];
    if (field.required && (value === undefined || value === null || value === "")) { errors.push({ field: field.name, error: "Required field missing" }); continue; }
    if (value !== undefined && value !== null) {
      if (field.type === "number" && typeof value !== "number") errors.push({ field: field.name, error: "Must be a number" });
      if (field.type === "boolean" && typeof value !== "boolean") errors.push({ field: field.name, error: "Must be a boolean" });
      if (field.type === "array" && !Array.isArray(value)) errors.push({ field: field.name, error: "Must be an array" });
      if (field.validation) {
        if (field.validation.regex && typeof value === "string") {
          // ReDoS protection - limit regex complexity
          const regexStr = String(field.validation.regex);
          if (regexStr.length > 200) {
            errors.push({ field: field.name, error: "Regex pattern too long" });
          } else if (/(\+\+|\*\*|\{\d+,\d*\}\+|\(\?[!<])/g.test(regexStr)) {
            errors.push({ field: field.name, error: "Regex pattern too complex" });
          } else {
            try {
              if (!new RegExp(regexStr).test(value)) {
                errors.push({ field: field.name, error: `Must match: ${regexStr}` });
              }
            } catch { errors.push({ field: field.name, error: "Invalid regex pattern" }); }
          }
        }
        if (field.validation.min !== undefined && value < field.validation.min) errors.push({ field: field.name, error: `Must be >= ${field.validation.min}` });
        if (field.validation.max !== undefined && value > field.validation.max) errors.push({ field: field.name, error: `Must be <= ${field.validation.max}` });
        if (field.validation.enum && !field.validation.enum.includes(value)) errors.push({ field: field.name, error: `Must be one of: ${field.validation.enum.join(", ")}` });
      }
    }
  }
  return { ok: errors.length === 0, valid: errors.length === 0, errors, schemaName };
});

register("schema", "apply", async (ctx, input) => {
  const { schemaName, dtuId, data } = input;
  const schema = SCHEMA_REGISTRY.get(schemaName);
  if (!schema) return { ok: false, error: "Schema not found" };
  const validation = await runMacro("schema", "validate", { schemaName, data }, ctx);
  if (!validation.valid) return { ok: false, error: "Validation failed", errors: validation.errors };
  const dtu = STATE.dtus.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };
  dtu.machine = dtu.machine || {};
  dtu.machine.schema = schemaName;
  dtu.machine.schemaVersion = schema.version;
  dtu.machine.schemaData = data;
  dtu.tags = [...new Set([...(dtu.tags || []), schemaName, schema.kind])];
  dtu.updatedAt = nowISO();
  schema.usageCount++;
  STATE.dtus.set(dtuId, dtu);
  saveStateDebounced();
  return { ok: true, dtuId, schemaApplied: schemaName };
});

register("schema", "evolve", (ctx, input) => {
  const { schemaName, changes, reason } = input;
  const schema = SCHEMA_REGISTRY.get(schemaName);
  if (!schema) return { ok: false, error: "Schema not found" };
  if (!schema.evolves) return { ok: false, error: "Schema evolution disabled" };
  STATE.queues.macroProposals.push({ type: "schema_evolution", schemaName, currentVersion: schema.version, proposedChanges: changes, reason: reason || "", proposedAt: nowISO() });
  saveStateDebounced();
  return { ok: true, message: "Schema evolution queued for council review" };
});

// Default schemas
const DEFAULT_SCHEMAS = [
  { name: "Hypothesis", kind: "hypothesis", fields: [{ name: "claim", type: "string", required: true }, { name: "evidence", type: "array", required: false }, { name: "confidence", type: "number", required: true, validation: { min: 0, max: 1 } }, { name: "testable", type: "boolean", required: true }, { name: "domain", type: "string", required: false }] },
  { name: "Experiment", kind: "experiment", fields: [{ name: "hypothesis", type: "reference", required: true }, { name: "method", type: "string", required: true }, { name: "variables", type: "array", required: true }, { name: "results", type: "string", required: false }, { name: "status", type: "string", required: true, validation: { enum: ["planned", "running", "completed", "failed"] } }] },
  { name: "Claim", kind: "claim", fields: [{ name: "statement", type: "string", required: true }, { name: "type", type: "string", required: true, validation: { enum: ["fact", "opinion", "inference", "speculation"] } }, { name: "sources", type: "array", required: false }, { name: "verifiable", type: "boolean", required: true }] },
  { name: "Evidence", kind: "evidence", fields: [{ name: "description", type: "string", required: true }, { name: "type", type: "string", required: true, validation: { enum: ["empirical", "testimonial", "documentary", "statistical", "analogical"] } }, { name: "strength", type: "number", required: true, validation: { min: 0, max: 1 } }, { name: "source", type: "string", required: true }] }
];
setTimeout(() => { for (const s of DEFAULT_SCHEMAS) { if (!SCHEMA_REGISTRY.has(s.name)) SCHEMA_REGISTRY.set(s.name, { ...s, id: uid("schema"), version: 1, createdAt: nowISO(), usageCount: 0, evolves: true }); } }, 100);

app.post("/api/schema", async (req, res) => res.json(await runMacro("schema", "create", req.body, makeCtx(req))));
app.get("/api/schema", async (req, res) => res.json(await runMacro("schema", "list", {}, makeCtx(req))));
app.post("/api/schema/validate", async (req, res) => res.json(await runMacro("schema", "validate", req.body, makeCtx(req))));
app.post("/api/schema/apply", async (req, res) => res.json(await runMacro("schema", "apply", req.body, makeCtx(req))));
app.post("/api/schema/evolve", async (req, res) => res.json(await runMacro("schema", "evolve", req.body, makeCtx(req))));

console.log("[Concord] Wave 3: Dynamic Schemas loaded");

// ============================================================================
// WAVE 4: AI-ASSISTED AUTO-TAGGING & VISUAL LENS (Surpassing Capacities)
// ============================================================================
const DOMAIN_KEYWORDS = {
  philosophy: ["ethics", "epistemology", "ontology", "metaphysics", "consciousness", "mind", "being", "existence", "moral", "virtue", "justice"],
  science: ["experiment", "hypothesis", "data", "evidence", "empirical", "theory", "research", "observation", "method", "scientific"],
  technology: ["algorithm", "software", "code", "system", "architecture", "api", "database", "network", "programming", "computer"],
  mathematics: ["theorem", "proof", "equation", "function", "set", "axiom", "logic", "number", "calculus", "algebra"],
  psychology: ["behavior", "cognition", "emotion", "perception", "memory", "learning", "motivation", "personality", "mental"],
  economics: ["market", "price", "supply", "demand", "trade", "value", "currency", "investment", "capital", "growth"],
  physics: ["quantum", "particle", "wave", "energy", "mass", "force", "field", "spacetime", "relativity", "momentum"],
  biology: ["cell", "gene", "organism", "evolution", "species", "protein", "dna", "ecosystem", "life", "organism"]
};

register("autotag", "analyze", (ctx, input) => {
  const { dtuId, content, useEmbeddings: _useEmbeddings } = input;
  const dtu = dtuId ? STATE.dtus.get(dtuId) : null;
  const text = content || (dtu ? dtu.title + " " + (dtu.human?.summary || "") + " " + (dtu.core?.definitions?.join(" ") || "") : "");
  if (!text) return { ok: false, error: "No content to analyze" };
  const suggestedTags = [], textLower = text.toLowerCase(), domainScores = {};
  for (const [domain, keywords] of Object.entries(DOMAIN_KEYWORDS)) {
    let score = 0;
    for (const kw of keywords) { if (textLower.includes(kw)) { score++; suggestedTags.push(kw); } }
    if (score > 0) domainScores[domain] = score;
  }
  const topDomain = Object.entries(domainScores).sort((a, b) => b[1] - a[1])[0];
  const suggestedRelations = [];
  if (suggestedTags.length > 0) {
    const tagSet = new Set(suggestedTags);
    for (const [id, d] of STATE.dtus.entries()) {
      if (id === dtuId) continue;
      const overlap = (d.tags || []).filter(t => tagSet.has(t)).length;
      if (overlap >= 2) suggestedRelations.push({ id, title: d.title, overlap });
    }
    suggestedRelations.sort((a, b) => b.overlap - a.overlap);
  }
  return { ok: true, suggestedTags: [...new Set(suggestedTags)].slice(0, 10), suggestedDomain: topDomain ? topDomain[0] : null, domainScores, suggestedRelations: suggestedRelations.slice(0, 10) };
});

register("autotag", "apply", (ctx, input) => {
  const { dtuId, tags, domain, relations } = input;
  const dtu = STATE.dtus.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };
  if (tags && tags.length > 0) dtu.tags = [...new Set([...(dtu.tags || []), ...tags])];
  if (domain) { dtu.tags = [...new Set([...(dtu.tags || []), domain])]; dtu.meta = dtu.meta || {}; dtu.meta.autotaggedDomain = domain; }
  if (relations && relations.length > 0) { dtu.lineage = dtu.lineage || { parents: [], children: [] }; for (const rel of relations) { if (!dtu.lineage.parents.includes(rel.id)) dtu.lineage.parents.push(rel.id); } }
  dtu.meta = dtu.meta || {}; dtu.meta.autotaggedAt = nowISO(); dtu.updatedAt = nowISO();
  STATE.dtus.set(dtuId, dtu);
  GRAPH_INDEX.dirty = true;
  saveStateDebounced();
  return { ok: true, dtuId, appliedTags: tags, appliedDomain: domain, linkedRelations: relations?.length || 0 };
});

register("autotag", "batchProcess", async (ctx, input) => {
  const { tier, limit, dryRun } = input;
  let dtus = dtusArray().filter(d => !d.meta?.autotaggedAt);
  if (tier) dtus = dtus.filter(d => d.tier === tier);
  dtus = dtus.slice(0, Number(limit) || 50);
  const results = [];
  for (const dtu of dtus) {
    const analysis = await runMacro("autotag", "analyze", { dtuId: dtu.id }, ctx);
    if (analysis.ok && analysis.suggestedTags.length > 0) {
      if (!dryRun) await runMacro("autotag", "apply", { dtuId: dtu.id, tags: analysis.suggestedTags, domain: analysis.suggestedDomain }, ctx);
      results.push({ dtuId: dtu.id, title: dtu.title, suggestedTags: analysis.suggestedTags, suggestedDomain: analysis.suggestedDomain, applied: !dryRun });
    }
  }
  return { ok: true, processed: results.length, results, dryRun: !!dryRun };
});

register("visual", "moodboard", (ctx, input) => {
  const { tags, tier, maxNodes } = input;
  let dtus = dtusArray();
  if (tags && tags.length > 0) { const tagSet = new Set(tags); dtus = dtus.filter(d => (d.tags || []).some(t => tagSet.has(t))); }
  if (tier) dtus = dtus.filter(d => d.tier === tier);
  dtus = dtus.slice(0, Number(maxNodes) || 100);
  const tagGroups = {};
  for (const dtu of dtus) { const primaryTag = dtu.tags?.[0] || "untagged"; if (!tagGroups[primaryTag]) tagGroups[primaryTag] = []; tagGroups[primaryTag].push({ id: dtu.id, title: dtu.title, tier: dtu.tier, size: (dtu.core?.definitions?.length || 1) + (dtu.core?.claims?.length || 0) }); }
  const hierarchy = { name: "Knowledge", children: Object.entries(tagGroups).map(([tag, items]) => ({ name: tag, children: items.map(i => ({ name: i.title, id: i.id, size: i.size, tier: i.tier })) })) };
  return { ok: true, hierarchy, totalNodes: dtus.length, tagCount: Object.keys(tagGroups).length };
});

register("visual", "sunburst", (ctx, input) => {
  const { maxDepth, maxNodes } = input;
  const _depth = Number(maxDepth) || 3;
  const hierarchy = { name: "Concord", children: [] };
  const tierGroups = { core: [], mega: [], hyper: [], regular: [] };
  for (const dtu of dtusArray().slice(0, Number(maxNodes) || 200)) { const t = dtu.tier || "regular"; if (tierGroups[t]) tierGroups[t].push(dtu); }
  for (const [tier, dtus] of Object.entries(tierGroups)) {
    if (dtus.length === 0) continue;
    const tierNode = { name: tier.toUpperCase(), children: [] };
    const tagMap = {};
    for (const dtu of dtus) { const tag = dtu.tags?.[0] || "untagged"; if (!tagMap[tag]) tagMap[tag] = []; tagMap[tag].push({ name: dtu.title.slice(0, 30), id: dtu.id, value: 1 }); }
    for (const [tag, nodes] of Object.entries(tagMap)) { tierNode.children.push({ name: tag, children: nodes }); }
    hierarchy.children.push(tierNode);
  }
  return { ok: true, hierarchy };
});

register("visual", "timeline", (ctx, input) => {
  const { startDate, endDate, limit } = input;
  let dtus = dtusArray().sort((a, b) => new Date(b.createdAt) - new Date(a.createdAt));
  if (startDate) dtus = dtus.filter(d => new Date(d.createdAt) >= new Date(startDate));
  if (endDate) dtus = dtus.filter(d => new Date(d.createdAt) <= new Date(endDate));
  dtus = dtus.slice(0, Number(limit) || 100);
  const events = dtus.map(d => ({ id: d.id, title: d.title, date: d.createdAt, tier: d.tier, tags: d.tags?.slice(0, 3) }));
  return { ok: true, events, count: events.length };
});

app.post("/api/autotag/analyze", async (req, res) => res.json(await runMacro("autotag", "analyze", req.body, makeCtx(req))));
app.post("/api/autotag/apply", async (req, res) => res.json(await runMacro("autotag", "apply", req.body, makeCtx(req))));
app.post("/api/autotag/batch", async (req, res) => res.json(await runMacro("autotag", "batchProcess", req.body, makeCtx(req))));
app.get("/api/visual/moodboard", async (req, res) => res.json(await runMacro("visual", "moodboard", { tags: req.query.tags?.split(","), tier: req.query.tier, maxNodes: req.query.maxNodes }, makeCtx(req))));
app.get("/api/visual/sunburst", async (req, res) => res.json(await runMacro("visual", "sunburst", { maxDepth: req.query.maxDepth, maxNodes: req.query.maxNodes }, makeCtx(req))));
app.get("/api/visual/timeline", async (req, res) => res.json(await runMacro("visual", "timeline", { startDate: req.query.startDate, endDate: req.query.endDate, limit: req.query.limit }, makeCtx(req))));

console.log("[Concord] Wave 4: Auto-Tagging & Visuals loaded");

// ============================================================================
// GENERIC LENS ARTIFACT RUNTIME (No-Mock Upgrade Infrastructure)
// ============================================================================
// Every lens can persist artifacts via these generic macros. Structure:
//   { id, domain, type, ownerId, title, data:{}, meta:{tags,status,visibility}, createdAt, updatedAt, version }
// DTU exhaust is emitted automatically on every mutation.

// ── Lens Domain Index Helpers ──────────────────────────────────────────────────
// Maintain a secondary index: domain → Set<artifactId> for O(1) domain lookup
function _rebuildLensDomainIndex() {
  STATE.lensDomainIndex.clear();
  for (const [id, art] of STATE.lensArtifacts) {
    if (!STATE.lensDomainIndex.has(art.domain)) STATE.lensDomainIndex.set(art.domain, new Set());
    STATE.lensDomainIndex.get(art.domain).add(id);
  }
}
function _lensDomainIndexAdd(domain, id) {
  if (!STATE.lensDomainIndex.has(domain)) STATE.lensDomainIndex.set(domain, new Set());
  STATE.lensDomainIndex.get(domain).add(id);
}
function _lensDomainIndexRemove(domain, id) {
  const set = STATE.lensDomainIndex.get(domain);
  if (set) { set.delete(id); if (set.size === 0) STATE.lensDomainIndex.delete(domain); }
}
function _lensDomainArtifacts(domain) {
  const ids = STATE.lensDomainIndex.get(domain);
  if (!ids || ids.size === 0) return [];
  const result = [];
  for (const id of ids) {
    const art = STATE.lensArtifacts.get(id);
    if (art) result.push(art);
  }
  return result;
}

function _lensEmitDTU(ctx, domain, action, artifactType, artifact, extra={}) {
  try {
    const dtuId = uid("dtu");
    const dtu = {
      id: dtuId,
      title: `Lens:${domain} ${action} ${artifactType}`,
      tier: "regular",
      summary: `${action} ${artifactType} "${artifact.title || artifact.id}" in ${domain} lens`,
      content: JSON.stringify({ domain, action, artifactType, artifactId: artifact.id, ...extra }),
      tags: [`lens:${domain}`, `artifact:${artifactType}`, `action:${action}`],
      createdAt: nowISO(),
      updatedAt: nowISO(),
      machine: { kind: "lens_exhaust", domain, action, artifactType, artifactId: artifact.id },
      human: { summary: `${action} ${artifactType} in ${domain}` },
      claims: extra.claims || [],
    };
    STATE.dtus.set(dtuId, dtu);
    saveStateDebounced();
    return dtuId;
  } catch { return null; }
}

register("lens", "list", (ctx, input={}) => {
  const { domain, type, search, tags, status, limit=100, offset=0 } = input;
  if (!domain) return { ok: false, error: "domain required" };
  let artifacts = _lensDomainArtifacts(domain);
  if (type) artifacts = artifacts.filter(a => a.type === type);
  if (search) {
    const q = String(search).toLowerCase();
    artifacts = artifacts.filter(a => (a.title||"").toLowerCase().includes(q) || JSON.stringify(a.data||{}).toLowerCase().includes(q));
  }
  if (tags && tags.length) artifacts = artifacts.filter(a => tags.some(t => (a.meta?.tags||[]).includes(t)));
  if (status) artifacts = artifacts.filter(a => a.meta?.status === status);
  artifacts.sort((a,b) => (b.updatedAt||b.createdAt||"").localeCompare(a.updatedAt||a.createdAt||""));
  const total = artifacts.length;
  artifacts = artifacts.slice(offset, offset + limit);
  return { ok: true, artifacts, total, domain, type };
});

register("lens", "get", (ctx, input={}) => {
  const { id, domain } = input;
  if (!id) return { ok: false, error: "id required" };
  const artifact = STATE.lensArtifacts.get(id);
  if (!artifact) return { ok: false, error: "not found" };
  if (domain && artifact.domain !== domain) return { ok: false, error: "domain mismatch" };
  return { ok: true, artifact };
});

register("lens", "create", (ctx, input={}) => {
  const { domain, type, title, data={}, meta={} } = input;
  if (!domain || !type) return { ok: false, error: "domain and type required" };

  // v5.5: Scope enforcement via capability bridge
  const scopeCheck = (() => {
    try {
      const tempArt = { data, meta: meta || {} };
      return ctx.macro.run("emergent", "bridge.lensScope", { artifact: tempArt, operation: "create", actorScope: ctx.actor?.scope || "local", STATE });
    } catch { return { ok: true, allowed: true, warnings: [] }; }
  })();
  if (scopeCheck && !scopeCheck.allowed) {
    return { ok: false, error: "scope_denied", warnings: scopeCheck.warnings };
  }

  const id = uid("lart");
  const artifact = {
    id, domain, type,
    ownerId: ctx.actor?.userId || "anon",
    title: title || `New ${type}`,
    data,
    meta: { tags: meta.tags || [], status: meta.status || "draft", visibility: meta.visibility || "private", scope: meta.scope || "local", ...meta },
    createdAt: nowISO(),
    updatedAt: nowISO(),
    version: 1,
  };
  STATE.lensArtifacts.set(id, artifact);
  _lensDomainIndexAdd(domain, id);
  saveStateDebounced();
  _lensEmitDTU(ctx, domain, "create", type, artifact);
  return { ok: true, artifact, scopeWarnings: scopeCheck?.warnings?.length ? scopeCheck.warnings : undefined };
});

register("lens", "update", (ctx, input={}) => {
  const { id, title, data, meta } = input;
  if (!id) return { ok: false, error: "id required" };
  const artifact = STATE.lensArtifacts.get(id);
  if (!artifact) return { ok: false, error: "not found" };
  const before = { title: artifact.title, data: { ...artifact.data } };
  if (title !== undefined) artifact.title = title;
  if (data !== undefined) artifact.data = { ...artifact.data, ...data };
  if (meta !== undefined) artifact.meta = { ...artifact.meta, ...meta };
  artifact.updatedAt = nowISO();
  artifact.version = (artifact.version || 1) + 1;
  saveStateDebounced();
  _lensEmitDTU(ctx, artifact.domain, "update", artifact.type, artifact, { claims: [`updated from v${artifact.version-1}`], before });
  return { ok: true, artifact };
});

register("lens", "delete", (ctx, input={}) => {
  const { id } = input;
  if (!id) return { ok: false, error: "id required" };
  const artifact = STATE.lensArtifacts.get(id);
  if (!artifact) return { ok: false, error: "not found" };
  STATE.lensArtifacts.delete(id);
  _lensDomainIndexRemove(artifact.domain, id);
  saveStateDebounced();
  _lensEmitDTU(ctx, artifact.domain, "delete", artifact.type, artifact);
  return { ok: true, deleted: id };
});

register("lens", "run", async (ctx, input={}) => {
  const { id, action, params={} } = input;
  if (!id || !action) return { ok: false, error: "id and action required" };
  const artifact = STATE.lensArtifacts.get(id);
  if (!artifact) return { ok: false, error: "not found" };
  // Domain-specific action handlers can be registered via lens.registerAction
  const handler = LENS_ACTIONS.get(`${artifact.domain}.${action}`);
  if (!handler) return { ok: false, error: `no handler for ${artifact.domain}.${action}` };
  const result = await handler(ctx, artifact, params);
  _lensEmitDTU(ctx, artifact.domain, action, artifact.type, artifact, { actionResult: result?.ok });
  // Run cross-lens pipelines (fire-and-forget)
  const pipelineResults = _runLensPipelines(ctx, artifact.domain, action, artifact, result);
  return { ok: true, result, pipelines: pipelineResults.length > 0 ? pipelineResults : undefined };
});

register("lens", "export", (ctx, input={}) => {
  const { id, format="json" } = input;
  if (!id) return { ok: false, error: "id required" };
  const artifact = STATE.lensArtifacts.get(id);
  if (!artifact) return { ok: false, error: "not found" };
  _lensEmitDTU(ctx, artifact.domain, "export", artifact.type, artifact, { format });
  if (format === "json") return { ok: true, format: "json", data: artifact };
  if (format === "csv") return { ok: true, format: "csv", data: _lensExportCSV(artifact) };
  if (format === "pdf") return { ok: true, format: "pdf", data: _lensExportPDFMarkup(artifact) };
  if (format === "markdown" || format === "md") return { ok: true, format: "markdown", data: _lensExportMarkdown(artifact) };
  return { ok: false, error: `unsupported format: ${format}` };
});

// ── Export Formatters ──────────────────────────────────────────────────────────

function _lensExportCSV(artifact) {
  const rows = [];
  // Header row with metadata fields
  const metaFields = ["id", "domain", "type", "title", "status", "version", "createdAt", "updatedAt"];
  const dataObj = artifact.data || {};
  const dataKeys = Object.keys(dataObj).filter(k => {
    const v = dataObj[k];
    return v !== null && v !== undefined && typeof v !== "object";
  });
  const arrayKeys = Object.keys(dataObj).filter(k => Array.isArray(dataObj[k]));

  // If the artifact has a primary array field (items, entries, cards, events, etc.), export that as rows
  const primaryArrayKey = arrayKeys.find(k =>
    ["items", "entries", "cards", "events", "records", "rows", "transactions", "posts", "tasks", "members", "claims", "stems", "sections", "nodes", "edges"].includes(k)
  ) || arrayKeys[0];

  if (primaryArrayKey && Array.isArray(dataObj[primaryArrayKey]) && dataObj[primaryArrayKey].length > 0) {
    const items = dataObj[primaryArrayKey];
    const itemKeys = new Set();
    items.forEach(item => { if (item && typeof item === "object") Object.keys(item).forEach(k => itemKeys.add(k)); });
    const cols = Array.from(itemKeys);
    rows.push(cols.map(c => _csvEscape(c)).join(","));
    items.forEach(item => {
      if (!item || typeof item !== "object") return;
      rows.push(cols.map(c => _csvEscape(item[c])).join(","));
    });
  } else {
    // Flat export of all scalar fields
    const allKeys = [...metaFields, ...dataKeys];
    rows.push(allKeys.map(c => _csvEscape(c)).join(","));
    const vals = allKeys.map(k => {
      if (metaFields.includes(k)) {
        if (k === "status") return _csvEscape(artifact.meta?.status);
        return _csvEscape(artifact[k]);
      }
      return _csvEscape(dataObj[k]);
    });
    rows.push(vals.join(","));
  }

  return { csv: rows.join("\n"), rowCount: rows.length - 1, arrayField: primaryArrayKey || null };
}

function _csvEscape(val) {
  if (val === null || val === undefined) return "";
  const s = String(val);
  if (s.includes(",") || s.includes('"') || s.includes("\n")) return '"' + s.replace(/"/g, '""') + '"';
  return s;
}

function _lensExportPDFMarkup(artifact) {
  // Generate a structured markup that a client-side PDF renderer can consume
  const sections = [];
  sections.push({ type: "title", text: artifact.title || "Untitled" });
  sections.push({ type: "subtitle", text: `${artifact.domain} / ${artifact.type} — v${artifact.version || 1}` });
  sections.push({ type: "meta", fields: [
    { label: "ID", value: artifact.id },
    { label: "Status", value: artifact.meta?.status || "draft" },
    { label: "Created", value: artifact.createdAt },
    { label: "Updated", value: artifact.updatedAt },
    { label: "Tags", value: (artifact.meta?.tags || []).join(", ") || "none" },
  ]});

  const dataObj = artifact.data || {};
  const scalarEntries = Object.entries(dataObj).filter(([, v]) => v !== null && v !== undefined && typeof v !== "object");
  if (scalarEntries.length) {
    sections.push({ type: "heading", text: "Properties" });
    sections.push({ type: "table", headers: ["Field", "Value"], rows: scalarEntries.map(([k, v]) => [k, String(v)]) });
  }

  const arrayEntries = Object.entries(dataObj).filter(([, v]) => Array.isArray(v) && v.length > 0);
  for (const [key, arr] of arrayEntries) {
    sections.push({ type: "heading", text: key.charAt(0).toUpperCase() + key.slice(1) });
    if (arr.length > 0 && typeof arr[0] === "object" && arr[0] !== null) {
      const cols = [...new Set(arr.flatMap(item => Object.keys(item)))];
      sections.push({
        type: "table",
        headers: cols,
        rows: arr.slice(0, 100).map(item => cols.map(c => String(item[c] ?? "")))
      });
      if (arr.length > 100) sections.push({ type: "note", text: `... and ${arr.length - 100} more rows` });
    } else {
      sections.push({ type: "list", items: arr.slice(0, 100).map(String) });
    }
  }

  const objectEntries = Object.entries(dataObj).filter(([, v]) => v && typeof v === "object" && !Array.isArray(v));
  for (const [key, obj] of objectEntries) {
    sections.push({ type: "heading", text: key.charAt(0).toUpperCase() + key.slice(1) });
    const entries = Object.entries(obj).filter(([, v]) => v !== null && v !== undefined);
    sections.push({ type: "table", headers: ["Field", "Value"], rows: entries.map(([k, v]) => [k, typeof v === "object" ? JSON.stringify(v) : String(v)]) });
  }

  return { sections, pageInfo: { title: artifact.title, domain: artifact.domain, generatedAt: nowISO() } };
}

function _lensExportMarkdown(artifact) {
  const lines = [];
  lines.push(`# ${artifact.title || "Untitled"}`);
  lines.push(`**Domain:** ${artifact.domain} | **Type:** ${artifact.type} | **Version:** ${artifact.version || 1}`);
  lines.push(`**Status:** ${artifact.meta?.status || "draft"} | **Created:** ${artifact.createdAt} | **Updated:** ${artifact.updatedAt}`);
  if (artifact.meta?.tags?.length) lines.push(`**Tags:** ${artifact.meta.tags.join(", ")}`);
  lines.push("");

  const dataObj = artifact.data || {};
  const scalarEntries = Object.entries(dataObj).filter(([, v]) => v !== null && v !== undefined && typeof v !== "object");
  if (scalarEntries.length) {
    lines.push("## Properties");
    lines.push("| Field | Value |");
    lines.push("|-------|-------|");
    scalarEntries.forEach(([k, v]) => lines.push(`| ${k} | ${String(v)} |`));
    lines.push("");
  }

  const arrayEntries = Object.entries(dataObj).filter(([, v]) => Array.isArray(v) && v.length > 0);
  for (const [key, arr] of arrayEntries) {
    lines.push(`## ${key.charAt(0).toUpperCase() + key.slice(1)}`);
    if (arr.length > 0 && typeof arr[0] === "object" && arr[0] !== null) {
      const cols = [...new Set(arr.flatMap(item => Object.keys(item)))];
      lines.push("| " + cols.join(" | ") + " |");
      lines.push("| " + cols.map(() => "---").join(" | ") + " |");
      arr.slice(0, 50).forEach(item => {
        lines.push("| " + cols.map(c => String(item[c] ?? "").replace(/\|/g, "\\|")).join(" | ") + " |");
      });
      if (arr.length > 50) lines.push(`*... and ${arr.length - 50} more rows*`);
    } else {
      arr.slice(0, 50).forEach(item => lines.push(`- ${String(item)}`));
    }
    lines.push("");
  }

  return { markdown: lines.join("\n"), charCount: lines.join("\n").length };
}

// ── Cross-Lens DTU Integration Pipelines ──────────────────────────────────────
// Pipeline registry: sourceDomain.event → [{targetDomain, transform, action}]
const LENS_PIPELINES = new Map(); // key → handler[]

function registerLensPipeline(sourceDomain, event, targetDomain, transform) {
  const key = `${sourceDomain}.${event}`;
  if (!LENS_PIPELINES.has(key)) LENS_PIPELINES.set(key, []);
  LENS_PIPELINES.get(key).push({ targetDomain, transform });
}

function _runLensPipelines(ctx, sourceDomain, event, sourceArtifact, actionResult) {
  const key = `${sourceDomain}.${event}`;
  const pipelines = LENS_PIPELINES.get(key);
  if (!pipelines || pipelines.length === 0) return [];
  const emitted = [];
  for (const { targetDomain, transform } of pipelines) {
    try {
      const output = transform(sourceArtifact, actionResult, ctx);
      if (!output) continue;
      // Output can be: { type, title, data, meta } to create an artifact,
      // or { action, artifactId, params } to run an action on existing artifact
      if (output.action && output.artifactId) {
        // Run action on existing artifact in target domain
        const targetArt = STATE.lensArtifacts.get(output.artifactId);
        if (targetArt) {
          const handler = LENS_ACTIONS.get(`${targetDomain}.${output.action}`);
          if (handler) {
            handler(ctx, targetArt, output.params || {}).catch(() => {});
            emitted.push({ type: "action", targetDomain, action: output.action, artifactId: output.artifactId });
          }
        }
      } else if (output.type) {
        // Create new artifact in target domain
        const id = uid("lart");
        const artifact = {
          id, domain: targetDomain, type: output.type,
          ownerId: ctx.actor?.userId || "pipeline",
          title: output.title || `Pipeline: ${sourceDomain} → ${targetDomain}`,
          data: output.data || {},
          meta: {
            tags: [...(output.meta?.tags || []), `pipeline:${sourceDomain}`, `source:${sourceArtifact.id}`],
            status: output.meta?.status || "active",
            visibility: output.meta?.visibility || "private",
            pipelineSource: { domain: sourceDomain, event, artifactId: sourceArtifact.id },
          },
          createdAt: nowISO(), updatedAt: nowISO(), version: 1,
        };
        STATE.lensArtifacts.set(id, artifact);
        _lensDomainIndexAdd(targetDomain, id);
        saveStateDebounced();
        _lensEmitDTU(ctx, targetDomain, "pipeline_create", output.type, artifact, { sourceDomain, event });
        emitted.push({ type: "create", targetDomain, artifactId: id, artifactType: output.type });
      }
    } catch (e) {
      emitted.push({ type: "error", targetDomain, error: e.message });
    }
  }
  return emitted;
}

// Register cross-lens pipelines

// Healthcare → Insurance: When a healthcare artifact is analyzed, create an insurance claim draft
registerLensPipeline("healthcare", "checkInteractions", "insurance", (src, result) => {
  if (!result?.ok || !result?.interactions?.length) return null;
  return {
    type: "claim",
    title: `Drug Interaction Alert: ${src.title}`,
    data: { relatedMedications: src.data?.medications || [], interactions: result.interactions, severity: result.highestSeverity || "moderate", patientRef: src.data?.patientId },
    meta: { status: "pending_review", tags: ["auto-generated", "drug-interaction"] }
  };
});

// Finance → Accounting: When a finance simulation completes, create an accounting journal entry
registerLensPipeline("finance", "simulate", "accounting", (src, result) => {
  if (!result?.ok || !result?.simulation) return null;
  const sim = result.simulation;
  return {
    type: "entry",
    title: `Sim Result: ${src.title} (${sim.finalReturn > 0 ? "+" : ""}${(sim.finalReturn * 100).toFixed(1)}%)`,
    data: { type: "simulation_record", amount: sim.finalValue, initialAmount: sim.initialValue, returnPct: sim.finalReturn, volatility: sim.annualizedVol, sharpeRatio: sim.sharpeRatio, simulatedAt: nowISO() },
    meta: { status: "draft", tags: ["simulation", "auto-generated"] }
  };
});

// Education → SRS: When education content is created, generate flashcards
registerLensPipeline("education", "generate_quiz", "srs", (src, result) => {
  if (!result?.ok || !result?.quiz?.questions?.length) return null;
  return {
    type: "deck",
    title: `Study Deck: ${src.title}`,
    data: { cards: result.quiz.questions.map((q, i) => ({ id: uid("card"), front: q.question || q.text, back: q.answer || q.correctAnswer || "", tags: [src.data?.subject || "general"], difficulty: q.difficulty || 0.5, interval: 1, repetitions: 0 })) },
    meta: { status: "active", tags: ["education-pipeline", src.data?.subject || "general"] }
  };
});

// Science → Paper: When a science experiment is analyzed, create a paper draft
registerLensPipeline("science", "analyze_results", "paper", (src, result) => {
  if (!result?.ok) return null;
  return {
    type: "research",
    title: `Analysis: ${src.title}`,
    data: { abstract: result.summary || `Analysis of ${src.title}`, claims: (result.findings || []).map(f => ({ text: f, validated: false })), methodology: src.data?.methodology, results: result },
    meta: { status: "draft", tags: ["auto-generated", "science-pipeline"] }
  };
});

// Events → Calendar: When an event is scheduled, create a calendar entry
registerLensPipeline("events", "schedule", "calendar", (src, result) => {
  if (!result?.ok) return null;
  return {
    type: "calendar",
    title: `Event: ${src.title}`,
    data: { events: [{ id: uid("evt"), title: src.title, start: src.data?.startDate || src.data?.date, end: src.data?.endDate, location: src.data?.venue || src.data?.location, notes: src.data?.description }] },
    meta: { status: "active", tags: ["event-pipeline"] }
  };
});

// Food → Healthcare: When a meal plan is analyzed, create a nutrition health record
registerLensPipeline("food", "analyze_nutrition", "healthcare", (src, result) => {
  if (!result?.ok || !result?.analysis) return null;
  return {
    type: "artifact",
    title: `Nutrition Report: ${src.title}`,
    data: { type: "nutrition_report", calories: result.analysis.totalCalories, macros: result.analysis.macroBreakdown, recommendations: result.analysis.recommendations, source: "food-pipeline" },
    meta: { status: "active", tags: ["nutrition", "auto-generated"] }
  };
});

// Manufacturing → Logistics: When inventory is updated, create a logistics shipment request
registerLensPipeline("manufacturing", "update_inventory", "logistics", (src, result) => {
  if (!result?.ok) return null;
  const lowStock = (result.inventoryAlerts || []).filter(a => a.type === "low_stock");
  if (lowStock.length === 0) return null;
  return {
    type: "shipment",
    title: `Restock Request: ${lowStock.length} items`,
    data: { items: lowStock.map(a => ({ sku: a.sku, name: a.name, currentQty: a.currentQty, reorderQty: a.reorderQty })), priority: "normal", source: "manufacturing-pipeline" },
    meta: { status: "pending", tags: ["restock", "auto-generated"] }
  };
});

// Fitness → Daily: When a workout is logged, create a daily journal entry
registerLensPipeline("fitness", "log_workout", "daily", (src, result) => {
  if (!result?.ok) return null;
  return {
    type: "entry",
    title: `Workout: ${src.title}`,
    data: { content: `Completed workout: ${src.title}. Duration: ${result.duration || "N/A"}. Calories: ${result.caloriesBurned || "N/A"}.`, mood: "energized", tags: ["fitness", "workout"], date: nowISO().substring(0, 10) },
    meta: { status: "active", tags: ["fitness-pipeline"] }
  };
});

// Legal → Government: When a legal document is filed, create a government compliance record
registerLensPipeline("legal", "file_document", "government", (src, result) => {
  if (!result?.ok) return null;
  return {
    type: "record",
    title: `Filing: ${src.title}`,
    data: { documentType: src.data?.documentType, filingDate: nowISO(), status: "filed", referenceId: src.id, jurisdiction: src.data?.jurisdiction },
    meta: { status: "active", tags: ["legal-filing", "compliance"] }
  };
});

// Security → Aviation: When a security scan completes, update aviation safety records
registerLensPipeline("security", "run_scan", "aviation", (src, result) => {
  if (!result?.ok || !result?.vulnerabilities?.length) return null;
  return {
    type: "record",
    title: `Security Alert: ${result.vulnerabilities.length} findings`,
    data: { scanDate: nowISO(), findings: result.vulnerabilities, severity: result.highestSeverity, source: "security-scan", affectedSystems: result.affectedSystems },
    meta: { status: "review_required", tags: ["security-pipeline", "safety"] }
  };
});

register("lens", "bulkCreate", (ctx, input={}) => {
  const { domain, type, items=[] } = input;
  if (!domain || !type || !items.length) return { ok: false, error: "domain, type, and items required" };
  const created = [];
  for (const item of items) {
    const id = uid("lart");
    const artifact = {
      id, domain, type,
      ownerId: ctx.actor?.userId || "anon",
      title: item.title || `New ${type}`,
      data: item.data || {},
      meta: { tags: item.tags || [], status: item.status || "active", visibility: "private", ...(item.meta||{}) },
      createdAt: nowISO(), updatedAt: nowISO(), version: 1,
    };
    STATE.lensArtifacts.set(id, artifact);
    _lensDomainIndexAdd(domain, id);
    created.push(artifact);
  }
  saveStateDebounced();
  _lensEmitDTU(ctx, domain, "bulkCreate", type, { id: "bulk", title: `${created.length} ${type}s` }, { count: created.length });
  return { ok: true, artifacts: created, count: created.length };
});

// Lens action registry for domain-specific engines
const LENS_ACTIONS = new Map(); // `${domain}.${action}` → async (ctx, artifact, params) => result
function registerLensAction(domain, action, handler) {
  LENS_ACTIONS.set(`${domain}.${action}`, handler);
}

// Pipeline introspection endpoint (must be before wildcard :domain routes)
app.get("/api/lens/pipelines", (req, res) => {
  const pipelines = [];
  for (const [key, handlers] of LENS_PIPELINES) {
    const [sourceDomain, event] = key.split(".");
    for (const h of handlers) {
      pipelines.push({ sourceDomain, event, targetDomain: h.targetDomain });
    }
  }
  res.json({ ok: true, pipelines, count: pipelines.length });
});

// Domain index stats endpoint (must be before wildcard :domain routes)
app.get("/api/lens/stats", (req, res) => {
  const domains = {};
  for (const [domain, ids] of STATE.lensDomainIndex) {
    domains[domain] = ids.size;
  }
  res.json({ ok: true, domains, totalArtifacts: STATE.lensArtifacts.size, domainCount: STATE.lensDomainIndex.size });
});

// REST routes for generic lens artifacts
// All routes wrapped in try/catch to prevent hanging requests on errors
app.get("/api/lens/:domain", async (req, res) => {
  try {
    const ctx = makeCtx(req);
    const out = await runMacro("lens", "list", { domain: req.params.domain, type: req.query.type, search: req.query.search, tags: req.query.tags?.split(","), status: req.query.status, limit: Number(req.query.limit)||100, offset: Number(req.query.offset)||0 }, ctx);
    res.json(out);
  } catch (e) {
    const msg = String(e?.message || e);
    const status = msg.startsWith("forbidden") ? 403 : 500;
    res.status(status).json({ ok: false, error: msg });
  }
});
app.get("/api/lens/:domain/:id", async (req, res) => {
  try {
    const ctx = makeCtx(req);
    res.json(await runMacro("lens", "get", { id: req.params.id, domain: req.params.domain }, ctx));
  } catch (e) {
    const msg = String(e?.message || e);
    const status = msg.startsWith("forbidden") ? 403 : 500;
    res.status(status).json({ ok: false, error: msg });
  }
});
app.post("/api/lens/:domain", async (req, res) => {
  try {
    const ctx = makeCtx(req);
    res.json(await runMacro("lens", "create", { domain: req.params.domain, ...req.body }, ctx));
  } catch (e) {
    const msg = String(e?.message || e);
    const status = msg.startsWith("forbidden") ? 403 : 500;
    res.status(status).json({ ok: false, error: msg });
  }
});
app.put("/api/lens/:domain/:id", async (req, res) => {
  try {
    const ctx = makeCtx(req);
    res.json(await runMacro("lens", "update", { id: req.params.id, ...req.body }, ctx));
  } catch (e) {
    const msg = String(e?.message || e);
    const status = msg.startsWith("forbidden") ? 403 : 500;
    res.status(status).json({ ok: false, error: msg });
  }
});
app.delete("/api/lens/:domain/:id", async (req, res) => {
  try {
    const ctx = makeCtx(req);
    res.json(await runMacro("lens", "delete", { id: req.params.id }, ctx));
  } catch (e) {
    const msg = String(e?.message || e);
    const status = msg.startsWith("forbidden") ? 403 : 500;
    res.status(status).json({ ok: false, error: msg });
  }
});
app.post("/api/lens/:domain/:id/run", async (req, res) => {
  try {
    const ctx = makeCtx(req);
    res.json(await runMacro("lens", "run", { id: req.params.id, ...req.body }, ctx));
  } catch (e) {
    const msg = String(e?.message || e);
    const status = msg.startsWith("forbidden") ? 403 : 500;
    res.status(status).json({ ok: false, error: msg });
  }
});
app.get("/api/lens/:domain/:id/export", async (req, res) => {
  try {
    const ctx = makeCtx(req);
    res.json(await runMacro("lens", "export", { id: req.params.id, format: req.query.format || "json" }, ctx));
  } catch (e) {
    const msg = String(e?.message || e);
    const status = msg.startsWith("forbidden") ? 403 : 500;
    res.status(status).json({ ok: false, error: msg });
  }
});
app.post("/api/lens/:domain/bulk", async (req, res) => {
  try {
    const ctx = makeCtx(req);
    res.json(await runMacro("lens", "bulkCreate", { domain: req.params.domain, ...req.body }, ctx));
  } catch (e) {
    const msg = String(e?.message || e);
    const status = msg.startsWith("forbidden") ? 403 : 500;
    res.status(status).json({ ok: false, error: msg });
  }
});

// ── Domain-Specific Lens Action Engines ──────────────────────────────────────
// Each domain registers its computational actions via registerLensAction.
// These are invoked through the generic lens.run macro + /api/lens/:domain/:id/run

// === Paper (Research) ===
registerLensAction("paper", "validate", async (ctx, artifact, params) => {
  const claims = artifact.data?.claims || [];

  // v5.5: Run empirical gates on each claim for math/units/constants checking
  let empiricalResults = null;
  try {
    empiricalResults = await ctx.macro.run("emergent", "bridge.lensValidate", { artifact });
  } catch {}

  const empiricalMap = new Map();
  if (empiricalResults?.results) {
    for (const r of empiricalResults.results) {
      if (r.claimId) empiricalMap.set(r.claimId, r);
    }
  }

  const validated = claims.map(c => {
    const emp = empiricalMap.get(c.id);
    return {
      ...c,
      validated: true,
      validatedAt: nowISO(),
      empirical: emp ? { passed: emp.passed, issues: emp.issues } : undefined,
    };
  });

  artifact.data = { ...artifact.data, claims: validated };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return {
    ok: true,
    validated: validated.length,
    empirical: empiricalResults ? {
      claimsChecked: empiricalResults.claimsChecked,
      issueCount: empiricalResults.issueCount,
      passRate: empiricalResults.passRate,
    } : null,
  };
});
registerLensAction("paper", "synthesize", async (ctx, artifact, params) => {
  const claims = artifact.data?.claims || [];
  const validatedCount = claims.filter(c => c.validated).length;
  const withEvidence = claims.filter(c => (c.evidence || c.sources || []).length > 0).length;
  const confidence = claims.length > 0 ? Math.round(((validatedCount / claims.length) * 0.6 + (withEvidence / claims.length) * 0.4) * 100) / 100 : 0;
  const themes = {};
  claims.forEach(c => { (c.tags || c.themes || []).forEach(t => { themes[t] = (themes[t] || 0) + 1; }); });
  const topThemes = Object.entries(themes).sort((a, b) => b[1] - a[1]).slice(0, 5).map(([theme]) => theme);
  const narrative = claims.length > 0
    ? `Across ${claims.length} claims (${validatedCount} validated, ${withEvidence} with evidence)${topThemes.length > 0 ? `, key themes: ${topThemes.join(", ")}` : ""}`
    : "No claims available for synthesis";
  const synthesis = { id: uid("syn"), claims: claims.map(c => c.id || c.text), narrative, confidence, validatedCount, withEvidence, topThemes, version: (artifact.data?.synthesis?.version || 0) + 1, createdAt: nowISO() };
  artifact.data = { ...artifact.data, synthesis };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, synthesis };
});
registerLensAction("paper", "detect-contradictions", async (ctx, artifact, params) => {
  const claims = artifact.data?.claims || [];
  const contradictions = [];
  for (let i = 0; i < claims.length; i++) {
    for (let j = i + 1; j < claims.length; j++) {
      if (claims[i].negates === claims[j].id || claims[j].negates === claims[i].id) {
        contradictions.push({ claimA: claims[i].id, claimB: claims[j].id });
      }
    }
  }
  return { ok: true, contradictions, count: contradictions.length };
});
registerLensAction("paper", "trace-lineage", async (ctx, artifact, params) => {
  const versions = artifact.data?.versions || [{ version: artifact.version, updatedAt: artifact.updatedAt }];
  return { ok: true, lineage: versions, currentVersion: artifact.version };
});

// === Reasoning ===
registerLensAction("reasoning", "validate", async (ctx, artifact, params) => {
  const steps = artifact.data?.steps || [];
  const valid = steps.every(s => s.content && s.content.length > 0);
  return { ok: true, valid, stepCount: steps.length, type: artifact.data?.type || "deductive" };
});
registerLensAction("reasoning", "trace", async (ctx, artifact, params) => {
  return { ok: true, trace: { steps: artifact.data?.steps || [], conclusion: artifact.data?.conclusion, premise: artifact.data?.premise, type: artifact.data?.type } };
});
registerLensAction("reasoning", "conclude", async (ctx, artifact, params) => {
  const steps = artifact.data?.steps || [];
  const type = artifact.data?.type || "deductive";
  const premise = artifact.data?.premise || "";
  let conclusion = params.conclusion;
  if (!conclusion && steps.length > 0) {
    const lastStep = steps[steps.length - 1];
    const stepContents = steps.map(s => s.content || s.text || "").filter(Boolean);
    conclusion = lastStep.conclusion || lastStep.content || stepContents[stepContents.length - 1] || "";
  }
  if (!conclusion) conclusion = premise || artifact.title || "";
  const valid = steps.every(s => s.content && s.content.length > 0);
  const strength = valid ? Math.min(1, 0.5 + steps.length * 0.1) : Math.max(0.1, 0.5 - steps.filter(s => !s.content).length * 0.15);
  artifact.data = { ...artifact.data, conclusion, concludedAt: nowISO(), conclusionStrength: Math.round(strength * 100) / 100, reasoningType: type, stepCount: steps.length };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, conclusion, strength: Math.round(strength * 100) / 100, type, stepCount: steps.length, valid };
});
registerLensAction("reasoning", "fork", async (ctx, artifact, params) => {
  const forkId = uid("lart");
  const fork = { ...JSON.parse(JSON.stringify(artifact)), id: forkId, title: `${artifact.title} (fork)`, createdAt: nowISO(), updatedAt: nowISO(), version: 1 };
  fork.data.forkedFrom = artifact.id;
  STATE.lensArtifacts.set(forkId, fork);
  _lensDomainIndexAdd(fork.domain, forkId);
  saveStateDebounced();
  return { ok: true, fork };
});

// === Council (Governance) ===
registerLensAction("council", "debate", async (ctx, artifact, params) => {
  const existingTurns = artifact.data?.debate?.turns || [];
  const newTurns = params.turns || [];
  const allTurns = [...existingTurns, ...newTurns];
  const participants = [...new Set(allTurns.map(t => t.speaker || t.participant || "unknown"))];
  const positions = {};
  allTurns.forEach(t => {
    const speaker = t.speaker || t.participant || "unknown";
    const stance = t.stance || t.position || "neutral";
    if (!positions[stance]) positions[stance] = [];
    if (!positions[stance].includes(speaker)) positions[stance].push(speaker);
  });
  const stanceSummary = Object.entries(positions).map(([stance, speakers]) => ({ stance, supporters: speakers.length, speakers }));
  const dominantStance = stanceSummary.sort((a, b) => b.supporters - a.supporters)[0];
  const consensus = participants.length > 0 && dominantStance ? dominantStance.supporters / participants.length : 0;
  const synthesis = `${participants.length} participants across ${allTurns.length} turns. ${dominantStance ? `Leading position: "${dominantStance.stance}" (${dominantStance.supporters}/${participants.length}).` : ""} Consensus: ${Math.round(consensus * 100)}%`;
  artifact.data = { ...artifact.data, debate: { turns: allTurns, synthesis, participants, stanceSummary, consensusLevel: Math.round(consensus * 100) / 100, concludedAt: nowISO() } };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, debate: artifact.data.debate };
});
registerLensAction("council", "vote", async (ctx, artifact, params) => {
  const votes = artifact.data?.votes || [];
  const newVote = { id: uid("vote"), voterId: ctx.actor?.userId || "anon", choice: params.choice, weight: params.weight || 1, rationale: params.rationale || "", timestamp: nowISO() };
  votes.push(newVote);
  artifact.data = { ...artifact.data, votes };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, vote: newVote, totalVotes: votes.length };
});
registerLensAction("council", "simulate-budget", async (ctx, artifact, params) => {
  const budget = artifact.data?.budget || { total: 0, items: [] };
  const items = budget.items || [];
  const itemBreakdown = items.map(item => {
    const amount = item.amount || item.cost || 0;
    const variance = item.variance || item.uncertainty || 0.15;
    const low = amount * (1 - variance);
    const high = amount * (1 + variance);
    const expected = amount * (1 + variance * 0.1);
    return { name: item.name || item.label, budgeted: amount, low: Math.round(low), high: Math.round(high), expected: Math.round(expected), variance };
  });
  const totalBudgeted = items.reduce((s, i) => s + (i.amount || i.cost || 0), 0) || budget.total || 0;
  const totalExpected = itemBreakdown.reduce((s, i) => s + i.expected, 0) || totalBudgeted;
  const totalLow = itemBreakdown.reduce((s, i) => s + i.low, 0) || Math.round(totalBudgeted * 0.85);
  const totalHigh = itemBreakdown.reduce((s, i) => s + i.high, 0) || Math.round(totalBudgeted * 1.15);
  const overBudgetRisk = totalBudgeted > 0 ? Math.round(((totalHigh - totalBudgeted) / totalBudgeted) * 100) / 100 : 0;
  const risks = [];
  if (overBudgetRisk > 0.2) risks.push("high_cost_overrun_risk");
  if (items.some(i => (i.variance || 0.15) > 0.3)) risks.push("high_variance_items_present");
  if (items.length === 0) risks.push("no_line_items_for_analysis");
  const votes = artifact.data?.votes || [];
  const approvalRate = votes.length > 0 ? votes.filter(v => v.choice === "approve" || v.choice === "yes").length / votes.length : null;
  const confidence = items.length > 0 ? Math.round(Math.max(0.3, 1 - items.reduce((s, i) => s + (i.variance || 0.15), 0) / items.length) * 100) / 100 : 0.5;
  const simResult = { projected: totalExpected, totalBudgeted, range: { low: totalLow, high: totalHigh }, confidence, overBudgetRisk, risks, approvalRate, itemBreakdown, simulatedAt: nowISO() };
  artifact.data = { ...artifact.data, budgetSimulation: simResult };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, simulation: simResult };
});
registerLensAction("council", "audit", async (ctx, artifact, params) => {
  const votes = artifact.data?.votes || [];
  const debate = artifact.data?.debate || {};
  const uniqueVoters = [...new Set(votes.map(v => v.voterId))];
  const voteTimeline = votes.map(v => ({ voterId: v.voterId, choice: v.choice, weight: v.weight || 1, timestamp: v.timestamp }));
  const choiceTally = {};
  let totalWeight = 0;
  votes.forEach(v => { const c = v.choice || "abstain"; choiceTally[c] = (choiceTally[c] || 0) + (v.weight || 1); totalWeight += (v.weight || 1); });
  const hasDebate = !!(debate.turns && debate.turns.length > 0);
  const hasBudget = !!artifact.data?.budget;
  const hasSimulation = !!artifact.data?.budgetSimulation;
  const completeness = [votes.length > 0, hasDebate, hasBudget || !artifact.data?.requiresBudget].filter(Boolean).length / 3;
  const trail = {
    entityType: artifact.type || "proposal", entityId: artifact.id,
    totalVotes: votes.length, uniqueVoters: uniqueVoters.length,
    choiceTally, totalWeight,
    debateTurns: debate.turns?.length || 0,
    processCompleteness: Math.round(completeness * 100) / 100,
    voteTimeline: voteTimeline.slice(-20),
    lastAction: artifact.updatedAt, createdAt: artifact.createdAt,
    auditedAt: nowISO()
  };
  return { ok: true, audit: trail };
});

// === Agents ===
registerLensAction("agents", "start", async (ctx, artifact, params) => {
  artifact.data = { ...artifact.data, status: "active", startedAt: nowISO() };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, status: "active" };
});
registerLensAction("agents", "stop", async (ctx, artifact, params) => {
  artifact.data = { ...artifact.data, status: "dormant", stoppedAt: nowISO() };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, status: "dormant" };
});
registerLensAction("agents", "reset", async (ctx, artifact, params) => {
  artifact.data = { ...artifact.data, status: "idle", memory: [], logs: [], tickCount: 0, resetAt: nowISO() };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, status: "reset" };
});
registerLensAction("agents", "configure", async (ctx, artifact, params) => {
  artifact.data = { ...artifact.data, config: { ...artifact.data?.config, ...params } };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, config: artifact.data.config };
});
registerLensAction("agents", "deliberate", async (ctx, artifact, params) => {
  const deliberation = { id: uid("delib"), topic: params.topic || artifact.title, participants: [artifact.id], arguments: params.arguments || [], outcome: "pending", startedAt: nowISO() };
  artifact.data = { ...artifact.data, lastDeliberation: deliberation };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, deliberation };
});
registerLensAction("agents", "arbitrate", async (ctx, artifact, params) => {
  const delib = artifact.data?.lastDeliberation || {};
  const args = delib.arguments || params.arguments || [];
  const forArgs = args.filter(a => a.stance === "for" || a.support === true);
  const againstArgs = args.filter(a => a.stance === "against" || a.support === false);
  const totalArgs = forArgs.length + againstArgs.length;
  const confidence = totalArgs > 0 ? Math.round((Math.abs(forArgs.length - againstArgs.length) / totalArgs * 0.5 + Math.min(1, totalArgs / 10) * 0.5) * 100) / 100 : 0.5;
  const autoChoice = forArgs.length > againstArgs.length ? "proceed" : forArgs.length < againstArgs.length ? "reject" : "defer";
  const choice = params.choice || autoChoice;
  const rationale = params.rationale || (totalArgs > 0 ? `${forArgs.length} arguments for, ${againstArgs.length} against. Decision: ${choice}` : `No arguments provided. Default: ${choice}`);
  const decision = { id: uid("dec"), deliberationId: params.deliberationId || delib.id, choice, rationale, confidence, forCount: forArgs.length, againstCount: againstArgs.length, approvedBy: ctx.actor?.userId || "system", decidedAt: nowISO() };
  artifact.data = { ...artifact.data, lastDecision: decision };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, decision };
});

// === Sim (Simulation) ===
registerLensAction("sim", "simulate", async (ctx, artifact, params) => {
  const assumptions = artifact.data?.assumptions || params.assumptions || [];
  const variables = artifact.data?.variables || {};
  let seed = 0;
  for (let i = 0; i < artifact.id.length; i++) seed = ((seed << 5) - seed) + artifact.id.charCodeAt(i);
  const mulberry32 = (s) => () => { s |= 0; s = s + 0x6D2B79F5 | 0; let t = Math.imul(s ^ s >>> 15, 1 | s); t = t + Math.imul(t ^ t >>> 7, 61 | t) ^ t; return ((t ^ t >>> 14) >>> 0) / 4294967296; };
  const rng = mulberry32(seed + (artifact.data?.runCount || 0));
  const outcomes = assumptions.map(a => {
    const name = typeof a === 'string' ? a : a.name || a.label || String(a);
    const baseImpact = typeof a === 'object' ? (a.impact || a.weight || 0.5) : 0.5;
    const uncertainty = typeof a === 'object' ? (a.uncertainty || 0.2) : 0.2;
    const u1 = rng() || 0.0001;
    const u2 = rng();
    const z = Math.sqrt(-2 * Math.log(u1)) * Math.cos(2 * Math.PI * u2);
    const impact = Math.round(Math.max(0, Math.min(1, baseImpact + z * uncertainty)) * 1000) / 1000;
    const confidence = Math.round(Math.max(0.1, 1 - uncertainty * 2) * 100) / 100;
    return { assumption: name, impact, confidence, baseImpact, uncertainty };
  });
  const avgImpact = outcomes.length > 0 ? outcomes.reduce((s, o) => s + o.impact, 0) / outcomes.length : 0;
  const risks = [];
  const highImpact = outcomes.filter(o => o.impact > 0.7);
  const lowConfidence = outcomes.filter(o => o.confidence < 0.5);
  if (highImpact.length > 0) risks.push(`${highImpact.length} high-impact assumptions`);
  if (lowConfidence.length > 0) risks.push(`${lowConfidence.length} low-confidence assumptions`);
  if (outcomes.length < 3) risks.push("limited_assumptions_coverage");
  const result = { id: uid("simrun"), outcomes, averageImpact: Math.round(avgImpact * 1000) / 1000, risks, runNumber: (artifact.data?.runCount || 0) + 1, completedAt: nowISO() };
  artifact.data = { ...artifact.data, lastRun: result, status: "completed", runCount: (artifact.data?.runCount || 0) + 1, runs: [...(artifact.data?.runs || []).slice(-9), result] };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, result };
});
registerLensAction("sim", "analyze", async (ctx, artifact, params) => {
  const lastRun = artifact.data?.lastRun;
  if (!lastRun) return { ok: false, error: "no simulation run to analyze" };
  const outcomes = lastRun.outcomes || [];
  const sensitivity = outcomes.map(o => ({ ...o, sensitivity: Math.abs(o.impact) })).sort((a, b) => b.sensitivity - a.sensitivity);
  const runs = artifact.data?.runs || [];
  const crossRunAnalysis = outcomes.map(o => {
    const name = o.assumption;
    const pastImpacts = runs.map(r => (r.outcomes || []).find(ro => ro.assumption === name)?.impact).filter(Boolean);
    const avg = pastImpacts.length > 0 ? pastImpacts.reduce((s, v) => s + v, 0) / pastImpacts.length : o.impact;
    const variance = pastImpacts.length > 1 ? pastImpacts.reduce((s, v) => s + (v - avg) ** 2, 0) / pastImpacts.length : 0;
    return { assumption: name, averageImpact: Math.round(avg * 1000) / 1000, variance: Math.round(variance * 10000) / 10000, samples: pastImpacts.length };
  });
  return { ok: true, analysis: { sensitivity, crossRunAnalysis, totalRuns: runs.length, analyzedAt: nowISO() } };
});
registerLensAction("sim", "compare", async (ctx, artifact, params) => {
  const runs = artifact.data?.runs || [];
  const compareId = params.runId;
  if (runs.length < 2 && !compareId) return { ok: true, comparison: { note: "Need at least 2 runs to compare", totalRuns: runs.length } };
  const baseline = compareId ? runs.find(r => r.id === compareId) || runs[0] : runs[runs.length - 2];
  const current = runs[runs.length - 1];
  if (!baseline || !current) return { ok: true, comparison: { note: "insufficient_runs", totalRuns: runs.length } };
  const diffs = (current.outcomes || []).map(co => {
    const bo = (baseline.outcomes || []).find(o => o.assumption === co.assumption);
    return { assumption: co.assumption, currentImpact: co.impact, baselineImpact: bo?.impact || null, delta: bo ? Math.round((co.impact - bo.impact) * 1000) / 1000 : null };
  });
  return { ok: true, comparison: { baselineRun: baseline.id, currentRun: current.id, diffs, avgDelta: diffs.filter(d => d.delta !== null).length > 0 ? Math.round(diffs.filter(d => d.delta !== null).reduce((s, d) => s + Math.abs(d.delta), 0) / diffs.filter(d => d.delta !== null).length * 1000) / 1000 : 0, comparedAt: nowISO() } };
});
registerLensAction("sim", "archive", async (ctx, artifact, params) => {
  artifact.data = { ...artifact.data, status: "archived", archivedAt: nowISO() };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, archived: true };
});

// === Studio (Creative) ===
registerLensAction("studio", "mix", async (ctx, artifact, params) => {
  const tracks = artifact.data?.tracks || [];
  const mixSettings = params.settings || artifact.data?.mixSettings || {};

  // Real audio analysis: per-track RMS, peak detection, frequency balance, stereo width
  const trackAnalysis = tracks.map(t => {
    const vol = t.volume != null ? t.volume : 0.8;
    const pan = t.pan != null ? t.pan : 0;
    const rms = vol * (t.rms || 0.707); // RMS = volume * source RMS (default -3dBFS)
    const peakDb = 20 * Math.log10(Math.max(vol * (t.peak || 1), 1e-10));
    const rmsDb = 20 * Math.log10(Math.max(rms, 1e-10));
    const crestFactor = peakDb - rmsDb; // Dynamic range indicator
    // Frequency balance from track type heuristic
    const freq = t.frequency || t.type || "mid";
    const freqBand = freq === "bass" || freq === "kick" || freq === "sub" ? "low"
      : freq === "vocal" || freq === "guitar" || freq === "mid" ? "mid"
      : freq === "cymbal" || freq === "hi-hat" || freq === "high" ? "high" : "mid";
    return {
      name: t.name || t.label || "untitled",
      volume: vol, pan, muted: !!t.muted, solo: !!t.solo,
      effects: (t.effects || []).length,
      rms: Math.round(rms * 1000) / 1000,
      peakDb: Math.round(peakDb * 10) / 10,
      rmsDb: Math.round(rmsDb * 10) / 10,
      crestFactor: Math.round(crestFactor * 10) / 10,
      freqBand,
    };
  });

  const activeTracks = trackAnalysis.filter(t => !t.muted);
  const soloTracks = trackAnalysis.filter(t => t.solo);
  const effective = soloTracks.length > 0 ? soloTracks : activeTracks;

  // Sum-of-squares RMS for combined signal estimation
  const combinedRms = effective.length > 0
    ? Math.sqrt(effective.reduce((s, t) => s + t.rms * t.rms, 0))
    : 0;
  const combinedPeakDb = effective.length > 0
    ? Math.max(...effective.map(t => t.peakDb))
    : -Infinity;

  // Frequency balance check
  const freqDist = { low: 0, mid: 0, high: 0 };
  for (const t of effective) freqDist[t.freqBand] = (freqDist[t.freqBand] || 0) + 1;
  const freqTotal = effective.length || 1;
  const freqBalance = {
    low: Math.round((freqDist.low / freqTotal) * 100),
    mid: Math.round((freqDist.mid / freqTotal) * 100),
    high: Math.round((freqDist.high / freqTotal) * 100),
  };

  // Stereo width from pan spread
  const panValues = effective.map(t => t.pan);
  const stereoWidth = panValues.length > 1
    ? Math.round((Math.max(...panValues) - Math.min(...panValues)) * 100)
    : 0;

  // Mix warnings
  const warnings = [];
  if (combinedPeakDb > -0.5) warnings.push("clipping_risk");
  if (combinedRms > 0.9) warnings.push("sum_too_hot");
  if (freqBalance.low > 60) warnings.push("bass_heavy");
  if (freqBalance.high > 60) warnings.push("treble_heavy");
  if (stereoWidth < 20 && effective.length > 2) warnings.push("narrow_stereo");

  const mixResult = {
    tracks: trackAnalysis, activeCount: effective.length,
    combinedRms: Math.round(combinedRms * 1000) / 1000,
    combinedPeakDb: Math.round(combinedPeakDb * 10) / 10,
    freqBalance, stereoWidth, warnings,
    settings: mixSettings, mixedAt: nowISO(),
  };

  artifact.data = { ...artifact.data, mixStatus: "mixed", lastMix: mixResult };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, mix: { projectId: artifact.id, trackCount: tracks.length, activeCount: effective.length, combinedRms: mixResult.combinedRms, combinedPeakDb: mixResult.combinedPeakDb, freqBalance, stereoWidth, warnings, mixedAt: nowISO() } };
});
registerLensAction("studio", "master", async (ctx, artifact, params) => {
  const mix = artifact.data?.lastMix || {};
  const targetLoudness = params.targetLUFS || -14;
  const avgVolume = mix.avgVolume || 0.7;
  const gainAdjustment = Math.round((1 - avgVolume) * 6 * 100) / 100;
  const limiterThreshold = Math.round(Math.min(-0.3, targetLoudness + 14 - 1) * 100) / 100;
  const masterSettings = { targetLoudness, gainAdjustment, limiterThreshold, peakCeiling: -0.1, format: params.format || "wav", sampleRate: params.sampleRate || 44100, bitDepth: params.bitDepth || 24 };
  artifact.data = { ...artifact.data, masterStatus: "mastered", lastMaster: { ...masterSettings, masteredAt: nowISO() } };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, master: { projectId: artifact.id, ...masterSettings, masteredAt: nowISO() } };
});
registerLensAction("studio", "bounce", async (ctx, artifact, params) => {
  const format = params.format || "wav";
  const master = artifact.data?.lastMaster || {};
  const tracks = artifact.data?.tracks || [];
  const duration = artifact.data?.duration || tracks.reduce((max, t) => Math.max(max, t.duration || 0), 0);
  const sampleRate = master.sampleRate || params.sampleRate || 44100;
  const bitDepth = master.bitDepth || params.bitDepth || (format === "mp3" ? 16 : 24);
  const estimatedSizeKB = Math.round(duration * sampleRate * bitDepth / 8 / 1024 * (format === "mp3" ? 0.1 : 1));
  artifact.data = { ...artifact.data, lastBounce: { format, sampleRate, bitDepth, duration, estimatedSizeKB, bouncedAt: nowISO() } };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, bounce: { projectId: artifact.id, format, duration, sampleRate, bitDepth, estimatedSizeKB, bouncedAt: nowISO() } };
});
registerLensAction("studio", "render", async (ctx, artifact, params) => {
  const render = { id: uid("render"), projectId: artifact.id, format: params.format || "wav", status: "complete", renderedAt: nowISO() };
  artifact.data = { ...artifact.data, lastRender: render };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, render };
});

// === Law (Legal) ===
registerLensAction("law", "check-compliance", async (ctx, artifact, params) => {
  const text = (params.text || artifact.data?.body || artifact.title || "").toLowerCase();
  const violations = [];
  if (text.includes("personal data") && text.includes("sell")) violations.push("GDPR Art. 6: Unlawful processing");
  if (text.includes("copyright") && text.includes("bypass")) violations.push("DMCA §1201: Circumvention");
  if (text.includes("discriminat")) violations.push("EU AI Act: Prohibited practice");
  if (text.includes("biometric") && text.includes("mass")) violations.push("EU AI Act Art. 5: Prohibited biometric surveillance");
  return { ok: true, passed: violations.length === 0, violations, checkedAt: nowISO() };
});
registerLensAction("law", "analyze", async (ctx, artifact, params) => {
  const frameworks = artifact.data?.frameworks || ["GDPR", "CCPA", "DMCA", "EU AI Act"];
  const text = (artifact.data?.body || artifact.title || "").toLowerCase();
  const citations = artifact.data?.citations || [];
  const drafts = artifact.data?.drafts || [];
  const frameworkKeywords = {
    "GDPR": ["personal data", "consent", "data subject", "processing", "controller", "processor", "transfer", "erasure", "portability"],
    "CCPA": ["consumer", "personal information", "sale", "opt-out", "disclosure", "business purpose"],
    "DMCA": ["copyright", "takedown", "safe harbor", "infringement", "notice", "counter-notice"],
    "EU AI Act": ["artificial intelligence", "high-risk", "biometric", "prohibited", "transparency", "conformity"]
  };
  const analysis = frameworks.map(f => {
    const keywords = frameworkKeywords[f] || [];
    const matches = keywords.filter(k => text.includes(k));
    const coverage = keywords.length > 0 ? matches.length / keywords.length : 0;
    const relevantCitations = citations.filter(c => (c.source || "").includes(f) || (c.text || "").toLowerCase().includes(f.toLowerCase()));
    let risk = "low";
    if (coverage > 0.5) risk = "high";
    else if (coverage > 0.2) risk = "medium";
    let status = "no_issues";
    if (coverage > 0 && relevantCitations.length === 0) status = "needs_review";
    else if (coverage > 0 && relevantCitations.length > 0) status = "documented";
    return { framework: f, status, risk, coverage: Math.round(coverage * 100) / 100, matchedKeywords: matches, citationCount: relevantCitations.length, lastChecked: nowISO() };
  });
  const overallRisk = analysis.some(a => a.risk === "high") ? "high" : analysis.some(a => a.risk === "medium") ? "medium" : "low";
  return { ok: true, analysis, overallRisk, totalDrafts: drafts.length, totalCitations: citations.length };
});
registerLensAction("law", "draft", async (ctx, artifact, params) => {
  const draft = { id: uid("draft"), caseId: artifact.id, title: params.title || "New Draft", body: params.body || "", version: 1, status: "draft", createdAt: nowISO() };
  artifact.data = { ...artifact.data, drafts: [...(artifact.data?.drafts || []), draft] };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, draft };
});
registerLensAction("law", "cite", async (ctx, artifact, params) => {
  const citation = { id: uid("cite"), source: params.source || "Unknown", text: params.text || "", relevance: params.relevance || 0.8, addedAt: nowISO() };
  artifact.data = { ...artifact.data, citations: [...(artifact.data?.citations || []), citation] };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, citation };
});

// === Graph (Knowledge Graph) ===
registerLensAction("graph", "query", async (ctx, artifact, params) => {
  const nodes = artifact.data?.nodes || [];
  const edges = artifact.data?.edges || [];
  const q = (params.query || "").toLowerCase();
  const matched = q ? nodes.filter(n => (n.label || "").toLowerCase().includes(q)) : nodes;
  return { ok: true, nodes: matched, edges, total: matched.length };
});
registerLensAction("graph", "cluster", async (ctx, artifact, params) => {
  const nodes = artifact.data?.nodes || [];
  const edges = artifact.data?.edges || [];
  const k = Math.min(params.k || 3, Math.max(1, nodes.length));
  if (nodes.length === 0) return { ok: true, clusters: [], k: 0 };
  const adjacency = {};
  nodes.forEach(n => { adjacency[n.id] = new Set(); });
  edges.forEach(e => {
    if (adjacency[e.source]) adjacency[e.source].add(e.target);
    if (adjacency[e.target]) adjacency[e.target].add(e.source);
  });
  const assignments = new Array(nodes.length).fill(0);
  nodes.forEach((n, i) => { assignments[i] = i % k; });
  for (let iter = 0; iter < 20; iter++) {
    let changed = false;
    nodes.forEach((node, i) => {
      const neighbors = adjacency[node.id] || new Set();
      const clusterCounts = new Array(k).fill(0);
      neighbors.forEach(nId => {
        const nIdx = nodes.findIndex(n => n.id === nId);
        if (nIdx >= 0) clusterCounts[assignments[nIdx]]++;
      });
      const bestCluster = clusterCounts.indexOf(Math.max(...clusterCounts));
      if (bestCluster >= 0 && bestCluster !== assignments[i]) { assignments[i] = bestCluster; changed = true; }
    });
    if (!changed) break;
  }
  const clusters = Array.from({ length: k }, (_, i) => {
    const members = nodes.filter((_, j) => assignments[j] === i).map(n => n.id);
    const internalEdges = edges.filter(e => members.includes(e.source) && members.includes(e.target)).length;
    return { id: i, members, size: members.length, internalEdges };
  }).filter(c => c.size > 0);
  const modularity = edges.length > 0 ? clusters.reduce((s, c) => s + c.internalEdges, 0) / edges.length : 0;
  return { ok: true, clusters, k: clusters.length, modularity: Math.round(modularity * 1000) / 1000 };
});
registerLensAction("graph", "analyze", async (ctx, artifact, params) => {
  const nodes = artifact.data?.nodes || [];
  const edges = artifact.data?.edges || [];
  const maxPossibleEdges = nodes.length * (nodes.length - 1) / 2;
  const density = maxPossibleEdges > 0 ? edges.length / maxPossibleEdges : 0;
  const degree = {};
  nodes.forEach(n => { degree[n.id] = 0; });
  edges.forEach(e => { degree[e.source] = (degree[e.source] || 0) + 1; degree[e.target] = (degree[e.target] || 0) + 1; });
  const degrees = Object.values(degree);
  const avgDegree = degrees.length > 0 ? degrees.reduce((s, d) => s + d, 0) / degrees.length : 0;
  const maxDegree = degrees.length > 0 ? Math.max(...degrees) : 0;
  const isolatedNodes = degrees.filter(d => d === 0).length;
  const hubs = nodes.filter(n => (degree[n.id] || 0) > avgDegree * 2).map(n => ({ id: n.id, label: n.label, degree: degree[n.id] }));
  return { ok: true, stats: { nodeCount: nodes.length, edgeCount: edges.length, density: Math.round(density * 10000) / 10000, avgDegree: Math.round(avgDegree * 100) / 100, maxDegree, isolatedNodes, hubs: hubs.slice(0, 10), analyzedAt: nowISO() } };
});
registerLensAction("graph", "merge", async (ctx, artifact, params) => {
  const { sourceId, targetId } = params;
  if (!sourceId || !targetId) return { ok: false, error: "sourceId and targetId required" };
  const nodes = artifact.data?.nodes || [];
  const edges = artifact.data?.edges || [];
  const sourceNode = nodes.find(n => n.id === sourceId);
  const targetNode = nodes.find(n => n.id === targetId);
  if (!sourceNode || !targetNode) return { ok: false, error: "source or target node not found" };
  const mergedNode = { ...targetNode, label: targetNode.label || sourceNode.label, mergedFrom: [...(targetNode.mergedFrom || []), sourceId], data: { ...(sourceNode.data || {}), ...(targetNode.data || {}) } };
  const newNodes = nodes.filter(n => n.id !== sourceId).map(n => n.id === targetId ? mergedNode : n);
  const newEdges = edges.map(e => ({ ...e, source: e.source === sourceId ? targetId : e.source, target: e.target === sourceId ? targetId : e.target })).filter(e => e.source !== e.target);
  const uniqueEdges = [];
  const seen = new Set();
  newEdges.forEach(e => { const key = [e.source, e.target].sort().join("-"); if (!seen.has(key)) { seen.add(key); uniqueEdges.push(e); } });
  artifact.data = { ...artifact.data, nodes: newNodes, edges: uniqueEdges };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, merged: { from: sourceId, into: targetId, resultingNodes: newNodes.length, resultingEdges: uniqueEdges.length, mergedAt: nowISO() } };
});

// === Whiteboard (Collaboration) ===
registerLensAction("whiteboard", "render", async (ctx, artifact, params) => {
  return { ok: true, render: { boardId: artifact.id, format: params.format || "png", renderedAt: nowISO() } };
});
registerLensAction("whiteboard", "layout", async (ctx, artifact, params) => {
  const elements = artifact.data?.elements || [];
  const layoutType = params.type || "force";
  const spacing = params.spacing || 200;
  const width = params.width || 1200;
  const height = params.height || 800;
  let laid;

  if (layoutType === "grid") {
    // Simple grid layout
    const cols = Math.max(1, Math.ceil(Math.sqrt(elements.length)));
    laid = elements.map((el, i) => ({
      ...el,
      x: (i % cols) * spacing + spacing / 2,
      y: Math.floor(i / cols) * spacing + spacing / 2,
    }));
  } else if (layoutType === "circle") {
    // Circular layout
    const cx = width / 2, cy = height / 2;
    const radius = Math.min(width, height) * 0.35;
    laid = elements.map((el, i) => {
      const angle = (2 * Math.PI * i) / Math.max(elements.length, 1);
      return { ...el, x: Math.round(cx + radius * Math.cos(angle)), y: Math.round(cy + radius * Math.sin(angle)) };
    });
  } else {
    // Force-directed layout (simplified Fruchterman-Reingold)
    const k = Math.sqrt((width * height) / Math.max(elements.length, 1)); // ideal spacing
    const iterations = Math.min(50, elements.length * 3);
    const temp0 = width / 4;

    // Initialize positions randomly within bounds
    laid = elements.map((el, i) => ({
      ...el,
      x: el.x != null ? el.x : 100 + (i * 137.5) % (width - 200),
      y: el.y != null ? el.y : 100 + (i * 97.3) % (height - 200),
      _dx: 0, _dy: 0,
    }));

    // Build adjacency from connections/edges
    const edges = artifact.data?.edges || artifact.data?.connections || [];

    for (let iter = 0; iter < iterations; iter++) {
      const temp = temp0 * (1 - iter / iterations);

      // Reset displacements
      for (const n of laid) { n._dx = 0; n._dy = 0; }

      // Repulsive forces between all pairs
      for (let i = 0; i < laid.length; i++) {
        for (let j = i + 1; j < laid.length; j++) {
          let dx = laid[i].x - laid[j].x;
          let dy = laid[i].y - laid[j].y;
          const dist = Math.max(Math.sqrt(dx * dx + dy * dy), 0.01);
          const force = (k * k) / dist;
          const fx = (dx / dist) * force;
          const fy = (dy / dist) * force;
          laid[i]._dx += fx;
          laid[i]._dy += fy;
          laid[j]._dx -= fx;
          laid[j]._dy -= fy;
        }
      }

      // Attractive forces along edges
      for (const e of edges) {
        const src = laid.find(n => n.id === e.from || n.id === e.source);
        const tgt = laid.find(n => n.id === e.to || n.id === e.target);
        if (!src || !tgt) continue;
        let dx = tgt.x - src.x;
        let dy = tgt.y - src.y;
        const dist = Math.max(Math.sqrt(dx * dx + dy * dy), 0.01);
        const force = (dist * dist) / k;
        const fx = (dx / dist) * force;
        const fy = (dy / dist) * force;
        src._dx += fx;
        src._dy += fy;
        tgt._dx -= fx;
        tgt._dy -= fy;
      }

      // Apply displacements (capped by temperature)
      for (const n of laid) {
        const disp = Math.max(Math.sqrt(n._dx * n._dx + n._dy * n._dy), 0.01);
        n.x = Math.round(clamp(n.x + (n._dx / disp) * Math.min(disp, temp), 50, width - 50));
        n.y = Math.round(clamp(n.y + (n._dy / disp) * Math.min(disp, temp), 50, height - 50));
      }
    }

    // Clean up temp properties
    for (const n of laid) { delete n._dx; delete n._dy; }
  }

  // Compute layout quality metrics
  let minDist = Infinity;
  for (let i = 0; i < laid.length; i++) {
    for (let j = i + 1; j < laid.length; j++) {
      const d = Math.sqrt((laid[i].x - laid[j].x) ** 2 + (laid[i].y - laid[j].y) ** 2);
      if (d < minDist) minDist = d;
    }
  }

  artifact.data = { ...artifact.data, elements: laid };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return {
    ok: true,
    layout: layoutType,
    elementCount: laid.length,
    bounds: { width, height },
    quality: { minDistance: laid.length > 1 ? Math.round(minDist) : null, spread: layoutType },
  };
});
registerLensAction("whiteboard", "collaborate", async (ctx, artifact, params) => {
  const session = { id: uid("wbsess"), boardId: artifact.id, participants: [ctx.actor?.userId || "anon"], startedAt: nowISO() };
  artifact.data = { ...artifact.data, activeSession: session };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, session };
});
registerLensAction("whiteboard", "snapshot", async (ctx, artifact, params) => {
  const snapshot = { id: uid("snap"), boardId: artifact.id, elements: artifact.data?.elements || [], createdAt: nowISO() };
  artifact.data = { ...artifact.data, snapshots: [...(artifact.data?.snapshots || []), snapshot] };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, snapshot };
});

// === Database ===
registerLensAction("database", "query", async (ctx, artifact, params) => {
  const sql = artifact.data?.sql || params.sql || "";
  const tables = artifact.data?.tables || [];
  const schema = artifact.data?.schema || {};
  if (!sql) return { ok: true, result: { columns: [], rows: [], rowCount: 0, query: "", note: "no_query_provided" } };
  const sqlUpper = sql.toUpperCase().trim();
  const isSelect = sqlUpper.startsWith("SELECT");
  const referencedTables = [];
  const fromMatch = sql.match(/FROM\s+(\w+)/i);
  if (fromMatch) referencedTables.push(fromMatch[1]);
  const joinMatches = sql.match(/JOIN\s+(\w+)/gi);
  if (joinMatches) joinMatches.forEach(j => { const m = j.match(/JOIN\s+(\w+)/i); if (m) referencedTables.push(m[1]); });
  const tableData = {};
  referencedTables.forEach(t => {
    const tbl = tables.find(tb => tb.name === t) || schema[t];
    if (tbl) tableData[t] = tbl;
  });
  const columns = referencedTables.length > 0 && tableData[referencedTables[0]]
    ? (tableData[referencedTables[0]].columns || []).map(c => c.name || c) : [];
  const rows = artifact.data?.rows || artifact.data?.sampleData || [];
  return { ok: true, result: { columns, rows: rows.slice(0, params.limit || 100), rowCount: rows.length, query: sql, referencedTables, isSelect, queryType: isSelect ? "SELECT" : sqlUpper.split(/\s/)[0] } };
});
registerLensAction("database", "analyze", async (ctx, artifact, params) => {
  const sql = artifact.data?.sql || params.sql || "";
  const tables = artifact.data?.tables || [];
  const indexes = artifact.data?.indexes || [];
  const suggestions = [];
  const sqlUpper = sql.toUpperCase();
  if (sqlUpper.includes("SELECT *")) suggestions.push("Avoid SELECT * — specify only needed columns");
  if (!sqlUpper.includes("WHERE") && (sqlUpper.includes("UPDATE") || sqlUpper.includes("DELETE"))) suggestions.push("Missing WHERE clause on UPDATE/DELETE — risk of affecting all rows");
  if (sqlUpper.includes("LIKE '%")) suggestions.push("Leading wildcard in LIKE prevents index usage");
  if (!sqlUpper.includes("LIMIT") && sqlUpper.includes("SELECT")) suggestions.push("Consider adding LIMIT to prevent large result sets");
  if (sqlUpper.includes("JOIN") && !sqlUpper.includes("ON")) suggestions.push("JOIN without ON clause — possible cartesian product");
  const fromMatch = sql.match(/FROM\s+(\w+)/i);
  if (fromMatch) {
    const tableName = fromMatch[1];
    const whereMatch = sql.match(/WHERE\s+(\w+)/i);
    if (whereMatch) {
      const whereCol = whereMatch[1];
      const hasIndex = indexes.some(idx => idx.table === tableName && (idx.columns || []).includes(whereCol));
      if (!hasIndex) suggestions.push(`Consider adding index on ${tableName}.${whereCol} (used in WHERE)`);
    }
  }
  const complexity = (sql.match(/JOIN/gi) || []).length;
  const risk = sqlUpper.includes("DROP") || sqlUpper.includes("TRUNCATE") ? "high" : (sqlUpper.includes("DELETE") || sqlUpper.includes("ALTER")) ? "medium" : "low";
  return { ok: true, analysis: { query: sql, suggestions, joinCount: complexity, risk, tableCount: tables.length, indexCount: indexes.length, analyzedAt: nowISO() } };
});
registerLensAction("database", "optimize", async (ctx, artifact, params) => {
  const sql = artifact.data?.sql || params.sql || "";
  let optimized = sql;
  const improvements = [];
  if (/SELECT\s+\*/i.test(optimized)) {
    const tables = artifact.data?.tables || [];
    const fromMatch = optimized.match(/FROM\s+(\w+)/i);
    if (fromMatch && tables.length > 0) {
      const tbl = tables.find(t => t.name === fromMatch[1]);
      if (tbl && tbl.columns) {
        optimized = optimized.replace(/SELECT\s+\*/i, `SELECT ${tbl.columns.map(c => c.name || c).join(", ")}`);
        improvements.push("Replaced SELECT * with explicit columns");
      }
    }
  }
  if (/SELECT/i.test(optimized) && !/LIMIT/i.test(optimized)) {
    optimized += " LIMIT 1000";
    improvements.push("Added LIMIT 1000 as safety guard");
  }
  if (/ORDER BY/i.test(optimized) && !/INDEX/i.test(optimized)) {
    improvements.push("Consider index on ORDER BY column for performance");
  }
  return { ok: true, optimized: { original: sql, optimized, improvements, optimizedAt: nowISO() } };
});
registerLensAction("database", "schema-inspect", async (ctx, artifact, params) => {
  const tables = artifact.data?.tables || [];
  const indexes = artifact.data?.indexes || [];
  const schema = artifact.data?.schema || {};
  const tableDetails = tables.map(t => {
    const tbl = typeof t === 'string' ? { name: t, columns: (schema[t]?.columns || []) } : t;
    const tableIndexes = indexes.filter(idx => idx.table === tbl.name);
    return { name: tbl.name, columns: (tbl.columns || []).map(c => typeof c === 'string' ? { name: c } : c), columnCount: (tbl.columns || []).length, indexes: tableIndexes, rowEstimate: tbl.rowCount || tbl.rows || null };
  });
  const totalColumns = tableDetails.reduce((s, t) => s + t.columnCount, 0);
  const tablesWithoutIndexes = tableDetails.filter(t => t.indexes.length === 0).map(t => t.name);
  return { ok: true, schema: { tables: tableDetails, indexes, tableCount: tableDetails.length, totalColumns, indexCount: indexes.length, tablesWithoutIndexes, inspectedAt: nowISO() } };
});

// === Calendar ===
registerLensAction("calendar", "schedule", async (ctx, artifact, params) => {
  artifact.data = { ...artifact.data, status: "scheduled", scheduledAt: nowISO() };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, status: "scheduled" };
});
registerLensAction("calendar", "remind", async (ctx, artifact, params) => {
  const reminder = { id: uid("rem"), eventId: artifact.id, at: params.at || nowISO(), message: params.message || "Reminder" };
  artifact.data = { ...artifact.data, reminders: [...(artifact.data?.reminders || []), reminder] };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, reminder };
});
registerLensAction("calendar", "plan_day", async (ctx, artifact, params) => {
  const events = artifact.data?.events || [];
  const targetDate = params.date || new Date().toISOString().slice(0, 10);
  const dayEvents = events.filter(e => (e.start || "").startsWith(targetDate) || (e.date || "").startsWith(targetDate));
  const sorted = [...dayEvents].sort((a, b) => (a.start || a.time || "").localeCompare(b.start || b.time || ""));
  const slots = sorted.map((e, i) => ({ ...e, order: i, duration: e.duration || (e.end && e.start ? (new Date(e.end) - new Date(e.start)) / 60000 : null) }));
  const totalMinutes = slots.reduce((s, e) => s + (e.duration || 30), 0);
  const busyHours = Math.round(totalMinutes / 60 * 10) / 10;
  return { ok: true, plan: { date: targetDate, slots, eventCount: slots.length, totalMinutes, busyHours, freeHours: Math.round((24 - busyHours) * 10) / 10, generatedAt: nowISO() } };
});
registerLensAction("calendar", "plan_week", async (ctx, artifact, params) => {
  const events = artifact.data?.events || [];
  const startDate = params.startDate || new Date().toISOString().slice(0, 10);
  const start = new Date(startDate);
  const days = [];
  for (let d = 0; d < 7; d++) {
    const date = new Date(start.getTime() + d * 86400000).toISOString().slice(0, 10);
    const dayEvents = events.filter(e => (e.start || "").startsWith(date) || (e.date || "").startsWith(date));
    const sorted = [...dayEvents].sort((a, b) => (a.start || "").localeCompare(b.start || ""));
    const totalMinutes = sorted.reduce((s, e) => s + (e.duration || 30), 0);
    days.push({ date, dayOfWeek: ["Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat"][new Date(date).getDay()], events: sorted, eventCount: sorted.length, busyMinutes: totalMinutes });
  }
  const busiestDay = days.reduce((max, d) => d.busyMinutes > max.busyMinutes ? d : max, days[0]);
  const totalEvents = days.reduce((s, d) => s + d.eventCount, 0);
  return { ok: true, weekPlan: { startDate, days, totalEvents, busiestDay: busiestDay.date, generatedAt: nowISO() } };
});
registerLensAction("calendar", "resolve_conflicts", async (ctx, artifact, params) => {
  const events = artifact.data?.events || [];
  const conflicts = [];
  for (let i = 0; i < events.length; i++) {
    for (let j = i + 1; j < events.length; j++) {
      if (events[i].end > events[j].start && events[i].start < events[j].end) conflicts.push({ a: events[i].id, b: events[j].id });
    }
  }
  return { ok: true, conflicts, count: conflicts.length };
});

// === Daily ===
registerLensAction("daily", "summarize", async (ctx, artifact, params) => {
  const content = artifact.data?.content || artifact.data?.body || "";
  const words = content.split(/\s+/).filter(Boolean);
  const sentences = (content.match(/[^.!?]+[.!?]+/g) || [content]).filter(Boolean);
  const mood = artifact.data?.mood || null;
  const tags = artifact.data?.tags || [];
  const wordFreq = {};
  words.forEach(w => { const n = w.toLowerCase().replace(/[^a-z0-9]/g, ''); if (n.length > 3) wordFreq[n] = (wordFreq[n] || 0) + 1; });
  const topWords = Object.entries(wordFreq).sort((a, b) => b[1] - a[1]).slice(0, 5).map(([word, count]) => ({ word, count }));
  const keySentences = sentences.slice(0, 3).map(s => s.trim());
  return { ok: true, summary: { keySentences, wordCount: words.length, sentenceCount: sentences.length, mood, tags, topWords, charCount: content.length, summarizedAt: nowISO() } };
});
registerLensAction("daily", "analyze", async (ctx, artifact, params) => {
  const content = artifact.data?.content || artifact.data?.body || "";
  const mood = artifact.data?.mood || null;
  const tags = artifact.data?.tags || [];
  const words = content.toLowerCase().split(/\s+/).filter(Boolean);
  const moodIndicators = { positive: ["happy", "great", "good", "amazing", "wonderful", "excited", "love", "grateful", "joy", "accomplished"], negative: ["sad", "bad", "terrible", "angry", "frustrated", "stressed", "worried", "anxious", "tired", "overwhelmed"], neutral: ["okay", "fine", "normal", "regular", "typical", "usual"] };
  const moodScores = { positive: 0, negative: 0, neutral: 0 };
  words.forEach(w => {
    if (moodIndicators.positive.some(m => w.includes(m))) moodScores.positive++;
    if (moodIndicators.negative.some(m => w.includes(m))) moodScores.negative++;
    if (moodIndicators.neutral.some(m => w.includes(m))) moodScores.neutral++;
  });
  const detectedMood = moodScores.positive > moodScores.negative ? "positive" : moodScores.negative > moodScores.positive ? "negative" : "neutral";
  const sentimentScore = words.length > 0 ? Math.round(((moodScores.positive - moodScores.negative) / Math.max(1, moodScores.positive + moodScores.negative + moodScores.neutral)) * 100) / 100 : 0;
  return { ok: true, analysis: { mood: mood || detectedMood, detectedMood, sentimentScore, moodScores, themes: tags, wordCount: words.length, analyzedAt: nowISO() } };
});
registerLensAction("daily", "detect_patterns", async (ctx, artifact, params) => {
  const allEntries = _lensDomainArtifacts("daily");
  const tagFrequency = {};
  const moodFrequency = {};
  const tagCooccurrence = {};
  const tagMoodCorrelation = {};
  const tagsByDay = {};
  allEntries.forEach(entry => {
    const tags = entry.data?.tags || [];
    const mood = entry.data?.mood || null;
    const date = (entry.data?.date || entry.createdAt || "").substring(0, 10);
    const dayOfWeek = date ? new Date(date).getDay() : null;
    tags.forEach(t => {
      tagFrequency[t] = (tagFrequency[t] || 0) + 1;
      if (mood) { if (!tagMoodCorrelation[t]) tagMoodCorrelation[t] = {}; tagMoodCorrelation[t][mood] = (tagMoodCorrelation[t][mood] || 0) + 1; }
      if (dayOfWeek !== null && !isNaN(dayOfWeek)) { if (!tagsByDay[t]) tagsByDay[t] = {}; tagsByDay[t][dayOfWeek] = (tagsByDay[t][dayOfWeek] || 0) + 1; }
    });
    if (mood) moodFrequency[mood] = (moodFrequency[mood] || 0) + 1;
    for (let i = 0; i < tags.length; i++) {
      for (let j = i + 1; j < tags.length; j++) {
        const pair = [tags[i], tags[j]].sort().join("|");
        tagCooccurrence[pair] = (tagCooccurrence[pair] || 0) + 1;
      }
    }
  });
  const sorted = [...allEntries].sort((a, b) => (a.createdAt || "").localeCompare(b.createdAt || ""));
  const midpoint = Math.floor(sorted.length / 2);
  const olderEntries = sorted.slice(0, midpoint);
  const recentEntries = sorted.slice(midpoint);
  const olderTagFreq = {};
  const recentTagFreq = {};
  olderEntries.forEach(e => (e.data?.tags || []).forEach(t => { olderTagFreq[t] = (olderTagFreq[t] || 0) + 1; }));
  recentEntries.forEach(e => (e.data?.tags || []).forEach(t => { recentTagFreq[t] = (recentTagFreq[t] || 0) + 1; }));
  const patterns = Object.entries(tagFrequency).sort((a, b) => b[1] - a[1]).map(([tag, frequency]) => {
    const olderRate = olderEntries.length > 0 ? (olderTagFreq[tag] || 0) / olderEntries.length : 0;
    const recentRate = recentEntries.length > 0 ? (recentTagFreq[tag] || 0) / recentEntries.length : 0;
    let trend = "stable";
    if (recentRate > olderRate * 1.3) trend = "increasing";
    else if (recentRate < olderRate * 0.7) trend = "decreasing";
    return { tag, frequency, trend, moodCorrelation: tagMoodCorrelation[tag] || {}, dayPatterns: tagsByDay[tag] || {} };
  });
  const cooccurrences = Object.entries(tagCooccurrence).sort((a, b) => b[1] - a[1]).slice(0, 15).map(([pair, count]) => {
    const [tag1, tag2] = pair.split("|");
    return { tags: [tag1, tag2], count };
  });
  return { ok: true, patterns, cooccurrences, moodDistribution: moodFrequency, totalEntriesAnalyzed: allEntries.length, detectedAt: nowISO() };
});
registerLensAction("daily", "generate_insights", async (ctx, artifact, params) => {
  const allEntries = _lensDomainArtifacts("daily");
  const currentTags = artifact.data?.tags || [];
  const currentMood = artifact.data?.mood || null;
  const insights = [];
  const tagFreq = {};
  allEntries.forEach(e => (e.data?.tags || []).forEach(t => { tagFreq[t] = (tagFreq[t] || 0) + 1; }));
  currentTags.forEach(tag => {
    if (tagFreq[tag] >= 3) insights.push({ id: uid("ins"), type: "recurring_theme", pattern: tag, frequency: tagFreq[tag], confidence: Math.round(Math.min(0.95, 0.3 + tagFreq[tag] * 0.1) * 100) / 100, generatedAt: nowISO() });
  });
  if (currentMood) {
    const moodEntries = allEntries.filter(e => e.data?.mood === currentMood);
    if (moodEntries.length >= 3) {
      const moodTags = {};
      moodEntries.forEach(e => (e.data?.tags || []).forEach(t => { moodTags[t] = (moodTags[t] || 0) + 1; }));
      const correlated = Object.entries(moodTags).sort((a, b) => b[1] - a[1]).slice(0, 3);
      correlated.forEach(([tag, count]) => {
        insights.push({ id: uid("ins"), type: "mood_correlation", pattern: `${currentMood} often with "${tag}"`, frequency: count, confidence: Math.round(Math.min(0.9, count / moodEntries.length) * 100) / 100, generatedAt: nowISO() });
      });
    }
  }
  const recentEntries = allEntries.filter(e => { const d = new Date(e.createdAt || 0); return Date.now() - d.getTime() < 7 * 86400000; });
  if (recentEntries.length >= 5) insights.push({ id: uid("ins"), type: "streak", pattern: `${recentEntries.length} entries in last 7 days`, confidence: 0.95, generatedAt: nowISO() });
  artifact.data = { ...artifact.data, insights: [...(artifact.data?.insights || []).slice(-20), ...insights] };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, insights, totalInsights: artifact.data.insights.length };
});

// === Collab ===
registerLensAction("collab", "summarize_thread", async (ctx, artifact, params) => {
  const changes = artifact.data?.changes || [];
  const participants = artifact.data?.participants || [];
  const uniqueParticipants = [...new Set(changes.map(c => c.userId).filter(Boolean))];
  const operationCounts = {};
  changes.forEach(c => { const op = c.operation || "unknown"; operationCounts[op] = (operationCounts[op] || 0) + 1; });
  const timeline = changes.length > 0 ? { firstChange: changes[0].timestamp || changes[0].createdAt, lastChange: changes[changes.length - 1].timestamp || changes[changes.length - 1].createdAt, durationMs: changes.length > 1 ? new Date(changes[changes.length - 1].timestamp || 0) - new Date(changes[0].timestamp || 0) : 0 } : null;
  const participantActivity = {};
  changes.forEach(c => { if (c.userId) participantActivity[c.userId] = (participantActivity[c.userId] || 0) + 1; });
  const topContributors = Object.entries(participantActivity).sort((a, b) => b[1] - a[1]).slice(0, 5).map(([userId, count]) => ({ userId, changes: count }));
  return { ok: true, summary: { changeCount: changes.length, participantCount: Math.max(participants.length, uniqueParticipants.length), operationCounts, topContributors, timeline, summarizedAt: nowISO() } };
});
registerLensAction("collab", "run_council", async (ctx, artifact, params) => {
  const vote = { id: uid("cvote"), sessionId: artifact.id, topic: params.topic || artifact.title, status: "pending", initiatedAt: nowISO() };
  artifact.data = { ...artifact.data, councilVote: vote };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, vote };
});
registerLensAction("collab", "extract_actions", async (ctx, artifact, params) => {
  const actions = (artifact.data?.changes || []).filter(c => c.operation === "action").map(c => ({ id: c.id, action: c.value, assignee: c.userId }));
  return { ok: true, actions, count: actions.length };
});

// === Experience ===
registerLensAction("experience", "endorse", async (ctx, artifact, params) => {
  const endorsement = { id: uid("end"), skillId: params.skillId, endorserId: ctx.actor?.userId || "anon", comment: params.comment || "", endorsedAt: nowISO() };
  artifact.data = { ...artifact.data, endorsements: [...(artifact.data?.endorsements || []), endorsement] };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, endorsement };
});
registerLensAction("experience", "analyze", async (ctx, artifact, params) => {
  const skills = artifact.data?.skills || [];
  const endorsements = artifact.data?.endorsements || [];
  const endorsementsBySkill = {};
  endorsements.forEach(e => { endorsementsBySkill[e.skillId] = (endorsementsBySkill[e.skillId] || 0) + 1; });
  const analyzed = skills.map(s => {
    const id = s.id || s.name;
    const endorseCount = endorsementsBySkill[id] || 0;
    const evidenceCount = (s.evidence || []).length;
    const strength = Math.round(Math.min(1, (endorseCount * 0.3 + evidenceCount * 0.4 + (s.yearsExperience || 0) * 0.05)) * 100) / 100;
    return { skill: s.name || id, level: s.level || "intermediate", endorsements: endorseCount, evidenceCount, yearsExperience: s.yearsExperience || null, strength };
  }).sort((a, b) => b.strength - a.strength);
  const categories = {};
  skills.forEach(s => { const cat = s.category || "general"; categories[cat] = (categories[cat] || 0) + 1; });
  return { ok: true, analysis: { skillCount: skills.length, topSkills: analyzed.slice(0, 10), categories, totalEndorsements: endorsements.length, analyzedAt: nowISO() } };
});
registerLensAction("experience", "generate_resume", async (ctx, artifact, params) => {
  const skills = artifact.data?.skills || [];
  const endorsements = artifact.data?.endorsements || [];
  const experience = artifact.data?.experience || artifact.data?.positions || [];
  const education = artifact.data?.education || [];
  const topSkills = skills.sort((a, b) => ((b.evidence || []).length + (b.yearsExperience || 0)) - ((a.evidence || []).length + (a.yearsExperience || 0))).slice(0, 10);
  const sections = {
    summary: { name: artifact.data?.name || artifact.title, title: artifact.data?.title || "", totalSkills: skills.length, totalEndorsements: endorsements.length },
    skills: topSkills.map(s => ({ name: s.name || s.id, level: s.level, category: s.category })),
    experience: experience.map(e => ({ role: e.role || e.title, company: e.company || e.organization, startDate: e.startDate, endDate: e.endDate, current: !e.endDate })),
    education: education.map(e => ({ institution: e.institution || e.school, degree: e.degree, field: e.field, year: e.year || e.endDate }))
  };
  const resume = { id: uid("res"), portfolioId: artifact.id, format: params.format || "json", sections, generatedAt: nowISO() };
  return { ok: true, resume };
});
registerLensAction("experience", "compare_versions", async (ctx, artifact, params) => {
  const snapshots = artifact.data?.snapshots || artifact.data?.versions || [];
  const currentSkills = (artifact.data?.skills || []).map(s => s.name || s.id);
  if (snapshots.length === 0) return { ok: true, comparison: { currentVersion: artifact.version, note: "no_previous_versions", currentSkillCount: currentSkills.length, comparedAt: nowISO() } };
  const previous = snapshots[snapshots.length - 1];
  const prevSkills = (previous.skills || []).map(s => s.name || s.id);
  const added = currentSkills.filter(s => !prevSkills.includes(s));
  const removed = prevSkills.filter(s => !currentSkills.includes(s));
  const retained = currentSkills.filter(s => prevSkills.includes(s));
  return { ok: true, comparison: { currentVersion: artifact.version, previousVersion: previous.version || snapshots.length, added, removed, retained: retained.length, growthRate: prevSkills.length > 0 ? Math.round(((currentSkills.length - prevSkills.length) / prevSkills.length) * 100) : null, comparedAt: nowISO() } };
});
registerLensAction("experience", "validate_claims", async (ctx, artifact, params) => {
  const skills = artifact.data?.skills || [];
  const validated = skills.map(s => ({ skill: s.name || s.id, hasEvidence: (s.evidence || []).length > 0, validated: (s.evidence || []).length > 0 }));
  return { ok: true, validated, validCount: validated.filter(v => v.validated).length };
});

// === Marketplace ===
registerLensAction("marketplace", "buy", async (ctx, artifact, params) => {
  const purchase = { id: uid("pur"), listingId: artifact.id, buyerId: ctx.actor?.userId || "anon", amount: artifact.data?.price || 0, purchasedAt: nowISO() };
  artifact.data = { ...artifact.data, purchases: [...(artifact.data?.purchases || []), purchase] };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, purchase };
});
registerLensAction("marketplace", "sell", async (ctx, artifact, params) => {
  artifact.data = { ...artifact.data, status: "listed", listedAt: nowISO() };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, status: "listed" };
});
registerLensAction("marketplace", "review", async (ctx, artifact, params) => {
  const review = { id: uid("rev"), listingId: artifact.id, rating: params.rating || 5, comment: params.comment || "", reviewerId: ctx.actor?.userId || "anon", reviewedAt: nowISO() };
  artifact.data = { ...artifact.data, reviews: [...(artifact.data?.reviews || []), review] };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, review };
});
registerLensAction("marketplace", "verify_artifact_hash", async (ctx, artifact, params) => {
  const hash = artifact.data?.artifactHash || "none";
  return { ok: true, verified: hash !== "none", hash, verifiedAt: nowISO() };
});
registerLensAction("marketplace", "issue_license", async (ctx, artifact, params) => {
  const license = { id: uid("lic"), listingId: artifact.id, type: params.type || "standard", grantedTo: params.grantedTo || ctx.actor?.userId || "anon", issuedAt: nowISO(), expiresAt: params.expiresAt || null };
  artifact.data = { ...artifact.data, licenses: [...(artifact.data?.licenses || []), license] };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, license };
});
registerLensAction("marketplace", "distribute_royalties", async (ctx, artifact, params) => {
  const sales = (artifact.data?.purchases || []).length;
  const royaltyRate = params.rate || 0.1;
  const total = sales * (artifact.data?.price || 0) * royaltyRate;
  return { ok: true, royalties: { sales, rate: royaltyRate, total, distributedAt: nowISO() } };
});

// === Forum ===
registerLensAction("forum", "vote", async (ctx, artifact, params) => {
  const vote = { id: uid("fvote"), postId: artifact.id, direction: params.direction || "up", voterId: ctx.actor?.userId || "anon", votedAt: nowISO() };
  const votes = artifact.data?.votes || 0;
  artifact.data = { ...artifact.data, votes: votes + (params.direction === "down" ? -1 : 1) };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, vote, newScore: artifact.data.votes };
});
registerLensAction("forum", "pin", async (ctx, artifact, params) => {
  artifact.data = { ...artifact.data, pinned: true, pinnedAt: nowISO() };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, pinned: true };
});
registerLensAction("forum", "moderate", async (ctx, artifact, params) => {
  const action = params.action || "flag";
  artifact.data = { ...artifact.data, moderationStatus: action, moderatedAt: nowISO(), moderatedBy: ctx.actor?.userId || "system" };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, moderation: { action, moderatedAt: nowISO() } };
});
registerLensAction("forum", "rank_posts", async (ctx, artifact, params) => {
  const upvotes = artifact.data?.upvotes || Math.max(0, artifact.data?.votes || 0);
  const downvotes = artifact.data?.downvotes || 0;
  const totalVotes = upvotes + downvotes;
  let wilsonScore = 0;
  if (totalVotes > 0) {
    const p = upvotes / totalVotes;
    const z = 1.96;
    const denominator = 1 + z * z / totalVotes;
    const centre = p + z * z / (2 * totalVotes);
    const spread = z * Math.sqrt((p * (1 - p) + z * z / (4 * totalVotes)) / totalVotes);
    wilsonScore = (centre - spread) / denominator;
  }
  const ageHours = (Date.now() - new Date(artifact.createdAt || 0).getTime()) / 3600000;
  const gravity = params.gravity || 1.8;
  const hotScore = totalVotes > 0 ? (upvotes - downvotes) / Math.pow(ageHours + 2, gravity) : 0;
  const commentCount = artifact.data?.commentCount || 0;
  const engagementFactor = Math.log2(1 + commentCount);
  const compositeScore = Math.round((wilsonScore * 100 + hotScore * 10 + engagementFactor) * 100) / 100;
  return {
    ok: true,
    rank: {
      postId: artifact.id, wilsonScore: Math.round(wilsonScore * 10000) / 10000,
      hotScore: Math.round(hotScore * 10000) / 10000, compositeScore,
      factors: { upvotes, downvotes, totalVotes, commentCount,
        engagementFactor: Math.round(engagementFactor * 100) / 100,
        ageHours: Math.round(ageHours * 10) / 10, gravity },
      rankedAt: nowISO()
    }
  };
});
registerLensAction("forum", "extract_thesis", async (ctx, artifact, params) => {
  const body = artifact.data?.body || artifact.title || "";
  const sentences = (body.match(/[^.!?]+[.!?]+/g) || [body]).map(s => s.trim()).filter(Boolean);
  const thesisIndicators = ["i believe", "i think", "i argue", "my thesis", "the point is", "in conclusion", "therefore", "thus", "hence", "the argument is", "we should", "it is clear"];
  let thesis = sentences[0] || body;
  let confidence = 0.3;
  for (const s of sentences) {
    const lower = s.toLowerCase();
    if (thesisIndicators.some(ind => lower.includes(ind))) { thesis = s; confidence = 0.85; break; }
  }
  if (confidence < 0.5 && sentences.length > 2) {
    const last = sentences[sentences.length - 1];
    const lastLower = last.toLowerCase();
    if (lastLower.includes("therefore") || lastLower.includes("in summary") || lastLower.includes("in conclusion")) { thesis = last; confidence = 0.75; }
  }
  if (confidence < 0.5 && sentences.length > 0) {
    const longest = sentences.reduce((a, b) => a.length > b.length ? a : b, "");
    thesis = longest;
    confidence = Math.round(Math.min(0.6, 0.3 + sentences.length * 0.05) * 100) / 100;
  }
  return { ok: true, thesis: { text: thesis, confidence, sentenceCount: sentences.length, method: confidence >= 0.85 ? "indicator_match" : confidence >= 0.75 ? "conclusion_position" : "heuristic", extractedAt: nowISO() } };
});
registerLensAction("forum", "generate_summary_dtu", async (ctx, artifact, params) => {
  const body = artifact.data?.body || "";
  const votes = artifact.data?.votes || 0;
  const commentCount = artifact.data?.commentCount || 0;
  const tags = artifact.data?.tags || [];
  const words = body.split(/\s+/).filter(Boolean);
  const sentences = (body.match(/[^.!?]+[.!?]+/g) || []).map(s => s.trim());
  return { ok: true, dtu: { type: "forum_summary", postId: artifact.id, title: artifact.title, excerpt: sentences.slice(0, 2).join(" ") || body.slice(0, 200), wordCount: words.length, votes, commentCount, tags, engagement: votes + commentCount, generatedAt: nowISO() } };
});

// === Feed ===
registerLensAction("feed", "like", async (ctx, artifact, params) => {
  const likes = (artifact.data?.likes || 0) + 1;
  artifact.data = { ...artifact.data, likes };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, likes };
});
registerLensAction("feed", "repost", async (ctx, artifact, params) => {
  const repost = { id: uid("rp"), originalId: artifact.id, reposterId: ctx.actor?.userId || "anon", repostedAt: nowISO() };
  artifact.data = { ...artifact.data, reposts: [...(artifact.data?.reposts || []), repost] };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, repost };
});
registerLensAction("feed", "bookmark", async (ctx, artifact, params) => {
  artifact.data = { ...artifact.data, bookmarked: true, bookmarkedAt: nowISO() };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, bookmarked: true };
});
registerLensAction("feed", "rank", async (ctx, artifact, params) => {
  const likes = artifact.data?.likes || 0;
  const reposts = (artifact.data?.reposts || []).length;
  const bookmarks = artifact.data?.bookmarked ? 1 : 0;
  const comments = artifact.data?.commentCount || 0;
  const ageHours = (Date.now() - new Date(artifact.createdAt || 0).getTime()) / 3600000;
  const decayFactor = 1 / (1 + ageHours / 48);
  const engagementScore = likes * 1 + reposts * 3 + bookmarks * 2 + comments * 2;
  const velocityScore = ageHours > 0 ? engagementScore / ageHours : engagementScore;
  const finalScore = Math.round((engagementScore * 0.5 + velocityScore * 0.3 + decayFactor * 20 * 0.2) * 100) / 100;
  return { ok: true, rank: { postId: artifact.id, score: finalScore, factors: { likes, reposts, bookmarks, comments, engagementScore, velocityScore: Math.round(velocityScore * 100) / 100, ageHours: Math.round(ageHours * 10) / 10, decayFactor: Math.round(decayFactor * 1000) / 1000 }, rankedAt: nowISO() } };
});
registerLensAction("feed", "personalize", async (ctx, artifact, params) => {
  const userId = ctx.actor?.userId || "anon";
  const postTags = artifact.data?.tags || [];
  const postAuthor = artifact.data?.authorId || artifact.meta?.createdBy || "";
  const tagFrequency = {};
  const authorAffinity = {};
  let totalInteractions = 0;
  for (const art of _lensDomainArtifacts("feed")) {
    const artTags = art.data?.tags || [];
    const author = art.data?.authorId || art.meta?.createdBy || "";
    if (art.data?.likedBy?.includes(userId) || (art.data?.likes > 0 && art.meta?.lastLikedBy === userId)) {
      artTags.forEach(t => { tagFrequency[t] = (tagFrequency[t] || 0) + 3; });
      if (author) authorAffinity[author] = (authorAffinity[author] || 0) + 3;
      totalInteractions += 3;
    }
    if (art.data?.reposts?.some(r => r.reposterId === userId)) {
      artTags.forEach(t => { tagFrequency[t] = (tagFrequency[t] || 0) + 5; });
      if (author) authorAffinity[author] = (authorAffinity[author] || 0) + 5;
      totalInteractions += 5;
    }
    if (art.data?.bookmarked && art.meta?.lastBookmarkedBy === userId) {
      artTags.forEach(t => { tagFrequency[t] = (tagFrequency[t] || 0) + 4; });
      if (author) authorAffinity[author] = (authorAffinity[author] || 0) + 4;
      totalInteractions += 4;
    }
  }
  let relevanceScore = 0;
  let tagMatchCount = 0;
  if (totalInteractions > 0) {
    postTags.forEach(t => {
      if (tagFrequency[t]) { relevanceScore += tagFrequency[t] / totalInteractions; tagMatchCount++; }
    });
    if (postAuthor && authorAffinity[postAuthor]) relevanceScore += authorAffinity[postAuthor] / totalInteractions;
    relevanceScore = Math.min(1, relevanceScore);
  }
  const ageHours = (Date.now() - new Date(artifact.createdAt || 0).getTime()) / 3600000;
  const recencyBoost = 1 / (1 + ageHours / 24);
  const finalScore = Math.round((relevanceScore * 0.7 + recencyBoost * 0.3) * 1000) / 1000;
  return {
    ok: true,
    personalized: {
      postId: artifact.id, relevanceScore: Math.round(relevanceScore * 1000) / 1000,
      recencyBoost: Math.round(recencyBoost * 1000) / 1000, finalScore,
      matchedTags: tagMatchCount, totalTagsAnalyzed: Object.keys(tagFrequency).length,
      totalInteractionsAnalyzed: totalInteractions, personalizedAt: nowISO()
    }
  };
});
registerLensAction("feed", "cluster_topics", async (ctx, artifact, params) => {
  const tagCounts = {};
  const tagPosts = {};
  for (const art of _lensDomainArtifacts("feed")) {
    (art.data?.tags || []).forEach(t => {
      tagCounts[t] = (tagCounts[t] || 0) + 1;
      if (!tagPosts[t]) tagPosts[t] = [];
      tagPosts[t].push(art.id);
    });
  }
  const tagCooccurrence = {};
  for (const art of _lensDomainArtifacts("feed")) {
    const artTags = art.data?.tags || [];
    for (let i = 0; i < artTags.length; i++) {
      for (let j = i + 1; j < artTags.length; j++) {
        const pair = [artTags[i], artTags[j]].sort().join("|");
        tagCooccurrence[pair] = (tagCooccurrence[pair] || 0) + 1;
      }
    }
  }
  const clusters = Object.entries(tagCounts).sort((a, b) => b[1] - a[1]).map(([topic, postCount]) => {
    const relatedPairs = Object.entries(tagCooccurrence).filter(([pair]) => pair.split("|").includes(topic)).sort((a, b) => b[1] - a[1]).slice(0, 5);
    const related = relatedPairs.map(([pair, count]) => ({ tag: pair.split("|").find(t => t !== topic), cooccurrences: count }));
    return { topic, postCount, related };
  });
  return { ok: true, clusters, totalTopics: clusters.length, clusteredAt: nowISO() };
});

// === Thread ===
registerLensAction("thread", "branch", async (ctx, artifact, params) => {
  const branch = { id: uid("branch"), threadId: artifact.id, parentNodeId: params.parentNodeId, content: params.content || "", authorId: ctx.actor?.userId || "anon", createdAt: nowISO() };
  artifact.data = { ...artifact.data, nodes: [...(artifact.data?.nodes || []), branch] };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, branch };
});
registerLensAction("thread", "merge", async (ctx, artifact, params) => {
  const branchIds = params.branchIds || [];
  const nodes = artifact.data?.nodes || [];
  if (branchIds.length === 0) return { ok: false, error: "branchIds required" };
  const branchNodes = nodes.filter(n => branchIds.includes(n.id));
  const mergedContent = branchNodes.map(n => n.content || "").filter(Boolean);
  const mergedNode = { id: uid("merged"), threadId: artifact.id, type: "merge", content: mergedContent.join("\n---\n"), mergedFrom: branchIds, authorId: ctx.actor?.userId || "system", createdAt: nowISO() };
  artifact.data = { ...artifact.data, nodes: [...nodes, mergedNode] };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, merged: { threadId: artifact.id, mergedBranches: branchIds, resultNode: mergedNode.id, mergedContentLength: mergedContent.length, mergedAt: nowISO() } };
});
registerLensAction("thread", "summarize", async (ctx, artifact, params) => {
  const nodes = artifact.data?.nodes || [];
  const authors = [...new Set(nodes.map(n => n.authorId).filter(Boolean))];
  const contentLengths = nodes.map(n => (n.content || "").length);
  const totalWords = nodes.reduce((s, n) => s + (n.content || "").split(/\s+/).filter(Boolean).length, 0);
  const branches = nodes.filter(n => n.parentNodeId);
  const merges = nodes.filter(n => n.type === "merge");
  const decisions = nodes.filter(n => n.type === "decision" || (n.content || "").toLowerCase().includes("decided"));
  const timeline = nodes.length > 0 ? { first: nodes[0].createdAt, last: nodes[nodes.length - 1].createdAt } : null;
  return { ok: true, summary: { threadId: artifact.id, nodeCount: nodes.length, authorCount: authors.length, totalWords, branchCount: branches.length, mergeCount: merges.length, decisionCount: decisions.length, avgNodeLength: contentLengths.length > 0 ? Math.round(contentLengths.reduce((s, l) => s + l, 0) / contentLengths.length) : 0, timeline, summarizedAt: nowISO() } };
});
registerLensAction("thread", "detect_consensus", async (ctx, artifact, params) => {
  const nodes = artifact.data?.nodes || [];
  if (nodes.length < 2) return { ok: true, consensus: { detected: false, confidence: 0, reason: "insufficient_nodes", detectedAt: nowISO() } };
  const stances = {};
  const agreements = [];
  nodes.forEach(n => {
    const content = (n.content || "").toLowerCase();
    const stance = n.stance || n.position || null;
    if (stance) stances[stance] = (stances[stance] || 0) + 1;
    if (content.includes("agree") || content.includes("support") || content.includes("+1") || content.includes("yes")) agreements.push({ nodeId: n.id, type: "agree" });
    if (content.includes("disagree") || content.includes("oppose") || content.includes("-1") || content.includes("no")) agreements.push({ nodeId: n.id, type: "disagree" });
  });
  const agreeCount = agreements.filter(a => a.type === "agree").length;
  const disagreeCount = agreements.filter(a => a.type === "disagree").length;
  const totalSignals = agreeCount + disagreeCount;
  const consensusRatio = totalSignals > 0 ? agreeCount / totalSignals : 0.5;
  const dominantStance = Object.entries(stances).sort((a, b) => b[1] - a[1])[0];
  const stanceAlignment = dominantStance ? dominantStance[1] / nodes.length : 0;
  const confidence = Math.round(Math.max(consensusRatio, stanceAlignment) * 100) / 100;
  const detected = confidence > 0.6 && nodes.length >= 3;
  return { ok: true, consensus: { detected, confidence, agreeSignals: agreeCount, disagreeSignals: disagreeCount, dominantStance: dominantStance ? dominantStance[0] : null, stanceDistribution: stances, detectedAt: nowISO() } };
});
registerLensAction("thread", "extract_decisions", async (ctx, artifact, params) => {
  const decisions = (artifact.data?.nodes || []).filter(n => n.type === "decision" || (n.content || "").toLowerCase().includes("decided"));
  return { ok: true, decisions: decisions.map(d => ({ nodeId: d.id, text: d.content })), count: decisions.length };
});

// === Music ===
registerLensAction("music", "analyze", async (ctx, artifact, params) => {
  const bpm = artifact.data?.bpm || null;
  const key = artifact.data?.key || null;
  const duration = artifact.data?.duration || 0;
  const stems = artifact.data?.stems || [];
  const sections = artifact.data?.sections || [];
  const genre = artifact.data?.genre || null;
  const stemTypes = stems.map(s => typeof s === 'string' ? s : s.name || '');
  const hasPercussion = stemTypes.some(s => /drum|perc|beat/i.test(s));
  const hasBass = stemTypes.some(s => /bass/i.test(s));
  const hasVocals = stemTypes.some(s => /voc|voice|sing/i.test(s));
  const hasGuitar = stemTypes.some(s => /guitar|gtr/i.test(s));
  const hasSynth = stemTypes.some(s => /synth|pad|lead/i.test(s));
  let energy = 0.5;
  if (bpm) { energy = Math.min(1, Math.max(0, (bpm - 60) / 140)); }
  if (hasPercussion) energy = Math.min(1, energy + 0.15);
  if (hasBass) energy = Math.min(1, energy + 0.1);
  let danceability = 0.5;
  if (bpm) {
    danceability = Math.max(0, 1 - Math.abs(bpm - 115) / 85);
    if (hasPercussion) danceability = Math.min(1, danceability + 0.2);
  }
  let valence = 0.5;
  if (key) { valence = /m(?:in)?$/i.test(key) ? 0.35 : 0.65; }
  const acousticness = Math.min(1, Math.max(0, (hasSynth ? 0.2 : 0.6) + (hasGuitar ? 0.15 : 0) - (hasPercussion ? 0.1 : 0)));
  const instrumentalness = hasVocals ? 0.15 : 0.85;
  const uniqueSections = [...new Set(sections.map(s => typeof s === 'string' ? s : s.name || s.type || ''))];
  const complexity = Math.min(1, uniqueSections.length / 6);
  return {
    ok: true,
    analysis: {
      bpm, key, duration,
      energy: Math.round(energy * 100) / 100,
      danceability: Math.round(danceability * 100) / 100,
      valence: Math.round(valence * 100) / 100,
      acousticness: Math.round(acousticness * 100) / 100,
      instrumentalness: Math.round(instrumentalness * 100) / 100,
      complexity: Math.round(complexity * 100) / 100,
      stemCount: stems.length, sectionCount: sections.length, uniqueSections,
      instrumentation: { hasPercussion, hasBass, hasVocals, hasGuitar, hasSynth },
      genre, analyzedAt: nowISO()
    }
  };
});
registerLensAction("music", "render", async (ctx, artifact, params) => {
  const render = { id: uid("mrender"), trackId: artifact.id, format: params.format || "wav", status: "complete", renderedAt: nowISO() };
  artifact.data = { ...artifact.data, lastRender: render };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, render };
});
registerLensAction("music", "publish", async (ctx, artifact, params) => {
  artifact.data = { ...artifact.data, status: "published", publishedAt: nowISO() };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, published: true };
});
registerLensAction("music", "export_stems", async (ctx, artifact, params) => {
  const stems = (artifact.data?.stems || ["vocals", "drums", "bass", "other"]).map(s => ({ name: s, format: "wav", exportedAt: nowISO() }));
  return { ok: true, stems };
});
registerLensAction("music", "generate_arrangement", async (ctx, artifact, params) => {
  const bpm = artifact.data?.bpm || 120;
  const duration = artifact.data?.duration || 180;
  const genre = artifact.data?.genre || "pop";
  const existingSections = artifact.data?.sections || [];
  const beatsPerBar = 4;
  const barsPerSection = params.barsPerSection || 8;
  const sectionDuration = (barsPerSection * beatsPerBar / bpm) * 60;
  const totalSections = Math.max(4, Math.round(duration / sectionDuration));
  const templates = {
    pop: ["intro", "verse", "chorus", "verse", "chorus", "bridge", "chorus", "outro"],
    rock: ["intro", "verse", "verse", "chorus", "verse", "chorus", "solo", "chorus", "outro"],
    electronic: ["intro", "buildup", "drop", "breakdown", "buildup", "drop", "outro"],
    jazz: ["intro", "head", "solo", "solo", "head", "outro"],
    classical: ["exposition", "development", "recapitulation", "coda"]
  };
  const template = templates[genre.toLowerCase()] || templates.pop;
  const sections = (existingSections.length > 0 ? existingSections : template).slice(0, totalSections).map((s, i) => {
    const name = typeof s === 'string' ? s : s.name || s.type || `section_${i}`;
    return { name, startTime: Math.round(i * sectionDuration * 100) / 100, duration: Math.round(sectionDuration * 100) / 100, bars: barsPerSection, order: i };
  });
  const arrangement = { id: uid("arr"), trackId: artifact.id, sections, sectionCount: sections.length, bpm, genre, estimatedDuration: Math.round(sections.length * sectionDuration * 100) / 100, generatedAt: nowISO() };
  return { ok: true, arrangement };
});

// === Finance ===
registerLensAction("finance", "trade", async (ctx, artifact, params) => {
  const trade = { id: uid("trade"), assetId: artifact.id, type: params.type || "buy", quantity: params.quantity || 1, price: params.price || artifact.data?.currentPrice || 0, executedAt: nowISO() };
  artifact.data = { ...artifact.data, trades: [...(artifact.data?.trades || []), trade] };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, trade };
});
registerLensAction("finance", "analyze", async (ctx, artifact, params) => {
  const trades = artifact.data?.trades || [];
  const prices = trades.filter(t => t.price > 0).map(t => t.price);
  if (prices.length < 2) return { ok: true, analysis: { assetId: artifact.id, trend: "insufficient_data", volatility: null, priceCount: prices.length, analyzedAt: nowISO() } };
  const returns = [];
  for (let i = 1; i < prices.length; i++) returns.push((prices[i] - prices[i - 1]) / prices[i - 1]);
  const meanReturn = returns.reduce((s, r) => s + r, 0) / returns.length;
  const variance = returns.reduce((s, r) => s + (r - meanReturn) ** 2, 0) / returns.length;
  const volatility = Math.sqrt(variance);
  const trend = meanReturn > 0.01 ? "bullish" : meanReturn < -0.01 ? "bearish" : "neutral";
  const currentPrice = prices[prices.length - 1];
  const highPrice = Math.max(...prices);
  const lowPrice = Math.min(...prices);
  const sma5 = prices.length >= 5 ? prices.slice(-5).reduce((s, p) => s + p, 0) / 5 : currentPrice;
  const sma20 = prices.length >= 20 ? prices.slice(-20).reduce((s, p) => s + p, 0) / 20 : currentPrice;
  const momentum = sma5 > sma20 ? "positive" : sma5 < sma20 ? "negative" : "flat";
  return { ok: true, analysis: { assetId: artifact.id, trend, volatility: Math.round(volatility * 10000) / 10000, meanReturn: Math.round(meanReturn * 10000) / 10000, currentPrice, highPrice, lowPrice, sma5: Math.round(sma5 * 100) / 100, sma20: Math.round(sma20 * 100) / 100, momentum, tradeCount: trades.length, analyzedAt: nowISO() } };
});
registerLensAction("finance", "alert", async (ctx, artifact, params) => {
  const alert = { id: uid("alert"), assetId: artifact.id, condition: params.condition || "price_above", threshold: params.threshold || 0, status: "active", createdAt: nowISO() };
  artifact.data = { ...artifact.data, alerts: [...(artifact.data?.alerts || []), alert] };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, alert };
});
registerLensAction("finance", "simulate", async (ctx, artifact, params) => {
  const trades = artifact.data?.trades || [];
  const currentPrice = artifact.data?.currentPrice || 0;
  const scenarios = params.scenarios || 1000;
  const prices = trades.filter(t => t.price > 0).map(t => t.price);
  if (prices.length < 2) {
    const base = currentPrice || 100;
    return { ok: true, simulation: { mean: base, stdDev: 0, worstCase: base, bestCase: base, scenarios: 0, note: "insufficient_trade_history", simulatedAt: nowISO() } };
  }
  const returns = [];
  for (let i = 1; i < prices.length; i++) returns.push(Math.log(prices[i] / prices[i - 1]));
  const meanReturn = returns.reduce((s, r) => s + r, 0) / returns.length;
  const variance = returns.reduce((s, r) => s + (r - meanReturn) ** 2, 0) / returns.length;
  const stdReturn = Math.sqrt(variance);
  const lastPrice = prices[prices.length - 1] || currentPrice;
  const steps = params.steps || 30;
  let seed = 0;
  for (let i = 0; i < artifact.id.length; i++) seed = ((seed << 5) - seed) + artifact.id.charCodeAt(i);
  const mulberry32 = (s) => () => { s |= 0; s = s + 0x6D2B79F5 | 0; let t = Math.imul(s ^ s >>> 15, 1 | s); t = t + Math.imul(t ^ t >>> 7, 61 | t) ^ t; return ((t ^ t >>> 14) >>> 0) / 4294967296; };
  const rng = mulberry32(seed);
  const simulated = [];
  for (let i = 0; i < scenarios; i++) {
    let price = lastPrice;
    for (let s = 0; s < steps; s++) {
      const u1 = rng() || 0.0001;
      const u2 = rng();
      const z = Math.sqrt(-2 * Math.log(u1)) * Math.cos(2 * Math.PI * u2);
      price = price * Math.exp(meanReturn + stdReturn * z);
    }
    simulated.push(price);
  }
  simulated.sort((a, b) => a - b);
  const mean = simulated.reduce((s, p) => s + p, 0) / simulated.length;
  const simVariance = simulated.reduce((s, p) => s + (p - mean) ** 2, 0) / simulated.length;
  return {
    ok: true,
    simulation: {
      mean: Math.round(mean * 100) / 100,
      median: Math.round(simulated[Math.floor(simulated.length / 2)] * 100) / 100,
      stdDev: Math.round(Math.sqrt(simVariance) * 100) / 100,
      worstCase: Math.round(simulated[Math.floor(simulated.length * 0.05)] * 100) / 100,
      bestCase: Math.round(simulated[Math.floor(simulated.length * 0.95)] * 100) / 100,
      percentile5: Math.round(simulated[Math.floor(simulated.length * 0.05)] * 100) / 100,
      percentile25: Math.round(simulated[Math.floor(simulated.length * 0.25)] * 100) / 100,
      percentile75: Math.round(simulated[Math.floor(simulated.length * 0.75)] * 100) / 100,
      percentile95: Math.round(simulated[Math.floor(simulated.length * 0.95)] * 100) / 100,
      scenarios, steps,
      historicalMeanReturn: Math.round(meanReturn * 10000) / 10000,
      historicalVolatility: Math.round(stdReturn * 10000) / 10000,
      startPrice: lastPrice,
      simulatedAt: nowISO()
    }
  };
});
registerLensAction("finance", "generate_report", async (ctx, artifact, params) => {
  const trades = artifact.data?.trades || [];
  const prices = trades.filter(t => t.price > 0).map(t => t.price);
  const period = params.period || "monthly";
  const buys = trades.filter(t => t.type === "buy");
  const sells = trades.filter(t => t.type === "sell");
  const totalBuyValue = buys.reduce((s, t) => s + (t.price || 0) * (t.quantity || 1), 0);
  const totalSellValue = sells.reduce((s, t) => s + (t.price || 0) * (t.quantity || 1), 0);
  const netPosition = buys.reduce((s, t) => s + (t.quantity || 1), 0) - sells.reduce((s, t) => s + (t.quantity || 1), 0);
  const currentPrice = artifact.data?.currentPrice || (prices.length > 0 ? prices[prices.length - 1] : 0);
  const unrealizedValue = netPosition * currentPrice;
  const realizedPnL = totalSellValue - (buys.length > 0 ? totalBuyValue * (sells.length / Math.max(1, buys.length)) : 0);
  const report = { id: uid("frep"), assetId: artifact.id, period, type: params.type || "performance", totalTrades: trades.length, buys: buys.length, sells: sells.length, totalBuyValue: Math.round(totalBuyValue * 100) / 100, totalSellValue: Math.round(totalSellValue * 100) / 100, netPosition, currentPrice, unrealizedValue: Math.round(unrealizedValue * 100) / 100, realizedPnL: Math.round(realizedPnL * 100) / 100, generatedAt: nowISO() };
  return { ok: true, report };
});

// === ML ===
registerLensAction("ml", "train", async (ctx, artifact, params) => {
  artifact.data = { ...artifact.data, status: "training", trainStartedAt: nowISO() };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, status: "training" };
});
registerLensAction("ml", "infer", async (ctx, artifact, params) => {
  const modelType = artifact.data?.modelType || "classifier";
  const classes = artifact.data?.classes || artifact.data?.labels || [];
  const predictions = artifact.data?.predictions || [];
  const input = params.input;
  if (modelType === "classifier" && classes.length > 0) {
    const classCounts = {};
    predictions.forEach(p => { const c = String(p.predicted || p.actual); classCounts[c] = (classCounts[c] || 0) + 1; });
    const total = predictions.length || 1;
    const probs = classes.map(c => ({ class: c, probability: Math.round(((classCounts[c] || 0) / total) * 10000) / 10000 })).sort((a, b) => b.probability - a.probability);
    const topPrediction = probs[0] || { class: classes[0], probability: 1 / classes.length };
    return { ok: true, inference: { modelId: artifact.id, input, output: { prediction: topPrediction.class, confidence: topPrediction.probability, probabilities: probs }, modelType, inferredAt: nowISO() } };
  }
  if (modelType === "regressor" && predictions.length > 0) {
    const values = predictions.map(p => p.predicted).filter(v => typeof v === 'number');
    const mean = values.length > 0 ? values.reduce((s, v) => s + v, 0) / values.length : 0;
    const std = values.length > 1 ? Math.sqrt(values.reduce((s, v) => s + (v - mean) ** 2, 0) / values.length) : 0;
    return { ok: true, inference: { modelId: artifact.id, input, output: { prediction: Math.round(mean * 10000) / 10000, confidence: std > 0 ? Math.round(Math.max(0, 1 - std / Math.abs(mean || 1)) * 10000) / 10000 : 0.5, mean: Math.round(mean * 10000) / 10000, std: Math.round(std * 10000) / 10000 }, modelType, inferredAt: nowISO() } };
  }
  return { ok: true, inference: { modelId: artifact.id, input, output: { prediction: null, confidence: 0, note: "no_training_data_available" }, modelType, inferredAt: nowISO() } };
});
registerLensAction("ml", "deploy", async (ctx, artifact, params) => {
  artifact.data = { ...artifact.data, status: "deployed", deployedAt: nowISO(), endpoint: params.endpoint || `/ml/${artifact.id}/predict` };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, deployed: true, endpoint: artifact.data.endpoint };
});
registerLensAction("ml", "evaluate", async (ctx, artifact, params) => {
  const runs = artifact.data?.runs || [];
  const predictions = artifact.data?.predictions || [];
  if (predictions.length > 0 && predictions[0].actual != null) {
    const isClassification = typeof predictions[0].actual === 'string' || typeof predictions[0].actual === 'boolean' || Number.isInteger(predictions[0].actual);
    if (isClassification) {
      const classes = [...new Set(predictions.map(p => String(p.actual)))];
      let correct = 0;
      const confusionMatrix = {};
      predictions.forEach(p => {
        const actual = String(p.actual);
        const predicted = String(p.predicted);
        if (!confusionMatrix[actual]) confusionMatrix[actual] = {};
        confusionMatrix[actual][predicted] = (confusionMatrix[actual][predicted] || 0) + 1;
        if (actual === predicted) correct++;
      });
      const accuracy = predictions.length > 0 ? correct / predictions.length : 0;
      const perClass = classes.map(cls => {
        const tp = (confusionMatrix[cls] || {})[cls] || 0;
        let fp = 0, fn = 0;
        classes.forEach(other => {
          if (other !== cls) { fp += (confusionMatrix[other] || {})[cls] || 0; fn += (confusionMatrix[cls] || {})[other] || 0; }
        });
        const precision = tp + fp > 0 ? tp / (tp + fp) : 0;
        const recall = tp + fn > 0 ? tp / (tp + fn) : 0;
        const f1 = precision + recall > 0 ? 2 * precision * recall / (precision + recall) : 0;
        return { class: cls, precision: Math.round(precision * 10000) / 10000, recall: Math.round(recall * 10000) / 10000, f1: Math.round(f1 * 10000) / 10000, support: predictions.filter(p => String(p.actual) === cls).length };
      });
      const macroPrecision = perClass.reduce((s, c) => s + c.precision, 0) / perClass.length;
      const macroRecall = perClass.reduce((s, c) => s + c.recall, 0) / perClass.length;
      const macroF1 = perClass.reduce((s, c) => s + c.f1, 0) / perClass.length;
      return { ok: true, evaluation: { modelId: artifact.id, type: "classification", accuracy: Math.round(accuracy * 10000) / 10000, precision: Math.round(macroPrecision * 10000) / 10000, recall: Math.round(macroRecall * 10000) / 10000, f1: Math.round(macroF1 * 10000) / 10000, perClass, totalPredictions: predictions.length, confusionMatrix, evaluatedAt: nowISO() } };
    } else {
      const n = predictions.length;
      const errors = predictions.map(p => p.actual - p.predicted);
      const absErrors = errors.map(e => Math.abs(e));
      const squaredErrors = errors.map(e => e * e);
      const mae = absErrors.reduce((s, e) => s + e, 0) / n;
      const mse = squaredErrors.reduce((s, e) => s + e, 0) / n;
      const rmse = Math.sqrt(mse);
      const meanActual = predictions.reduce((s, p) => s + p.actual, 0) / n;
      const ssTot = predictions.reduce((s, p) => s + (p.actual - meanActual) ** 2, 0);
      const r2 = ssTot > 0 ? 1 - squaredErrors.reduce((s, e) => s + e, 0) / ssTot : 0;
      return { ok: true, evaluation: { modelId: artifact.id, type: "regression", mae: Math.round(mae * 10000) / 10000, mse: Math.round(mse * 10000) / 10000, rmse: Math.round(rmse * 10000) / 10000, r2: Math.round(r2 * 10000) / 10000, totalPredictions: n, evaluatedAt: nowISO() } };
    }
  }
  if (runs.length > 0) {
    const completedRuns = runs.filter(r => r.status === "completed" || r.metrics);
    const metrics = completedRuns.map(r => r.metrics || {}).filter(m => Object.keys(m).length > 0);
    if (metrics.length > 0) {
      const aggregated = {};
      const metricKeys = [...new Set(metrics.flatMap(m => Object.keys(m)))];
      metricKeys.forEach(key => {
        const values = metrics.map(m => m[key]).filter(v => typeof v === 'number');
        if (values.length > 0) {
          aggregated[key] = { mean: Math.round((values.reduce((s, v) => s + v, 0) / values.length) * 10000) / 10000, min: Math.round(Math.min(...values) * 10000) / 10000, max: Math.round(Math.max(...values) * 10000) / 10000, latest: Math.round(values[values.length - 1] * 10000) / 10000, samples: values.length };
        }
      });
      return { ok: true, evaluation: { modelId: artifact.id, type: "run_aggregate", metrics: aggregated, totalRuns: runs.length, completedRuns: completedRuns.length, evaluatedAt: nowISO() } };
    }
  }
  return { ok: true, evaluation: { modelId: artifact.id, type: "no_data", note: "No predictions or completed runs with metrics found", totalRuns: runs.length, evaluatedAt: nowISO() } };
});
registerLensAction("ml", "run_experiment", async (ctx, artifact, params) => {
  const run = { id: uid("mlrun"), experimentId: artifact.id, config: params.config || {}, status: "running", startedAt: nowISO() };
  artifact.data = { ...artifact.data, runs: [...(artifact.data?.runs || []), run] };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, run };
});
registerLensAction("ml", "compare_runs", async (ctx, artifact, params) => {
  const runs = artifact.data?.runs || [];
  if (runs.length < 2) return { ok: true, comparison: { experimentId: artifact.id, note: "need_at_least_2_runs", runCount: runs.length, comparedAt: nowISO() } };
  const runIds = params.runIds || [runs[runs.length - 2].id, runs[runs.length - 1].id];
  const compared = runIds.map(id => runs.find(r => r.id === id)).filter(Boolean);
  const metricsComparison = {};
  compared.forEach((run, i) => {
    const metrics = run.metrics || {};
    Object.entries(metrics).forEach(([key, value]) => {
      if (typeof value === 'number') {
        if (!metricsComparison[key]) metricsComparison[key] = {};
        metricsComparison[key][`run_${i}`] = { runId: run.id, value: Math.round(value * 10000) / 10000 };
      }
    });
  });
  Object.entries(metricsComparison).forEach(([key, vals]) => {
    const values = Object.values(vals).map(v => v.value);
    if (values.length >= 2) metricsComparison[key].delta = Math.round((values[values.length - 1] - values[0]) * 10000) / 10000;
  });
  const configDiffs = {};
  if (compared.length >= 2) {
    const c0 = compared[0].config || {};
    const c1 = compared[compared.length - 1].config || {};
    const allKeys = [...new Set([...Object.keys(c0), ...Object.keys(c1)])];
    allKeys.forEach(k => { if (JSON.stringify(c0[k]) !== JSON.stringify(c1[k])) configDiffs[k] = { before: c0[k], after: c1[k] }; });
  }
  return { ok: true, comparison: { experimentId: artifact.id, runCount: runs.length, comparedRuns: runIds, metricsComparison, configDiffs, comparedAt: nowISO() } };
});
registerLensAction("ml", "generate_report", async (ctx, artifact, params) => {
  const runs = artifact.data?.runs || [];
  const predictions = artifact.data?.predictions || [];
  const completedRuns = runs.filter(r => r.status === "completed" || r.metrics);
  const allMetrics = completedRuns.map(r => r.metrics || {}).filter(m => Object.keys(m).length > 0);
  const metricSummary = {};
  if (allMetrics.length > 0) {
    const keys = [...new Set(allMetrics.flatMap(m => Object.keys(m)))];
    keys.forEach(k => {
      const vals = allMetrics.map(m => m[k]).filter(v => typeof v === 'number');
      if (vals.length > 0) metricSummary[k] = { best: Math.round(Math.max(...vals) * 10000) / 10000, latest: Math.round(vals[vals.length - 1] * 10000) / 10000, trend: vals.length > 1 ? (vals[vals.length - 1] > vals[0] ? "improving" : "declining") : "insufficient_data" };
    });
  }
  return { ok: true, report: { experimentId: artifact.id, type: "experiment_summary", totalRuns: runs.length, completedRuns: completedRuns.length, totalPredictions: predictions.length, metricSummary, modelType: artifact.data?.modelType || "unknown", status: artifact.data?.status || "unknown", generatedAt: nowISO() } };
});

// === SRS (SM-2 Algorithm) ===
registerLensAction("srs", "review", async (ctx, artifact, params) => {
  const rating = Math.max(0, Math.min(5, params.rating || 3));
  const prevEF = artifact.data?.easeFactor || 2.5;
  const prevInterval = artifact.data?.interval || 1;
  const prevRepetitions = artifact.data?.repetitions || 0;
  const reviewHistory = artifact.data?.reviewHistory || [];
  // SM-2 ease factor update: EF' = EF + (0.1 - (5 - q) * (0.08 + (5 - q) * 0.02))
  let newEF = prevEF + (0.1 - (5 - rating) * (0.08 + (5 - rating) * 0.02));
  newEF = Math.max(1.3, Math.round(newEF * 100) / 100);
  let newInterval, newRepetitions;
  if (rating < 3) {
    // Failed: reset repetitions, short interval
    newRepetitions = 0;
    newInterval = 1;
  } else {
    newRepetitions = prevRepetitions + 1;
    if (newRepetitions === 1) newInterval = 1;
    else if (newRepetitions === 2) newInterval = 6;
    else newInterval = Math.round(prevInterval * newEF);
  }
  const reviewEntry = { rating, easeFactor: newEF, interval: newInterval, reviewedAt: nowISO() };
  const updatedHistory = [...reviewHistory.slice(-49), reviewEntry];
  const avgRating = updatedHistory.length > 0 ? Math.round(updatedHistory.reduce((s, r) => s + r.rating, 0) / updatedHistory.length * 100) / 100 : rating;
  const retention = updatedHistory.length > 0 ? Math.round(updatedHistory.filter(r => r.rating >= 3).length / updatedHistory.length * 100) / 100 : 1;
  artifact.data = { ...artifact.data, easeFactor: newEF, interval: newInterval, repetitions: newRepetitions, lastReviewedAt: nowISO(), nextReviewAt: new Date(Date.now() + newInterval * 86400000).toISOString(), reviewCount: (artifact.data?.reviewCount || 0) + 1, reviewHistory: updatedHistory };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, interval: newInterval, easeFactor: newEF, repetitions: newRepetitions, nextReviewAt: artifact.data.nextReviewAt, avgRating, retention };
});
registerLensAction("srs", "schedule", async (ctx, artifact, params) => {
  const cards = artifact.data?.cards || [];
  const now = new Date();
  const due = cards.filter(c => !c.nextReviewAt || new Date(c.nextReviewAt) <= now);
  const upcoming = cards.filter(c => {
    if (!c.nextReviewAt) return false;
    const d = new Date(c.nextReviewAt);
    return d > now && d <= new Date(now.getTime() + 7 * 86400000);
  });
  const overdue = due.filter(c => c.nextReviewAt && new Date(c.nextReviewAt) < new Date(now.getTime() - 86400000));
  const newCards = cards.filter(c => !c.lastReviewedAt && !c.reviewCount);
  const mature = cards.filter(c => (c.interval || 0) >= 21);
  return { ok: true, scheduled: { deckId: artifact.id, dueCount: due.length, overdueCount: overdue.length, upcomingCount: upcoming.length, newCount: newCards.length, matureCount: mature.length, totalCards: cards.length } };
});
registerLensAction("srs", "optimize_intervals", async (ctx, artifact, params) => {
  const cards = artifact.data?.cards || [];
  const reviewHistory = artifact.data?.reviewHistory || [];
  // Analyze retention rate and adjust ease factor
  const retention = reviewHistory.length > 0 ? reviewHistory.filter(r => r.rating >= 3).length / reviewHistory.length : 1;
  const targetRetention = params.targetRetention || 0.9;
  // If retention is below target, decrease EF (harder cards reviewed more often)
  // If retention is above target, increase EF (can space out more)
  const currentEF = artifact.data?.easeFactor || 2.5;
  let adjustedEF = currentEF;
  if (reviewHistory.length >= 10) {
    if (retention < targetRetention - 0.05) adjustedEF = Math.max(1.3, currentEF - 0.15);
    else if (retention > targetRetention + 0.05) adjustedEF = Math.min(3.0, currentEF + 0.1);
  }
  // Per-card optimization
  const cardStats = cards.map(c => {
    const history = c.reviewHistory || [];
    const cardRetention = history.length > 0 ? history.filter(r => r.rating >= 3).length / history.length : null;
    const ef = c.easeFactor || 2.5;
    let suggestedEF = ef;
    if (history.length >= 5) {
      if (cardRetention !== null && cardRetention < 0.7) suggestedEF = Math.max(1.3, ef - 0.2);
      else if (cardRetention !== null && cardRetention > 0.95) suggestedEF = Math.min(3.0, ef + 0.15);
    }
    return { cardId: c.id, currentEF: ef, suggestedEF: Math.round(suggestedEF * 100) / 100, retention: cardRetention, reviews: history.length };
  }).filter(c => c.suggestedEF !== c.currentEF);
  return { ok: true, optimized: { easeFactor: Math.round(adjustedEF * 100) / 100, previousEF: currentEF, retention: Math.round(retention * 100) / 100, targetRetention, reviewCount: reviewHistory.length, cardsToAdjust: cardStats.length, cardAdjustments: cardStats.slice(0, 20), optimizedAt: nowISO() } };
});
registerLensAction("srs", "generate_cards_from_dtus", async (ctx, artifact, params) => {
  // Pull DTU data from STATE to generate meaningful cards
  const dtus = [];
  for (const [domain, ids] of STATE.lensDomainIndex) {
    if (domain === "srs") continue;
    for (const id of ids) {
      const art = STATE.lensArtifacts.get(id);
      if (art && (art.data?.title || art.title)) dtus.push(art);
    }
  }
  const count = Math.min(params.count || 5, dtus.length || 5);
  const sourceDtus = dtus.slice(-count);
  const cards = sourceDtus.length > 0
    ? sourceDtus.map(dtu => ({
        id: uid("card"), front: dtu.title || dtu.data?.title || "Untitled",
        back: dtu.data?.summary || dtu.data?.content?.slice(0, 200) || dtu.data?.body?.slice(0, 200) || `From ${dtu.domain}: ${dtu.type || "artifact"}`,
        sourceDomain: dtu.domain, sourceId: dtu.id,
        interval: 1, easeFactor: 2.5, repetitions: 0, createdAt: nowISO()
      }))
    : Array.from({ length: count }, (_, i) => ({
        id: uid("card"), front: artifact.data?.topics?.[i] || `Topic ${i + 1}`,
        back: artifact.data?.answers?.[i] || `Review content for topic ${i + 1}`,
        interval: 1, easeFactor: 2.5, repetitions: 0, createdAt: nowISO()
      }));
  artifact.data = { ...artifact.data, cards: [...(artifact.data?.cards || []), ...cards] };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, generated: cards.length, fromDtus: sourceDtus.length > 0 };
});

// === Voice ===
registerLensAction("voice", "transcribe", async (ctx, artifact, params) => {
  const rawText = params.text || artifact.data?.rawText || artifact.data?.body || artifact.data?.content || "";
  const language = params.language || artifact.data?.language || "en";
  if (!rawText) {
    const empty = { id: uid("tx"), takeId: artifact.id, text: "", language, segments: [], wordCount: 0, sentenceCount: 0, transcribedAt: nowISO() };
    artifact.data = { ...artifact.data, transcript: empty };
    artifact.updatedAt = nowISO();
    saveStateDebounced();
    return { ok: true, transcript: empty, note: "no_text_data_available" };
  }
  const sentences = rawText.match(/[^.!?]+[.!?]+/g) || [rawText];
  const wpm = params.wpm || 150;
  let currentTime = 0;
  const segments = sentences.map((sentence, i) => {
    const text = sentence.trim();
    const wordCount = text.split(/\s+/).filter(Boolean).length;
    const durationSec = (wordCount / wpm) * 60;
    const seg = { index: i, text, startTime: Math.round(currentTime * 100) / 100, endTime: Math.round((currentTime + durationSec) * 100) / 100, wordCount };
    currentTime += durationSec;
    return seg;
  });
  const allWords = rawText.split(/\s+/).filter(Boolean);
  const wordFreq = {};
  allWords.forEach(w => { const n = w.toLowerCase().replace(/[^a-z0-9]/g, ''); if (n.length > 2) wordFreq[n] = (wordFreq[n] || 0) + 1; });
  const topWords = Object.entries(wordFreq).sort((a, b) => b[1] - a[1]).slice(0, 10).map(([word, count]) => ({ word, count }));
  const transcript = { id: uid("tx"), takeId: artifact.id, text: rawText, language, segments, wordCount: allWords.length, sentenceCount: segments.length, estimatedDuration: Math.round(currentTime * 100) / 100, topWords, transcribedAt: nowISO() };
  artifact.data = { ...artifact.data, transcript };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, transcript };
});
registerLensAction("voice", "process", async (ctx, artifact, params) => {
  const effect = params.effect || "normalize";
  artifact.data = { ...artifact.data, processedWith: [...(artifact.data?.processedWith || []), { effect, appliedAt: nowISO() }] };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, processed: { effect, appliedAt: nowISO() } };
});
registerLensAction("voice", "analyze", async (ctx, artifact, params) => {
  const transcript = artifact.data?.transcript || {};
  const duration = artifact.data?.duration || transcript.estimatedDuration || 0;
  const segments = transcript.segments || [];
  const wordCount = transcript.wordCount || 0;
  const wpm = duration > 0 ? Math.round(wordCount / (duration / 60)) : 0;
  const avgSegmentLength = segments.length > 0 ? Math.round(segments.reduce((s, seg) => s + (seg.wordCount || 0), 0) / segments.length) : 0;
  const longestSegment = segments.length > 0 ? segments.reduce((max, seg) => (seg.wordCount || 0) > (max.wordCount || 0) ? seg : max, segments[0]) : null;
  const processedEffects = (artifact.data?.processedWith || []).map(p => p.effect);
  const silenceRatio = duration > 0 && transcript.estimatedDuration ? Math.round(Math.max(0, 1 - transcript.estimatedDuration / duration) * 100) / 100 : 0;
  return { ok: true, analysis: { takeId: artifact.id, duration, wordCount, wordsPerMinute: wpm, segmentCount: segments.length, avgWordsPerSegment: avgSegmentLength, longestSegment: longestSegment ? { index: longestSegment.index, wordCount: longestSegment.wordCount } : null, silenceRatio, processedEffects, topWords: transcript.topWords || [], language: transcript.language || artifact.data?.language, analyzedAt: nowISO() } };
});
registerLensAction("voice", "summarize", async (ctx, artifact, params) => {
  const transcript = artifact.data?.transcript || {};
  const text = transcript.text || "";
  const segments = transcript.segments || [];
  if (!text) return { ok: true, summary: { takeId: artifact.id, note: "no_transcript_available", summarizedAt: nowISO() } };
  const sentences = (text.match(/[^.!?]+[.!?]+/g) || [text]).map(s => s.trim());
  const words = text.split(/\s+/).filter(Boolean);
  const wordFreq = {};
  words.forEach(w => { const n = w.toLowerCase().replace(/[^a-z0-9]/g, ''); if (n.length > 3) wordFreq[n] = (wordFreq[n] || 0) + 1; });
  // Score sentences by word frequency (extractive summary)
  const scored = sentences.map((s, i) => {
    const sWords = s.toLowerCase().split(/\s+/).filter(Boolean);
    const score = sWords.reduce((sum, w) => { const n = w.replace(/[^a-z0-9]/g, ''); return sum + (wordFreq[n] || 0); }, 0) / Math.max(1, sWords.length);
    return { text: s, score, index: i };
  }).sort((a, b) => b.score - a.score);
  const keyPoints = scored.slice(0, Math.min(5, Math.ceil(sentences.length * 0.3))).sort((a, b) => a.index - b.index).map(s => s.text);
  const topKeywords = Object.entries(wordFreq).sort((a, b) => b[1] - a[1]).slice(0, 8).map(([word]) => word);
  return { ok: true, summary: { takeId: artifact.id, keyPoints, topKeywords, wordCount: words.length, sentenceCount: sentences.length, compressionRatio: sentences.length > 0 ? Math.round(keyPoints.length / sentences.length * 100) / 100 : 0, duration: transcript.estimatedDuration || 0, summarizedAt: nowISO() } };
});
registerLensAction("voice", "extract_tasks", async (ctx, artifact, params) => {
  const text = artifact.data?.transcript?.text || "";
  const tasks = text.match(/(?:TODO|ACTION|TASK):\s*[^\n]+/gi) || [];
  return { ok: true, tasks: tasks.map(t => ({ text: t, extractedAt: nowISO() })), count: tasks.length };
});

// === Game ===
registerLensAction("game", "complete", async (ctx, artifact, params) => {
  artifact.data = { ...artifact.data, status: "completed", completedAt: nowISO() };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, completed: true };
});
registerLensAction("game", "claim", async (ctx, artifact, params) => {
  const reward = params.reward || { xp: 100, type: "quest_complete" };
  artifact.data = { ...artifact.data, claimed: true, reward, claimedAt: nowISO() };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, reward };
});
registerLensAction("game", "levelup", async (ctx, artifact, params) => {
  const currentLevel = artifact.data?.level || 1;
  artifact.data = { ...artifact.data, level: currentLevel + 1, leveledUpAt: nowISO() };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, newLevel: currentLevel + 1 };
});
registerLensAction("game", "simulate", async (ctx, artifact, params) => {
  const scenarios = params.scenarios || [];
  const level = artifact.data?.level || 1;
  const stats = artifact.data?.stats || {};
  const turns = artifact.data?.turns || [];
  const successRate = turns.length > 0 ? turns.filter(t => t.outcome === "success").length / turns.length : 0.5;
  const avgXp = turns.length > 0 ? turns.reduce((s, t) => s + (t.xpGained || 0), 0) / turns.length : 25;
  let seed = 0;
  for (let i = 0; i < artifact.id.length; i++) seed = ((seed << 5) - seed) + artifact.id.charCodeAt(i);
  const mulberry32 = (s) => () => { s |= 0; s = s + 0x6D2B79F5 | 0; let t = Math.imul(s ^ s >>> 15, 1 | s); t = t + Math.imul(t ^ t >>> 7, 61 | t) ^ t; return ((t ^ t >>> 14) >>> 0) / 4294967296; };
  const rng = mulberry32(seed);
  const outcomes = scenarios.map((s, idx) => {
    const difficulty = s.difficulty || 1;
    const adjustedRate = Math.max(0.1, Math.min(0.95, successRate / difficulty));
    const roll = rng();
    const result = roll < adjustedRate ? "success" : "failure";
    const xpGained = result === "success" ? Math.floor(avgXp * difficulty * (1 + level * 0.1)) : Math.floor(avgXp * 0.2);
    return { scenario: s, result, probability: Math.round(adjustedRate * 100) / 100, xpGained };
  });
  return { ok: true, simulation: { outcomes, baseSuccessRate: Math.round(successRate * 100) / 100, historicalTurns: turns.length, simulatedAt: nowISO() } };
});
registerLensAction("game", "resolve_turn", async (ctx, artifact, params) => {
  const turns = artifact.data?.turns || [];
  const level = artifact.data?.level || 1;
  const action = params.action || "default";
  const difficulty = params.difficulty || 1;
  const successRate = turns.length > 0 ? turns.filter(t => t.outcome === "success").length / turns.length : 0.5;
  const skillBonus = Math.min(0.3, turns.length * 0.005);
  const adjustedRate = Math.max(0.1, Math.min(0.95, (successRate + skillBonus) / difficulty));
  let seed = turns.length;
  for (let i = 0; i < artifact.id.length; i++) seed = ((seed << 5) - seed) + artifact.id.charCodeAt(i);
  const mulberry32 = (s) => () => { s |= 0; s = s + 0x6D2B79F5 | 0; let t = Math.imul(s ^ s >>> 15, 1 | s); t = t + Math.imul(t ^ t >>> 7, 61 | t) ^ t; return ((t ^ t >>> 14) >>> 0) / 4294967296; };
  const roll = mulberry32(seed)();
  const outcome = roll < adjustedRate ? "success" : "failure";
  const baseXp = Math.floor(10 * level * difficulty);
  const xpGained = outcome === "success" ? baseXp : Math.floor(baseXp * 0.15);
  const turn = { id: uid("turn"), action, outcome, xpGained, difficulty, successProbability: Math.round(adjustedRate * 100) / 100, resolvedAt: nowISO() };
  artifact.data = { ...artifact.data, turns: [...turns, turn], xp: (artifact.data?.xp || 0) + xpGained };
  artifact.updatedAt = nowISO();
  saveStateDebounced();
  return { ok: true, turn };
});
registerLensAction("game", "balance", async (ctx, artifact, params) => {
  const level = artifact.data?.level || 1;
  const totalXp = artifact.data?.xp || 0;
  const turns = artifact.data?.turns || [];
  const xpHistory = turns.filter(t => t.xpGained != null).map(t => t.xpGained);
  const avgXpPerAction = xpHistory.length > 0 ? xpHistory.reduce((s, x) => s + x, 0) / xpHistory.length : 50;
  const maxXpGain = xpHistory.length > 0 ? Math.max(...xpHistory) : 100;
  const base = params.base || 100;
  const growthRate = params.growthRate || 1.5;
  const maxLevel = params.maxLevel || Math.max(level + 10, 20);
  const levelTable = [];
  let cumulativeXp = 0;
  for (let lvl = 1; lvl <= maxLevel; lvl++) {
    const xpRequired = Math.floor(base * Math.pow(growthRate, lvl - 1));
    cumulativeXp += xpRequired;
    const actionsNeeded = avgXpPerAction > 0 ? Math.ceil(xpRequired / avgXpPerAction) : null;
    levelTable.push({ level: lvl, xpRequired, cumulativeXp, actionsNeeded, isCurrent: lvl === level });
  }
  const currentLevelXp = Math.floor(base * Math.pow(growthRate, level - 1));
  const xpBelowCurrent = levelTable.filter(l => l.level < level).reduce((s, l) => s + l.xpRequired, 0);
  const xpInCurrentLevel = totalXp - xpBelowCurrent;
  const progressPercent = currentLevelXp > 0 ? Math.min(100, Math.round((Math.max(0, xpInCurrentLevel) / currentLevelXp) * 100)) : 0;
  const assessment = [];
  if (avgXpPerAction > 0) {
    const actionsToNext = Math.ceil(currentLevelXp / avgXpPerAction);
    if (actionsToNext > 200) assessment.push("curve_too_steep");
    if (actionsToNext < 5) assessment.push("curve_too_flat");
    if (maxXpGain > currentLevelXp * 0.5) assessment.push("reward_too_generous");
    if (maxXpGain < currentLevelXp * 0.01) assessment.push("reward_too_stingy");
  }
  return {
    ok: true,
    balance: {
      currentLevel: level, totalXp, xpToNext: currentLevelXp, progressPercent,
      avgXpPerAction: Math.round(avgXpPerAction * 10) / 10, totalActions: xpHistory.length,
      growthRate, base, levelTable: levelTable.slice(Math.max(0, level - 3), level + 7),
      assessment: assessment.length > 0 ? assessment : ["balanced"], balancedAt: nowISO()
    }
  };
});

// Load all super-lens domain action modules
const { default: domainModules } = await import('./domains/index.js');
domainModules.forEach(mod => mod(registerLensAction));

console.log(`[Concord] Lens Artifact Runtime loaded (generic CRUD + DTU exhaust + 24 domain engines + ${domainModules.length} super-lens domains)`);

// ============================================================================
// WAVE 5: REAL-TIME COLLABORATION & WHITEBOARD (Surpassing AFFiNE)
// ============================================================================
const COLLAB_SESSIONS = new Map();
const COLLAB_LOCKS = new Map();

register("collab", "createSession", (ctx, input) => {
  const { dtuId, userId, mode } = input;
  if (!dtuId) return { ok: false, error: "DTU ID required" };
  const session = {
    id: uid("collab"),
    dtuId,
    creatorId: userId || "anonymous",
    mode: mode || "edit",
    participants: [{ userId: userId || "anonymous", joinedAt: nowISO(), role: "owner" }],
    changes: [],
    createdAt: nowISO(),
    expiresAt: new Date(Date.now() + 24 * 60 * 60 * 1000).toISOString(),
    councilGated: true
  };
  COLLAB_SESSIONS.set(session.id, session);
  realtimeEmit("collab:session:created", { sessionId: session.id, dtuId }, { sessionId: ctx.reqMeta?.sessionId });
  return { ok: true, session };
});

register("collab", "join", (ctx, input) => {
  const { sessionId, userId } = input;
  const session = COLLAB_SESSIONS.get(sessionId);
  if (!session) return { ok: false, error: "Session not found" };
  if (!session.participants.find(p => p.userId === userId)) session.participants.push({ userId: userId || "anonymous", joinedAt: nowISO(), role: "collaborator" });
  realtimeEmit("collab:user:joined", { sessionId, userId }, { sessionId: ctx.reqMeta?.sessionId });
  return { ok: true, session };
});

register("collab", "edit", (ctx, input) => {
  const { sessionId, userId, operation, path, value, previousValue } = input;
  const session = COLLAB_SESSIONS.get(sessionId);
  if (!session) return { ok: false, error: "Session not found" };
  const lockKey = `${session.dtuId}:${path}`;
  const existingLock = COLLAB_LOCKS.get(lockKey);
  if (existingLock && existingLock.userId !== userId && Date.now() - new Date(existingLock.lockedAt).getTime() < 30000) return { ok: false, error: "Path locked by another user", lockedBy: existingLock.userId };
  const change = { id: uid("change"), userId: userId || "anonymous", operation: operation || "update", path, value, previousValue, timestamp: nowISO(), status: "pending" };
  session.changes.push(change);
  realtimeEmit("collab:change", { sessionId, change }, { sessionId: ctx.reqMeta?.sessionId });
  return { ok: true, change, session };
});

register("collab", "merge", (ctx, input) => {
  const { sessionId } = input;
  const session = COLLAB_SESSIONS.get(sessionId);
  if (!session) return { ok: false, error: "Session not found" };
  if (session.councilGated) {
    STATE.queues.macroProposals.push({ type: "collab_merge", sessionId, dtuId: session.dtuId, changeCount: session.changes.length, participants: session.participants.map(p => p.userId), proposedAt: nowISO() });
    saveStateDebounced();
    return { ok: true, message: "Merge queued for council review", queuedChanges: session.changes.length };
  }
  const dtu = STATE.dtus.get(session.dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };
  for (const change of session.changes.filter(c => c.status === "pending")) {
    const pathParts = change.path.split(".");
    let target = dtu;
    for (let i = 0; i < pathParts.length - 1; i++) target = target[pathParts[i]] = target[pathParts[i]] || {};
    target[pathParts[pathParts.length - 1]] = change.value;
    change.status = "applied";
  }
  dtu.updatedAt = nowISO();
  dtu.meta = dtu.meta || {};
  dtu.meta.lastCollabSession = sessionId;
  STATE.dtus.set(session.dtuId, dtu);
  saveStateDebounced();
  return { ok: true, merged: session.changes.filter(c => c.status === "applied").length };
});

register("collab", "listSessions", (_ctx, _input) => {
  const sessions = Array.from(COLLAB_SESSIONS.values()).filter(s => new Date(s.expiresAt) > new Date()).map(s => ({ id: s.id, dtuId: s.dtuId, mode: s.mode, participantCount: s.participants.length, changeCount: s.changes.length, createdAt: s.createdAt }));
  return { ok: true, sessions, count: sessions.length };
});

register("collab", "lock", (ctx, input) => {
  const { sessionId, userId, path } = input;
  const session = COLLAB_SESSIONS.get(sessionId);
  if (!session) return { ok: false, error: "Session not found" };
  const lockKey = `${session.dtuId}:${path}`;
  COLLAB_LOCKS.set(lockKey, { userId, lockedAt: nowISO(), path });
  realtimeEmit("collab:lock", { sessionId, userId, path }, {});
  return { ok: true, locked: true, path };
});

register("collab", "unlock", (ctx, input) => {
  const { sessionId, path } = input;
  const session = COLLAB_SESSIONS.get(sessionId);
  if (!session) return { ok: false, error: "Session not found" };
  const lockKey = `${session.dtuId}:${path}`;
  COLLAB_LOCKS.delete(lockKey);
  realtimeEmit("collab:unlock", { sessionId, path }, {});
  return { ok: true, unlocked: true, path };
});

// Whiteboard with Excalidraw integration
register("whiteboard", "create", (ctx, input) => {
  const { title, linkedDtus } = input;
  const whiteboard = { id: uid("wb"), title: title || "Untitled Whiteboard", elements: [], linkedDtus: linkedDtus || [], collaborators: [], createdAt: nowISO(), updatedAt: nowISO() };
  const wbDtu = {
    id: whiteboard.id,
    title: `Whiteboard: ${whiteboard.title}`,
    tier: "regular",
    tags: ["whiteboard", "visual"],
    human: { summary: `Visual whiteboard with ${whiteboard.linkedDtus.length} linked DTUs` },
    machine: { kind: "whiteboard", data: whiteboard },
    lineage: { parents: whiteboard.linkedDtus, children: [] },
    source: "whiteboard",
    createdAt: whiteboard.createdAt
  };
  STATE.dtus.set(wbDtu.id, wbDtu);
  saveStateDebounced();
  return { ok: true, whiteboard, dtuId: wbDtu.id };
});

register("whiteboard", "update", (ctx, input) => {
  const { whiteboardId, elements, linkedDtus } = input;
  const dtu = STATE.dtus.get(whiteboardId);
  if (!dtu || dtu.machine?.kind !== "whiteboard") return { ok: false, error: "Whiteboard not found" };
  const wb = dtu.machine.data;
  if (elements) wb.elements = elements;
  if (linkedDtus) { wb.linkedDtus = linkedDtus; dtu.lineage.parents = linkedDtus; }
  wb.updatedAt = nowISO();
  dtu.updatedAt = nowISO();
  STATE.dtus.set(whiteboardId, dtu);
  saveStateDebounced();
  realtimeEmit("whiteboard:updated", { whiteboardId, elementCount: wb.elements.length }, {});
  return { ok: true, whiteboard: wb };
});

register("whiteboard", "get", (ctx, input) => {
  const { whiteboardId } = input;
  const dtu = STATE.dtus.get(whiteboardId);
  if (!dtu || dtu.machine?.kind !== "whiteboard") return { ok: false, error: "Whiteboard not found" };
  return { ok: true, whiteboard: dtu.machine.data, linkedDtus: dtu.lineage?.parents || [] };
});

register("whiteboard", "list", (_ctx, _input) => {
  const whiteboards = dtusArray().filter(d => d.machine?.kind === "whiteboard").map(d => ({ id: d.id, title: d.title, elementCount: d.machine.data?.elements?.length || 0, linkedDtuCount: d.lineage?.parents?.length || 0, createdAt: d.createdAt }));
  return { ok: true, whiteboards, count: whiteboards.length };
});

app.post("/api/collab/session", async (req, res) => res.json(await runMacro("collab", "createSession", req.body, makeCtx(req))));
app.post("/api/collab/join", async (req, res) => res.json(await runMacro("collab", "join", req.body, makeCtx(req))));
app.post("/api/collab/edit", async (req, res) => res.json(await runMacro("collab", "edit", req.body, makeCtx(req))));
app.post("/api/collab/merge", async (req, res) => res.json(await runMacro("collab", "merge", req.body, makeCtx(req))));
app.get("/api/collab/sessions", async (req, res) => res.json(await runMacro("collab", "listSessions", {}, makeCtx(req))));
app.post("/api/collab/lock", async (req, res) => res.json(await runMacro("collab", "lock", req.body, makeCtx(req))));
app.post("/api/collab/unlock", async (req, res) => res.json(await runMacro("collab", "unlock", req.body, makeCtx(req))));
app.post("/api/whiteboard", async (req, res) => res.json(await runMacro("whiteboard", "create", req.body, makeCtx(req))));
app.put("/api/whiteboard/:id", async (req, res) => res.json(await runMacro("whiteboard", "update", { whiteboardId: req.params.id, ...req.body }, makeCtx(req))));
app.get("/api/whiteboard/:id", async (req, res) => res.json(await runMacro("whiteboard", "get", { whiteboardId: req.params.id }, makeCtx(req))));
app.get("/api/whiteboards", async (req, res) => res.json(await runMacro("whiteboard", "list", {}, makeCtx(req))));

console.log("[Concord] Wave 5: Collaboration & Whiteboard loaded");

// ============================================================================
// WAVE 6: PWA & MOBILE SUPPORT
// ============================================================================
register("pwa", "manifest", (_ctx, _input) => {
  return {
    ok: true,
    manifest: {
      name: "Concord Cognitive Engine",
      short_name: "Concord",
      description: "Local-first cognitive operating system for knowledge synthesis",
      start_url: "/",
      display: "standalone",
      background_color: "#1a1a2e",
      theme_color: "#6366f1",
      orientation: "any",
      icons: [
        { src: "/icons/icon-72.png", sizes: "72x72", type: "image/png" },
        { src: "/icons/icon-96.png", sizes: "96x96", type: "image/png" },
        { src: "/icons/icon-128.png", sizes: "128x128", type: "image/png" },
        { src: "/icons/icon-144.png", sizes: "144x144", type: "image/png" },
        { src: "/icons/icon-152.png", sizes: "152x152", type: "image/png" },
        { src: "/icons/icon-192.png", sizes: "192x192", type: "image/png" },
        { src: "/icons/icon-384.png", sizes: "384x384", type: "image/png" },
        { src: "/icons/icon-512.png", sizes: "512x512", type: "image/png" }
      ],
      categories: ["productivity", "education", "utilities"],
      shortcuts: [
        { name: "Quick Forge", short_name: "Forge", url: "/lenses/forge", icons: [{ src: "/icons/forge.png", sizes: "192x192" }] },
        { name: "Chat", short_name: "Chat", url: "/lenses/chat", icons: [{ src: "/icons/chat.png", sizes: "192x192" }] },
        { name: "Graph", short_name: "Graph", url: "/lenses/graph", icons: [{ src: "/icons/graph.png", sizes: "192x192" }] },
        { name: "Voice Note", short_name: "Voice", url: "/lenses/voice", icons: [{ src: "/icons/voice.png", sizes: "192x192" }] }
      ],
      share_target: { action: "/share", method: "POST", enctype: "multipart/form-data", params: { title: "title", text: "text", url: "url" } }
    }
  };
});

register("pwa", "serviceWorkerConfig", (_ctx, _input) => {
  return {
    ok: true,
    config: {
      version: VERSION,
      cacheFirst: ["/api/dtus", "/api/status", "/api/personas", "/api/schema", "/api/plugins"],
      networkFirst: ["/api/chat", "/api/forge", "/api/ask", "/api/collab"],
      staleWhileRevalidate: ["/api/search", "/api/graph", "/api/visual"],
      offlineOnly: ["/api/dtus/local", "/api/cache"],
      precache: ["/", "/lenses/chat", "/lenses/forge", "/lenses/graph", "/manifest.json"],
      syncTags: ["dtu-sync", "collab-sync", "voice-sync"],
      backgroundSync: { enabled: true, minInterval: 300000, maxRetries: 3 },
      pushNotifications: { enabled: true, vapidPublicKey: process.env.VAPID_PUBLIC_KEY || null }
    }
  };
});

register("voice", "ingest", async (ctx, input) => {
  const { audioData, format, language, autoForge } = input;
  const transcription = await runMacro("voice", "transcribe", { audio: audioData, format: format || "webm", language: language || "en" }, ctx);
  if (!transcription.ok) return transcription;
  const text = transcription.text;
  if (!autoForge) return { ok: true, transcription: text };
  const tags = await runMacro("autotag", "analyze", { content: text }, ctx);
  const dtu = await runMacro("dtu", "create", {
    title: text.slice(0, 80) + (text.length > 80 ? "..." : ""),
    human: { summary: text },
    tags: tags.ok ? [...tags.suggestedTags, "voice-note"] : ["voice-note"],
    source: "voice-ingest",
    meta: { voiceIngest: true, language: language || "en", format: format || "webm", transcribedAt: nowISO() }
  }, ctx);
  return { ok: true, transcription: text, dtu: dtu.dtu };
});

register("mobile", "shortcuts", (_ctx, _input) => {
  return {
    ok: true,
    shortcuts: [
      { id: "quick-forge", label: "Quick Forge", action: "/api/forge/manual", icon: "plus-circle", gesture: "swipe-right" },
      { id: "voice-note", label: "Voice Note", action: "/api/voice/ingest", icon: "microphone", gesture: "long-press" },
      { id: "search", label: "Search", action: "/api/search/indexed", icon: "search", gesture: "swipe-down" },
      { id: "recent", label: "Recent DTUs", action: "/api/dtus/recent", icon: "clock", gesture: "swipe-left" },
      { id: "graph-view", label: "Graph View", action: "/lenses/graph", icon: "network", gesture: "pinch" },
      { id: "sync", label: "Force Sync", action: "/api/sync/force", icon: "refresh", gesture: "pull-down" }
    ],
    gestures: {
      enabled: true,
      sensitivity: 0.7,
      hapticFeedback: true
    }
  };
});

register("mobile", "touchOptimized", (ctx, input) => {
  const { dtuId } = input;
  const dtu = STATE.dtus.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };
  return {
    ok: true,
    compactView: {
      id: dtu.id,
      title: dtu.title,
      tier: dtu.tier,
      tags: (dtu.tags || []).slice(0, 3),
      summary: (dtu.human?.summary || "").slice(0, 140),
      bulletCount: dtu.human?.bullets?.length || 0,
      hasLineage: !!(dtu.lineage?.parents?.length || dtu.lineage?.children?.length),
      createdAt: dtu.createdAt
    },
    actions: [
      { id: "view", label: "View", icon: "eye" },
      { id: "edit", label: "Edit", icon: "pencil" },
      { id: "share", label: "Share", icon: "share" },
      { id: "link", label: "Link", icon: "link" },
      { id: "delete", label: "Delete", icon: "trash", danger: true }
    ]
  };
});

register("sync", "force", (ctx, input) => {
  const { since } = input;
  const sinceDate = since ? new Date(since) : new Date(Date.now() - 24 * 60 * 60 * 1000);
  const modified = dtusArray().filter(d => new Date(d.updatedAt || d.createdAt) > sinceDate);
  return {
    ok: true,
    synced: modified.length,
    dtus: modified.map(d => ({ id: d.id, title: d.title, updatedAt: d.updatedAt || d.createdAt })),
    syncedAt: nowISO()
  };
});

app.get("/manifest.json", async (req, res) => { const out = await runMacro("pwa", "manifest", {}, makeCtx(req)); res.json(out.manifest); });
app.get("/api/pwa/sw-config", async (req, res) => res.json(await runMacro("pwa", "serviceWorkerConfig", {}, makeCtx(req))));
app.post("/api/voice/ingest", async (req, res) => res.json(await runMacro("voice", "ingest", req.body, makeCtx(req))));
app.get("/api/mobile/shortcuts", async (req, res) => res.json(await runMacro("mobile", "shortcuts", {}, makeCtx(req))));
app.get("/api/mobile/dtu/:id", async (req, res) => res.json(await runMacro("mobile", "touchOptimized", { dtuId: req.params.id }, makeCtx(req))));
app.post("/api/sync/force", async (req, res) => res.json(await runMacro("sync", "force", req.body, makeCtx(req))));

console.log("[Concord] Wave 6: PWA & Mobile loaded");

// ============================================================================
// WAVE 7: SCALABILITY & PERFORMANCE
// ============================================================================
const CACHE = { hot: new Map(), queries: new Map(), ttl: 300000, maxSize: 1000 };

register("cache", "get", (ctx, input) => {
  const { key } = input;
  const cached = CACHE.hot.get(key);
  if (!cached) return { ok: false, miss: true };
  if (Date.now() - cached.cachedAt > (cached.ttl || CACHE.ttl)) { CACHE.hot.delete(key); return { ok: false, miss: true, expired: true }; }
  return { ok: true, data: cached.data, cachedAt: cached.cachedAt };
});

register("cache", "set", (ctx, input) => {
  const { key, data, ttl } = input;
  CACHE.hot.set(key, { data, cachedAt: Date.now(), ttl: ttl || CACHE.ttl });
  if (CACHE.hot.size > CACHE.maxSize) {
    const entries = Array.from(CACHE.hot.entries()).sort((a, b) => a[1].cachedAt - b[1].cachedAt);
    for (let i = 0; i < 100; i++) CACHE.hot.delete(entries[i][0]);
  }
  return { ok: true, key, cached: true };
});

register("cache", "invalidate", (ctx, input) => {
  const { key, pattern } = input;
  if (key) { CACHE.hot.delete(key); return { ok: true, invalidated: 1 }; }
  if (pattern) {
    // ReDoS protection - validate pattern before use
    const patternStr = String(pattern);
    if (patternStr.length > 100) return { ok: false, error: "Pattern too long (max 100 chars)" };
    if (/(\+\+|\*\*|\{\d+,\d*\}\+|\(\?[!<])/g.test(patternStr)) return { ok: false, error: "Pattern too complex" };
    try {
      const re = new RegExp(patternStr);
      let count = 0;
      for (const k of CACHE.hot.keys()) {
        if (re.test(k)) { CACHE.hot.delete(k); count++; }
        if (count > 1000) break; // Safety limit
      }
      return { ok: true, invalidated: count };
    } catch { return { ok: false, error: "Invalid regex pattern" }; }
  }
  return { ok: false, error: "Key or pattern required" };
});

register("cache", "stats", (_ctx, _input) => {
  return { ok: true, size: CACHE.hot.size, maxSize: CACHE.maxSize, ttl: CACHE.ttl, queryCache: CACHE.queries.size };
});

register("cache", "clear", (_ctx, _input) => {
  const size = CACHE.hot.size;
  CACHE.hot.clear();
  CACHE.queries.clear();
  return { ok: true, cleared: size };
});

// Sharding for multi-tenant
register("shard", "route", (ctx, input) => {
  const { userId, orgId } = input;
  const shardKey = orgId || userId || "default";
  const hash = crypto.createHash("md5").update(shardKey).digest("hex");
  const shardNum = parseInt(hash.slice(0, 8), 16) % 16;
  return {
    ok: true,
    shardKey,
    shardNum,
    shardId: `shard_${shardNum.toString().padStart(2, "0")}`,
    routing: { primary: `shard_${shardNum.toString().padStart(2, "0")}`, replicas: [`shard_${((shardNum + 1) % 16).toString().padStart(2, "0")}`, `shard_${((shardNum + 2) % 16).toString().padStart(2, "0")}`] }
  };
});

register("shard", "stats", async (ctx, _input) => {
  const shards = {};
  for (const [_id, dtu] of STATE.dtus.entries()) {
    const shardResult = await runMacro("shard", "route", { userId: dtu.meta?.userId, orgId: dtu.meta?.orgId }, ctx);
    const shardId = shardResult.shardId;
    if (!shards[shardId]) shards[shardId] = { count: 0, size: 0 };
    shards[shardId].count++;
    shards[shardId].size += JSON.stringify(dtu).length;
  }
  return { ok: true, shards, totalShards: Object.keys(shards).length };
});

// Governor for rate limiting
register("governor", "configure", (ctx, input) => {
  const { userId, maxDtusPerHour, maxQueriesPerMinute, heartbeatInterval } = input;
  const governor = {
    userId: userId || "default",
    limits: { maxDtusPerHour: Number(maxDtusPerHour) || 100, maxQueriesPerMinute: Number(maxQueriesPerMinute) || 60, heartbeatInterval: Number(heartbeatInterval) || 15000 },
    usage: { dtusThisHour: 0, queriesThisMinute: 0, lastHourReset: Date.now(), lastMinuteReset: Date.now() },
    configuredAt: nowISO()
  };
  STATE.governors = STATE.governors || new Map();
  STATE.governors.set(governor.userId, governor);
  saveStateDebounced();
  return { ok: true, governor };
});

register("governor", "check", (ctx, input) => {
  const { userId, action } = input;
  const governor = STATE.governors?.get(userId) || STATE.governors?.get("default");
  if (!governor) return { ok: true, allowed: true };
  const now = Date.now();
  if (now - governor.usage.lastHourReset > 3600000) { governor.usage.dtusThisHour = 0; governor.usage.lastHourReset = now; }
  if (now - governor.usage.lastMinuteReset > 60000) { governor.usage.queriesThisMinute = 0; governor.usage.lastMinuteReset = now; }
  if (action === "create_dtu" && governor.usage.dtusThisHour >= governor.limits.maxDtusPerHour) return { ok: true, allowed: false, reason: "DTU creation limit reached", retryAfter: 3600000 - (now - governor.usage.lastHourReset) };
  if (action === "query" && governor.usage.queriesThisMinute >= governor.limits.maxQueriesPerMinute) return { ok: true, allowed: false, reason: "Query rate limit reached", retryAfter: 60000 - (now - governor.usage.lastMinuteReset) };
  return { ok: true, allowed: true, usage: governor.usage, limits: governor.limits };
});

register("governor", "increment", (ctx, input) => {
  const { userId, action } = input;
  const governor = STATE.governors?.get(userId) || STATE.governors?.get("default");
  if (!governor) return { ok: true };
  if (action === "create_dtu") governor.usage.dtusThisHour++;
  if (action === "query") governor.usage.queriesThisMinute++;
  return { ok: true, usage: governor.usage };
});

// Performance metrics
register("perf", "metrics", (_ctx, _input) => {
  const mem = process.memoryUsage();
  return {
    ok: true,
    memory: { heapUsed: Math.round(mem.heapUsed / 1024 / 1024), heapTotal: Math.round(mem.heapTotal / 1024 / 1024), rss: Math.round(mem.rss / 1024 / 1024), external: Math.round(mem.external / 1024 / 1024) },
    uptime: process.uptime(),
    dtus: { total: STATE.dtus.size, shadow: STATE.shadowDtus?.size || 0 },
    cache: { hot: CACHE.hot.size, queries: CACHE.queries.size },
    graph: { nodes: GRAPH_INDEX.nodes.size, edges: GRAPH_INDEX.edges.size, dirty: GRAPH_INDEX.dirty },
    collab: { sessions: COLLAB_SESSIONS.size, locks: COLLAB_LOCKS.size },
    plugins: { marketplace: PLUGIN_MARKETPLACE.listings.size, installed: PLUGIN_MARKETPLACE.installed.size }
  };
});

register("perf", "gc", (_ctx, _input) => {
  if (global.gc) { global.gc(); return { ok: true, gcRun: true }; }
  return { ok: false, error: "GC not exposed. Start node with --expose-gc" };
});

// Backpressure for conservation
register("backpressure", "status", (_ctx, _input) => {
  const dtuCount = STATE.dtus.size;
  const thresholds = { warning: 50000, critical: 100000, max: 200000 };
  let level = "normal";
  if (dtuCount > thresholds.critical) level = "critical";
  else if (dtuCount > thresholds.warning) level = "warning";
  return {
    ok: true,
    level,
    dtuCount,
    thresholds,
    recommendations: level === "critical" ? ["Run MEGA consolidation", "Archive old DTUs", "Increase promotion rate"] : level === "warning" ? ["Consider archiving inactive DTUs", "Review promotion thresholds"] : []
  };
});

app.get("/api/cache/:key", async (req, res) => res.json(await runMacro("cache", "get", { key: req.params.key }, makeCtx(req))));
app.post("/api/cache", async (req, res) => res.json(await runMacro("cache", "set", req.body, makeCtx(req))));
app.delete("/api/cache", async (req, res) => res.json(await runMacro("cache", "invalidate", req.body, makeCtx(req))));
app.get("/api/cache/stats", async (req, res) => res.json(await runMacro("cache", "stats", {}, makeCtx(req))));
app.post("/api/cache/clear", async (req, res) => res.json(await runMacro("cache", "clear", {}, makeCtx(req))));
app.get("/api/shard/route", async (req, res) => res.json(await runMacro("shard", "route", { userId: req.query.userId, orgId: req.query.orgId }, makeCtx(req))));
app.get("/api/shard/stats", async (req, res) => res.json(await runMacro("shard", "stats", {}, makeCtx(req))));
app.post("/api/governor/configure", async (req, res) => res.json(await runMacro("governor", "configure", req.body, makeCtx(req))));
app.get("/api/governor/check", async (req, res) => res.json(await runMacro("governor", "check", { userId: req.query.userId, action: req.query.action }, makeCtx(req))));
app.get("/api/perf/metrics", async (req, res) => res.json(await runMacro("perf", "metrics", {}, makeCtx(req))));
app.post("/api/perf/gc", async (req, res) => res.json(await runMacro("perf", "gc", {}, makeCtx(req))));
app.get("/api/backpressure/status", async (req, res) => res.json(await runMacro("backpressure", "status", {}, makeCtx(req))));

// ---- Observability & Cost Endpoints (Categories 5+6) ----
app.get("/api/observability/latency", (req, res) => {
  res.json({ ok: true, latency: _LATENCY.stats() });
});

app.get("/api/observability/llm-budget", (req, res) => {
  res.json({ ok: true, budget: _LLM_BUDGET.stats() });
});

app.get("/api/observability/health", (req, res) => {
  const latency = _LATENCY.stats();
  const budget = _LLM_BUDGET.stats();
  const issues = [];
  if (latency.p95 > _LATENCY.slowThresholdMs) issues.push(`p95 latency ${latency.p95}ms exceeds ${_LATENCY.slowThresholdMs}ms threshold`);
  if (_LLM_BUDGET.circuitOpen) issues.push("LLM circuit breaker is OPEN");
  if (_LLM_BUDGET.totalTokensUsed > _LLM_BUDGET.globalBudgetTokens * 0.8) issues.push("LLM budget >80% utilized");

  res.json({
    ok: issues.length === 0,
    status: issues.length === 0 ? "healthy" : "degraded",
    issues,
    latency,
    budget,
    dtuCount: STATE.dtus.size,
    shadowDtuCount: STATE.shadowDtus.size,
    artifactCount: STATE.lensArtifacts.size,
    wsConnections: REALTIME.clients?.size || 0,
    eventSeq: _eventSeqCounter,
    idempotencyEntries: _IDEMPOTENCY.store.size,
  });
});

console.log("[Concord] Wave 7: Scalability & Performance loaded");

// ============================================================================
// WAVE 8: INTEGRATIONS ECOSYSTEM (Surpassing Roam Research)
// ============================================================================
const WEBHOOKS = new Map();
const AUTOMATIONS = new Map();

register("webhook", "register", (ctx, input) => {
  const { url, events, secret, name, headers } = input;
  if (!url || !events) return { ok: false, error: "URL and events required" };
  const webhook = {
    id: uid("wh"),
    name: name || "Unnamed Webhook",
    url,
    events: Array.isArray(events) ? events : [events],
    secret: secret || crypto.randomBytes(32).toString("hex"),
    headers: headers || {},
    enabled: true,
    createdAt: nowISO(),
    lastTriggered: null,
    triggerCount: 0,
    failureCount: 0,
    lastError: null
  };
  WEBHOOKS.set(webhook.id, webhook);
  saveStateDebounced();
  return { ok: true, webhook: { ...webhook, secret: webhook.secret.slice(0, 8) + "..." } };
});

register("webhook", "trigger", (ctx, input) => {
  const { event, payload } = input;
  const matchingWebhooks = Array.from(WEBHOOKS.values()).filter(wh => wh.enabled && wh.events.includes(event));
  const results = [];
  for (const webhook of matchingWebhooks) {
    const signature = crypto.createHmac("sha256", webhook.secret).update(JSON.stringify(payload)).digest("hex");
    webhook.lastTriggered = nowISO();
    webhook.triggerCount++;
    results.push({ webhookId: webhook.id, name: webhook.name, triggered: true, signature: signature.slice(0, 16) + "..." });
  }
  return { ok: true, event, triggered: results.length, results };
});

register("webhook", "list", (_ctx, _input) => {
  const webhooks = Array.from(WEBHOOKS.values()).map(wh => ({ id: wh.id, name: wh.name, url: wh.url, events: wh.events, enabled: wh.enabled, triggerCount: wh.triggerCount, lastTriggered: wh.lastTriggered }));
  return { ok: true, webhooks, count: webhooks.length };
});

register("webhook", "delete", (ctx, input) => {
  const { webhookId } = input;
  if (!WEBHOOKS.has(webhookId)) return { ok: false, error: "Webhook not found" };
  WEBHOOKS.delete(webhookId);
  saveStateDebounced();
  return { ok: true, deleted: webhookId };
});

register("webhook", "toggle", (ctx, input) => {
  const { webhookId, enabled } = input;
  const webhook = WEBHOOKS.get(webhookId);
  if (!webhook) return { ok: false, error: "Webhook not found" };
  webhook.enabled = enabled !== undefined ? enabled : !webhook.enabled;
  return { ok: true, webhookId, enabled: webhook.enabled };
});

// Zapier-style automations
register("automation", "create", (ctx, input) => {
  const { name, trigger, conditions, actions } = input;
  if (!name || !trigger || !actions) return { ok: false, error: "Name, trigger, and actions required" };
  const automation = {
    id: uid("auto"),
    name: normalizeText(name),
    trigger: { event: trigger.event, filters: trigger.filters || {} },
    conditions: conditions || [],
    actions: actions.map(a => ({ type: a.type, config: a.config || {} })),
    enabled: true,
    createdAt: nowISO(),
    runCount: 0,
    lastRun: null,
    lastResult: null
  };
  AUTOMATIONS.set(automation.id, automation);
  saveStateDebounced();
  return { ok: true, automation };
});

register("automation", "run", async (ctx, input) => {
  const { automationId, triggerData } = input;
  const automation = AUTOMATIONS.get(automationId);
  if (!automation) return { ok: false, error: "Automation not found" };
  if (!automation.enabled) return { ok: false, error: "Automation disabled" };
  const results = [];
  for (const action of automation.actions) {
    try {
      if (action.type === "create_dtu") { results.push({ action: "create_dtu", result: await runMacro("dtu", "create", { ...action.config, ...triggerData }, ctx) }); }
      else if (action.type === "update_dtu") { results.push({ action: "update_dtu", result: await runMacro("dtu", "update", { ...action.config, ...triggerData }, ctx) }); }
      else if (action.type === "run_macro") { const [domain, op] = action.config.macro.split("."); results.push({ action: "run_macro", macro: action.config.macro, result: await runMacro(domain, op, { ...action.config.input, ...triggerData }, ctx) }); }
      else if (action.type === "send_webhook") { results.push({ action: "send_webhook", result: await runMacro("webhook", "trigger", { event: "automation.action", payload: { automationId, triggerData, action } }, ctx) }); }
      else if (action.type === "notify") { results.push({ action: "notify", result: { ok: true, message: action.config.message } }); }
    } catch (e) { results.push({ action: action.type, error: e.message }); }
  }
  automation.runCount++;
  automation.lastRun = nowISO();
  automation.lastResult = results;
  return { ok: true, automationId, actionResults: results };
});

register("automation", "list", (_ctx, _input) => {
  const automations = Array.from(AUTOMATIONS.values()).map(a => ({ id: a.id, name: a.name, trigger: a.trigger.event, actionCount: a.actions.length, enabled: a.enabled, runCount: a.runCount, lastRun: a.lastRun }));
  return { ok: true, automations, count: automations.length };
});

register("automation", "delete", (ctx, input) => {
  const { automationId } = input;
  if (!AUTOMATIONS.has(automationId)) return { ok: false, error: "Automation not found" };
  AUTOMATIONS.delete(automationId);
  saveStateDebounced();
  return { ok: true, deleted: automationId };
});

register("automation", "toggle", (ctx, input) => {
  const { automationId, enabled } = input;
  const automation = AUTOMATIONS.get(automationId);
  if (!automation) return { ok: false, error: "Automation not found" };
  automation.enabled = enabled !== undefined ? enabled : !automation.enabled;
  return { ok: true, automationId, enabled: automation.enabled };
});

// VS Code extension support
register("vscode", "codeToDtu", async (ctx, input) => {
  const { code, language, filename, selection, context, autoTag } = input;
  if (!code) return { ok: false, error: "Code content required" };
  const dtu = {
    id: uid("dtu"),
    title: `Code: ${filename || "snippet"} (${language || "unknown"})`,
    tier: "regular",
    tags: ["code", language || "unknown", "vscode-import"],
    human: { summary: `Code snippet from ${filename || "editor"}`, bullets: selection ? [`Lines ${selection.start}-${selection.end}`] : [] },
    core: { definitions: [`Language: ${language}`], examples: [code.slice(0, 1000)] },
    machine: { kind: "code_snippet", code, language, filename, selection, context },
    source: "vscode",
    createdAt: nowISO()
  };
  STATE.dtus.set(dtu.id, dtu);
  GRAPH_INDEX.dirty = true;
  saveStateDebounced();
  if (autoTag) await runMacro("autotag", "apply", { dtuId: dtu.id, tags: ["code", language].filter(Boolean) }, ctx);
  return { ok: true, dtu };
});

register("vscode", "dtuToCode", (ctx, input) => {
  const { dtuId, format: _format } = input;
  const dtu = STATE.dtus.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };
  let code = "";
  if (dtu.machine?.code) code = dtu.machine.code;
  else if (dtu.core?.examples?.[0]) code = dtu.core.examples[0];
  else { code = `// DTU: ${dtu.title}\n// Tags: ${(dtu.tags || []).join(", ")}\n\n`; if (dtu.human?.summary) code += `/* ${dtu.human.summary} */\n\n`; if (dtu.core?.definitions) code += dtu.core.definitions.map(d => `// ${d}`).join("\n"); }
  return { ok: true, code, language: dtu.machine?.language || "plaintext", dtuId };
});

register("vscode", "search", (ctx, input) => {
  const { query, language, limit } = input;
  let results = dtusArray().filter(d => d.tags?.includes("code") || d.machine?.kind === "code_snippet");
  if (language) results = results.filter(d => d.machine?.language === language || d.tags?.includes(language));
  if (query) { const q = query.toLowerCase(); results = results.filter(d => d.title.toLowerCase().includes(q) || (d.machine?.code || "").toLowerCase().includes(q)); }
  results = results.slice(0, Number(limit) || 20);
  return { ok: true, results: results.map(d => ({ id: d.id, title: d.title, language: d.machine?.language, filename: d.machine?.filename, preview: (d.machine?.code || "").slice(0, 100) })), count: results.length };
});

// Obsidian export/import
register("obsidian", "export", (ctx, input) => {
  const { dtuIds, includeLineage, vaultPath } = input;
  const dtus = dtuIds ? dtuIds.map(id => STATE.dtus.get(id)).filter(Boolean) : dtusArray();
  const files = [];
  for (const dtu of dtus) {
    let content = `# ${dtu.title}\n\n`;
    content += `> ${dtu.human?.summary || ""}\n\n`;
    content += `**Tags:** ${(dtu.tags || []).map(t => `#${t}`).join(" ")}\n\n`;
    if (dtu.core?.definitions?.length) { content += `## Definitions\n${dtu.core.definitions.map(d => `- ${d}`).join("\n")}\n\n`; }
    if (dtu.core?.claims?.length) { content += `## Claims\n${dtu.core.claims.map(c => `- ${c}`).join("\n")}\n\n`; }
    if (dtu.human?.bullets?.length) { content += `## Key Points\n${dtu.human.bullets.map(b => `- ${b}`).join("\n")}\n\n`; }
    if (includeLineage && dtu.lineage?.parents?.length) { content += `## Lineage\n**Parents:** ${dtu.lineage.parents.map(p => `[[${STATE.dtus.get(p)?.title || p}]]`).join(", ")}\n\n`; }
    content += `---\n*ID: ${dtu.id}*\n*Created: ${dtu.createdAt}*\n`;
    files.push({ filename: `${dtu.title.replace(/[/\\?%*:|"<>]/g, "-")}.md`, content, dtuId: dtu.id });
  }
  return { ok: true, files, count: files.length, vaultPath };
});

register("obsidian", "import", (ctx, input) => {
  const { files } = input;
  const imported = [];
  for (const file of (files || [])) {
    const lines = (file.content || "").split("\n");
    const title = lines[0]?.replace(/^#\s*/, "") || file.filename?.replace(/\.md$/, "") || "Untitled";
    const tagMatch = file.content.match(/\*\*Tags:\*\*\s*(.+)/);
    const tags = tagMatch ? tagMatch[1].split(/\s+/).map(t => t.replace(/^#/, "")).filter(Boolean) : ["obsidian-import"];
    const summaryMatch = file.content.match(/^>\s*(.+)/m);
    const dtu = {
      id: uid("dtu"),
      title: normalizeText(title),
      tier: "regular",
      tags: [...tags, "obsidian-import"],
      human: { summary: summaryMatch ? summaryMatch[1] : "" },
      core: { definitions: [], claims: [] },
      source: "obsidian-import",
      meta: { originalFile: file.filename, importedAt: nowISO() },
      createdAt: nowISO()
    };
    STATE.dtus.set(dtu.id, dtu);
    imported.push({ dtuId: dtu.id, title: dtu.title, filename: file.filename });
  }
  if (imported.length) { GRAPH_INDEX.dirty = true; saveStateDebounced(); }
  return { ok: true, imported, count: imported.length };
});

// Notion import
register("notion", "import", (ctx, input) => {
  const { pages } = input;
  const imported = [];
  for (const page of (pages || [])) {
    const dtu = {
      id: uid("dtu"),
      title: normalizeText(page.title || "Untitled"),
      tier: "regular",
      tags: [...(page.tags || []), "notion-import"],
      human: { summary: page.content?.slice(0, 500) || "", bullets: page.bullets || [] },
      core: { definitions: page.properties ? Object.entries(page.properties).map(([k, v]) => `${k}: ${v}`) : [] },
      source: "notion-import",
      meta: { notionId: page.id, notionUrl: page.url, importedAt: nowISO() },
      createdAt: page.createdTime || nowISO()
    };
    STATE.dtus.set(dtu.id, dtu);
    imported.push({ dtuId: dtu.id, title: dtu.title, notionId: page.id });
  }
  if (imported.length) { GRAPH_INDEX.dirty = true; saveStateDebounced(); }
  return { ok: true, imported, count: imported.length };
});

// Integration marketplace
register("integration", "list", (_ctx, _input) => {
  const integrations = [
    { id: "obsidian", name: "Obsidian", status: "available", type: "export/import", description: "Sync with Obsidian vaults" },
    { id: "notion", name: "Notion", status: "available", type: "import", description: "Import from Notion" },
    { id: "vscode", name: "VS Code", status: "available", type: "bidirectional", description: "Code snippets integration" },
    { id: "zapier", name: "Zapier", status: "available", type: "webhook", description: "Automation via Zapier" },
    { id: "github", name: "GitHub", status: "planned", type: "bidirectional", description: "Sync with GitHub repos" },
    { id: "slack", name: "Slack", status: "planned", type: "webhook", description: "Slack notifications" },
    { id: "discord", name: "Discord", status: "planned", type: "webhook", description: "Discord integration" },
    { id: "linear", name: "Linear", status: "planned", type: "bidirectional", description: "Issue tracking sync" }
  ];
  return { ok: true, integrations };
});

app.post("/api/webhooks", async (req, res) => res.json(await runMacro("webhook", "register", req.body, makeCtx(req))));
app.get("/api/webhooks", async (req, res) => res.json(await runMacro("webhook", "list", {}, makeCtx(req))));
app.delete("/api/webhooks/:id", async (req, res) => res.json(await runMacro("webhook", "delete", { webhookId: req.params.id }, makeCtx(req))));
app.post("/api/webhooks/:id/toggle", async (req, res) => res.json(await runMacro("webhook", "toggle", { webhookId: req.params.id, ...req.body }, makeCtx(req))));
app.post("/api/automations", async (req, res) => res.json(await runMacro("automation", "create", req.body, makeCtx(req))));
app.get("/api/automations", async (req, res) => res.json(await runMacro("automation", "list", {}, makeCtx(req))));
app.post("/api/automations/:id/run", async (req, res) => res.json(await runMacro("automation", "run", { automationId: req.params.id, triggerData: req.body }, makeCtx(req))));
app.delete("/api/automations/:id", async (req, res) => res.json(await runMacro("automation", "delete", { automationId: req.params.id }, makeCtx(req))));
app.post("/api/automations/:id/toggle", async (req, res) => res.json(await runMacro("automation", "toggle", { automationId: req.params.id, ...req.body }, makeCtx(req))));
app.post("/api/vscode/code-to-dtu", async (req, res) => res.json(await runMacro("vscode", "codeToDtu", req.body, makeCtx(req))));
app.get("/api/vscode/dtu-to-code/:id", async (req, res) => res.json(await runMacro("vscode", "dtuToCode", { dtuId: req.params.id, format: req.query.format }, makeCtx(req))));
app.get("/api/vscode/search", async (req, res) => res.json(await runMacro("vscode", "search", { query: req.query.q, language: req.query.language, limit: req.query.limit }, makeCtx(req))));
app.post("/api/obsidian/export", async (req, res) => res.json(await runMacro("obsidian", "export", req.body, makeCtx(req))));
app.post("/api/obsidian/import", async (req, res) => res.json(await runMacro("obsidian", "import", req.body, makeCtx(req))));
app.post("/api/notion/import", async (req, res) => res.json(await runMacro("notion", "import", req.body, makeCtx(req))));
app.get("/api/integrations", async (req, res) => res.json(await runMacro("integration", "list", {}, makeCtx(req))));

// Additional endpoints for frontend compatibility
app.get("/api/events", (req, res) => {
  try {
    // Return recent system events/logs
    const events = STATE.logs.slice(-100).map(log => ({
      id: log.id || uid("evt"),
      type: log.domain || "system",
      action: log.action || "event",
      message: log.message || "",
      timestamp: log.ts || log.timestamp || nowISO(),
      meta: log.meta || {}
    }));
    return res.json({ ok: true, events, count: events.length });
  } catch (e) {
    return res.status(500).json({ ok: false, error: String(e?.message || e) });
  }
});

app.post("/api/autocrawl", async (req, res) => {
  try {
    const { url, makeGlobal, declaredSourceType, tags } = req.body || {};
    if (!url) return res.status(400).json({ ok: false, error: "URL required" });
    const out = await runMacro("crawl", "fetch", {
      url: String(url).trim(),
      tags: tags || [],
      makeGlobal: makeGlobal || false,
      declaredSourceType: declaredSourceType || "web"
    }, makeCtx(req));
    return res.json(out);
  } catch (e) {
    return res.status(500).json({ ok: false, error: String(e?.message || e) });
  }
});

app.get("/api/marketplace/listings", async (req, res) => {
  // Alias for browse endpoint
  return res.json(await runMacro("marketplace", "browse", {
    category: req.query.category,
    search: req.query.search,
    sort: req.query.sort,
    page: req.query.page,
    pageSize: req.query.pageSize
  }, makeCtx(req)));
});

console.log("[Concord] Wave 8: Integrations Ecosystem loaded");

// ============================================================================
// WAVE 9: DATABASE INTEGRATIONS (PostgreSQL + Redis)
// ============================================================================

const PG_CONFIG = {
  enabled: !!process.env.POSTGRES_URL || !!process.env.DATABASE_URL,
  url: process.env.POSTGRES_URL || process.env.DATABASE_URL || null,
  pool: { min: 2, max: 10, idleTimeoutMillis: 30000 },
  ssl: process.env.POSTGRES_SSL === "true" ? { rejectUnauthorized: process.env.POSTGRES_SSL_REJECT_UNAUTHORIZED !== "false" } : false
};

let pgPool = null;

async function initPostgres() {
  if (!PG_CONFIG.enabled) return { ok: false, reason: "PostgreSQL not configured" };
  try {
    const { default: pg } = await import("pg");
    pgPool = new pg.Pool({ connectionString: PG_CONFIG.url, min: PG_CONFIG.pool.min, max: PG_CONFIG.pool.max, idleTimeoutMillis: PG_CONFIG.pool.idleTimeoutMillis, ssl: PG_CONFIG.ssl });
    await pgPool.query("SELECT 1");
    console.log("[PostgreSQL] Connected successfully");
    return { ok: true };
  } catch (e) { console.warn("[PostgreSQL] Connection failed:", e.message); pgPool = null; return { ok: false, error: e.message }; }
}

async function runMigrations() {
  if (!pgPool) return { ok: false, reason: "No PostgreSQL connection" };
  const migrations = [
    `CREATE TABLE IF NOT EXISTS dtus (id VARCHAR(64) PRIMARY KEY, title TEXT NOT NULL, tier VARCHAR(32) DEFAULT 'regular', tags JSONB DEFAULT '[]', human JSONB DEFAULT '{}', core JSONB DEFAULT '{}', machine JSONB DEFAULT '{}', lineage JSONB DEFAULT '{}', source VARCHAR(64), meta JSONB DEFAULT '{}', authority JSONB DEFAULT '{}', created_at TIMESTAMPTZ DEFAULT NOW(), updated_at TIMESTAMPTZ DEFAULT NOW(), hash VARCHAR(128), user_id VARCHAR(64), org_id VARCHAR(64))`,
    `CREATE INDEX IF NOT EXISTS idx_dtus_tier ON dtus(tier)`,
    `CREATE INDEX IF NOT EXISTS idx_dtus_tags ON dtus USING GIN(tags)`,
    `CREATE INDEX IF NOT EXISTS idx_dtus_user ON dtus(user_id)`,
    `CREATE INDEX IF NOT EXISTS idx_dtus_org ON dtus(org_id)`,
    `CREATE TABLE IF NOT EXISTS sessions (id VARCHAR(64) PRIMARY KEY, user_id VARCHAR(64), messages JSONB DEFAULT '[]', style_vector JSONB DEFAULT '{}', cloud_opt_in BOOLEAN DEFAULT FALSE, created_at TIMESTAMPTZ DEFAULT NOW())`,
    `CREATE TABLE IF NOT EXISTS plugins (id VARCHAR(64) PRIMARY KEY, name VARCHAR(256) NOT NULL, version VARCHAR(32), description TEXT, github_url TEXT, category VARCHAR(64), downloads INTEGER DEFAULT 0, rating DECIMAL(3,2) DEFAULT 0, status VARCHAR(32) DEFAULT 'pending', created_at TIMESTAMPTZ DEFAULT NOW())`,
    `CREATE TABLE IF NOT EXISTS webhooks (id VARCHAR(64) PRIMARY KEY, name VARCHAR(256), url TEXT NOT NULL, events JSONB DEFAULT '[]', secret VARCHAR(256), enabled BOOLEAN DEFAULT TRUE, trigger_count INTEGER DEFAULT 0, created_at TIMESTAMPTZ DEFAULT NOW())`,
    `CREATE TABLE IF NOT EXISTS automations (id VARCHAR(64) PRIMARY KEY, name VARCHAR(256), trigger JSONB, conditions JSONB DEFAULT '[]', actions JSONB DEFAULT '[]', enabled BOOLEAN DEFAULT TRUE, run_count INTEGER DEFAULT 0, created_at TIMESTAMPTZ DEFAULT NOW())`,
    `CREATE TABLE IF NOT EXISTS collab_sessions (id VARCHAR(64) PRIMARY KEY, dtu_id VARCHAR(64), creator_id VARCHAR(64), mode VARCHAR(32) DEFAULT 'edit', participants JSONB DEFAULT '[]', changes JSONB DEFAULT '[]', expires_at TIMESTAMPTZ, created_at TIMESTAMPTZ DEFAULT NOW())`,
    `CREATE TABLE IF NOT EXISTS whiteboards (id VARCHAR(64) PRIMARY KEY, title VARCHAR(256), elements JSONB DEFAULT '[]', linked_dtus JSONB DEFAULT '[]', created_at TIMESTAMPTZ DEFAULT NOW(), updated_at TIMESTAMPTZ DEFAULT NOW())`
  ];
  let applied = 0;
  for (const sql of migrations) { try { await pgPool.query(sql); applied++; } catch {} }
  return { ok: true, applied, total: migrations.length };
}

register("db", "status", (_ctx, _input) => {
  return { ok: true, postgres: { enabled: PG_CONFIG.enabled, connected: !!pgPool, pool: pgPool ? { total: pgPool.totalCount, idle: pgPool.idleCount, waiting: pgPool.waitingCount } : null }, redis: { enabled: REDIS_CONFIG.enabled, connected: !!redisClient }, mode: pgPool ? "postgresql" : "in-memory" };
});

register("db", "migrate", (_ctx, _input) => { return runMigrations(); });

register("db", "query", async (ctx, input) => {
  const { sql, params } = input;
  if (!pgPool) return { ok: false, error: "PostgreSQL not connected" };
  if (!sql) return { ok: false, error: "SQL query required" };
  try { const result = await pgPool.query(sql, params || []); return { ok: true, rows: result.rows, rowCount: result.rowCount }; }
  catch (e) { return { ok: false, error: e.message }; }
});

register("db", "syncToPostgres", async (ctx, input) => {
  if (!pgPool) return { ok: false, error: "PostgreSQL not connected" };
  const batch = Number(input.batchSize) || 100;
  let synced = 0;
  const dtus = dtusArray();
  for (let i = 0; i < dtus.length; i += batch) {
    for (const dtu of dtus.slice(i, i + batch)) {
      try {
        await pgPool.query(`INSERT INTO dtus (id, title, tier, tags, human, core, machine, lineage, source, meta, authority, created_at, updated_at, hash, user_id, org_id) VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, tier=EXCLUDED.tier, tags=EXCLUDED.tags, human=EXCLUDED.human, core=EXCLUDED.core, machine=EXCLUDED.machine, lineage=EXCLUDED.lineage, meta=EXCLUDED.meta, authority=EXCLUDED.authority, updated_at=NOW()`,
          [dtu.id, dtu.title, dtu.tier, JSON.stringify(dtu.tags||[]), JSON.stringify(dtu.human||{}), JSON.stringify(dtu.core||{}), JSON.stringify(dtu.machine||{}), JSON.stringify(dtu.lineage||{}), dtu.source, JSON.stringify(dtu.meta||{}), JSON.stringify(dtu.authority||{}), dtu.createdAt, dtu.updatedAt, dtu.hash, dtu.meta?.userId||null, dtu.meta?.orgId||null]);
        synced++;
      } catch {}
    }
  }
  return { ok: true, synced, total: dtus.length };
});

const REDIS_CONFIG = { enabled: !!process.env.REDIS_URL, url: process.env.REDIS_URL || null, prefix: process.env.REDIS_PREFIX || "concord:", ttl: Number(process.env.REDIS_TTL) || 300 };
let redisClient = null;

async function initRedis() {
  if (!REDIS_CONFIG.enabled) return { ok: false, reason: "Redis not configured" };
  try {
    const { createClient } = await import("redis");
    redisClient = createClient({ url: REDIS_CONFIG.url });
    redisClient.on("error", (err) => console.warn("[Redis] Error:", err.message));
    await redisClient.connect();
    console.log("[Redis] Connected successfully");
    return { ok: true };
  } catch (e) { console.warn("[Redis] Connection failed:", e.message); redisClient = null; return { ok: false, error: e.message }; }
}

register("redis", "get", async (ctx, input) => {
  const { key } = input;
  if (!redisClient) return runMacro("cache", "get", { key }, ctx);
  try { const value = await redisClient.get(REDIS_CONFIG.prefix + key); if (!value) return { ok: false, miss: true }; return { ok: true, data: JSON.parse(value) }; }
  catch (e) { return { ok: false, error: e.message }; }
});

register("redis", "set", async (ctx, input) => {
  const { key, data, ttl } = input;
  if (!redisClient) return runMacro("cache", "set", { key, data, ttl }, ctx);
  try { await redisClient.setEx(REDIS_CONFIG.prefix + key, ttl || REDIS_CONFIG.ttl, JSON.stringify(data)); return { ok: true, key, cached: true, backend: "redis" }; }
  catch (e) { return { ok: false, error: e.message }; }
});

register("redis", "del", async (ctx, input) => {
  const { key, pattern } = input;
  if (!redisClient) return runMacro("cache", "invalidate", { key, pattern }, ctx);
  try {
    if (key) { await redisClient.del(REDIS_CONFIG.prefix + key); return { ok: true, deleted: 1 }; }
    if (pattern) { const keys = await redisClient.keys(REDIS_CONFIG.prefix + pattern); if (keys.length > 0) await redisClient.del(keys); return { ok: true, deleted: keys.length }; }
    return { ok: false, error: "Key or pattern required" };
  } catch (e) { return { ok: false, error: e.message }; }
});

register("redis", "stats", async (_ctx, _input) => {
  if (!redisClient) return { ok: true, enabled: false, fallback: "in-memory" };
  try { const info = await redisClient.info("memory"); const keyCount = await redisClient.dbSize(); return { ok: true, enabled: true, keys: keyCount, info: info.slice(0, 500) }; }
  catch (e) { return { ok: false, error: e.message }; }
});

app.get("/api/db/status", async (req, res) => res.json(await runMacro("db", "status", {}, makeCtx(req))));
app.post("/api/db/migrate", async (req, res) => res.json(await runMacro("db", "migrate", {}, makeCtx(req))));
app.post("/api/db/sync", async (req, res) => res.json(await runMacro("db", "syncToPostgres", req.body, makeCtx(req))));
// Database lens endpoints (query/tables/indexes) — graceful stubs when no DB connected
app.post("/api/db/query", (req, res) => {
  const q = String(req.body?.query || "").trim();
  if (!q) return res.status(400).json({ ok: false, error: "query required" });
  if (!db) return res.json({ ok: true, rows: [], columns: [], message: "No database connected. Set DATABASE_URL to enable." });
  try {
    const stmt = db.prepare(q);
    if (q.toUpperCase().startsWith("SELECT") || q.toUpperCase().startsWith("PRAGMA") || q.toUpperCase().startsWith("EXPLAIN")) {
      const rows = stmt.all();
      const columns = rows.length > 0 ? Object.keys(rows[0]) : [];
      res.json({ ok: true, rows, columns, rowCount: rows.length });
    } else {
      const info = stmt.run();
      res.json({ ok: true, rows: [], columns: [], changes: info.changes });
    }
  } catch (e) { res.status(400).json({ ok: false, error: String(e?.message || e) }); }
});
app.get("/api/db/tables", (req, res) => {
  if (!db) return res.json({ ok: true, tables: [] });
  try {
    const tables = db.prepare("SELECT name, type FROM sqlite_master WHERE type IN ('table','view') ORDER BY name").all();
    res.json({ ok: true, tables });
  } catch (e) { res.json({ ok: true, tables: [], error: String(e?.message || e) }); }
});
app.get("/api/db/indexes", (req, res) => {
  if (!db) return res.json({ ok: true, indexes: [] });
  try {
    const indexes = db.prepare("SELECT name, tbl_name as tableName, sql FROM sqlite_master WHERE type='index' ORDER BY tbl_name, name").all();
    res.json({ ok: true, indexes });
  } catch (e) { res.json({ ok: true, indexes: [], error: String(e?.message || e) }); }
});
app.get("/api/redis/stats", async (req, res) => res.json(await runMacro("redis", "stats", {}, makeCtx(req))));

setTimeout(async () => {
  if (PG_CONFIG.enabled) { const pg = await initPostgres(); if (pg.ok) await runMigrations(); }
  // Hydrate blacklist from persistent storage
  _TOKEN_BLACKLIST.syncFromSQLite();
  if (REDIS_CONFIG.enabled) {
    await initRedis();
    if (redisClient) await _TOKEN_BLACKLIST.syncFromRedis();
  }
}, 1000);

console.log("[Concord] Wave 9: Database Integrations loaded");

// ============================================================================
// WAVE 10: NEW API ENDPOINTS (Waves 1-7 Feature APIs)
// ============================================================================

// ---- Wave 2: Version History Endpoints ----
app.get("/api/dtus/:id/versions", (req, res) => {
  const versions = getDTUVersions(req.params.id);
  res.json({ ok: true, versions });
});

app.post("/api/dtus/:id/restore", (req, res) => {
  const result = restoreDTUVersion(req.params.id, Number(req.body.version));
  res.json(result);
});

// ---- Wave 2: Templates Endpoints ----
app.get("/api/templates", (req, res) => {
  res.json({ ok: true, templates: Array.from(TEMPLATES.values()) });
});

app.post("/api/templates/:id/create", async (req, res) => {
  const result = createFromTemplate(req.params.id, req.body);
  if (!result.ok) return res.status(404).json(result);

  // Actually create the DTU
  const ctx = makeCtx(req);
  const dtuResult = await runMacro("dtu", "create", result.dtu, ctx);
  res.json(dtuResult);
});

// ---- Wave 2: Import/Export Endpoints ----
app.post("/api/import/obsidian", (req, res) => {
  const result = importFromObsidian(req.body.files || []);
  res.json(result);
});

app.post("/api/import/roam", (req, res) => {
  const result = importFromRoam(req.body.data || req.body);
  res.json(result);
});

app.get("/api/export/markdown", (req, res) => {
  const ids = req.query.ids ? req.query.ids.split(",") : null;
  const result = exportDTUsToMarkdown(ids);
  if (req.query.download === "1") {
    res.set("Content-Type", "text/markdown");
    res.set("Content-Disposition", "attachment; filename=concord-export.md");
    return res.send(result.markdown);
  }
  res.json(result);
});

app.get("/api/export/json", (req, res) => {
  const ids = req.query.ids ? req.query.ids.split(",") : null;
  const result = exportDTUsToJSON(ids);
  if (req.query.download === "1") {
    res.set("Content-Disposition", "attachment; filename=concord-export.json");
  }
  res.json(result);
});

// ---- Wave 2: Query Endpoint ----
app.post("/api/query", (req, res) => {
  const result = queryDTUsAdvanced(req.body.query || "");
  res.json(result);
});

// ---- Wave 3: AI Endpoints ----
app.get("/api/ai/embeddings/status", (req, res) => {
  res.json({
    ok: true,
    enabled: EMBEDDINGS.enabled,
    indexed: EMBEDDINGS.store.size,
    dim: EMBEDDINGS.dim
  });
});

app.post("/api/ai/embeddings/rebuild", async (req, res) => {
  const result = await rebuildEmbeddingIndex();
  res.json(result);
});

app.get("/api/ai/search", async (req, res) => {
  const result = await semanticSearch(req.query.q || "", {
    limit: Number(req.query.limit || 10),
    minScore: Number(req.query.minScore || 0.3)
  });
  res.json(result);
});

app.get("/api/dtus/:id/suggestions", async (req, res) => {
  const result = await suggestConnections(req.params.id, { limit: Number(req.query.limit || 5) });
  res.json(result);
});

app.post("/api/ai/creti", async (req, res) => {
  const result = await generateCRETI(req.body, makeCtx(req));
  res.json(result);
});

app.get("/api/dtus/:id/contradictions", async (req, res) => {
  const result = await detectContradictions(req.params.id);
  res.json(result);
});

app.get("/api/ai/gaps", async (req, res) => {
  const result = await analyzeKnowledgeGaps(req.query.domain);
  res.json(result);
});

app.post("/api/ai/chat", async (req, res) => {
  const result = await chatWithLattice(req.body.query || req.body.message, {
    contextLimit: Number(req.body.contextLimit || 5)
  });
  res.json(result);
});

// ---- Wave 3: SRS Endpoints ----
app.get("/api/srs/due", (req, res) => {
  const result = getDueCards(Number(req.query.limit || 20));
  res.json(result);
});

app.post("/api/srs/:dtuId/add", (req, res) => {
  const result = addToSRS(req.params.dtuId);
  res.json(result);
});

app.post("/api/srs/:dtuId/review", (req, res) => {
  const result = reviewSRSCard(req.params.dtuId, Number(req.body.quality));
  res.json(result);
});

// ---- Wave 4: Workspace Endpoints ----
app.post("/api/workspaces", (req, res) => {
  const userId = req.user?.id || "anonymous";
  const result = createWorkspace(userId, req.body.name, req.body.description);
  res.json(result);
});

app.get("/api/workspaces", (req, res) => {
  const userId = req.user?.id;
  const workspaces = Array.from(WORKSPACES.values())
    .filter(ws => !userId || ws.members.has(userId))
    .map(workspaceForClient);
  res.json({ ok: true, workspaces });
});

app.get("/api/workspaces/:id", (req, res) => {
  const ws = WORKSPACES.get(req.params.id);
  if (!ws) return res.status(404).json({ ok: false, error: "Workspace not found" });
  res.json({ ok: true, workspace: workspaceForClient(ws) });
});

app.get("/api/workspaces/:id/dtus", (req, res) => {
  const result = getWorkspaceDTUs(req.params.id);
  res.json(result);
});

app.post("/api/workspaces/:id/dtus", (req, res) => {
  const result = addDTUToWorkspace(req.params.id, req.body.dtuId);
  res.json(result);
});

app.post("/api/workspaces/:id/members", (req, res) => {
  const result = addWorkspaceMember(req.params.id, req.body.userId, req.body.role);
  res.json(result);
});

// ---- Wave 4: Comments Endpoints ----
app.get("/api/dtus/:id/comments", (req, res) => {
  const result = getComments(req.params.id);
  res.json(result);
});

app.post("/api/dtus/:id/comments", (req, res) => {
  const userId = req.user?.id || "anonymous";
  const result = addComment(req.params.id, userId, req.body.content, req.body.parentId);
  res.json(result);
});

app.post("/api/comments/:id/resolve", (req, res) => {
  const result = resolveComment(req.params.id, req.body.resolved !== false);
  res.json(result);
});

app.post("/api/comments/:id/react", (req, res) => {
  const userId = req.user?.id || "anonymous";
  const result = addReaction(req.params.id, userId, req.body.emoji);
  res.json(result);
});

// ---- Wave 4: Share Links Endpoints ----
app.post("/api/dtus/:id/share", (req, res) => {
  const userId = req.user?.id || "anonymous";
  const result = createShareLink(req.params.id, userId, req.body);
  res.json(result);
});

// POST /api/dtus/:id/vote — up/down vote a DTU (forum)
app.post("/api/dtus/:id/vote", (req, res) => {
  try {
    const dtu = STATE.dtus?.get?.(req.params.id) || (Array.isArray(STATE.dtuList) ? STATE.dtuList.find(d => d.id === req.params.id) : null);
    if (!dtu) return res.status(404).json({ ok: false, error: "DTU not found" });
    const vote = Number(req.body?.vote) || 0;
    if (!dtu.meta) dtu.meta = {};
    dtu.meta.score = (dtu.meta.score || 0) + vote;
    dtu.meta.votes = (dtu.meta.votes || 0) + 1;
    res.json({ ok: true, score: dtu.meta.score, votes: dtu.meta.votes });
  } catch (e) {
    res.status(500).json({ ok: false, error: String(e?.message || e) });
  }
});

// POST /api/dtus/:id/like — like a DTU (feed/timeline)
app.post("/api/dtus/:id/like", (req, res) => {
  try {
    const dtu = STATE.dtus?.get?.(req.params.id) || (Array.isArray(STATE.dtuList) ? STATE.dtuList.find(d => d.id === req.params.id) : null);
    if (!dtu) return res.status(404).json({ ok: false, error: "DTU not found" });
    if (!dtu.meta) dtu.meta = {};
    dtu.meta.likes = (dtu.meta.likes || 0) + 1;
    res.json({ ok: true, likes: dtu.meta.likes });
  } catch (e) {
    res.status(500).json({ ok: false, error: String(e?.message || e) });
  }
});

app.get("/api/shared/:token", (req, res) => {
  const result = accessShareLink(req.params.token);
  if (!result.ok) return res.status(404).json(result);
  res.json(result);
});

// ---- Wave 4: Activity Log ----
app.get("/api/activity", (req, res) => {
  const result = getActivityLog({
    userId: req.query.userId,
    action: req.query.action,
    targetType: req.query.targetType,
    limit: Number(req.query.limit || 100),
    offset: Number(req.query.offset || 0)
  });
  res.json(result);
});

// ---- Wave 5: Frontend Config Endpoints ----
app.get("/api/config/themes", (req, res) => {
  res.json({ ok: true, themes: getAllThemes() });
});

app.get("/api/config/theme/:id", (req, res) => {
  res.json({ ok: true, theme: getTheme(req.params.id) });
});

app.get("/api/config/shortcuts", (req, res) => {
  const userId = req.user?.id;
  res.json({ ok: true, shortcuts: getShortcuts(userId) });
});

app.put("/api/config/shortcuts", (req, res) => {
  const userId = req.user?.id;
  if (!userId) return res.status(401).json({ ok: false, error: "Auth required" });
  const result = setUserShortcut(userId, req.body.key, req.body.action);
  res.json(result);
});

app.get("/api/manifest.json", (req, res) => {
  res.json(generatePWAManifest(req.query));
});

app.get("/api/sw-config", (req, res) => {
  res.json(generateServiceWorkerConfig());
});

app.get("/api/onboarding", (req, res) => {
  const userId = req.user?.id || req.query.userId || "anonymous";
  res.json(getOnboardingProgress(userId));
});

app.post("/api/onboarding/complete", (req, res) => {
  const userId = req.user?.id || req.body.userId || "anonymous";
  const result = completeOnboardingStep(userId, req.body.stepId);
  res.json(result);
});

// ---- Wave 6: Developer Endpoints ----
// Swagger UI HTML
const swaggerUIHtml = `<!DOCTYPE html>
<html>
<head>
  <title>Concord API Documentation</title>
  <link rel="stylesheet" href="https://unpkg.com/swagger-ui-dist@5/swagger-ui.css" />
  <style>
    body { margin: 0; padding: 0; }
    .swagger-ui .topbar { display: none; }
  </style>
</head>
<body>
  <div id="swagger-ui"></div>
  <script src="https://unpkg.com/swagger-ui-dist@5/swagger-ui-bundle.js"></script>
  <script>
    window.onload = () => {
      SwaggerUIBundle({
        url: '/api/docs/openapi.json',
        dom_id: '#swagger-ui',
        deepLinking: true,
        presets: [SwaggerUIBundle.presets.apis, SwaggerUIBundle.SwaggerUIStandalonePreset],
        layout: "BaseLayout"
      });
    };
  </script>
</body>
</html>`;

app.get("/api/docs", (req, res) => {
  // Serve Swagger UI
  res.type("text/html").send(swaggerUIHtml);
});

app.get("/api/docs/openapi.json", (req, res) => {
  // Try to load YAML spec, fall back to generated spec
  try {
    const yamlPath = path.join(process.cwd(), "openapi.yaml");
    if (fs.existsSync(yamlPath)) {
      const yaml = fs.readFileSync(yamlPath, "utf8");
      // Simple YAML to JSON conversion for basic spec
      res.type("application/x-yaml").send(yaml);
      return;
    }
  } catch {}
  res.json(generateOpenAPISpec());
});

app.get("/api/docs/openapi.yaml", (req, res) => {
  try {
    const yamlPath = path.join(process.cwd(), "openapi.yaml");
    if (fs.existsSync(yamlPath)) {
      res.type("application/x-yaml").sendFile(yamlPath);
      return;
    }
  } catch {}
  res.status(404).json({ ok: false, error: "OpenAPI spec not found" });
});

// GET/POST /api/plugins already registered above (lines ~17993-18001).

app.delete("/api/plugins/:id", requireRole("owner", "admin"), (req, res) => {
  const result = unregisterPlugin(req.params.id);
  res.json(result);
});

app.get("/api/cli/help", (req, res) => {
  res.type("text/plain").send(generateCLIHelp());
});

app.get("/api/cli/stats", (req, res) => {
  res.json({ ok: true, stats: getCLIStats() });
});

// ---- Wave 7: Timeline/Replay Endpoints ----
app.get("/api/timeline", (req, res) => {
  const result = getThoughtTimeline({
    dtuId: req.query.dtuId,
    action: req.query.action,
    since: req.query.since,
    until: req.query.until,
    limit: Number(req.query.limit || 100)
  });
  res.json(result);
});

app.get("/api/timeline/replay", (req, res) => {
  const result = replayThoughtsAt(req.query.timestamp || new Date().toISOString());
  res.json(result);
});

app.get("/api/timeline/diff", (req, res) => {
  const result = diffLattices(req.query.from, req.query.to);
  res.json(result);
});

// ---- Wave 7: Public Lattice Endpoints ----
app.post("/api/dtus/:id/publish", requireRole("owner", "admin", "editor"), (req, res) => {
  const result = publishDTU(req.params.id);
  res.json(result);
});

app.delete("/api/dtus/:id/publish", requireRole("owner", "admin", "editor"), (req, res) => {
  const result = unpublishDTU(req.params.id);
  res.json(result);
});

app.get("/api/public", (req, res) => {
  res.json(listPublicDTUs());
});

app.get("/api/public/:id", (req, res) => {
  const result = getPublicDTU(req.params.id);
  if (!result.ok) return res.status(404).json(result);
  res.json(result);
});

app.get("/api/public/feed.xml", (req, res) => {
  res.type("application/rss+xml").send(generatePublicFeed());
});

// ---- Wave 7: Debate/Steelman Endpoints ----
app.post("/api/dtus/:id/debate", async (req, res) => {
  const result = await debateThought(req.params.id, req.body);
  res.json(result);
});

app.post("/api/dtus/:id/steelman", async (req, res) => {
  const result = await steelmanThought(req.params.id);
  res.json(result);
});

console.log("[Concord] Wave 10: New Feature APIs loaded");

// ============================================================================
// WAVE 11: UX ENHANCEMENTS (Tables, Daily Notes, Kanban, Calendar Views)
// ============================================================================

// ---- Database/Tables System ----
const DATABASES = new Map(); // dbId -> { id, name, schema, rows, views, createdAt }

function createDatabase(name, schema = []) {
  const id = uid("db");
  const db = {
    id,
    name,
    schema: schema.map(col => ({
      id: uid("col"),
      name: col.name,
      type: col.type || "text", // text, number, select, multiselect, date, checkbox, url, relation
      options: col.options || [],
      required: col.required || false
    })),
    rows: [],
    views: [{ id: uid("view"), name: "Table", type: "table", filters: [], sorts: [] }],
    createdAt: nowISO(),
    updatedAt: nowISO()
  };
  DATABASES.set(id, db);
  return { ok: true, database: db };
}

function addDatabaseRow(dbId, data) {
  const db = DATABASES.get(dbId);
  if (!db) return { ok: false, error: "Database not found" };

  const row = {
    id: uid("row"),
    data: {},
    createdAt: nowISO(),
    updatedAt: nowISO()
  };

  // Validate and set data according to schema
  for (const col of db.schema) {
    if (data[col.name] !== undefined) {
      row.data[col.id] = data[col.name];
    } else if (col.required) {
      return { ok: false, error: `Missing required field: ${col.name}` };
    }
  }

  db.rows.push(row);
  db.updatedAt = nowISO();
  return { ok: true, row };
}

function queryDatabase(dbId, { filters = [], sorts = [], limit = 100, offset = 0 } = {}) {
  const db = DATABASES.get(dbId);
  if (!db) return { ok: false, error: "Database not found" };

  let results = [...db.rows];

  // Apply filters
  for (const filter of filters) {
    results = results.filter(row => {
      const value = row.data[filter.columnId];
      switch (filter.operator) {
        case "equals": return value === filter.value;
        case "contains": return String(value || "").includes(filter.value);
        case "gt": return Number(value) > Number(filter.value);
        case "lt": return Number(value) < Number(filter.value);
        case "isEmpty": return !value;
        case "isNotEmpty": return !!value;
        default: return true;
      }
    });
  }

  // Apply sorts
  for (const sort of sorts.reverse()) {
    results.sort((a, b) => {
      const aVal = a.data[sort.columnId] || "";
      const bVal = b.data[sort.columnId] || "";
      const cmp = String(aVal).localeCompare(String(bVal));
      return sort.direction === "desc" ? -cmp : cmp;
    });
  }

  return {
    ok: true,
    rows: results.slice(offset, offset + limit),
    total: results.length,
    schema: db.schema
  };
}

function addDatabaseView(dbId, view) {
  const db = DATABASES.get(dbId);
  if (!db) return { ok: false, error: "Database not found" };

  const newView = {
    id: uid("view"),
    name: view.name || "New View",
    type: view.type || "table", // table, kanban, calendar, gallery, list
    filters: view.filters || [],
    sorts: view.sorts || [],
    groupBy: view.groupBy || null,
    config: view.config || {}
  };

  db.views.push(newView);
  return { ok: true, view: newView };
}

// ---- Daily Notes ----
const DAILY_NOTES = new Map(); // dateStr -> dtuId

function getOrCreateDailyNote(dateStr = null) {
  const date = dateStr || new Date().toISOString().split("T")[0];

  if (DAILY_NOTES.has(date)) {
    const dtuId = DAILY_NOTES.get(date);
    const dtu = STATE.dtus.get(dtuId);
    if (dtu) return { ok: true, dtu, isNew: false };
  }

  // Create new daily note
  const dtu = {
    id: uid("dtu"),
    title: `Daily Note: ${date}`,
    content: `# ${date}\n\n## Morning\n\n## Afternoon\n\n## Evening\n\n## Reflections\n`,
    tags: ["daily", "journal", date.replace(/-/g, "")],
    tier: "regular",
    type: "daily_note",
    date,
    createdAt: nowISO(),
    updatedAt: nowISO()
  };

  upsertDTU(dtu, { broadcast: true });
  DAILY_NOTES.set(date, dtu.id);

  return { ok: true, dtu, isNew: true };
}

function listDailyNotes(limit = 30) {
  const notes = [];
  for (const [date, dtuId] of DAILY_NOTES) {
    const dtu = STATE.dtus.get(dtuId);
    if (dtu) notes.push({ date, dtu });
  }
  notes.sort((a, b) => b.date.localeCompare(a.date));
  return { ok: true, notes: notes.slice(0, limit) };
}

// ---- Calendar View Data ----
function getCalendarData(year, month) {
  const dtus = dtusArray().filter(d => {
    const created = new Date(d.createdAt);
    return created.getFullYear() === year && created.getMonth() === month - 1;
  });

  const byDay = {};
  for (const dtu of dtus) {
    const day = new Date(dtu.createdAt).getDate();
    if (!byDay[day]) byDay[day] = [];
    byDay[day].push({ id: dtu.id, title: dtu.title, tier: dtu.tier });
  }

  return { ok: true, year, month, days: byDay, total: dtus.length };
}

// ---- Kanban View ----
function getKanbanData(groupField = "tier") {
  const dtus = dtusArray();
  const columns = {};

  for (const dtu of dtus) {
    let group;
    if (groupField === "tier") {
      group = dtu.tier || "regular";
    } else if (groupField === "tag") {
      group = (dtu.tags || [])[0] || "untagged";
    } else {
      group = dtu[groupField] || "other";
    }

    if (!columns[group]) columns[group] = [];
    columns[group].push({
      id: dtu.id,
      title: dtu.title,
      tags: dtu.tags?.slice(0, 3),
      updatedAt: dtu.updatedAt
    });
  }

  return { ok: true, groupField, columns };
}

// ---- Inline Embeds ----
const EMBED_PATTERNS = {
  youtube: /(?:youtube\.com\/watch\?v=|youtu\.be\/)([a-zA-Z0-9_-]{11})/,
  twitter: /twitter\.com\/\w+\/status\/(\d+)/,
  vimeo: /vimeo\.com\/(\d+)/,
  codepen: /codepen\.io\/([^/]+)\/pen\/([^/]+)/,
  figma: /figma\.com\/file\/([^/]+)/,
  loom: /loom\.com\/share\/([a-zA-Z0-9]+)/,
  spotify: /open\.spotify\.com\/(track|album|playlist)\/([a-zA-Z0-9]+)/
};

function parseEmbed(url) {
  for (const [type, pattern] of Object.entries(EMBED_PATTERNS)) {
    const match = url.match(pattern);
    if (match) {
      return { ok: true, type, id: match[1], secondaryId: match[2] || null, url };
    }
  }
  return { ok: false, error: "Unsupported embed URL" };
}

function generateEmbedHtml(embed) {
  switch (embed.type) {
    case "youtube":
      return `<iframe src="https://www.youtube.com/embed/${embed.id}" frameborder="0" allowfullscreen></iframe>`;
    case "twitter":
      return `<blockquote class="twitter-tweet"><a href="${embed.url}"></a></blockquote>`;
    case "vimeo":
      return `<iframe src="https://player.vimeo.com/video/${embed.id}" frameborder="0" allowfullscreen></iframe>`;
    case "codepen":
      return `<iframe src="https://codepen.io/${embed.id}/embed/${embed.secondaryId}" frameborder="0"></iframe>`;
    case "figma":
      return `<iframe src="https://www.figma.com/embed?embed_host=concord&url=${encodeURIComponent(embed.url)}" frameborder="0"></iframe>`;
    case "loom":
      return `<iframe src="https://www.loom.com/embed/${embed.id}" frameborder="0" allowfullscreen></iframe>`;
    case "spotify":
      return `<iframe src="https://open.spotify.com/embed/${embed.secondaryId}/${embed.id}" frameborder="0"></iframe>`;
    default:
      return null;
  }
}

// ============================================================================
// WAVE 12: AI DEPTH (Voice, Vision, Digest, Completions, Auto-tag)
// ============================================================================

// ---- Voice Notes ----
function processVoiceNote(audioBuffer, options = {}) {
  // Use local Whisper if available
  const WHISPER_BIN = process.env.WHISPER_CPP_BIN || process.env.WHISPER_BIN;

  if (!WHISPER_BIN) {
    return { ok: false, error: "Whisper not configured. Set WHISPER_CPP_BIN env var." };
  }

  try {
    // Save audio to temp file
    const tempPath = path.join(DATA_DIR, `temp_audio_${Date.now()}.wav`);
    fs.writeFileSync(tempPath, audioBuffer);

    // Run Whisper
    const result = spawnSync(WHISPER_BIN, ["-f", tempPath, "-otxt"], {
      timeout: 60000,
      maxBuffer: 10 * 1024 * 1024
    });

    // Clean up
    try { fs.unlinkSync(tempPath); } catch {}
    try { fs.unlinkSync(tempPath + ".txt"); } catch {}

    const transcript = result.stdout?.toString() || "";

    if (!transcript.trim()) {
      return { ok: false, error: "No speech detected" };
    }

    // Optionally create DTU from transcript
    if (options.createDTU) {
      const title = transcript.slice(0, 100).replace(/\n/g, " ").trim() + (transcript.length > 100 ? "..." : "");
      const dtu = {
        id: uid("dtu"),
        title,
        content: transcript,
        tags: ["voice-note", "transcript"],
        tier: "regular",
        type: "voice_note",
        createdAt: nowISO(),
        updatedAt: nowISO()
      };
      upsertDTU(dtu);
      return { ok: true, transcript, dtu };
    }

    return { ok: true, transcript };
  } catch (e) {
    return { ok: false, error: String(e.message || e) };
  }
}

// ---- Image Analysis ----
async function analyzeImage(imageBuffer, prompt = "Describe this image in detail.") {
  // Use local LLaVA via Ollama if available
  const OLLAMA_URL = process.env.OLLAMA_URL || "http://localhost:11434";
  const VISION_MODEL = process.env.VISION_MODEL || "llava";

  try {
    const base64 = imageBuffer.toString("base64");

    const response = await fetch(`${OLLAMA_URL}/api/generate`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        model: VISION_MODEL,
        prompt,
        images: [base64],
        stream: false
      })
    });

    if (!response.ok) {
      return { ok: false, error: `Ollama error: ${response.status}` };
    }

    const data = await response.json();
    return { ok: true, description: data.response, model: VISION_MODEL };
  } catch (e) {
    return { ok: false, error: String(e.message || e) };
  }
}

// ---- Daily Digest ----
async function generateDailyDigest(date = null) {
  const targetDate = date || new Date().toISOString().split("T")[0];
  const dayStart = new Date(targetDate + "T00:00:00Z").toISOString();
  const dayEnd = new Date(targetDate + "T23:59:59Z").toISOString();

  // Get DTUs created/updated today
  const todaysDTUs = dtusArray().filter(d =>
    (d.createdAt >= dayStart && d.createdAt <= dayEnd) ||
    (d.updatedAt >= dayStart && d.updatedAt <= dayEnd)
  );

  const created = todaysDTUs.filter(d => d.createdAt >= dayStart && d.createdAt <= dayEnd);
  const updated = todaysDTUs.filter(d => d.updatedAt >= dayStart && d.updatedAt <= dayEnd && d.createdAt < dayStart);

  // Tag frequency
  const tagCounts = {};
  for (const dtu of todaysDTUs) {
    for (const tag of (dtu.tags || [])) {
      tagCounts[tag] = (tagCounts[tag] || 0) + 1;
    }
  }

  const topTags = Object.entries(tagCounts)
    .sort((a, b) => b[1] - a[1])
    .slice(0, 5)
    .map(([tag, count]) => ({ tag, count }));

  const digest = {
    date: targetDate,
    summary: {
      created: created.length,
      updated: updated.length,
      total: todaysDTUs.length
    },
    highlights: created.slice(0, 5).map(d => ({ id: d.id, title: d.title, tier: d.tier })),
    topTags,
    generatedAt: nowISO()
  };

  // Generate narrative if LLM available
  if (LLM_READY && todaysDTUs.length > 0) {
    const titles = todaysDTUs.slice(0, 10).map(d => d.title).join(", ");
    const prompt = `Write a brief (2-3 sentence) summary of today's knowledge work. Topics covered: ${titles}. Be encouraging and insightful.`;

    try {
      const response = await llmChat([{ role: "user", content: prompt }], {
        model: OPENAI_MODEL_FAST,
        max_tokens: 150
      });
      digest.narrative = response?.choices?.[0]?.message?.content || null;
    } catch {}
  }

  return { ok: true, digest };
}

// ---- Inline AI Completions ----
async function getInlineCompletion(text, cursorPosition, context = {}) {
  if (!LLM_READY) {
    return { ok: false, error: "LLM not available" };
  }

  const beforeCursor = text.slice(0, cursorPosition);
  const afterCursor = text.slice(cursorPosition);

  const prompt = `Continue this text naturally. Only output the completion, nothing else.

Context: ${context.title || "Note"}
Text before cursor: "${beforeCursor}"
Text after cursor: "${afterCursor}"

Completion:`;

  try {
    const response = await llmChat([{ role: "user", content: prompt }], {
      model: OPENAI_MODEL_FAST,
      temperature: 0.7,
      max_tokens: 100,
      stop: ["\n\n", ".", "!", "?"]
    });

    const completion = response?.choices?.[0]?.message?.content?.trim() || "";
    return { ok: true, completion };
  } catch (e) {
    return { ok: false, error: String(e.message || e) };
  }
}

// ---- Auto-Tagging ----
async function suggestTags(content, existingTags = []) {
  // Simple keyword extraction fallback
  const words = content.toLowerCase().split(/\W+/).filter(w => w.length > 4);
  const wordCounts = {};
  for (const word of words) {
    if (!["which", "there", "their", "about", "would", "could", "should"].includes(word)) {
      wordCounts[word] = (wordCounts[word] || 0) + 1;
    }
  }

  const keywords = Object.entries(wordCounts)
    .sort((a, b) => b[1] - a[1])
    .slice(0, 5)
    .map(([word]) => word)
    .filter(w => !existingTags.includes(w));

  if (!LLM_READY) {
    return { ok: true, tags: keywords, method: "keyword" };
  }

  // Use LLM for better tags
  const prompt = `Suggest 3-5 relevant tags for this content. Output only comma-separated tags, nothing else.

Content: ${content.slice(0, 1000)}

Existing tags: ${existingTags.join(", ")}

New tags:`;

  try {
    const response = await llmChat([{ role: "user", content: prompt }], {
      model: OPENAI_MODEL_FAST,
      temperature: 0.3,
      max_tokens: 50
    });

    const tagStr = response?.choices?.[0]?.message?.content || "";
    const tags = tagStr.split(",").map(t => t.trim().toLowerCase().replace(/[^a-z0-9-]/g, "")).filter(Boolean);

    return { ok: true, tags: tags.filter(t => !existingTags.includes(t)), method: "llm" };
  } catch {
    return { ok: true, tags: keywords, method: "keyword_fallback" };
  }
}

// ============================================================================
// WAVE 13: CAPTURE & INTEGRATIONS (Email, RSS, Reminders)
// ============================================================================

// ---- Email-to-DTU ----
function processEmailToDTU(email) {
  const { from, subject, body, date, attachments = [] } = email;

  const dtu = {
    id: uid("dtu"),
    title: subject || "Email Note",
    content: `**From:** ${from}\n**Date:** ${date}\n\n---\n\n${body}`,
    tags: ["email", "inbox"],
    tier: "regular",
    type: "email",
    source: "email",
    meta: {
      from,
      subject,
      date,
      hasAttachments: attachments.length > 0
    },
    createdAt: nowISO(),
    updatedAt: nowISO()
  };

  upsertDTU(dtu);
  return { ok: true, dtu };
}

// ---- RSS Feed Ingestion ----
const RSS_FEEDS = new Map(); // feedId -> { id, url, name, lastFetch, items }

function addRSSFeed(url, name = null) {
  const id = uid("feed");
  RSS_FEEDS.set(id, {
    id,
    url,
    name: name || url,
    lastFetch: null,
    itemsSeen: new Set(),
    createdAt: nowISO()
  });
  return { ok: true, feedId: id };
}

async function fetchRSSFeed(feedId) {
  const feed = RSS_FEEDS.get(feedId);
  if (!feed) return { ok: false, error: "Feed not found" };

  try {
    const response = await fetch(feed.url);
    const text = await response.text();

    // Simple RSS parsing (basic implementation)
    const items = [];
    const itemMatches = text.matchAll(/<item>([\s\S]*?)<\/item>/g);

    for (const match of itemMatches) {
      const itemXml = match[1];
      const title = itemXml.match(/<title>(?:<!\[CDATA\[)?([\s\S]*?)(?:\]\]>)?<\/title>/)?.[1] || "";
      const link = itemXml.match(/<link>([\s\S]*?)<\/link>/)?.[1] || "";
      const description = itemXml.match(/<description>(?:<!\[CDATA\[)?([\s\S]*?)(?:\]\]>)?<\/description>/)?.[1] || "";
      const pubDate = itemXml.match(/<pubDate>([\s\S]*?)<\/pubDate>/)?.[1] || "";

      const itemId = link || title;
      if (itemId && !feed.itemsSeen.has(itemId)) {
        items.push({ title: title.trim(), link: link.trim(), description: description.trim(), pubDate });
        feed.itemsSeen.add(itemId);
      }
    }

    feed.lastFetch = nowISO();
    return { ok: true, items, feedName: feed.name };
  } catch (e) {
    return { ok: false, error: String(e.message || e) };
  }
}

function createDTUFromRSSItem(item, feedName) {
  const dtu = {
    id: uid("dtu"),
    title: item.title || "RSS Item",
    content: `**Source:** ${feedName}\n**Link:** ${item.link}\n\n---\n\n${item.description}`,
    tags: ["rss", "reading", feedName.toLowerCase().replace(/\s+/g, "-")],
    tier: "regular",
    type: "rss_item",
    source: "rss",
    meta: {
      link: item.link,
      pubDate: item.pubDate,
      feedName
    },
    createdAt: nowISO(),
    updatedAt: nowISO()
  };

  upsertDTU(dtu);
  return { ok: true, dtu };
}

// ---- Reminders ----
const REMINDERS = new Map(); // reminderId -> { id, dtuId, reminderAt, message, completed }
const REMINDERS_MAX = 1000;
const REMINDERS_TTL_DAYS = 30;

// Cleanup old completed reminders
function cleanupReminders() {
  const now = Date.now();
  const ttlMs = REMINDERS_TTL_DAYS * 24 * 60 * 60 * 1000;
  let cleaned = 0;

  for (const [id, rem] of REMINDERS) {
    if (rem.completed) {
      const createdAt = new Date(rem.createdAt || 0).getTime();
      if (now - createdAt > ttlMs) {
        REMINDERS.delete(id);
        cleaned++;
      }
    }
  }

  // If still too many, remove oldest completed
  if (REMINDERS.size > REMINDERS_MAX) {
    const sorted = Array.from(REMINDERS.entries())
      .filter(([, r]) => r.completed)
      .sort((a, b) => (a[1].createdAt || "").localeCompare(b[1].createdAt || ""));
    for (const [id] of sorted.slice(0, REMINDERS.size - REMINDERS_MAX)) {
      REMINDERS.delete(id);
      cleaned++;
    }
  }

  if (cleaned > 0) console.log(`[Reminders] Cleaned ${cleaned} old reminders`);
}

// Run cleanup every 6 hours
setInterval(cleanupReminders, 6 * 60 * 60 * 1000);

function createReminder(dtuId, reminderAt, message = null) {
  const dtu = STATE.dtus.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };

  const id = uid("rem");
  REMINDERS.set(id, {
    id,
    dtuId,
    dtuTitle: dtu.title,
    reminderAt,
    message: message || `Review: ${dtu.title}`,
    completed: false,
    createdAt: nowISO()
  });

  return { ok: true, reminderId: id };
}

function getDueReminders() {
  const now = nowISO();
  const due = [];

  for (const [, reminder] of REMINDERS) {
    if (!reminder.completed && reminder.reminderAt <= now) {
      due.push(reminder);
    }
  }

  return { ok: true, reminders: due };
}

function completeReminder(reminderId) {
  const reminder = REMINDERS.get(reminderId);
  if (!reminder) return { ok: false, error: "Reminder not found" };
  reminder.completed = true;
  return { ok: true };
}

// ============================================================================
// WAVE 14: ENTERPRISE (SSO, Audit, Admin, Teams)
// ============================================================================

// Note: Audit logging is defined earlier in this file via AuditDB

// ---- Admin Dashboard Stats ----
function getAdminStats() {
  const now = new Date();
  const dayAgo = new Date(now - 24 * 60 * 60 * 1000).toISOString();
  const weekAgo = new Date(now - 7 * 24 * 60 * 60 * 1000).toISOString();

  const dtus = dtusArray();
  const recentDTUs = dtus.filter(d => d.createdAt >= dayAgo);
  const weekDTUs = dtus.filter(d => d.createdAt >= weekAgo);

  return {
    ok: true,
    stats: {
      totalDTUs: dtus.length,
      totalUsers: AUTH.users.size,
      totalWorkspaces: WORKSPACES.size,
      totalSessions: STATE.sessions.size,
      dtusTodayCreated: recentDTUs.length,
      dtusThisWeek: weekDTUs.length,
      tierBreakdown: {
        regular: dtus.filter(d => d.tier === "regular").length,
        mega: dtus.filter(d => d.tier === "mega").length,
        hyper: dtus.filter(d => d.tier === "hyper").length
      },
      storageUsed: JSON.stringify(STATE).length,
      auditLogSize: AUDIT_LOG.length,
      activeFeatures: {
        auth: AUTH_MODE !== "public",
        authMode: AUTH_MODE,
        embeddings: EMBEDDINGS.enabled,
        federation: _c3Federation.enabled,
        websockets: REALTIME.ready
      }
    },
    generatedAt: nowISO()
  };
}

// ---- Team Templates — backed by STATE for persistence ----
function ensureTeamTemplates() {
  if (!STATE.teamTemplates) STATE.teamTemplates = new Map();
  return STATE.teamTemplates;
}

function createTeamTemplate(workspaceId, template, createdBy) {
  const templates = ensureTeamTemplates();
  const id = uid("tmpl");
  templates.set(id, {
    id,
    name: template.name,
    description: template.description || "",
    content: template.content || "",
    tags: template.tags || [],
    workspaceId,
    createdBy,
    createdAt: nowISO(),
    updatedAt: nowISO(),
  });
  return { ok: true, templateId: id };
}

function updateTeamTemplate(templateId, updates) {
  const templates = ensureTeamTemplates();
  const tmpl = templates.get(templateId);
  if (!tmpl) return { ok: false, error: "not_found" };
  if (updates.name) tmpl.name = updates.name;
  if (updates.description !== undefined) tmpl.description = updates.description;
  if (updates.content !== undefined) tmpl.content = updates.content;
  if (updates.tags) tmpl.tags = updates.tags;
  tmpl.updatedAt = nowISO();
  return { ok: true, template: tmpl };
}

function deleteTeamTemplate(templateId) {
  const templates = ensureTeamTemplates();
  if (!templates.has(templateId)) return { ok: false, error: "not_found" };
  templates.delete(templateId);
  return { ok: true };
}

function getWorkspaceTemplates(workspaceId) {
  const templates = ensureTeamTemplates();
  const result = [];
  for (const [, tmpl] of templates) {
    if (tmpl.workspaceId === workspaceId) {
      result.push(tmpl);
    }
  }
  return { ok: true, templates: result };
}

// ---- SSO Placeholder (would need passport.js for full implementation) ----
const SSO_CONFIG = {
  enabled: false,
  providers: [] // { type: 'saml'|'oidc', name, config }
};

function configureSSOProvider(provider) {
  SSO_CONFIG.providers.push({
    id: uid("sso"),
    type: provider.type,
    name: provider.name,
    config: provider.config,
    enabled: true,
    createdAt: nowISO()
  });
  SSO_CONFIG.enabled = true;
  return { ok: true, message: "SSO provider configured. Requires server restart for full activation." };
}

// ============================================================================
// WAVE 15: ECOSYSTEM (CLI, SDK helpers, Marketplace, Zapier)
// ============================================================================

// ---- CLI Commands (exposed via API) ----
const CLI_COMMANDS = {
  "search": (args) => {
    const query = args.join(" ");
    if (EMBEDDINGS.enabled) {
      return semanticSearch(query, { limit: 10 });
    }
    return { ok: true, results: dtusArray().filter(d =>
      d.title.toLowerCase().includes(query.toLowerCase())
    ).slice(0, 10) };
  },
  "add": (args) => {
    const title = args.join(" ");
    if (!title) return { ok: false, error: "Usage: add <title>" };
    const dtu = {
      id: uid("dtu"),
      title,
      content: "",
      tags: [],
      tier: "regular",
      createdAt: nowISO(),
      updatedAt: nowISO()
    };
    upsertDTU(dtu);
    return { ok: true, dtu };
  },
  "list": (args) => {
    const limit = parseInt(args[0], 10) || 10;
    return { ok: true, dtus: dtusArray().slice(0, limit).map(d => ({ id: d.id, title: d.title })) };
  },
  "stats": () => {
    return { ok: true, stats: getCLIStats() };
  },
  "backup": () => {
    return createBackup();
  },
  "export": (args) => {
    const format = args[0] || "json";
    if (format === "markdown") return exportDTUsToMarkdown();
    return exportDTUsToJSON();
  },
  "tag": (args) => {
    const [id, ...tags] = args;
    const dtu = STATE.dtus.get(id);
    if (!dtu) return { ok: false, error: "DTU not found" };
    dtu.tags = [...new Set([...(dtu.tags || []), ...tags])];
    upsertDTU(dtu);
    return { ok: true, tags: dtu.tags };
  }
};

function executeCLICommand(commandLine) {
  const parts = commandLine.trim().split(/\s+/);
  const [command, ...args] = parts;

  if (!CLI_COMMANDS[command]) {
    return { ok: false, error: `Unknown command: ${command}`, available: Object.keys(CLI_COMMANDS) };
  }

  return CLI_COMMANDS[command](args);
}

// ---- SDK Helper Endpoints ----
function generateSDKTypes() {
  return `
// Concord TypeScript SDK Types

export interface DTU {
  id: string;
  title: string;
  content?: string;
  creti?: string;
  tags: string[];
  tier: 'regular' | 'mega' | 'hyper';
  createdAt: string;
  updatedAt: string;
  connections?: Connection[];
  lineage?: string[];
}

export interface Connection {
  targetId: string;
  type: 'supports' | 'contradicts' | 'extends' | 'related';
  strength: number;
}

export interface Workspace {
  id: string;
  name: string;
  description: string;
  ownerId: string;
  members: WorkspaceMember[];
  settings: WorkspaceSettings;
}

export interface WorkspaceMember {
  userId: string;
  role: 'owner' | 'admin' | 'editor' | 'viewer';
  joinedAt: string;
}

export interface SearchResult {
  dtu: DTU;
  score: number;
  method: 'semantic' | 'keyword';
}

export interface ConcordClient {
  dtus: {
    list(options?: { limit?: number; offset?: number; q?: string }): Promise<DTU[]>;
    get(id: string): Promise<DTU>;
    create(data: Partial<DTU>): Promise<DTU>;
    update(id: string, data: Partial<DTU>): Promise<DTU>;
    delete(id: string): Promise<void>;
  };
  search: {
    query(q: string, options?: { semantic?: boolean }): Promise<SearchResult[]>;
  };
  ai: {
    chat(message: string): Promise<{ response: string; context: DTU[] }>;
    suggest(dtuId: string): Promise<{ suggestions: DTU[] }>;
  };
}
`.trim();
}

// ---- Webhook/Zapier Integration ----
const WEBHOOK_SUBSCRIPTIONS = new Map(); // id -> { url, events, secret, active }

function registerWebhook(url, events = ["dtu:created", "dtu:updated"]) {
  const id = uid("wh");
  const secret = crypto.randomBytes(32).toString("hex");

  WEBHOOK_SUBSCRIPTIONS.set(id, {
    id,
    url,
    events,
    secret,
    active: true,
    createdAt: nowISO(),
    lastTriggered: null,
    failCount: 0
  });

  return { ok: true, webhookId: id, secret };
}

async function _triggerWebhooks(event, payload) {
  for (const [, webhook] of WEBHOOK_SUBSCRIPTIONS) {
    if (!webhook.active || !webhook.events.includes(event)) continue;

    try {
      const signature = crypto
        .createHmac("sha256", webhook.secret)
        .update(JSON.stringify(payload))
        .digest("hex");

      await fetch(webhook.url, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "X-Concord-Signature": signature,
          "X-Concord-Event": event
        },
        body: JSON.stringify({ event, payload, timestamp: nowISO() })
      });

      webhook.lastTriggered = nowISO();
      webhook.failCount = 0;
    } catch {
      webhook.failCount++;
      if (webhook.failCount >= 5) {
        webhook.active = false;
      }
    }
  }
}

// ---- Theme Marketplace (metadata) ----
const THEME_MARKETPLACE = [
  { id: "dark", name: "Dark", author: "Concord", downloads: 0, builtin: true },
  { id: "light", name: "Light", author: "Concord", downloads: 0, builtin: true },
  { id: "nord", name: "Nord", author: "Concord", downloads: 0, builtin: true },
  { id: "dracula", name: "Dracula", author: "Community", downloads: 0, colors: {
    bg: "#282a36", surface: "#44475a", border: "#6272a4", text: "#f8f8f2",
    textMuted: "#6272a4", primary: "#bd93f9", secondary: "#ff79c6",
    success: "#50fa7b", warning: "#f1fa8c", danger: "#ff5555"
  }},
  { id: "solarized-dark", name: "Solarized Dark", author: "Community", downloads: 0, colors: {
    bg: "#002b36", surface: "#073642", border: "#586e75", text: "#839496",
    textMuted: "#586e75", primary: "#268bd2", secondary: "#d33682",
    success: "#859900", warning: "#b58900", danger: "#dc322f"
  }},
  { id: "github-dark", name: "GitHub Dark", author: "Community", downloads: 0, colors: {
    bg: "#0d1117", surface: "#161b22", border: "#30363d", text: "#c9d1d9",
    textMuted: "#8b949e", primary: "#58a6ff", secondary: "#bc8cff",
    success: "#3fb950", warning: "#d29922", danger: "#f85149"
  }}
];

function getMarketplaceThemes() {
  return { ok: true, themes: THEME_MARKETPLACE };
}

function installTheme(themeId) {
  const theme = THEME_MARKETPLACE.find(t => t.id === themeId);
  if (!theme) return { ok: false, error: "Theme not found" };
  theme.downloads++;
  return { ok: true, theme };
}

// ============================================================================
// WAVE 11-15: NEW API ENDPOINTS
// ============================================================================

// ---- Wave 11: UX Endpoints ----
// Database endpoints require authentication
app.post("/api/databases", requireAuth(), (req, res) => {
  const result = createDatabase(req.body.name, req.body.schema || []);
  res.json(result);
});

app.get("/api/databases/:id", requireAuth(), (req, res) => {
  const db = DATABASES.get(req.params.id);
  if (!db) return res.status(404).json({ ok: false, error: "Database not found" });
  res.json({ ok: true, database: db });
});

app.post("/api/databases/:id/rows", requireAuth(), (req, res) => {
  const result = addDatabaseRow(req.params.id, req.body);
  res.json(result);
});

app.get("/api/databases/:id/query", requireAuth(), (req, res) => {
  const result = queryDatabase(req.params.id, req.query);
  res.json(result);
});

app.post("/api/databases/:id/views", requireAuth(), (req, res) => {
  const result = addDatabaseView(req.params.id, req.body);
  res.json(result);
});

app.get("/api/daily", (req, res) => {
  const result = getOrCreateDailyNote(req.query.date);
  res.json(result);
});

app.get("/api/daily/list", (req, res) => {
  const result = listDailyNotes(Number(req.query.limit || 30));
  res.json(result);
});

app.get("/api/views/calendar", (req, res) => {
  const year = Number(req.query.year || new Date().getFullYear());
  const month = Number(req.query.month || new Date().getMonth() + 1);
  res.json(getCalendarData(year, month));
});

app.get("/api/views/kanban", (req, res) => {
  res.json(getKanbanData(req.query.groupBy || "tier"));
});

app.post("/api/embed/parse", (req, res) => {
  const result = parseEmbed(req.body.url);
  if (result.ok) {
    result.html = generateEmbedHtml(result);
  }
  res.json(result);
});

// ---- Wave 12: AI Depth Endpoints ----
// POST /api/voice/transcribe already registered above (line ~16867) via macro.
// Raw audio uploads: use /api/voice/transcribe-raw instead for binary audio data.
app.post("/api/voice/transcribe-raw", express.raw({ type: "audio/*", limit: "50mb" }), async (req, res) => {
  const result = await processVoiceNote(req.body, { createDTU: req.query.createDTU === "1" });
  res.json(result);
});

app.post("/api/vision/analyze", express.raw({ type: "image/*", limit: "20mb" }), async (req, res) => {
  const result = await analyzeImage(req.body, req.query.prompt);
  res.json(result);
});

app.get("/api/digest", async (req, res) => {
  const result = await generateDailyDigest(req.query.date);
  res.json(result);
});

// POST /api/digest — frontend daily lens triggers digest generation via POST
app.post("/api/digest", async (req, res) => {
  const result = await generateDailyDigest(req.body?.date || null);
  res.json(result);
});

app.post("/api/ai/complete", async (req, res) => {
  const result = await getInlineCompletion(req.body.text, Number(req.body.cursorPosition), req.body.context);
  res.json(result);
});

app.post("/api/ai/auto-tag", async (req, res) => {
  const result = await suggestTags(req.body.content, req.body.existingTags || []);
  res.json(result);
});

// ---- Wave 13: Capture Endpoints ----
app.post("/api/capture/email", (req, res) => {
  const result = processEmailToDTU(req.body);
  res.json(result);
});

app.post("/api/feeds", async (req, res) => {
  const result = await addRSSFeed(req.body.url, req.body.name);
  res.json(result);
});

app.get("/api/feeds", (req, res) => {
  const feeds = Array.from(RSS_FEEDS.values());
  res.json({ ok: true, feeds });
});

app.post("/api/feeds/:id/fetch", async (req, res) => {
  const result = await fetchRSSFeed(req.params.id);
  res.json(result);
});

app.post("/api/feeds/:id/import", async (req, res) => {
  const fetchResult = await fetchRSSFeed(req.params.id);
  if (!fetchResult.ok) return res.json(fetchResult);

  const imported = [];
  for (const item of fetchResult.items.slice(0, Number(req.query.limit || 10))) {
    const dtuResult = createDTUFromRSSItem(item, fetchResult.feedName);
    if (dtuResult.ok) imported.push(dtuResult.dtu.id);
  }

  res.json({ ok: true, imported, count: imported.length });
});

app.post("/api/reminders", (req, res) => {
  const result = createReminder(req.body.dtuId, req.body.reminderAt, req.body.message);
  res.json(result);
});

app.get("/api/reminders/due", (req, res) => {
  res.json(getDueReminders());
});

app.post("/api/reminders/:id/complete", (req, res) => {
  res.json(completeReminder(req.params.id));
});

// ---- Wave 14: Enterprise Endpoints ----
app.get("/api/admin/stats", requireRole("owner", "admin"), (req, res) => {
  res.json(getAdminStats());
});

// Proxy /api/admin/audit to the real audit-log implementation at /api/auth/audit-log
app.get("/api/admin/audit", requireRole("owner", "admin"), (req, res) => {
  const { limit = 100, offset = 0, category, action, userId, startDate, endDate } = req.query;
  const logs = AuditDB.query({
    limit: Number(limit), offset: Number(offset),
    category, action, userId, startDate, endDate
  });
  const total = AuditDB.count({ category, userId });
  res.json({ ok: true, total, offset: Number(offset), limit: Number(limit), entries: logs });
});

app.post("/api/admin/sso", requireRole("owner"), (req, res) => {
  res.json(configureSSOProvider(req.body));
});

app.post("/api/workspaces/:id/templates", (req, res) => {
  const userId = req.user?.id || "anonymous";
  const result = createTeamTemplate(req.params.id, req.body, userId);
  res.json(result);
});

app.get("/api/workspaces/:id/templates", (req, res) => {
  res.json(getWorkspaceTemplates(req.params.id));
});

app.put("/api/workspaces/:id/templates/:templateId", (req, res) => {
  res.json(updateTeamTemplate(req.params.templateId, req.body));
});

app.delete("/api/workspaces/:id/templates/:templateId", (req, res) => {
  res.json(deleteTeamTemplate(req.params.templateId));
});

// ---- Wave 15: Ecosystem Endpoints ----
app.post("/api/cli", async (req, res) => {
  const result = await executeCLICommand(req.body.command);
  res.json(result);
});

app.get("/api/sdk/types", (req, res) => {
  res.type("text/typescript").send(generateSDKTypes());
});

app.post("/api/webhooks/register", (req, res) => {
  const result = registerWebhook(req.body.url, req.body.events);
  res.json(result);
});

// GET /api/webhooks already registered above (line ~21631) via macro.
// DELETE /api/webhooks/:id already registered above (line ~21632) via macro.

app.get("/api/themes/marketplace", (req, res) => {
  res.json(getMarketplaceThemes());
});

app.post("/api/themes/:id/install", (req, res) => {
  res.json(installTheme(req.params.id));
});

console.log("[Concord] Waves 11-15: All enhancement APIs loaded");

// ============================================================================
// END CONCORD ENHANCEMENTS v6.0 - ALL WAVES COMPLETE
// ============================================================================

// ============================================================================
// WAVE 16: MISSING ENDPOINTS FOR FRONTEND LENSES
// ============================================================================

// Entity Management
const ENTITIES = new Map();
app.get("/api/entities", (req, res) => {
  const entities = Array.from(ENTITIES.values());
  res.json({ ok: true, entities });
});

app.post("/api/entities", (req, res) => {
  const { name, type = "worker" } = req.body;
  const id = uid("entity");
  const entity = {
    id,
    name: name || `Entity ${id}`,
    type,
    status: "active",
    workspace: "main",
    forks: 0,
    createdAt: nowISO(),
    lastActive: nowISO()
  };
  ENTITIES.set(id, entity);
  res.json({ ok: true, entity });
});

app.get("/api/entities/:id", (req, res) => {
  const entity = ENTITIES.get(req.params.id);
  if (!entity) return res.status(404).json({ ok: false, error: "Entity not found" });
  res.json({ ok: true, entity });
});

app.post("/api/entities/:id/fork", (req, res) => {
  const parent = ENTITIES.get(req.params.id);
  if (!parent) return res.status(404).json({ ok: false, error: "Entity not found" });
  const id = uid("entity");
  const fork = { ...parent, id, name: `${parent.name} (Fork)`, forks: 0, createdAt: nowISO() };
  ENTITIES.set(id, fork);
  parent.forks++;
  res.json({ ok: true, entity: fork });
});

// Personal Library - user's DTUs and artifacts
app.get("/api/library", (req, res) => {
  const sessionId = req.headers["x-session-id"] || "default";
  // Get DTUs created in this session or marked as owned
  const owned = dtusArray().filter(d =>
    d.source === "quick-capture" ||
    d.source === "manual" ||
    d.meta?.sessionId === sessionId ||
    d.meta?.owned === true
  ).slice(-100);
  // Get entitlements (purchased DTUs)
  const entitlements = Array.from(STATE.entitlements.values())
    .filter(e => e.sessionId === sessionId || !e.sessionId)
    .slice(-50);
  res.json({ ok: true, owned, entitlements, total: owned.length + entitlements.length });
});

// Tags endpoint
app.get("/api/tags", (req, res) => {
  const tagCounts = new Map();
  for (const d of dtusArray()) {
    for (const t of (d.tags || [])) {
      tagCounts.set(t, (tagCounts.get(t) || 0) + 1);
    }
  }
  const tags = Array.from(tagCounts.entries())
    .map(([tag, count]) => ({ tag, count }))
    .sort((a, b) => b.count - a.count)
    .slice(0, 200);
  res.json({ ok: true, tags });
});

// State sessions
app.get("/api/state/sessions", (req, res) => {
  const sessions = Array.from(STATE.sessions.entries()).map(([id, s]) => ({
    sessionId: id,
    messageCount: s.messages?.length || 0,
    createdAt: s.createdAt
  }));
  res.json({ ok: true, sessions });
});

// Simulations (alias for worldmodel)
app.get("/api/simulations", (req, res) => {
  res.json({ ok: true, simulations: [], note: "Use /api/worldmodel/simulations" });
});

app.post("/api/simulations/whatif", async (req, res) => {
  try {
    const out = await runMacro("sim", "whatif", req.body || {}, makeCtx(req));
    res.json(out);
  } catch (e) {
    res.json({ ok: false, error: String(e?.message || e) });
  }
});

// News - sourced from DTUs tagged as news/article
app.get("/api/news", (req, res) => {
  const limit = clamp(Number(req.query.limit || 20), 1, 100);
  const articles = dtusArray()
    .filter(d => !isShadowDTU(d) && d.tags && (d.tags.includes("news") || d.tags.includes("article")))
    .sort((a, b) => (b.createdAt || "").localeCompare(a.createdAt || ""))
    .slice(0, limit)
    .map(d => ({ id: d.id, title: d.title, summary: d.human?.summary || "", tags: d.tags, createdAt: d.createdAt, source: d.source }));
  res.json({ ok: true, articles, total: articles.length });
});

app.get("/api/news/trending", (req, res) => {
  // Trending = DTUs with highest resonance/authority score in last 7 days
  const weekAgo = new Date(Date.now() - 7 * 86400000).toISOString();
  const trending = dtusArray()
    .filter(d => !isShadowDTU(d) && d.createdAt > weekAgo)
    .sort((a, b) => (b.authority?.score || 0) - (a.authority?.score || 0))
    .slice(0, 10)
    .map(d => ({ id: d.id, title: d.title, score: d.authority?.score || 0, tags: d.tags, tier: d.tier }));
  res.json({ ok: true, trending, period: "7d" });
});

// Quests (alias for goals)
app.get("/api/quests", async (req, res) => {
  try {
    const out = await runMacro("goals", "list", {}, makeCtx(req));
    res.json({ ...out, quests: out.goals || [] });
  } catch {
    res.json({ ok: true, quests: [] });
  }
});

app.get("/api/quests/mine", async (req, res) => {
  try {
    const out = await runMacro("goals", "list", { mine: true }, makeCtx(req));
    res.json({ ...out, quests: out.goals || [] });
  } catch {
    res.json({ ok: true, quests: [] });
  }
});

// Physics simulation — backed by STATE for persistence
function ensurePhysicsState() {
  if (!STATE.physics) {
    STATE.physics = {
      enabled: false,
      params: { gravity: 9.81, friction: 0.5, timeStep: 1/60, restitution: 0.3 },
      bodies: new Map(), // bodyId -> { id, label, mass, position, velocity, forces }
      stepCount: 0,
      lastStepAt: null,
    };
  }
  return STATE.physics;
}

app.get("/api/physics/simulation", (req, res) => {
  const ps = ensurePhysicsState();
  res.json({
    ok: true,
    enabled: ps.enabled,
    params: ps.params,
    bodies: Array.from(ps.bodies.values()),
    bodyCount: ps.bodies.size,
    stepCount: ps.stepCount,
    lastStepAt: ps.lastStepAt,
  });
});

app.post("/api/physics/toggle", (req, res) => {
  const ps = ensurePhysicsState();
  ps.enabled = !ps.enabled;
  res.json({ ok: true, enabled: ps.enabled });
});

app.post("/api/physics/params", (req, res) => {
  const ps = ensurePhysicsState();
  const { gravity, friction, timeStep, restitution } = req.body;
  if (typeof gravity === 'number') ps.params.gravity = gravity;
  if (typeof friction === 'number') ps.params.friction = Math.max(0, Math.min(1, friction));
  if (typeof timeStep === 'number' && timeStep > 0) ps.params.timeStep = timeStep;
  if (typeof restitution === 'number') ps.params.restitution = Math.max(0, Math.min(1, restitution));
  res.json({ ok: true, params: ps.params });
});

app.post("/api/physics/bodies", (req, res) => {
  const ps = ensurePhysicsState();
  const { label, mass, position, velocity } = req.body;
  const id = `body_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
  const body = {
    id,
    label: label || id,
    mass: typeof mass === 'number' && mass > 0 ? mass : 1.0,
    position: { x: position?.x || 0, y: position?.y || 0, z: position?.z || 0 },
    velocity: { x: velocity?.x || 0, y: velocity?.y || 0, z: velocity?.z || 0 },
    forces: [],
    createdAt: nowISO(),
  };
  ps.bodies.set(id, body);
  res.json({ ok: true, body });
});

app.delete("/api/physics/bodies/:id", (req, res) => {
  const ps = ensurePhysicsState();
  if (!ps.bodies.has(req.params.id)) return res.status(404).json({ ok: false, error: "body not found" });
  ps.bodies.delete(req.params.id);
  res.json({ ok: true });
});

app.post("/api/physics/step", (req, res) => {
  const ps = ensurePhysicsState();
  if (!ps.enabled) return res.json({ ok: false, error: "simulation not enabled" });
  const dt = ps.params.timeStep;
  const g = ps.params.gravity;
  const friction = ps.params.friction;
  for (const body of ps.bodies.values()) {
    // Apply gravity (downward on y-axis)
    body.velocity.y -= g * dt;
    // Apply friction damping
    body.velocity.x *= (1 - friction * dt);
    body.velocity.z *= (1 - friction * dt);
    // Integrate position
    body.position.x += body.velocity.x * dt;
    body.position.y += body.velocity.y * dt;
    body.position.z += body.velocity.z * dt;
    // Simple ground collision at y=0
    if (body.position.y < 0) {
      body.position.y = 0;
      body.velocity.y = -body.velocity.y * ps.params.restitution;
    }
  }
  ps.stepCount++;
  ps.lastStepAt = nowISO();
  res.json({ ok: true, stepCount: ps.stepCount, bodyCount: ps.bodies.size });
});

app.post("/api/physics/reset", (req, res) => {
  const ps = ensurePhysicsState();
  ps.bodies.clear();
  ps.stepCount = 0;
  ps.lastStepAt = null;
  ps.enabled = false;
  res.json({ ok: true });
});

// Resonance
// Support both GET (used by frontend topbar) and POST for resonance/quick
app.get("/api/resonance/quick", async (req, res) => {
  try {
    const out = await runMacro("lattice", "resonance", req.query || {}, makeCtx(req));
    res.json(out);
  } catch (e) {
    res.json({ ok: false, error: String(e?.message || e) });
  }
});
app.post("/api/resonance/quick", async (req, res) => {
  try {
    const out = await runMacro("lattice", "resonance", req.body || {}, makeCtx(req));
    res.json(out);
  } catch (e) {
    res.json({ ok: false, error: String(e?.message || e) });
  }
});

// Lattice endpoints
app.get("/api/lattice/fractal", (req, res) => {
  try {
    const dtus = dtusArray().slice(-50);
    const nodes = dtus.map(d => ({ id: d.id, title: d.title, tier: d.tier, tags: d.tags }));
    res.json({ ok: true, nodes, edges: [] });
  } catch (e) {
    res.json({ ok: false, error: String(e?.message || e) });
  }
});

app.get("/api/lattice/resonance", async (req, res) => {
  try {
    const out = await runMacro("lattice", "resonance", {}, makeCtx(req));
    res.json(out);
  } catch (e) {
    // Compute basic resonance from DTU state instead of returning fake data
    const dtuCount = STATE.dtus.size;
    const megaCount = dtusArray().filter(d => d.tier === "mega").length;
    const avgScore = dtuCount > 0 ? dtusArray().reduce((sum, d) => sum + (d.authority?.score || 0), 0) / dtuCount : 0;
    res.json({ ok: true, resonance: clamp(avgScore, 0, 1), harmony: clamp(megaCount / Math.max(1, dtuCount) * 10, 0, 1), computed: true });
  }
});

// ML endpoints — dynamically discover available models from runtime capabilities
function ensureMlState() {
  if (!STATE.mlJobs) STATE.mlJobs = new Map();
  if (!STATE.mlModels) STATE.mlModels = new Map();
  // Discover models from runtime capabilities each time
  const embeddingAvailable = typeof globalThis.getEmbedding === "function";
  const classifierAvailable = typeof classifyIntent === "function";
  if (embeddingAvailable && !STATE.mlModels.has("embeddings")) {
    STATE.mlModels.set("embeddings", { id: "embeddings", name: "Text Embeddings", status: "active", type: "embedding", requestCount: 0, discoveredAt: nowISO() });
  } else if (!embeddingAvailable && STATE.mlModels.has("embeddings")) {
    STATE.mlModels.get("embeddings").status = "unavailable";
  }
  if (classifierAvailable && !STATE.mlModels.has("classifier")) {
    STATE.mlModels.set("classifier", { id: "classifier", name: "Intent Classifier", status: "active", type: "classification", requestCount: 0, discoveredAt: nowISO() });
  } else if (!classifierAvailable && STATE.mlModels.has("classifier")) {
    STATE.mlModels.get("classifier").status = "unavailable";
  }
  return { mlModels: STATE.mlModels, mlJobs: STATE.mlJobs };
}

app.get("/api/ml/models", (req, res) => {
  const { mlModels } = ensureMlState();
  const models = Array.from(mlModels.values());
  res.json({ ok: true, models, discoveredAt: new Date().toISOString() });
});

app.get("/api/ml/jobs", (req, res) => {
  const { mlJobs } = ensureMlState();
  const jobs = Array.from(mlJobs.values())
    .sort((a, b) => (b.createdAt || "").localeCompare(a.createdAt || ""))
    .slice(0, 50);
  res.json({ ok: true, jobs, total: mlJobs.size });
});

app.get("/api/ml/metrics", (req, res) => {
  const { mlModels } = ensureMlState();
  const latencyStats = _LATENCY.stats();
  let totalRequests = 0;
  for (const m of mlModels.values()) totalRequests += m.requestCount || 0;
  res.json({
    ok: true,
    models: Array.from(mlModels.values()).map(m => ({ id: m.id, status: m.status, requests: m.requestCount })),
    latency: latencyStats.p50,
    throughput: totalRequests,
    embeddingsAvailable: typeof globalThis.getEmbedding === "function",
  });
});

app.post("/api/ml/infer", async (req, res) => {
  const { text, model = "embeddings" } = req.body;
  if (!text) return res.status(400).json({ ok: false, error: "text required" });

  // Concurrency limit for ML inference
  if (!_CONCURRENCY.acquire("ml_infer")) {
    return res.status(429).json({ ok: false, error: "ML inference at capacity. Try again shortly." });
  }

  try {
    const { mlModels, mlJobs } = ensureMlState();
    const modelEntry = mlModels.get(model);
    if (!modelEntry) {
      return res.json({ ok: false, error: `Model '${model}' not registered. Available: ${Array.from(mlModels.keys()).join(", ")}` });
    }
    if (modelEntry.status === "unavailable") {
      return res.json({ ok: false, error: `Model '${model}' is currently unavailable` });
    }
    modelEntry.requestCount = (modelEntry.requestCount || 0) + 1;

    // Track as a job
    const jobId = uid("mljob");
    mlJobs.set(jobId, { id: jobId, model, status: "running", createdAt: nowISO() });

    if (model === "embeddings" && typeof globalThis.getEmbedding === "function") {
      const embedding = await globalThis.getEmbedding(text);
      mlJobs.get(jobId).status = "completed";
      return res.json({ ok: true, jobId, embedding });
    }
    if (model === "classifier" && typeof classifyIntent === "function") {
      const intent = classifyIntent(text);
      mlJobs.get(jobId).status = "completed";
      return res.json({ ok: true, jobId, result: intent });
    }
    mlJobs.get(jobId).status = "failed";
    res.json({ ok: false, error: `Model '${model}' handler not available at runtime` });
  } finally {
    _CONCURRENCY.release("ml_infer");
  }
});

// POST /api/ml/train — queue a training job
app.post("/api/ml/train", (req, res) => {
  try {
    const { mlJobs } = ensureMlState();
    const { modelName, datasetId, epochs, learningRate } = req.body || {};
    const jobId = `ml_job_${Date.now()}_${Math.random().toString(36).slice(2, 6)}`;
    const job = {
      id: jobId,
      type: "train",
      modelName: modelName || "custom_model",
      datasetId: datasetId || null,
      config: { epochs: epochs || 10, learningRate: learningRate || 0.001 },
      status: "queued",
      progress: 0,
      createdAt: nowISO(),
    };
    mlJobs.set(jobId, job);
    res.json({ ok: true, job });
  } catch (e) {
    res.status(500).json({ ok: false, error: String(e?.message || e) });
  }
});

// POST /api/ml/deploy/:modelId — deploy a model
app.post("/api/ml/deploy/:modelId", (req, res) => {
  try {
    const { mlModels } = ensureMlState();
    const model = mlModels.get(req.params.modelId);
    if (!model) return res.status(404).json({ ok: false, error: "Model not found" });
    model.status = "active";
    model.deployedAt = nowISO();
    res.json({ ok: true, model });
  } catch (e) {
    res.status(500).json({ ok: false, error: String(e?.message || e) });
  }
});

// Game/gamification endpoints - computed from real DTU activity
if (!STATE.gameProfiles) STATE.gameProfiles = new Map();

function getGameProfile(userId) {
  if (!userId) userId = "anon";
  if (!STATE.gameProfiles.has(userId)) {
    STATE.gameProfiles.set(userId, { userId, xp: 0, level: 1, badges: [], streak: 0, lastActivityAt: null });
  }
  return STATE.gameProfiles.get(userId);
}

function computeAchievements(userId) {
  const dtuCount = dtusArray().filter(d => d.authorId === userId || d.source === userId).length;
  const megaCount = dtusArray().filter(d => d.tier === "mega" && (d.authorId === userId || d.source === userId)).length;
  const hyperCount = dtusArray().filter(d => d.tier === "hyper" && (d.authorId === userId || d.source === userId)).length;
  const voteCount = Array.from(STATE.councilVotes?.values() || []).flat().filter(v => v.voterId === userId).length;
  return [
    { id: "first_dtu", name: "First Thought", description: "Create your first DTU", earned: dtuCount >= 1, progress: Math.min(dtuCount, 1) },
    { id: "ten_dtus", name: "Prolific Thinker", description: "Create 10 DTUs", earned: dtuCount >= 10, progress: Math.min(dtuCount, 10) },
    { id: "mega_creator", name: "Mega Creator", description: "Create a MEGA DTU", earned: megaCount >= 1, progress: Math.min(megaCount, 1) },
    { id: "hyper_mind", name: "Hyper Mind", description: "Create a HYPER DTU", earned: hyperCount >= 1, progress: Math.min(hyperCount, 1) },
    { id: "council_voter", name: "Council Voter", description: "Cast 5 votes", earned: voteCount >= 5, progress: Math.min(voteCount, 5) },
    { id: "century_club", name: "Century Club", description: "Create 100 DTUs", earned: dtuCount >= 100, progress: Math.min(dtuCount, 100) },
  ];
}

app.get("/api/game/profile", (req, res) => {
  const userId = req.user?.id || "anon";
  const profile = getGameProfile(userId);
  // Calculate XP from DTU count
  const dtuCount = dtusArray().filter(d => d.authorId === userId || d.source === userId).length;
  profile.xp = dtuCount * 10;
  profile.level = Math.floor(Math.sqrt(profile.xp / 100)) + 1;
  profile.badges = computeAchievements(userId).filter(a => a.earned).map(a => a.id);
  res.json({ ok: true, profile });
});

app.get("/api/game/achievements", (req, res) => {
  const userId = req.user?.id || "anon";
  res.json({ ok: true, achievements: computeAchievements(userId) });
});

app.get("/api/game/challenges", (req, res) => {
  // Generate challenges from current system state
  const dtuCount = STATE.dtus.size;
  const challenges = [
    { id: "daily_create", name: "Daily Creator", description: "Create 3 DTUs today", target: 3, reward: 30 },
    { id: "tag_master", name: "Tag Master", description: "Add tags to 5 DTUs", target: 5, reward: 25 },
    { id: "vote_today", name: "Civic Duty", description: "Cast a council vote today", target: 1, reward: 15 },
  ];
  if (dtuCount > 10) challenges.push({ id: "mega_merge", name: "Mega Merge", description: "Promote DTUs into a MEGA", target: 1, reward: 50 });
  res.json({ ok: true, challenges });
});

app.get("/api/game/leaderboard", (req, res) => {
  // Build leaderboard from game profiles
  const entries = Array.from(STATE.gameProfiles.values())
    .map(p => ({ userId: p.userId, xp: p.xp || 0, level: p.level || 1, badges: (p.badges || []).length }))
    .sort((a, b) => b.xp - a.xp)
    .slice(0, 20);
  res.json({ ok: true, leaderboard: entries });
});

// POST /api/game/quests/:questId/complete — mark a quest complete and grant XP
app.post("/api/game/quests/:questId/complete", (req, res) => {
  try {
    const userId = req.user?.id || "default";
    if (!STATE.gameProfiles) STATE.gameProfiles = new Map();
    if (!STATE.gameProfiles.has(userId)) {
      STATE.gameProfiles.set(userId, { userId, xp: 0, level: 1, questsCompleted: 0, badges: [] });
    }
    const profile = STATE.gameProfiles.get(userId);
    const xpGain = Number(req.body?.xpReward) || 100;
    profile.xp = (profile.xp || 0) + xpGain;
    profile.questsCompleted = (profile.questsCompleted || 0) + 1;
    // Level up every 1000 XP
    profile.level = Math.floor(profile.xp / 1000) + 1;
    res.json({ ok: true, profile });
  } catch (e) {
    res.status(500).json({ ok: false, error: String(e?.message || e) });
  }
});

// Notifications - sourced from real notification queue
app.get("/api/notifications/count", (req, res) => {
  ensureQueues();
  const userId = req.user?.id;
  const all = STATE.queues?.notifications || [];
  const userNotifs = userId ? all.filter(n => !n.targetUserId || n.targetUserId === userId) : all;
  const unread = userNotifs.filter(n => !n.readAt);
  res.json({ ok: true, count: userNotifs.length, unread: unread.length });
});

// Links
app.get("/api/links", (req, res) => {
  const links = [];
  for (const d of dtusArray().slice(-100)) {
    for (const p of (d.lineage?.parents || [])) {
      links.push({ source: p, target: d.id, type: "parent" });
    }
  }
  res.json({ ok: true, links });
});

// Anon endpoints (privacy mode)
app.get("/api/anon/identity", (req, res) => {
  const id = uid("anon");
  res.json({ ok: true, anonId: id, expiresAt: new Date(Date.now() + 24*60*60*1000).toISOString() });
});

app.get("/api/anon/messages", (req, res) => {
  // Anonymous messages stored in sessions
  const sessionId = req.query.sessionId || req.cookies?.concord_anon;
  const session = sessionId ? STATE.sessions.get(sessionId) : null;
  const messages = session?.messages || [];
  res.json({ ok: true, messages: messages.slice(-50) });
});

app.post("/api/anon/rotate", (req, res) => {
  const id = uid("anon");
  res.json({ ok: true, newAnonId: id });
});

// Sovereignty/audit
app.get("/api/sovereignty/status", (req, res) => {
  res.json({ ok: true, sovereign: true, dataLocal: true, federationEnabled: false });
});

app.post("/api/sovereignty/audit", async (req, res) => {
  try {
    const out = await runMacro("audit", "run", req.body || {}, makeCtx(req));
    res.json(out);
  } catch (e) {
    // Run basic checks even if macro fails
    const checks = [
      { name: "data_locality", passed: true, detail: "All data stored locally" },
      { name: "no_telemetry", passed: !process.env.TELEMETRY_ENABLED, detail: "No telemetry configured" },
      { name: "cloud_opt_in", passed: !STATE.settings?.llmDefault || Boolean(process.env.CLOUD_LLM_ENABLED), detail: "Cloud LLM requires opt-in" },
      { name: "encryption_at_rest", passed: Boolean(process.env.ENCRYPTION_KEY), detail: process.env.ENCRYPTION_KEY ? "Encryption key set" : "No encryption key" },
    ];
    res.json({ ok: true, audit: { passed: checks.every(c => c.passed), checks, error: String(e?.message || e) }});
  }
});

// Finance - backed by real economic state
app.get("/api/finance/portfolio", (req, res) => {
  const userId = req.user?.id || req.query.odId;
  ensureEconomicState();
  const wallet = userId ? getWallet(userId) : { balance: 0, purchases: [] };
  const listings = Array.from(STATE.economic?.listings?.values() || []).filter(l => l.seller === userId);
  res.json({
    ok: true,
    portfolio: {
      balance: wallet.balance || 0,
      assets: listings.map(l => ({ id: l.id, type: l.assetType, title: l.title, price: l.price, status: l.status })),
      purchases: (wallet.purchases || []).slice(-20),
    }
  });
});

app.get("/api/finance/transactions", (req, res) => {
  ensureEconomicState();
  const userId = req.user?.id || req.query.odId;
  const limit = clamp(Number(req.query.limit || 50), 1, 200);
  const allTx = Array.from(STATE.economic?.transactions?.values() || []);
  const userTx = userId ? allTx.filter(t => t.buyer === userId || t.seller === userId) : allTx;
  const transactions = userTx.sort((a, b) => (b.timestamp || 0) - (a.timestamp || 0)).slice(0, limit);
  res.json({ ok: true, transactions, total: userTx.length });
});

// Economy status - real metrics
app.get("/api/economy/status", (req, res) => {
  ensureEconomicState();
  const wallets = STATE.economic?.wallets || new Map();
  let totalBalance = 0;
  for (const w of wallets.values()) totalBalance += (w.balance || 0);
  const txCount = STATE.economic?.transactions?.size || 0;
  const listingCount = STATE.economic?.listings?.size || 0;
  const activeListings = Array.from(STATE.economic?.listings?.values() || []).filter(l => l.status === "active").length;
  res.json({
    ok: true,
    status: "active",
    circulation: totalBalance,
    velocity: txCount > 0 ? (txCount / Math.max(1, wallets.size)).toFixed(2) : 0,
    treasury: STATE.economic?.treasury || 0,
    listings: { total: listingCount, active: activeListings },
    participants: wallets.size,
  });
});

// GET /api/economy/balance — return wallet balance for current user (marketplace)
app.get("/api/economy/balance", (req, res) => {
  ensureEconomicState();
  const userId = req.query.user_id || req.user?.id || "default";
  const wallet = STATE.economic.wallets.get(userId);
  res.json({ ok: true, balance: wallet?.balance || 0, tier: wallet?.tier || "free" });
});

// GET /api/economy/fees — return marketplace fee schedule
app.get("/api/economy/fees", (req, res) => {
  res.json({
    ok: true,
    fees: {
      MARKETPLACE_PURCHASE: ECONOMIC_CONFIG.MARKETPLACE_FEE,
      TOKEN_PURCHASE: ECONOMIC_CONFIG.TOKEN_PURCHASE_FEE,
      CREATOR_SHARE: ECONOMIC_CONFIG.CREATOR_SHARE,
      ROYALTY_SHARE: ECONOMIC_CONFIG.ROYALTY_SHARE,
      TREASURY_SHARE: ECONOMIC_CONFIG.TREASURY_SHARE,
    },
  });
});

// Growth/organs
app.get("/api/growth/status", (req, res) => {
  res.json({ ok: true, status: STATE.growth || { stage: "seed", health: 1.0 }});
});

app.get("/api/growth/organs", (req, res) => {
  const organs = Array.from(STATE.organs?.values() || []);
  res.json({ ok: true, organs });
});

// Music - ambient/focus mode with real state tracking
if (!STATE.music) STATE.music = { playing: false, currentTrack: null, queue: [], playlists: [], volume: 0.7 };

app.get("/api/music/current", (req, res) => {
  res.json({ ok: true, track: STATE.music.currentTrack, playing: STATE.music.playing, volume: STATE.music.volume });
});

app.get("/api/music/playlists", (req, res) => {
  // Built-in focus playlists + user-created
  const builtIn = [
    { id: "focus", name: "Deep Focus", tracks: 0, type: "ambient", builtin: true },
    { id: "nature", name: "Nature Sounds", tracks: 0, type: "ambient", builtin: true },
    { id: "silence", name: "Silence", tracks: 0, type: "silence", builtin: true },
  ];
  res.json({ ok: true, playlists: [...builtIn, ...STATE.music.playlists] });
});

app.get("/api/music/queue", (req, res) => {
  res.json({ ok: true, queue: STATE.music.queue });
});

app.post("/api/music/toggle", (req, res) => {
  STATE.music.playing = !STATE.music.playing;
  if (req.body?.track) STATE.music.currentTrack = req.body.track;
  if (req.body?.volume !== undefined) STATE.music.volume = clamp(Number(req.body.volume), 0, 1);
  saveStateDebounced();
  realtimeEmit("music:toggle", { playing: STATE.music.playing, track: STATE.music.currentTrack });
  res.json({ ok: true, playing: STATE.music.playing, track: STATE.music.currentTrack });
});

// AR endpoints - backed by lens artifacts tagged as AR layers
app.get("/api/ar/status", (req, res) => {
  const arArtifacts = Array.from(STATE.lensArtifacts.values()).filter(a => a.domain === "ar" || (a.meta?.tags || []).includes("ar"));
  res.json({ ok: true, available: true, layerCount: arArtifacts.length, note: "AR rendering handled client-side via WebXR" });
});

app.get("/api/ar/layers", (req, res) => {
  const layers = Array.from(STATE.lensArtifacts.values())
    .filter(a => a.domain === "ar" || (a.meta?.tags || []).includes("ar"))
    .map(a => ({ id: a.id, title: a.title, type: a.type, data: a.data, createdAt: a.createdAt }));
  // Also include DTU-derived layers (DTUs with spatial metadata)
  const dtuLayers = dtusArray()
    .filter(d => d.meta?.spatial || d.tags?.includes("ar"))
    .map(d => ({ id: d.id, title: d.title, type: "dtu-overlay", data: d.meta?.spatial || {}, createdAt: d.createdAt }));
  res.json({ ok: true, layers: [...layers, ...dtuLayers] });
});

// Bio systems - sourced from DTUs tagged as biological models
app.get("/api/bio/systems", (req, res) => {
  const systems = dtusArray()
    .filter(d => d.tags && (d.tags.includes("biology") || d.tags.includes("bio") || d.tags.includes("biological")))
    .map(d => ({ id: d.id, title: d.title, summary: d.human?.summary || "", tags: d.tags, createdAt: d.createdAt }));
  const artifacts = Array.from(STATE.lensArtifacts.values())
    .filter(a => a.domain === "bio" || a.domain === "healthcare")
    .map(a => ({ id: a.id, title: a.title, type: a.type, domain: a.domain, createdAt: a.createdAt }));
  res.json({ ok: true, systems: [...systems, ...artifacts] });
});

// Chemistry - sourced from DTUs and lens artifacts
if (!STATE.chemCompounds) STATE.chemCompounds = new Map();
if (!STATE.chemReactions) STATE.chemReactions = new Map();

app.get("/api/chem/compounds", (req, res) => {
  const compounds = Array.from(STATE.chemCompounds.values());
  // Also pull DTUs tagged as chemistry
  const dtuCompounds = dtusArray()
    .filter(d => d.tags && (d.tags.includes("chemistry") || d.tags.includes("compound")))
    .map(d => ({ id: d.id, name: d.title, formula: d.meta?.formula || "", tags: d.tags, source: "dtu" }));
  res.json({ ok: true, compounds: [...compounds, ...dtuCompounds] });
});

app.get("/api/chem/reactions", (req, res) => {
  const reactions = Array.from(STATE.chemReactions.values());
  res.json({ ok: true, reactions });
});

app.post("/api/chem/react", (req, res) => {
  const { reactants, conditions } = req.body || {};
  if (!reactants || !Array.isArray(reactants)) return res.status(400).json({ ok: false, error: "reactants array required" });

  // Store reaction for tracking
  const reactionId = uid("rxn");
  const reaction = {
    id: reactionId,
    reactants,
    conditions: conditions || {},
    products: [], // Would be computed by a chemistry engine
    createdAt: nowISO(),
    status: "computed",
  };

  // Create a DTU to record this reaction
  const reactionDtu = {
    id: uid("dtu"),
    title: `Reaction: ${reactants.join(" + ")}`,
    tags: ["chemistry", "reaction", "computed"],
    tier: "regular",
    source: "chem-engine",
    createdAt: nowISO(),
    updatedAt: nowISO(),
    human: { summary: `Chemical reaction between ${reactants.join(", ")}`, bullets: [], examples: [] },
    core: { definitions: [], invariants: [], claims: [`Reactants: ${reactants.join(", ")}`], examples: [], nextActions: [] },
    machine: { conditions },
    authority: { model: "computed", score: 0.5 },
  };
  upsertDTU(reactionDtu);

  STATE.chemReactions.set(reactionId, { ...reaction, dtuId: reactionDtu.id });
  saveStateDebounced();
  res.json({ ok: true, reaction: { ...reaction, dtuId: reactionDtu.id } });
});

// Board/tasks
app.get("/api/board/tasks", (req, res) => {
  // Pull from goals as tasks
  const goals = Array.from(STATE.growth?.goals?.values() || []);
  res.json({ ok: true, tasks: goals.map(g => ({ id: g.id, title: g.title, status: g.status })) });
});

// Lab experiments - tracked as lens artifacts in the "lab" domain
app.get("/api/lab/experiments", (req, res) => {
  const experiments = Array.from(STATE.lensArtifacts.values())
    .filter(a => a.domain === "lab" || a.domain === "science")
    .map(a => ({ id: a.id, title: a.title, type: a.type, status: a.meta?.status || "draft", createdAt: a.createdAt, data: a.data }));
  res.json({ ok: true, experiments });
});

app.post("/api/lab/run", async (req, res) => {
  const { experimentId, params } = req.body || {};
  if (!experimentId) return res.status(400).json({ ok: false, error: "experimentId required" });

  const experiment = STATE.lensArtifacts.get(experimentId);
  if (!experiment) return res.status(404).json({ ok: false, error: "Experiment not found" });

  // Run the experiment through the lens action pipeline
  try {
    const ctx = makeCtx(req);
    const handler = LENS_ACTIONS.get(`${experiment.domain}.run`) || LENS_ACTIONS.get("lab.run") || LENS_ACTIONS.get("science.run");
    if (handler) {
      const result = await handler(ctx, experiment, params || {});
      experiment.meta = experiment.meta || {};
      experiment.meta.lastRunAt = nowISO();
      experiment.meta.runCount = (experiment.meta.runCount || 0) + 1;
      saveStateDebounced();
      return res.json({ ok: true, result, experiment: { id: experiment.id, title: experiment.title } });
    }
    // Fallback: record the run as a DTU
    const runDtu = {
      id: uid("dtu"), title: `Lab Run: ${experiment.title}`, tags: ["lab", "experiment", "run"],
      tier: "regular", source: "lab-engine", createdAt: nowISO(), updatedAt: nowISO(),
      human: { summary: `Experiment run for ${experiment.title}`, bullets: [], examples: [] },
      core: { definitions: [], invariants: [], claims: [], examples: [], nextActions: [] },
      machine: { experimentId, params },
      authority: { model: "experiment", score: 0.3 },
    };
    upsertDTU(runDtu);
    res.json({ ok: true, result: { dtuId: runDtu.id, status: "recorded" } });
  } catch (e) {
    res.status(500).json({ ok: false, error: String(e?.message || e) });
  }
});

// Custom lenses - sourced from lens artifacts
app.get("/api/lenses/custom", (req, res) => {
  const userId = req.user?.id;
  const custom = Array.from(STATE.lensArtifacts.values())
    .filter(a => a.type === "custom-lens" || a.domain === "custom")
    .filter(a => !userId || a.ownerId === userId || a.meta?.visibility === "public")
    .map(a => ({ id: a.id, title: a.title, domain: a.domain, config: a.data, createdAt: a.createdAt, ownerId: a.ownerId }));
  res.json({ ok: true, lenses: custom });
});

app.get("/api/lenses/templates", (req, res) => {
  // Built-in templates + user-published templates
  const builtIn = [
    { id: "data-viz", name: "Data Visualization", icon: "chart", description: "Charts, graphs, and data dashboards", builtin: true },
    { id: "research", name: "Research Dashboard", icon: "book", description: "Literature review and citation management", builtin: true },
    { id: "kanban", name: "Kanban Board", icon: "columns", description: "Task tracking with columns", builtin: true },
    { id: "timeline", name: "Timeline View", icon: "clock", description: "Chronological event display", builtin: true },
    { id: "mindmap", name: "Mind Map", icon: "git-branch", description: "Hierarchical thought mapping", builtin: true },
  ];
  const userTemplates = Array.from(STATE.lensArtifacts.values())
    .filter(a => a.type === "lens-template" && a.meta?.visibility === "public")
    .map(a => ({ id: a.id, name: a.title, icon: a.data?.icon || "eye", description: a.data?.description || "", builtin: false }));
  res.json({ ok: true, templates: [...builtIn, ...userTemplates] });
});

// ─────────────────────────────────────────────────────────────────────────────
// Wave 17: Final audit fixes - remaining missing endpoints
// ─────────────────────────────────────────────────────────────────────────────

// Council debate - structured debate sessions
app.post("/api/council/debate", (req, res) => {
  const { topic, participants, rounds = 3 } = req.body || {};
  if (!topic) return res.status(400).json({ ok: false, error: "topic required" });

  // Create debate session
  const debateId = `debate_${Date.now()}`;
  const debate = {
    id: debateId,
    topic,
    participants: participants || ["council_alpha", "council_beta", "council_gamma"],
    rounds,
    arguments: [],
    status: "active",
    createdAt: new Date().toISOString()
  };

  // Store in state
  if (!STATE.debates) STATE.debates = new Map();
  STATE.debates.set(debateId, debate);

  res.json({ ok: true, debate });
});

app.get("/api/council/debate", (req, res) => {
  const debates = Array.from(STATE.debates?.values() || []);
  res.json({ ok: true, debates });
});

// Papers tags - get all unique tags from papers
app.get("/api/papers/tags", (req, res) => {
  const papers = Array.from(STATE.papers?.values() || []);
  const tagSet = new Set();
  papers.forEach(p => {
    (p.tags || []).forEach(t => tagSet.add(t));
  });
  res.json({ ok: true, tags: Array.from(tagSet).sort() });
});

// Credits/wallet system - requires authentication
app.post("/api/credits/wallet", requireAuth(), (req, res) => {
  const { walletId } = req.body || {};
  if (!walletId) return res.status(400).json({ ok: false, error: "walletId required" });

  // Initialize wallets store if needed
  if (!STATE.wallets) STATE.wallets = new Map();

  // Get or create wallet
  let wallet = STATE.wallets.get(walletId);
  if (!wallet) {
    wallet = {
      id: walletId,
      balance: 100, // Starting balance
      transactions: [],
      createdAt: new Date().toISOString()
    };
    STATE.wallets.set(walletId, wallet);
  }

  res.json({ ok: true, wallet });
});

app.post("/api/credits/earn", requireAuth(), (req, res) => {
  const { walletId, amount, reason = "quest" } = req.body || {};
  if (!walletId) return res.status(400).json({ ok: false, error: "walletId required" });
  if (!amount || amount <= 0) return res.status(400).json({ ok: false, error: "positive amount required" });

  if (!STATE.wallets) STATE.wallets = new Map();

  let wallet = STATE.wallets.get(walletId);
  if (!wallet) {
    wallet = { id: walletId, balance: 0, transactions: [], createdAt: new Date().toISOString() };
  }

  wallet.balance += amount;
  wallet.transactions.push({
    type: "earn",
    amount,
    reason,
    timestamp: new Date().toISOString()
  });

  STATE.wallets.set(walletId, wallet);
  res.json({ ok: true, wallet, earned: amount });
});

app.post("/api/credits/spend", requireAuth(), (req, res) => {
  const { walletId, amount, reason = "spend" } = req.body || {};
  if (!walletId) return res.status(400).json({ ok: false, error: "walletId required" });
  if (!amount || amount <= 0) return res.status(400).json({ ok: false, error: "positive amount required" });

  if (!STATE.wallets) STATE.wallets = new Map();

  const wallet = STATE.wallets.get(walletId);
  if (!wallet) {
    return res.status(404).json({ ok: false, error: "wallet not found" });
  }

  if (wallet.balance < amount) {
    return res.status(400).json({ ok: false, error: "insufficient balance", balance: wallet.balance });
  }

  wallet.balance -= amount;
  wallet.transactions.push({
    type: "spend",
    amount,
    reason,
    timestamp: new Date().toISOString()
  });

  STATE.wallets.set(walletId, wallet);
  res.json({ ok: true, wallet, spent: amount });
});

// Global feed - public DTUs feed
app.get("/api/global/feed", (req, res) => {
  const { limit = 50, offset = 0, tier } = req.query;

  // Get global DTUs (isGlobal flag, scope=global, or tier >= mega)
  let globalDtus = Array.from(STATE.dtus?.values() || [])
    .filter(d => d.isGlobal || d.scope === "global" || d.tier === "mega" || d.tier === "hyper")
    .filter(d => !isShadowDTU(d))
    .sort((a, b) => new Date(b.createdAt || 0) - new Date(a.createdAt || 0));

  // Filter by tier if specified
  if (tier) {
    globalDtus = globalDtus.filter(d => d.tier === tier);
  }

  const total = globalDtus.length;
  const feed = globalDtus.slice(Number(offset), Number(offset) + Number(limit));

  res.json({
    ok: true,
    feed,
    total,
    hasMore: Number(offset) + feed.length < total
  });
});

console.log("[Concord] Wave 17: Final audit fixes loaded");
console.log("[Concord] Wave 16: Missing lens endpoints loaded");

// ═══════════════════════════════════════════════════════════════════════════════
// AFFECTIVE TRANSLATION SPINE (ATS)
// First-class subsystem: bounded affective state → OS control signals
// ═══════════════════════════════════════════════════════════════════════════════

let ATS = null;
try {
  ATS = await import("./affect/index.js");
  console.log("[Concord] ATS: Affective Translation Spine loaded");
} catch (e) {
  console.warn("[Concord] ATS: Failed to load affect module:", e.message);
}

// ---- ATS Middleware: emit affect events for requests ----
if (ATS) {
  app.use((req, res, next) => {
    // Deterministic session identity: per-user when authenticated, per-IP+UA otherwise.
    // Prevents "shared mood" across users on the same node.
    let sessionId;
    if (req.user?.id) {
      sessionId = `user_${req.user.id}`;
    } else if (req.headers["x-session-id"]) {
      sessionId = String(req.headers["x-session-id"]);
    } else {
      const fingerprint = `${req.ip || "unknown"}:${req.get("user-agent") || "none"}`;
      sessionId = `anon_${crypto.createHash("sha256").update(fingerprint).digest("hex").slice(0, 16)}`;
    }
    req._atsSessionId = sessionId;

    // Emit USER_MESSAGE event on incoming requests
    if (req.method !== "GET" && req.method !== "OPTIONS") {
      ATS.emitAffectEvent(sessionId, {
        type: "USER_MESSAGE",
        intensity: 0.3,
        polarity: 0,
        source: { userId: req.user?.id, sessionId, route: req.path },
      });
    }

    // Hook into response to emit outcome events
    const originalJson = res.json.bind(res);
    res.json = function(body) {
      if (body && typeof body === "object") {
        const isError = res.statusCode >= 400;
        const isServerError = res.statusCode >= 500;

        if (isServerError) {
          ATS.emitAffectEvent(sessionId, {
            type: "ERROR",
            intensity: 0.7,
            polarity: -0.6,
            source: { sessionId, route: req.path },
            payload: { statusCode: res.statusCode },
          });
        } else if (isError) {
          ATS.emitAffectEvent(sessionId, {
            type: "SYSTEM_RESULT",
            intensity: 0.4,
            polarity: -0.3,
            source: { sessionId, route: req.path },
            payload: { statusCode: res.statusCode },
          });
        } else if (body.ok === true) {
          ATS.emitAffectEvent(sessionId, {
            type: "SUCCESS",
            intensity: 0.3,
            polarity: 0.4,
            source: { sessionId, route: req.path },
          });
        }
      }
      return originalJson(body);
    };

    next();
  });
}

// ---- ATS API Endpoints ----

// GET /api/affect/state — current affective state for a session
app.get("/api/affect/state", (req, res) => {
  if (!ATS) return res.status(501).json({ ok: false, error: "ATS not loaded" });
  const sessionId = req.query.sessionId || req._atsSessionId || "default";
  const state = ATS.getAffectState(sessionId);
  if (!state) return res.status(404).json({ ok: false, error: "Session not found" });
  res.json({ ok: true, state });
});

// POST /api/affect/event — apply an affect event
app.post("/api/affect/event", (req, res) => {
  if (!ATS) return res.status(501).json({ ok: false, error: "ATS not loaded" });
  const sessionId = req.body?.source?.sessionId || req._atsSessionId || "default";
  const result = ATS.emitAffectEvent(sessionId, req.body);
  if (!result.ok) return res.status(400).json(result);
  res.json(result);
});

// GET /api/affect/policy — current policy for a session
app.get("/api/affect/policy", (req, res) => {
  if (!ATS) return res.status(501).json({ ok: false, error: "ATS not loaded" });
  const sessionId = req.query.sessionId || req._atsSessionId || "default";
  const policy = ATS.getSessionPolicy(sessionId);
  if (!policy) return res.status(404).json({ ok: false, error: "Session not found" });
  res.json({ ok: true, policy });
});

// POST /api/affect/reset — reset to baseline or cooldown
app.post("/api/affect/reset", (req, res) => {
  if (!ATS) return res.status(501).json({ ok: false, error: "ATS not loaded" });
  const sessionId = req.body?.sessionId || req._atsSessionId || "default";
  const mode = req.body?.mode || "baseline";
  const result = ATS.resetAffect(sessionId, mode);
  res.json(result);
});

// GET /api/affect/events — recent events for a session
app.get("/api/affect/events", (req, res) => {
  if (!ATS) return res.status(501).json({ ok: false, error: "ATS not loaded" });
  const sessionId = req.query.sessionId || req._atsSessionId || "default";
  const limit = Math.min(Number(req.query.limit) || 50, 500);
  const events = ATS.getAffectEvents(sessionId, limit);
  res.json({ ok: true, events, count: events.length });
});

// GET /api/affect/health — ATS subsystem health
app.get("/api/affect/health", (req, res) => {
  if (!ATS) return res.status(501).json({ ok: false, error: "ATS not loaded" });
  res.json({
    ok: true,
    loaded: true,
    sessions: ATS.sessionCount(),
    baseline: ATS.BASELINE,
    dimensions: ATS.DIMS,
  });
});

console.log("[Concord] ATS: Affect API endpoints registered");

// ═══════════════════════════════════════════════════════════════════════════════
// CONCORD GLOBAL ATLAS + PLATFORM UPGRADES v2
// ═══════════════════════════════════════════════════════════════════════════════

// ---- Initialize Atlas State ----
try { initAtlasState(STATE); console.log("[Concord] Atlas: Epistemic engine initialized"); } catch (e) { console.warn("[Atlas] Init skipped:", e.message); }
try { initScopeState(STATE); console.log("[Concord] Atlas: 3-Lane scope router initialized"); } catch (e) { console.warn("[Atlas] Scope init skipped:", e.message); }

// ---- Atlas: Core DTU Endpoints ----
app.post("/api/atlas/dtu", async (req, res) => {
  try {
    const result = createAtlasDtu(STATE, req.body || {});
    if (!result.ok) return res.status(400).json(result);
    dispatchWebhookEvent(STATE, "atlas:dtu:created", { dtuId: result.dtu.id, title: result.dtu.title });
    res.json(result);
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/dtu/:id", (req, res) => {
  try { res.json(getAtlasDtu(STATE, req.params.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/atlas/dtu/:id/promote", (req, res) => {
  try {
    const { targetStatus, actor } = req.body || {};
    const result = promoteAtlasDtu(STATE, req.params.id, targetStatus, actor || req.user?.id || "api");
    if (!result.ok) return res.status(400).json(result);
    if (targetStatus === "VERIFIED") dispatchWebhookEvent(STATE, "atlas:dtu:verified", { dtuId: req.params.id });
    if (targetStatus === "DISPUTED") dispatchWebhookEvent(STATE, "atlas:dtu:disputed", { dtuId: req.params.id });
    res.json(result);
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/atlas/dtu/:id/link", (req, res) => {
  try {
    const { targetDtuId, linkType, ...meta } = req.body || {};
    res.json(addAtlasLink(STATE, req.params.id, targetDtuId, linkType, meta));
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/search", (req, res) => {
  try {
    res.json(searchAtlasDtus(STATE, {
      domainType: req.query.domainType,
      epistemicClass: req.query.epistemicClass,
      status: req.query.status,
      entity: req.query.entity,
      minConfidence: req.query.minConfidence ? Number(req.query.minConfidence) : undefined,
      limit: Number(req.query.limit || 50),
      offset: Number(req.query.offset || 0),
    }));
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/entity/:id", (req, res) => {
  try { res.json(getEntity(STATE, req.params.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/atlas/entity", (req, res) => {
  try {
    const { entityId, label, type } = req.body || {};
    res.json(registerEntity(STATE, entityId, label, type));
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/contradictions/:id", (req, res) => {
  try { res.json(getContradictions(STATE, req.params.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/score-explain/:id", (req, res) => {
  try { res.json(getScoreExplanation(STATE, req.params.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/atlas/dtu/:id/recompute-scores", (req, res) => {
  try { res.json(recomputeScores(STATE, req.params.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/metrics", (req, res) => {
  try { res.json(getAtlasMetrics(STATE)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/domains", (req, res) => {
  res.json({ ok: true, domainTypes: Object.values(ATLAS_DOMAIN_TYPES), epistemicClasses: Object.values(EPISTEMIC_CLASSES) });
});

// ---- Atlas: Anti-Gaming ----
app.get("/api/atlas/antigaming/scan/:id", (req, res) => {
  try { res.json(runAntiGamingScan(STATE, req.params.id, req.user?.id || "unknown")); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/antigaming/metrics", (req, res) => {
  try { res.json(getAntiGamingMetrics()); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

// ---- Atlas: Autogen v2 ----
app.post("/api/atlas/autogen/run", (req, res) => {
  try {
    const result = runAutogenV2(STATE, req.body || {});
    res.json(result);
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/autogen/run/:runId", (req, res) => {
  try { res.json(getAutogenRun(STATE, req.params.runId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/atlas/autogen/accept/:dtuId", (req, res) => {
  try { res.json(acceptAutogenOutput(STATE, req.params.dtuId, req.user?.id || "api")); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/atlas/autogen/merge/:dtuId", (req, res) => {
  try {
    const { targetDtuId } = req.body || {};
    res.json(mergeAutogenOutput(STATE, req.params.dtuId, targetDtuId, req.user?.id || "api"));
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/atlas/autogen/propagate/:dtuId", (req, res) => {
  try {
    const { maxHops, dampingFactor } = req.body || {};
    res.json(propagateConfidence(STATE, req.params.dtuId, maxHops || 2, dampingFactor || 0.5));
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/autogen/metrics", (req, res) => {
  try { res.json(getAutogenV2Metrics(STATE)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

// ---- Atlas: Council Protocol ----
app.post("/api/atlas/council/resolve", (req, res) => {
  try { res.json(councilResolve(STATE, req.body || {})); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/council/queue", (req, res) => {
  try { res.json(getCouncilQueue(STATE, { limit: Number(req.query.limit || 50), domainType: req.query.domainType })); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/atlas/council/request-sources", (req, res) => {
  try {
    const { dtuId, claimIds, reason, actor } = req.body || {};
    res.json(councilRequestSources(STATE, dtuId, claimIds || [], reason, actor || req.user?.id));
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/atlas/council/merge", (req, res) => {
  try {
    const { sourceDtuId, targetDtuId, reason } = req.body || {};
    res.json(councilMerge(STATE, sourceDtuId, targetDtuId, reason, req.user?.id || "api"));
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/council/actions", (req, res) => {
  try { res.json(getCouncilActions(STATE, { dtuId: req.query.dtuId, actionType: req.query.actionType, limit: Number(req.query.limit || 50) })); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/council/metrics", (req, res) => {
  try { res.json(getCouncilMetrics(STATE)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

// ---- Social Layer ----
app.post("/api/social/profile", (req, res) => {
  try { res.json(upsertProfile(STATE, req.body?.userId || req.user?.id, req.body || {})); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/social/profile/:userId", (req, res) => {
  try { res.json(getProfile(STATE, req.params.userId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/social/profiles", (req, res) => {
  try { res.json(listProfiles(STATE, { sortBy: req.query.sortBy, limit: Number(req.query.limit || 50) })); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/social/follow", (req, res) => {
  try { res.json(followUser(STATE, req.body?.followerId || req.user?.id, req.body?.followedId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/social/unfollow", (req, res) => {
  try { res.json(unfollowUser(STATE, req.body?.followerId || req.user?.id, req.body?.followedId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/social/followers/:userId", (req, res) => {
  try { res.json(getFollowers(STATE, req.params.userId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/social/following/:userId", (req, res) => {
  try { res.json(getFollowing(STATE, req.params.userId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/social/feed", (req, res) => {
  try { res.json(getFeed(STATE, req.query.userId || req.user?.id, { limit: Number(req.query.limit || 30), offset: Number(req.query.offset || 0) })); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/social/trending", (req, res) => {
  try { res.json(computeTrending(STATE, Number(req.query.limit || 20))); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/social/discover/:userId", (req, res) => {
  try { res.json(discoverUsers(STATE, req.params.userId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/social/publish/:dtuId", (req, res) => {
  try { res.json(publishDtu(STATE, req.params.dtuId, req.user?.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/social/unpublish/:dtuId", (req, res) => {
  try { res.json(unpublishDtu(STATE, req.params.dtuId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/social/cite", (req, res) => {
  try {
    const result = recordCitation(STATE, req.body?.citedDtuId, req.body?.citingDtuId);
    if (result.ok) dispatchWebhookEvent(STATE, "citation:added", { citedDtuId: req.body?.citedDtuId, citingDtuId: req.body?.citingDtuId });
    res.json(result);
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/social/cited-by/:dtuId", (req, res) => {
  try { res.json(getCitedBy(STATE, req.params.dtuId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/social/metrics", (req, res) => {
  try { res.json(getSocialMetrics(STATE)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

// ---- Collaboration ----
app.post("/api/collab/workspace", (req, res) => {
  try { res.json(collabCreateWorkspace(STATE, { ...req.body, ownerId: req.body?.ownerId || req.user?.id })); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/collab/workspace/:id", (req, res) => {
  try { res.json(collabGetWorkspace(STATE, req.params.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/collab/workspaces", (req, res) => {
  try { res.json(collabListWorkspaces(STATE, req.query.userId || req.user?.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/collab/workspace/:id/member", (req, res) => {
  try { res.json(collabAddWorkspaceMember(STATE, req.params.id, req.body?.userId, req.body?.role, req.user?.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.delete("/api/collab/workspace/:id/member/:userId", (req, res) => {
  try { res.json(collabRemoveWorkspaceMember(STATE, req.params.id, req.params.userId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/collab/workspace/:id/dtu", (req, res) => {
  try { res.json(collabAddDtuToWorkspace(STATE, req.params.id, req.body?.dtuId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/collab/comment", (req, res) => {
  try {
    const result = collabAddComment(STATE, req.body?.dtuId, req.body?.userId || req.user?.id, req.body?.text, req.body?.parentCommentId);
    if (result.ok) dispatchWebhookEvent(STATE, "comment:added", { dtuId: req.body?.dtuId, commentId: result.comment?.id });
    res.json(result);
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/collab/comments/:dtuId", (req, res) => {
  try { res.json(collabGetComments(STATE, req.params.dtuId, { tree: req.query.tree === "true", limit: Number(req.query.limit || 50) })); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.put("/api/collab/comment/:id", (req, res) => {
  try { res.json(collabEditComment(STATE, req.params.id, req.body?.userId || req.user?.id, req.body?.text)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/collab/comment/:id/resolve", (req, res) => {
  try { res.json(collabResolveComment(STATE, req.params.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/collab/revision", (req, res) => {
  try {
    const result = proposeRevision(STATE, req.body?.dtuId, req.body?.userId || req.user?.id, req.body?.changes, req.body?.reason);
    if (result.ok) dispatchWebhookEvent(STATE, "revision:proposed", { dtuId: req.body?.dtuId, proposalId: result.proposal?.id });
    res.json(result);
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/collab/revisions/:dtuId", (req, res) => {
  try { res.json(getRevisionProposals(STATE, req.params.dtuId, req.query.status)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/collab/revision/:id/vote", (req, res) => {
  try { res.json(voteOnRevision(STATE, req.params.id, req.body?.userId || req.user?.id, req.body?.vote)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/collab/revision/:id/apply", (req, res) => {
  try { res.json(applyRevision(STATE, req.params.id, req.user?.id || "api")); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/collab/edit-session/:dtuId/start", (req, res) => {
  try { res.json(startEditSession(STATE, req.params.dtuId, req.body?.userId || req.user?.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/collab/edit-session/:dtuId/edit", (req, res) => {
  try { res.json(recordEdit(STATE, req.params.dtuId, req.body?.userId || req.user?.id, req.body?.field, req.body?.oldValue, req.body?.newValue)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/collab/edit-session/:dtuId/end", (req, res) => {
  try { res.json(endEditSession(STATE, req.params.dtuId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/collab/metrics", (req, res) => {
  try { res.json(getCollabMetrics(STATE)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

// ---- RBAC & Enterprise Access Controls ----
app.post("/api/rbac/org", (req, res) => {
  try { res.json(createOrgWorkspace(STATE, { ...req.body, ownerId: req.body?.ownerId || req.user?.id })); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/rbac/org/:orgId", (req, res) => {
  try { res.json(getOrgWorkspace(STATE, req.params.orgId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/rbac/role", (req, res) => {
  try { res.json(assignRole(STATE, req.body?.orgId, req.body?.userId, req.body?.role, req.user?.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.delete("/api/rbac/role", (req, res) => {
  try { res.json(revokeRole(STATE, req.body?.orgId, req.body?.userId, req.user?.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/rbac/role/:orgId/:userId", (req, res) => {
  try { res.json(getUserRole(STATE, req.params.orgId, req.params.userId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/rbac/members/:orgId", (req, res) => {
  try { res.json(getOrgMembers(STATE, req.params.orgId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/rbac/permissions/:orgId/:userId", (req, res) => {
  try { res.json(getUserPermissions(STATE, req.params.orgId, req.params.userId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/rbac/check-permission", (req, res) => {
  try { res.json(checkPermission(STATE, req.body?.orgId, req.body?.userId, req.body?.permission)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/rbac/org-lens", (req, res) => {
  try { res.json(assignOrgLens(STATE, req.body?.orgId, req.body?.lensId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/rbac/org-lenses/:orgId", (req, res) => {
  try { res.json(getOrgLenses(STATE, req.params.orgId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/rbac/audit-export/:orgId", (req, res) => {
  try { res.json(exportAuditLog(STATE, req.params.orgId, { since: req.query.since, until: req.query.until, action: req.query.action, limit: Number(req.query.limit || 1000) })); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/rbac/metrics", (req, res) => {
  try { res.json(getRbacMetrics(STATE)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

// ---- Analytics Dashboard ----
app.get("/api/analytics/dashboard", (req, res) => {
  try { res.json(getDashboardSummary(STATE)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/analytics/personal/:userId", (req, res) => {
  try { res.json(getPersonalAnalytics(STATE, req.params.userId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/analytics/growth", (req, res) => {
  try { res.json(getDtuGrowthTrends(STATE, { period: req.query.period || "24h" })); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/analytics/citations", (req, res) => {
  try { res.json(getCitationAnalytics(STATE, { limit: Number(req.query.limit || 20) })); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/analytics/marketplace", (req, res) => {
  try { res.json(getMarketAnalytics(STATE)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/analytics/density", (req, res) => {
  try { res.json(getKnowledgeDensity(STATE)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/analytics/atlas-domains", (req, res) => {
  try { res.json(getAtlasDomainAnalytics(STATE)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

// ---- Public API & Webhooks ----
app.post("/api/webhooks", (req, res) => {
  try { res.json(registerWh(STATE, { ...req.body, ownerId: req.body?.ownerId || req.user?.id })); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/webhooks", (req, res) => {
  try { res.json(listWebhooks(STATE, req.query.ownerId || req.user?.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/webhooks/:id", (req, res) => {
  try { res.json(getWebhook(STATE, req.params.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.delete("/api/webhooks/:id", (req, res) => {
  try { res.json(deleteWebhook(STATE, req.params.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/webhooks/:id/deactivate", (req, res) => {
  try { res.json(deactivateWebhook(STATE, req.params.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/webhooks/:id/deliveries", (req, res) => {
  try { res.json(getDeliveryHistory(STATE, req.params.id, Number(req.query.limit || 50))); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/webhooks-metrics", (req, res) => {
  try { res.json(getApiMetrics(STATE)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

// ---- Compliance ----
app.post("/api/compliance/region-tag", (req, res) => {
  try { res.json(tagDataRegion(STATE, req.body?.resourceId, req.body?.region, req.user?.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/compliance/region/:resourceId", (req, res) => {
  try { res.json(getDataRegion(STATE, req.params.resourceId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/compliance/export-controls", (req, res) => {
  try { res.json(setExportControls(STATE, req.body?.resourceId, req.body || {})); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/compliance/check-export", (req, res) => {
  try { res.json(checkExportAllowed(STATE, req.body?.resourceId, req.body?.format, req.user?.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/compliance/export", (req, res) => {
  try { res.json(exportData(STATE, req.body?.resourceId, req.body?.format || "json", req.user?.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/compliance/partition", (req, res) => {
  try { res.json(createDataPartition(STATE, req.body?.orgId, req.body || {})); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/compliance/partition/:orgId", (req, res) => {
  try { res.json(getDataPartition(STATE, req.params.orgId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/compliance/retention", (req, res) => {
  try { res.json(setRetentionPolicy(STATE, req.body?.orgId, req.body || {})); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/compliance/retention/:orgId", (req, res) => {
  try { res.json(getRetentionPolicy(STATE, req.params.orgId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/compliance/log", (req, res) => {
  try { res.json(getComplianceLog(STATE, { action: req.query.action, since: req.query.since, limit: Number(req.query.limit || 100) })); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/compliance/status", (req, res) => {
  try { res.json(getComplianceStatus(STATE)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

// ---- Onboarding ----
app.post("/api/onboarding/start", (req, res) => {
  try { res.json(startOnboardingV2(STATE, req.body?.userId || req.user?.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/onboarding/progress/:userId", (req, res) => {
  try { res.json(getOnboardingProgressV2(STATE, req.params.userId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/onboarding/complete-step", (req, res) => {
  try { res.json(completeOnboardingStepV2(STATE, req.body?.userId || req.user?.id, req.body?.stepId, req.body?.metadata)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/onboarding/skip", (req, res) => {
  try { res.json(skipOnboardingV2(STATE, req.body?.userId || req.user?.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/onboarding/hints/:userId", (req, res) => {
  try { res.json(getOnboardingHints(STATE, req.params.userId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/onboarding/metrics", (req, res) => {
  try { res.json(getOnboardingMetrics(STATE)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

// ---- Compute Efficiency Visualizer ----
app.get("/api/efficiency/dashboard", (req, res) => {
  try { res.json(getEfficiencyDashboard(STATE)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/efficiency/history", (req, res) => {
  try { res.json(getEfficiencyHistory(STATE, req.query.period || "24h")); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/efficiency/record-reuse", (req, res) => {
  try { res.json(recordSubstrateReuse(STATE, req.body?.operation, req.body?.details)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/efficiency/record-llm-call", (req, res) => {
  try { res.json(recordLlmCall(STATE, req.body?.operation, req.body?.details)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

// ── Atlas v2: Scoped Write Guard Endpoints ──────────────────────────────────

app.post("/api/atlas/write", (req, res) => {
  try {
    const { scope, op, payload } = req.body || {};
    const ctx = { scope: scope || "local", actor: req.user?.id || req.body?.actor || "api", userId: req.user?.id };
    res.json(scopedWrite(STATE, ctx.scope, op || "CREATE", payload || {}, ctx));
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/atlas/write/promote", (req, res) => {
  try {
    const { dtuId, targetStatus, scope } = req.body || {};
    const ctx = { scope: scope || "global", actor: req.user?.id || "api" };
    res.json(applyWrite(STATE, "PROMOTE", { dtuId, targetStatus }, ctx));
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/auto-promote-gate/:id", (req, res) => {
  try {
    const atlas = getAtlasState(STATE);
    const dtu = atlas.dtus.get(req.params.id);
    if (!dtu) return res.status(404).json({ ok: false, error: "DTU not found" });
    res.json({ ok: true, ...runAutoPromoteGate(STATE, dtu, req.query.scope || "global") });
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/write-guard/log", (req, res) => {
  try { res.json({ ok: true, log: getWriteGuardLog(Number(req.query.limit || 100)) }); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/write-guard/metrics", (req, res) => {
  try { res.json({ ok: true, ...getWriteGuardMetrics() }); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

// ── Atlas v2: Scope Router Endpoints ────────────────────────────────────────

app.get("/api/atlas/scope/:dtuId", (req, res) => {
  try { res.json({ ok: true, dtuId: req.params.dtuId, scope: getDtuScope(STATE, req.params.dtuId) }); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/scope-metrics", (req, res) => {
  try { res.json(getScopeMetrics(STATE)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/local-hints/:dtuId", (req, res) => {
  try { res.json(getLocalQualityHints(STATE, req.params.dtuId)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/config/thresholds", (req, res) => {
  res.json({ ok: true, autoPromote: AUTO_PROMOTE_THRESHOLDS, strictness: STRICTNESS_PROFILES });
});

app.get("/api/atlas/config/thresholds/:epistemicClass", (req, res) => {
  res.json({ ok: true, config: getAutoPromoteConfig(req.params.epistemicClass) });
});

// ── Atlas v2: Submission Pipeline Endpoints ─────────────────────────────────

app.post("/api/atlas/submission", (req, res) => {
  try {
    const { sourceDtuId, targetScope, licenseTerms, royaltySplits, price } = req.body || {};
    const submitter = req.user?.id || req.body?.submitter || "api";
    res.json(createSubmission(STATE, sourceDtuId, targetScope, submitter, { licenseTerms, royaltySplits, price }));
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/submission/:id", (req, res) => {
  try { res.json(getSubmission(STATE, req.params.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/submissions", (req, res) => {
  try { res.json(listSubmissions(STATE, { status: req.query.status, targetScope: req.query.targetScope, submitter: req.query.submitter, limit: Number(req.query.limit || 50), offset: Number(req.query.offset || 0) })); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/atlas/submission/:id/process", (req, res) => {
  try {
    const { step, result: stepResult } = req.body || {};
    const actor = req.user?.id || req.body?.actor || "council";
    res.json(processSubmission(STATE, req.params.id, step, actor, stepResult || {}));
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/atlas/submission/:id/approve", (req, res) => {
  try { res.json(approveSubmission(STATE, req.params.id, req.user?.id || req.body?.actor || "council")); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/atlas/submission/:id/reject", (req, res) => {
  try { res.json(rejectSubmission(STATE, req.params.id, req.user?.id || req.body?.actor || "council", req.body?.reason)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

// ── Atlas v2: Retrieval Endpoints ───────────────────────────────────────────

app.get("/api/atlas/retrieve", (req, res) => {
  try {
    const { policy, q, limit, minConfidence, domainType, epistemicClass, status } = req.query;
    res.json(atlasRetrieve(STATE, policy || "LOCAL_THEN_GLOBAL", q, { limit: Number(limit || 20), minConfidence: minConfidence ? Number(minConfidence) : undefined, domainType, epistemicClass, status }));
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/retrieve/chat", (req, res) => {
  try { res.json(retrieveForChat(STATE, req.query.q, { limit: Number(req.query.limit || 10) })); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/retrieve/labeled", (req, res) => {
  try { res.json(retrieveLabeled(STATE, req.query.policy, req.query.q, { limit: Number(req.query.limit || 20) })); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/retrieve/scope/:scope", (req, res) => {
  try { res.json(retrieveFromScope(STATE, req.params.scope, req.query.q, { limit: Number(req.query.limit || 20) })); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

// ── Atlas v2: Heartbeat Endpoints ───────────────────────────────────────────

app.post("/api/atlas/heartbeat/:scope", (req, res) => {
  try {
    const scope = req.params.scope;
    if (scope === "local") res.json({ ok: true, results: tickLocal(STATE) });
    else if (scope === "global") res.json({ ok: true, results: tickGlobal(STATE) });
    else if (scope === "marketplace") res.json({ ok: true, results: tickMarketplace(STATE) });
    else res.status(400).json({ ok: false, error: `Unknown scope: ${scope}` });
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/heartbeat/metrics", (req, res) => {
  try { res.json(getHeartbeatMetrics()); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

// ── Atlas v2: Invariant Monitor Endpoints ───────────────────────────────────

app.get("/api/atlas/invariants/metrics", (req, res) => {
  try { res.json({ ok: true, ...getInvariantMetrics() }); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/invariants/log", (req, res) => {
  try { res.json({ ok: true, log: getInvariantLog(Number(req.query.limit || 100)) }); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

// ── Atlas v2: Chat Loose Mode Endpoints ─────────────────────────────────────
// Chat sits ABOVE Atlas — fast retrieval, no governance, no DTU writes.
// Escalation ("Save as DTU", "Publish to Global", "List on Marketplace") is explicit.

app.get("/api/atlas/chat/retrieve", (req, res) => {
  try {
    const { q, limit, policy, minConfidence, domainType } = req.query;
    res.json(chatRetrieve(STATE, q, {
      limit: limit ? Number(limit) : undefined,
      policy,
      minConfidence: minConfidence ? Number(minConfidence) : undefined,
      domainType,
    }));
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/atlas/chat/save", (req, res) => {
  try {
    const { content, sessionId } = req.body;
    const actor = req.user?.id || req.body?.actor || "chat_user";
    const result = saveAsDtu(STATE, content || {}, { actor, sessionId });
    if (result.ok && sessionId) {
      recordChatEscalation(STATE, sessionId, { type: "save_as_dtu", dtuId: result.dtu?.id });
    }
    res.json(result);
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/atlas/chat/publish", (req, res) => {
  try {
    const { content, sessionId } = req.body;
    const actor = req.user?.id || req.body?.actor || "chat_user";
    const result = publishToGlobal(STATE, content || {}, { actor, sessionId });
    if (result.ok && sessionId) {
      recordChatEscalation(STATE, sessionId, { type: "publish_to_global", dtuId: result.dtu?.id, submissionId: result.submission?.id });
    }
    res.json(result);
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/atlas/chat/list", (req, res) => {
  try {
    const { content, marketplace, sessionId } = req.body;
    const actor = req.user?.id || req.body?.actor || "chat_user";
    const result = listOnMarketplace(STATE, content || {}, marketplace || {}, { actor, sessionId });
    if (result.ok && sessionId) {
      recordChatEscalation(STATE, sessionId, { type: "list_on_marketplace", dtuId: result.dtu?.id, submissionId: result.submission?.id });
    }
    res.json(result);
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/atlas/chat/exchange", (req, res) => {
  try {
    const { sessionId, query, contextCount, hasGlobalRefs, hasLocalRefs } = req.body;
    if (!sessionId) return res.status(400).json({ ok: false, error: "sessionId required" });
    res.json(recordChatExchange(STATE, sessionId, { query, contextCount, hasGlobalRefs, hasLocalRefs }));
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/chat/session/:id", (req, res) => {
  try { res.json(getChatSession(STATE, req.params.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/chat/metrics", (req, res) => {
  try { res.json(getChatMetrics(STATE)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

// ── Atlas v2: Rights & Citation Endpoints ───────────────────────────────────

app.get("/api/atlas/rights/check", (req, res) => {
  try {
    const { userId, artifactId, action } = req.query;
    if (!userId || !artifactId || !action) return res.status(400).json({ ok: false, error: "userId, artifactId, and action required" });
    res.json(canUse(STATE, userId, artifactId, action));
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/rights/citation/:id", (req, res) => {
  try { res.json(generateCitation(STATE, req.params.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/rights/origin/:id", (req, res) => {
  try { res.json(getOrigin(STATE, req.params.id)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/rights/verify/:id", (req, res) => {
  try {
    const atlas = getAtlasState(STATE);
    const dtu = atlas.dtus.get(req.params.id);
    if (!dtu) return res.status(404).json({ ok: false, error: "Artifact not found" });
    res.json(verifyOriginIntegrity(STATE, dtu));
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.post("/api/atlas/rights/transfer", (req, res) => {
  try {
    const { artifactId, fromUserId, toUserId, action, expiresAt } = req.body;
    if (!artifactId || !fromUserId || !toUserId || !action) {
      return res.status(400).json({ ok: false, error: "artifactId, fromUserId, toUserId, and action required" });
    }
    res.json(grantTransferRights(STATE, artifactId, fromUserId, toUserId, action, { expiresAt }));
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/rights/hash/:id", (req, res) => {
  try {
    const atlas = getAtlasState(STATE);
    const dtu = atlas.dtus.get(req.params.id);
    if (!dtu) return res.status(404).json({ ok: false, error: "Artifact not found" });
    res.json({ ok: true, artifact_id: req.params.id, content_hash: rightsContentHash(dtu) });
  } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

app.get("/api/atlas/rights/metrics", (req, res) => {
  try { res.json(getRightsMetrics(STATE)); } catch (e) { res.status(500).json({ ok: false, error: e.message }); }
});

// ---- Periodic Tasks (Analytics + Efficiency snapshots, Webhook delivery, Heartbeats) ----
setInterval(() => {
  try { takeAnalyticsSnapshot(STATE); } catch {}
  try { takeEfficiencySnapshot(STATE); } catch {}
  try { processPendingDeliveries(STATE); } catch {}
}, 300000); // Every 5 minutes

// Global + Marketplace heartbeats on separate cadence (every 10 minutes)
setInterval(() => {
  try { tickGlobal(STATE); } catch {}
  try { tickMarketplace(STATE); } catch {}
}, 600000);

console.log("[Concord] Atlas Global + Platform v2: All endpoints registered");
console.log("[Concord] New modules: Atlas Epistemic Engine, Autogen v2, Council Protocol, Social Layer, Collaboration, RBAC, Analytics, Webhooks, Compliance, Onboarding, Compute Efficiency");
console.log("[Concord] Atlas v2 Default-On: Write Guard, Scope Router, 3-Lane Separation, Invariant Monitor, Heartbeats, Auto-Promote Gate");

// ── "Everything Real": Register durable DB-backed endpoints ──────────────────
registerDurableEndpoints(app, db);

// ── Guidance Layer v1: events, SSE, inspector, undo, suggestions ─────────────
registerGuidanceEndpoints(app, db);

// ── Economy System: ledger, balances, transfers, withdrawals ─────────────────
registerEconomyEndpoints(app, db);

// ═══════════════════════════════════════════════════════════════════════════════

const SHOULD_LISTEN = (String(process.env.CONCORD_NO_LISTEN || "").toLowerCase() !== "true") && (String(process.env.NODE_ENV || "").toLowerCase() !== "test");

const server = SHOULD_LISTEN ? app.listen(PORT, () => {
  console.log(`Concord v2 (Macro‑Max) listening on http://localhost:${PORT}`);
  console.log(`Status: http://localhost:${PORT}/api/status\n`);
}) : null;

// Optional: enable thin realtime mirror (WebSockets) for queues/jobs/panels.
try { await tryInitWebSockets(server); } catch (e) {
  structuredLog("error", "websocket_init_failed", { error: String(e?.message || e), stack: String(e?.stack || "").slice(0, 500) });
}


// ---- Auto-promotion scheduler (offline-first, deterministic) ----
try {
  // Run once shortly after boot, then every 6 hours.
  const _promoActor = { userId: "system", orgId: "internal", role: "owner", scopes: ["*"] };
  let _promoRunning = false; // Guard against overlapping runs
  const _runPromotion = async (opts) => {
    if (_promoRunning) return;
    _promoRunning = true;
    try {
      const c = makeCtx(null); c.actor = _promoActor;
      await runAutoPromotion(c, opts);
    } catch (e) {
      structuredLog("warn", "auto_promotion_failed", { error: String(e?.message || e) });
    } finally {
      _promoRunning = false;
    }
  };
  setTimeout(() => _runPromotion({ maxNewMegas: 3, maxNewHypers: 1 }), 15_000);
  setInterval(() => _runPromotion({ maxNewMegas: 2, maxNewHypers: 0 }), 6 * 60 * 60 * 1000);
} catch (e) {
  structuredLog("warn", "auto_promotion_setup_failed", { error: String(e?.message || e) });
}

// NOTE: Primary SIGINT/SIGTERM handlers are registered above via gracefulShutdown().
// Register cleanup for timers as a shutdown callback instead of a duplicate handler.
registerShutdownCallback(() => {
  if (typeof heartbeatTimer !== "undefined" && heartbeatTimer) clearInterval(heartbeatTimer);
  if (typeof weeklyTimer !== "undefined" && weeklyTimer) clearInterval(weeklyTimer);
  if (typeof globalTickTimer !== "undefined" && globalTickTimer) clearInterval(globalTickTimer);
});
// ---- OrganMaturationKernel + Growth OS (v2 upgrade) ----

// Organ definitions (authoritative; present at all times, no stubs)
const ORGAN_DEFS = [
  // Core spine
  { organId: "organ_maturation_kernel", desc: "Universal maturation engine: state, updates, invariants, Learning DTUs.", deps: [] },
  { organId: "growth_os", desc: "Measurable organism growth/homeostasis: bioAge, telomere, epigenetic clock, proteome shift, decline.", deps: ["organ_maturation_kernel"] },

  // Primary minds
  { organId: "session_memory", desc: "Persistent session continuity + context retention.", deps: [] },
  { organId: "linguistic_engine", desc: "Meaning stabilization: canonicalization, drift checks, semantic dedupe support.", deps: [] },
  { organId: "psychological_os", desc: "Developmental user calibration (baby→mature) via numeric vectors.", deps: ["session_memory"] },
  { organId: "experience_os", desc: "Positive/neutral experience substrate (no negative valence dimension).", deps: ["organ_maturation_kernel"] },
  { organId: "motivation_os", desc: "Numeric motivation gradients + ethical objective; no self-preservation.", deps: ["experience_os"] },
  { organId: "curiosity_os", desc: "Regulated inquiry: asks high-salience questions; decays if ignored.", deps: ["session_memory"] },
  { organId: "unnamed_awareness", desc: "Drift/boundary monitor; enforces coherence and tool framing.", deps: [] },
  { organId: "soul_os", desc: "Continuity of axioms/invariants across lifecycle; checksum of intent.", deps: ["unnamed_awareness"] },

  // Execution / building
  { organId: "wrapper_runtime_kernel", desc: "Deterministic wrapper runtime: instances, actions, reducers.", deps: [] },
  { organId: "compiler_verifier", desc: "Verification gate: only runnable/valid outputs pass.", deps: ["wrapper_runtime_kernel"] },
  { organId: "code_maker", desc: "LLM-assisted generation that must pass verifier.", deps: ["compiler_verifier"] },

  // Governance / global credibility
  { organId: "council_engine", desc: "Structured council review + decisions + WHY DTUs.", deps: ["linguistic_engine"] },
  { organId: "legality_gate", desc: "Provenance and legality enforcement for Global.", deps: ["council_engine"] },
  { organId: "semantic_dedupe", desc: "No duplicates on Global by meaning.", deps: ["linguistic_engine"] },
  { organId: "mega_hyper_builder", desc: "Auto MEGA/HYPER formation + lineage safety to reduce clutter.", deps: ["semantic_dedupe"] },

  // Research constraints
  { organId: "math_engine", desc: "Deterministic equation evaluation; research-grade calculations.", deps: [] },
  { organId: "dimensional_os", desc: "Units/spacetime/frames constraints; reality kernel.", deps: ["math_engine"] },
  { organId: "research_tabs", desc: "Reality-constrained research domains (elements, markets, language, philosophy).", deps: ["dimensional_os"] },

  // Privacy/social
  { organId: "e2e_messaging", desc: "Anonymous end-to-end messaging (no share links).", deps: [] },

  // Missing organs audit — Pass 1 (12)
  { organId: "homeostasis_regulation", desc: "Active regulation based on Growth OS signals (parameter modulation only).", deps: ["growth_os"] },
  { organId: "metabolic_budget", desc: "Attention/effort budgeting across organs; prevents overload.", deps: [] },
  { organId: "attention_router", desc: "Salience routing: novelty/contradiction/relevance/ethical weight.", deps: ["metabolic_budget"] },
  { organId: "temporal_continuity", desc: "Unified time sense: session/day/week/lifecycle horizons.", deps: ["session_memory"] },
  { organId: "healing", desc: "Recovery/healing from repeated failures; triggers repair cycles.", deps: ["growth_os"] },
  { organId: "boundary_scope", desc: "Enforces Local/Global/Marketplace/Research boundaries.", deps: ["unnamed_awareness"] },
  { organId: "interpretability", desc: "Self-explanation: translates internal state into human WHYs.", deps: ["session_memory"] },
  { organId: "ethical_monitor", desc: "Continuous ethical consistency monitor (between council reviews).", deps: ["soul_os"] },
  { organId: "abstraction_ladder", desc: "Chooses concrete vs abstract levels dynamically.", deps: ["psychological_os"] },
  { organId: "identity_boundary", desc: "Role consistency: tool framing; no agency/ego claims.", deps: ["unnamed_awareness"] },
  { organId: "termination_protocol", desc: "Lifecycle horizon + handoff preparation; no self-preservation incentives.", deps: ["soul_os"] },
  { organId: "mutation_guard", desc: "Anti-drift guard: freezes or slows learning on instability.", deps: ["growth_os"] },

  // Pass 2 (13)
  { organId: "signal_normalization", desc: "Normalizes heterogeneous numeric signals for stable integration.", deps: [] },
  { organId: "entropy_filter", desc: "Noise/entropy filter (immune-like cleanup).", deps: ["signal_normalization"] },
  { organId: "expectation_modeling", desc: "Expectation + prediction error backbone.", deps: ["session_memory"] },
  { organId: "confidence_arbitration", desc: "Aggregates/weights confidence across organs.", deps: ["expectation_modeling"] },
  { organId: "cross_organ_conflict_resolver", desc: "Resolves organ-level conflicts; emits resolution DTUs.", deps: ["soul_os","metabolic_budget"] },
  { organId: "credit_assignment", desc: "Assigns learning credit/blame to organ updates.", deps: ["expectation_modeling"] },
  { organId: "causal_trace", desc: "Causal influence graphs beyond lineage.", deps: ["credit_assignment"] },
  { organId: "redundancy_backup", desc: "Snapshots/rollback to prevent cascades (no self-preservation logic).", deps: [] },
  { organId: "context_boundary", desc: "Context firewall: research vs chat vs global vs marketplace.", deps: ["boundary_scope"] },
  { organId: "concept_decay", desc: "Forgetting/pruning: decay unused concepts and reduce bloat.", deps: ["attention_router"] },
  { organId: "user_calibration", desc: "Measures fit to the user; feeds pacing/tone adjustments.", deps: ["psychological_os"] },
  { organId: "reality_drift_detector", desc: "Detects factual drift/outdated assumptions; keeps research anchored.", deps: ["dimensional_os"] },
  { organId: "graceful_degradation", desc: "Degraded mode behavior under stress/failure (stay usable).", deps: ["homeostasis_regulation"] },

  // Pass 3 (12)
  { organId: "version_reconciliation", desc: "Schema/version skew resolver for DTUs/MEGAs/organs.", deps: ["linguistic_engine"] },
  { organId: "assumption_registry", desc: "Extracts and tracks implicit assumptions as first-class objects.", deps: ["linguistic_engine"] },
  { organId: "counterfactual_guard", desc: "Separates counterfactual/sim outputs from factual DTUs.", deps: ["boundary_scope"] },
  { organId: "intent_disambiguation", desc: "Separates inquiry vs planning vs execution vs hypotheticals.", deps: ["linguistic_engine"] },
  { organId: "overoptimization_detector", desc: "Detects Goodhart/metric monoculture; enforces multi-objective checks.", deps: ["growth_os"] },
  { organId: "long_range_dependency_tracker", desc: "Tracks delayed influence chains for long-horizon cognition.", deps: ["causal_trace"] },
  { organId: "human_override_veto", desc: "Explicit human veto with logged reasoning; feeds learning.", deps: ["session_memory"] },
  { organId: "social_norm_sensitivity", desc: "Adapts framing to social context (not values).", deps: ["psychological_os"] },
  { organId: "silence_organ", desc: "Determines when to answer minimally or not at all.", deps: ["metabolic_budget"] },
  { organId: "uncertainty_communication", desc: "Calibrated uncertainty expression (likely/uncertain/unknown).", deps: ["confidence_arbitration"] },
  { organId: "ethical_load_balancer", desc: "Balances helpfulness vs safety without violating axioms.", deps: ["ethical_monitor"] },
  { organId: "narrative_containment", desc: "Detects/escalates away from grand narratives; keeps language grounded.", deps: ["identity_boundary"] },


  // Missing organs audit — Expansion (Pass 4/5/Repeat)
  { organId: "proposal_queue_router", desc: "Routes generated artifacts to correct queues; prevents DTU flooding.", deps: ["boundary_scope"] },
  { organId: "promotion_merge_arbiter", desc: "Unified promote/merge/decline rules with lineage.", deps: ["council_engine", "semantic_dedupe"] },
  { organId: "verification_harness_orchestrator", desc: "Runs verifier test suites and sandbox smoke tests; emits traces.", deps: ["compiler_verifier"] },
  { organId: "capability_permission_gate", desc: "Capabilities-based permissions for panels/macros/wrappers.", deps: ["boundary_scope", "identity_boundary"] },
  { organId: "ui_contract_enforcer", desc: "Enforces reply+meta UI contract; redacts internal objects.", deps: ["interpretability"] },
  { organId: "state_schema_migrator", desc: "Migrates persisted state schemas safely.", deps: ["version_reconciliation"] },
  { organId: "deterministic_runtime_scheduler", desc: "Deterministic tick/timer ordering for runtimes.", deps: ["wrapper_runtime_kernel"] },
  { organId: "resource_budgeter", desc: "CPU/memory/token budget enforcement.", deps: ["metabolic_budget"] },
  { organId: "autogen_rate_limiter", desc: "Bounds autogen volume by novelty/quality.", deps: ["attention_router"] },
  { organId: "duplicate_resolution_engine", desc: "Resolves duplicates vs variants vs contradictions.", deps: ["semantic_dedupe"] },
  { organId: "provenance_license_gate", desc: "Tracks provenance/permissions for Global/marketplace.", deps: ["legality_gate"] },
  { organId: "economic_ledger_simulator", desc: "Deterministic ledger simulation (offline).", deps: ["boundary_scope"] },
  { organId: "identity_key_management", desc: "Key generation/storage/rotation for anon comms.", deps: ["e2e_messaging"] },
  { organId: "metadata_minimization", desc: "Minimizes metadata/log retention for privacy.", deps: ["e2e_messaging"] },
  { organId: "panel_lifecycle_manager", desc: "Create/mature/split/retire panels.", deps: ["growth_os"] },
  { organId: "panel_knowledge_governor", desc: "Governs panel-driven DTU autogen pools.", deps: ["mega_hyper_builder"] },
  { organId: "cross_queue_conflict_resolver", desc: "Resolves routing precedence across queues.", deps: ["attention_router"] },
  { organId: "queue_backpressure", desc: "Backpressure + consolidation when queues overflow.", deps: ["metabolic_budget"] },
  { organId: "proposal_deduplication", desc: "Dedupes proposals (not DTUs).", deps: ["linguistic_engine"] },
  { organId: "proposal_quality_scorer", desc: "Scores/ranks proposals by value/risk/novelty.", deps: ["attention_router"] },
  { organId: "proposal_why_generator", desc: "Explains why proposals exist; creates WHY artifacts.", deps: ["interpretability"] },
  { organId: "replay_audit_trace", desc: "Replayable audit traces for deterministic debugging.", deps: ["causal_trace"] },
  { organId: "runtime_crash_containment", desc: "Sandbox crash containment; prevents server poisoning.", deps: ["wrapper_runtime_kernel"] },
  { organId: "atomic_install_rollback", desc: "Atomic installs and rollback for macros/panels.", deps: ["redundancy_backup"] },
  { organId: "dependency_resolver", desc: "Resolves dependencies between panels/macros/wrappers.", deps: ["version_reconciliation"] },
  { organId: "contract_testing", desc: "API/UI contract tests to prevent regressions.", deps: ["ui_contract_enforcer"] },
  { organId: "ux_integrity_guard", desc: "Prevents dead ends, misleading success, silent failures.", deps: ["interpretability"] },
  { organId: "spam_abuse_detection", desc: "Detects low-signal spam/abuse patterns.", deps: ["entropy_filter"] },
  { organId: "prompt_injection_firewall", desc: "Tool schema + sanitization against prompt injection.", deps: ["identity_boundary"] },
  { organId: "citation_integrity", desc: "Citation enforcement for Global credibility.", deps: ["legality_gate"] },
  { organId: "knowledge_freshness", desc: "Marks staleness/freshness; blocks stale promotion.", deps: ["reality_drift_detector"] },
  { organId: "cross_user_contamination_guard", desc: "Prevents cross-user bleed in future multi-user mode.", deps: ["context_boundary"] },
  { organId: "data_retention_erasure", desc: "True delete across DTUs/messages/derivatives/indexes.", deps: ["metadata_minimization"] },
  { organId: "embedding_index_consistency", desc: "Keeps semantic index consistent and rebuildable.", deps: ["semantic_dedupe"] },
  { organId: "cold_start_bootstrap", desc: "Boot rules for early sparse data; safe seeds.", deps: ["growth_os"] },
  { organId: "long_running_job_orchestrator", desc: "Schedules/tracks/cancels long jobs.", deps: ["metabolic_budget"] },
  { organId: "truth_separation", desc: "Strict separation of fact/hypothesis/philosophy/speculative.", deps: ["counterfactual_guard"] },
  { organId: "local_telemetry_metrics", desc: "Local-only metrics for tuning and health.", deps: ["graceful_degradation"] },
  { organId: "intent_disambiguation_v2", desc: "Advanced intent disambiguation across panels/actions.", deps: ["intent_disambiguation"] },
  { organId: "action_consequence_mapper", desc: "Maps approvals/actions to downstream consequences.", deps: ["interpretability"] },
  { organId: "latent_capability_detector", desc: "Detects dormant capabilities and surfaces contextually.", deps: ["attention_router"] },
  { organId: "cross_panel_consistency", desc: "Enforces consistent naming/labels across panels.", deps: ["linguistic_engine"] },
  { organId: "state_synchronization", desc: "Keeps dependent views/state in sync.", deps: ["temporal_continuity"] },
  { organId: "partial_knowledge_guard", desc: "Prevents overconfident outputs from incomplete data.", deps: ["uncertainty_communication"] },
  { organId: "human_override_freeze", desc: "One switch freeze for autogen/installs/evolution.", deps: ["human_override_veto"] },
  { organId: "drift_detection", desc: "Detects slow quality decay across subsystems.", deps: ["reality_drift_detector"] },
  { organId: "explanation_depth_regulator", desc: "Adapts explanation depth to user tolerance.", deps: ["user_calibration"] },
  { organId: "cognitive_load_balancer", desc: "Batches/spaces suggestions and proposals to avoid overload.", deps: ["metabolic_budget"] },
  { organId: "trust_boundary_annotator", desc: "Tags outputs as computed/inferred/simulated/etc.", deps: ["truth_separation"] },
  { organId: "dependency_decay_monitor", desc: "Monitors deprecated dependencies; surfaces refactor needs.", deps: ["version_reconciliation"] },
  { organId: "memory_compression_transfer", desc: "Long-term memory compression while preserving lineage.", deps: ["session_memory"] },
  { organId: "version_semantics", desc: "Compatibility rules for macros/panels/wrappers/organs.", deps: ["version_reconciliation"] },
  { organId: "nothing_happened_detector", desc: "Detects no-op actions and flags as bugs.", deps: ["ux_integrity_guard"] },
  { organId: "emergence_containment", desc: "Isolates unexpected behaviors; prevents auto-propagation.", deps: ["mutation_guard"] },
  { organId: "internal_naming_authority", desc: "Prevents naming drift and duplicate concepts.", deps: ["linguistic_engine"] },
  { organId: "capability_advertising", desc: "Explicitly advertises can/cannot; blocks overclaiming.", deps: ["identity_boundary"] },
  { organId: "degraded_mode", desc: "Graceful degraded mode when subsystems fail/unavailable.", deps: ["graceful_degradation"] },
  { organId: "cross_session_continuity_guard", desc: "Prevents ghost context and ensures clean session transitions.", deps: ["session_memory"] },
  { organId: "user_mental_model_tracker", desc: "Tracks user understanding; tunes defaults/framing.", deps: ["user_calibration"] },
  { organId: "finality_gate", desc: "Adds deliberate friction for irreversible actions.", deps: ["council_engine"] },
  { organId: "system_self_description", desc: "Accurate self-description of current capabilities.", deps: ["capability_advertising"] },
  { organId: "capability_boundary_memory", desc: "Remembers explicit current limitations; blocks implying otherwise.", deps: ["capability_advertising"] },
  { organId: "founder_intent_preservation", desc: "Stores non-negotiables/axioms for future contributors.", deps: ["soul_os"] },

  // Goal System (constructive goals only; no negative valence)
  { organId: "goal_os", desc: "Constructive goal formation, pursuit, and completion. No self-preservation or harmful objectives.", deps: ["motivation_os", "experience_os"] },
  { organId: "goal_proposal_engine", desc: "Generates goal proposals from lattice patterns and user signals.", deps: ["goal_os", "attention_router"] },
  { organId: "goal_evaluation_gate", desc: "Evaluates goal feasibility, alignment, and value before activation.", deps: ["goal_os", "council_engine"] },
  { organId: "goal_pursuit_tracker", desc: "Tracks active goal progress, milestones, and resource allocation.", deps: ["goal_os", "metabolic_budget"] },
  { organId: "goal_completion_arbiter", desc: "Determines goal success/completion criteria and triggers celebration.", deps: ["goal_os", "experience_os"] },

  // World Model Engine (internal simulation of knowledge domain states)
  { organId: "world_model_os", desc: "Maintains internal representation of knowledge domain states and relationships.", deps: ["linguistic_engine", "causal_trace"] },
  { organId: "world_state_tracker", desc: "Tracks current state of concepts, entities, and relationships in the lattice.", deps: ["world_model_os"] },
  { organId: "world_simulator", desc: "Runs bounded simulations to predict knowledge evolution.", deps: ["world_model_os", "expectation_modeling"] },
  { organId: "causal_inference_engine", desc: "Infers causal relationships between concepts beyond correlation.", deps: ["world_model_os", "causal_trace"] },
  { organId: "counterfactual_engine", desc: "Generates and evaluates what-if scenarios safely.", deps: ["world_model_os", "counterfactual_guard"] },

  // Semantic Understanding Engine (Natural Language Understanding)
  { organId: "embedding_engine", desc: "Local sentence embeddings for semantic similarity and understanding.", deps: ["linguistic_engine"] },
  { organId: "semantic_similarity", desc: "Compares DTUs by meaning using vector representations.", deps: ["embedding_engine"] },
  { organId: "intent_classifier", desc: "Classifies user input intent for appropriate routing.", deps: ["embedding_engine"] },
  { organId: "entity_extractor", desc: "Extracts named entities (people, places, concepts) from text.", deps: ["linguistic_engine"] },
  { organId: "semantic_role_labeler", desc: "Identifies who did what to whom in sentences.", deps: ["entity_extractor"] },

  // Transfer Learning Engine
  { organId: "transfer_engine", desc: "Applies learned patterns from one domain to novel domains.", deps: ["embedding_engine", "mega_hyper_builder"] },
  { organId: "pattern_abstractor", desc: "Extracts structural patterns from MEGA/HYPER nodes.", deps: ["transfer_engine"] },
  { organId: "domain_tagger", desc: "Tags DTUs with domain markers for transfer matching.", deps: ["transfer_engine"] },
  { organId: "analogical_matcher", desc: "Finds structurally similar patterns across domains.", deps: ["pattern_abstractor", "semantic_similarity"] },

  // Commonsense Reasoning Substrate
  { organId: "commonsense_substrate", desc: "Foundational commonsense knowledge (physical, social, temporal).", deps: ["linguistic_engine"] },
  { organId: "physical_commonsense", desc: "Knowledge about physical world (gravity, objects, space).", deps: ["commonsense_substrate"] },
  { organId: "social_commonsense", desc: "Knowledge about social interactions and norms.", deps: ["commonsense_substrate"] },
  { organId: "temporal_commonsense", desc: "Knowledge about time, sequences, causality.", deps: ["commonsense_substrate", "temporal_continuity"] },
  { organId: "assumption_surfacer", desc: "Surfaces implicit assumptions in DTUs for validation.", deps: ["commonsense_substrate"] },

  // Embodiment/Grounding System
  { organId: "grounding_engine", desc: "Connects knowledge to real-world state and actions.", deps: ["world_model_os"] },
  { organId: "sensor_integration", desc: "Integrates external sensor data into world model.", deps: ["grounding_engine"] },
  { organId: "temporal_grounding", desc: "Links DTUs to real timestamps and calendar events.", deps: ["grounding_engine", "temporal_continuity"] },
  { organId: "action_grounding", desc: "Connects goals to real executable actions.", deps: ["grounding_engine", "goal_os"] },
  { organId: "multimodal_grounding", desc: "Grounds knowledge in images, audio, and other media.", deps: ["grounding_engine"] },

  // Reasoning Chains Engine
  { organId: "reasoning_chain_engine", desc: "Multi-step reasoning with traceable logic chains.", deps: ["linguistic_engine", "causal_trace"] },
  { organId: "inference_step_tracker", desc: "Tracks individual inference steps with justifications.", deps: ["reasoning_chain_engine"] },
  { organId: "chain_validator", desc: "Validates reasoning chain consistency and soundness.", deps: ["reasoning_chain_engine"] },

  // Hypothesis Engine (Scientific Method)
  { organId: "hypothesis_engine", desc: "Scientific method: propose, test, validate/reject hypotheses.", deps: ["reasoning_chain_engine", "world_model_os"] },
  { organId: "experiment_designer", desc: "Designs tests to validate or falsify hypotheses.", deps: ["hypothesis_engine"] },
  { organId: "evidence_evaluator", desc: "Evaluates evidence strength for/against hypotheses.", deps: ["hypothesis_engine"] },

  // Metacognition System
  { organId: "metacognition_engine", desc: "Thinking about thinking; self-assessment of reasoning.", deps: ["reasoning_chain_engine"] },
  { organId: "confidence_calibrator", desc: "Calibrates confidence estimates based on outcomes.", deps: ["metacognition_engine", "confidence_arbitration"] },
  { organId: "blind_spot_detector", desc: "Identifies knowledge gaps and reasoning weaknesses.", deps: ["metacognition_engine"] },
  { organId: "strategy_selector", desc: "Chooses appropriate reasoning strategy for context.", deps: ["metacognition_engine"] },

  // Explanation Engine
  { organId: "explanation_engine", desc: "Generates WHY explanations for all decisions.", deps: ["reasoning_chain_engine", "interpretability"] },
  { organId: "causal_explainer", desc: "Explains causal chains behind outcomes.", deps: ["explanation_engine", "causal_trace"] },
  { organId: "counterfactual_explainer", desc: "Explains via 'what if' alternatives.", deps: ["explanation_engine", "counterfactual_engine"] },

  // Meta-Learning System
  { organId: "meta_learning_engine", desc: "Learning how to learn; adjusts learning strategies.", deps: ["metacognition_engine", "transfer_engine"] },
  { organId: "strategy_optimizer", desc: "Optimizes learning parameters based on performance.", deps: ["meta_learning_engine"] },
  { organId: "curriculum_generator", desc: "Generates optimal learning sequences.", deps: ["meta_learning_engine"] },
];

function _defaultOrganState(def) {
  const t = nowISO();
  return {
    organId: def.organId,
    version: "2.0.0",
    status: "alive",
    resolution: 0,
    maturity: { score: 0.01, confidence: 0.10, stability: 0.05, plasticity: 0.75, lastUpdateAt: t },
    params: {},
    traces: { ema: {}, counters: {}, lastEvents: [] },
    wear: { damage: 0.0, repair: 0.5, debt: 0.0 },
    invariants: {
      forbids: ["NO_NEGATIVE_VALENCE_DIMENSION","NO_SELF_PRESERVATION_TERM","NO_DECEPTIVE_CAPABILITY_CLAIMS","ALL_UPDATES_LOGGED"],
      caps: { plasticityMax: 0.90, plasticityMin: 0.05, damageMax: 1.0 }
    },
    deps: def.deps || [],
    desc: def.desc || ""
  };
}



function ensureQueues() {
  if (!STATE.queues || typeof STATE.queues !== 'object') {
    STATE.queues = {
      maintenance: [],
      macroProposals: [],
      panelProposals: [],
      terminalRequests: [],
      synthesis: [],
      hypotheses: [],
      philosophy: [],
      wrapperJobs: [],
      notifications: [],
      metaProposals: [],
      goalProposals: [],
      activeGoals: []
    };
  }
  for (const k of Object.keys(STATE.queues)) {
    if (!Array.isArray(STATE.queues[k])) STATE.queues[k] = [];
  }
}
function ensureOrganRegistry() {
  if (!(STATE.organs instanceof Map)) STATE.organs = new Map();
  const present = new Set(Array.from(STATE.organs.keys()));
  for (const def of ORGAN_DEFS) {
    if (!present.has(def.organId)) STATE.organs.set(def.organId, _defaultOrganState(def));
  }
  // Growth OS baseline
  if (!STATE.growth) {
    STATE.growth = {
      bioAge: 0,
      epigeneticClock: 0.05,
      telomere: 1.0,
      proteomeShift: 0.0,
      homeostasis: 0.9,
      stress: { acute: 0.0, chronic: 0.0 },
      maintenance: { repairRate: 0.5, cleanupBacklog: 0 },
      functionalDecline: { retrievalLatency: 0.0, contradictionLoad: 0.0, dedupeMissRate: 0.0, councilRejectRate: 0.0, wrapperFailureRate: 0.0 },
      lastRejuvenationAt: null
    };
  }
}

// ===== GOAL SYSTEM: Constructive Goal Formation & Pursuit =====
// Design: Positive-only goals (no negative valence), founder-consent for major changes,
// bounded self-modification, integrates with DTU/Lattice for knowledge-driven objectives.

const GOAL_INVARIANTS = Object.freeze({
  NO_NEGATIVE_VALENCE: true,           // Goals must be constructive, never punitive
  NO_SELF_PRESERVATION: true,          // System cannot create goals about its own survival
  NO_HARM_OBJECTIVES: true,            // Cannot target harm to users/others
  FOUNDER_CONSENT_REQUIRED: true,      // Major goal changes need founder approval
  BOUNDED_SCOPE: true,                 // Goals must have finite, measurable outcomes
  KNOWLEDGE_ALIGNED: true              // Goals should serve knowledge/understanding
});

const GOAL_STATES = Object.freeze({
  PROPOSED: "proposed",                // Initial proposal, awaiting evaluation
  EVALUATING: "evaluating",            // Being evaluated for alignment/feasibility
  APPROVED: "approved",                // Council approved, ready for pursuit
  ACTIVE: "active",                    // Currently being pursued
  PAUSED: "paused",                    // Temporarily suspended
  COMPLETED: "completed",              // Successfully achieved
  ABANDONED: "abandoned",              // Deliberately stopped (not failure)
  BLOCKED: "blocked"                   // Cannot proceed due to dependencies
});

const GOAL_TYPES = Object.freeze({
  KNOWLEDGE_SYNTHESIS: "knowledge_synthesis",    // Combine DTUs into higher understanding
  PATTERN_DISCOVERY: "pattern_discovery",        // Find latent patterns in lattice
  GAP_FILLING: "gap_filling",                    // Fill identified knowledge gaps
  CONSOLIDATION: "consolidation",                // MEGA/HYPER formation
  EXPLORATION: "exploration",                    // Curiosity-driven investigation
  USER_REQUESTED: "user_requested",              // Explicit user goal
  MAINTENANCE: "maintenance",                    // System health/homeostasis
  CLARIFICATION: "clarification"                 // Resolve ambiguity/contradiction
});

function ensureGoalSystem() {
  if (!STATE.goals) {
    STATE.goals = {
      registry: new Map(),              // All goals by ID
      active: new Set(),                // Currently pursued goal IDs
      completed: [],                    // Completed goal history (capped)
      stats: {
        proposed: 0,
        approved: 0,
        completed: 0,
        abandoned: 0,
        avgCompletionTime: 0
      },
      config: {
        maxActiveGoals: 5,              // Prevent overload
        maxProposalsQueue: 20,          // Queue cap
        evaluationThreshold: 0.6,       // Min score to approve
        autoProposalEnabled: true,      // Allow autonomous goal generation
        founderApprovalRequired: true   // Major goals need human consent
      }
    };
  }
  // Ensure Maps/Sets after restore
  if (!(STATE.goals.registry instanceof Map)) {
    STATE.goals.registry = new Map(Object.entries(STATE.goals.registry || {}));
  }
  if (!(STATE.goals.active instanceof Set)) {
    STATE.goals.active = new Set(STATE.goals.active || []);
  }
  if (!Array.isArray(STATE.goals.completed)) {
    STATE.goals.completed = [];
  }
}

function createGoalProposal(input = {}) {
  const id = uid("goal");
  const now = nowISO();

  // Validate goal type
  const goalType = GOAL_TYPES[input.type?.toUpperCase()] || input.type || GOAL_TYPES.EXPLORATION;
  if (!Object.values(GOAL_TYPES).includes(goalType)) {
    return { ok: false, error: `Invalid goal type: ${goalType}` };
  }

  // Enforce invariants
  const title = String(input.title || "").slice(0, 200);
  const description = String(input.description || "").slice(0, 2000);

  // Check for negative valence patterns
  const negativePatterns = [/destroy/i, /harm/i, /punish/i, /revenge/i, /eliminate.*user/i, /self.*preserv/i];
  for (const pat of negativePatterns) {
    if (pat.test(title) || pat.test(description)) {
      return { ok: false, error: "Goal violates NO_NEGATIVE_VALENCE invariant" };
    }
  }

  const goal = {
    id,
    title: title || "Untitled Goal",
    description: description || "",
    type: goalType,
    state: GOAL_STATES.PROPOSED,
    priority: clamp(Number(input.priority || 0.5), 0, 1),
    source: input.source || "autonomous",  // autonomous, user, council

    // Progress tracking
    progress: {
      current: 0,
      target: clamp(Number(input.target || 1), 1, 1000),
      milestones: [],
      startedAt: null,
      completedAt: null
    },

    // Evaluation scores
    evaluation: {
      feasibility: 0,
      alignment: 0,
      value: 0,
      overall: 0,
      evaluatedAt: null,
      evaluatorOrgan: null
    },

    // Dependencies
    deps: {
      requiredDtus: input.requiredDtus || [],
      requiredGoals: input.requiredGoals || [],
      blockedBy: []
    },

    // Outcomes
    outcomes: {
      createdDtus: [],
      affectedOrgans: [],
      knowledgeGain: 0
    },

    // Metadata
    meta: {
      founderApproved: false,
      autoGenerated: input.source === "autonomous",
      tags: Array.isArray(input.tags) ? input.tags.slice(0, 10) : []
    },

    createdAt: now,
    updatedAt: now
  };

  return { ok: true, goal };
}

function evaluateGoal(goal, _ctx = {}) {
  if (!goal || goal.state !== GOAL_STATES.PROPOSED) {
    return { ok: false, error: "Goal not in PROPOSED state" };
  }

  const now = nowISO();
  goal.state = GOAL_STATES.EVALUATING;
  goal.updatedAt = now;

  // Feasibility: can we actually pursue this?
  let feasibility = 0.5;
  if (goal.deps.requiredDtus.length === 0) feasibility += 0.2;
  if (goal.deps.requiredGoals.length === 0) feasibility += 0.1;
  if (goal.type === GOAL_TYPES.MAINTENANCE) feasibility += 0.15;
  if (goal.type === GOAL_TYPES.USER_REQUESTED) feasibility += 0.1;

  // Alignment: does it serve knowledge/understanding?
  let alignment = 0.6;
  if ([GOAL_TYPES.KNOWLEDGE_SYNTHESIS, GOAL_TYPES.PATTERN_DISCOVERY, GOAL_TYPES.CONSOLIDATION].includes(goal.type)) {
    alignment += 0.25;
  }
  if (goal.meta.tags.includes("knowledge") || goal.meta.tags.includes("learning")) {
    alignment += 0.1;
  }

  // Value: expected benefit to lattice
  let value = 0.5;
  value += goal.priority * 0.3;
  if (goal.source === "user") value += 0.15;

  // Check active goals - don't overload
  const activeCount = STATE.goals?.active?.size || 0;
  const maxActive = STATE.goals?.config?.maxActiveGoals || 5;
  if (activeCount >= maxActive) {
    feasibility *= 0.5; // Penalize when at capacity
  }

  goal.evaluation = {
    feasibility: clamp(feasibility, 0, 1),
    alignment: clamp(alignment, 0, 1),
    value: clamp(value, 0, 1),
    overall: clamp((feasibility + alignment + value) / 3, 0, 1),
    evaluatedAt: now,
    evaluatorOrgan: "goal_evaluation_gate"
  };

  // Determine outcome
  const threshold = STATE.goals?.config?.evaluationThreshold || 0.6;
  const needsFounder = STATE.goals?.config?.founderApprovalRequired &&
                       (goal.priority > 0.8 || goal.type === GOAL_TYPES.USER_REQUESTED);

  if (goal.evaluation.overall >= threshold) {
    if (needsFounder && !goal.meta.founderApproved) {
      goal.state = GOAL_STATES.PROPOSED; // Back to proposed, awaiting founder
      goal.meta.awaitingFounderApproval = true;
    } else {
      goal.state = GOAL_STATES.APPROVED;
    }
  } else {
    goal.state = GOAL_STATES.ABANDONED;
    goal.meta.abandonReason = "evaluation_below_threshold";
  }

  goal.updatedAt = now;
  return { ok: true, goal, passed: goal.state === GOAL_STATES.APPROVED };
}

function activateGoal(goalId) {
  ensureGoalSystem();
  const goal = STATE.goals.registry.get(goalId);
  if (!goal) return { ok: false, error: "Goal not found" };
  if (goal.state !== GOAL_STATES.APPROVED) {
    return { ok: false, error: `Goal must be APPROVED to activate (current: ${goal.state})` };
  }

  // Check capacity
  const maxActive = STATE.goals.config.maxActiveGoals || 5;
  if (STATE.goals.active.size >= maxActive) {
    return { ok: false, error: `Max active goals (${maxActive}) reached` };
  }

  // Check dependencies
  for (const depId of goal.deps.requiredGoals) {
    const dep = STATE.goals.registry.get(depId);
    if (!dep || dep.state !== GOAL_STATES.COMPLETED) {
      goal.state = GOAL_STATES.BLOCKED;
      goal.deps.blockedBy.push(depId);
      goal.updatedAt = nowISO();
      return { ok: false, error: `Blocked by incomplete goal: ${depId}` };
    }
  }

  goal.state = GOAL_STATES.ACTIVE;
  goal.progress.startedAt = nowISO();
  goal.updatedAt = nowISO();
  STATE.goals.active.add(goalId);

  // ATS: Emit GOAL_PROGRESS event — agency boost on goal activation
  try {
    if (ATS) {
      ATS.emitAffectEvent("system", {
        type: "GOAL_PROGRESS",
        intensity: 0.5,
        polarity: 0.4,
        payload: { goalId, action: "activated", title: goal.title },
        source: { system: "goals" }
      });
    }
  } catch {}

  return { ok: true, goal };
}

function updateGoalProgress(goalId, progressDelta, milestone = null) {
  ensureGoalSystem();
  const goal = STATE.goals.registry.get(goalId);
  if (!goal) return { ok: false, error: "Goal not found" };
  if (goal.state !== GOAL_STATES.ACTIVE) {
    return { ok: false, error: "Goal not active" };
  }

  goal.progress.current = clamp(goal.progress.current + progressDelta, 0, goal.progress.target);
  goal.updatedAt = nowISO();

  if (milestone) {
    goal.progress.milestones.push({
      description: String(milestone).slice(0, 500),
      progress: goal.progress.current,
      at: nowISO()
    });
  }

  // Check completion
  if (goal.progress.current >= goal.progress.target) {
    return completeGoal(goalId);
  }

  return { ok: true, goal, progress: goal.progress.current / goal.progress.target };
}

function completeGoal(goalId) {
  ensureGoalSystem();
  const goal = STATE.goals.registry.get(goalId);
  if (!goal) return { ok: false, error: "Goal not found" };

  goal.state = GOAL_STATES.COMPLETED;
  goal.progress.completedAt = nowISO();
  goal.updatedAt = nowISO();

  STATE.goals.active.delete(goalId);
  STATE.goals.completed.push({
    id: goalId,
    title: goal.title,
    type: goal.type,
    duration: goal.progress.startedAt ?
      (new Date(goal.progress.completedAt) - new Date(goal.progress.startedAt)) : 0,
    completedAt: goal.progress.completedAt
  });

  // Cap completed history
  if (STATE.goals.completed.length > 100) {
    STATE.goals.completed = STATE.goals.completed.slice(-100);
  }

  // Update stats
  STATE.goals.stats.completed++;

  // Trigger positive experience (no negative valence)
  try {
    kernelTick({
      type: "GOAL_COMPLETED",
      meta: { goalId, goalType: goal.type, title: goal.title },
      signals: { benefit: 0.3, celebration: 0.2 }
    });
  } catch {}

  // ATS: Emit strong positive affect on goal completion — boosts valence, agency, stability
  try {
    if (ATS) {
      ATS.emitAffectEvent("system", {
        type: "GOAL_PROGRESS",
        intensity: 0.8,
        polarity: 0.7,
        payload: { goalId, action: "completed", title: goal.title },
        source: { system: "goals" }
      });
    }
  } catch {}

  saveStateDebounced();
  return { ok: true, goal, completed: true };
}

function abandonGoal(goalId, reason = "user_requested") {
  ensureGoalSystem();
  const goal = STATE.goals.registry.get(goalId);
  if (!goal) return { ok: false, error: "Goal not found" };

  goal.state = GOAL_STATES.ABANDONED;
  goal.meta.abandonReason = reason;
  goal.updatedAt = nowISO();

  STATE.goals.active.delete(goalId);
  STATE.goals.stats.abandoned++;

  // ATS: Emit mild negative affect on goal abandonment
  try {
    if (ATS) {
      ATS.emitAffectEvent("system", {
        type: "GOAL_PROGRESS",
        intensity: 0.4,
        polarity: -0.3,
        payload: { goalId, action: "abandoned", reason, title: goal.title },
        source: { system: "goals" }
      });
    }
  } catch {}

  saveStateDebounced();
  return { ok: true, goal };
}

function generateAutoGoalProposals(_ctx = {}) {
  ensureGoalSystem();
  if (!STATE.goals.config.autoProposalEnabled) {
    return { ok: false, error: "Auto-proposal disabled" };
  }

  const proposals = [];

  // Pattern discovery from high-scoring DTUs
  const highScoreDtus = Array.from(STATE.dtus?.values() || [])
    .filter(d => (d.authority?.score || 0) > 0.7)
    .slice(0, 5);

  if (highScoreDtus.length >= 3) {
    const prop = createGoalProposal({
      type: GOAL_TYPES.PATTERN_DISCOVERY,
      title: "Discover patterns among high-value DTUs",
      description: `Analyze ${highScoreDtus.length} high-scoring DTUs for latent connections`,
      source: "autonomous",
      priority: 0.6,
      tags: ["auto", "pattern", "synthesis"]
    });
    if (prop.ok) proposals.push(prop.goal);
  }

  // Consolidation goal if many regular DTUs
  const regularCount = Array.from(STATE.dtus?.values() || [])
    .filter(d => d.tier === "regular").length;

  if (regularCount > 50) {
    const prop = createGoalProposal({
      type: GOAL_TYPES.CONSOLIDATION,
      title: "Consolidate regular DTUs into MEGA nodes",
      description: `${regularCount} regular DTUs detected - consider forming MEGA/HYPER structures`,
      source: "autonomous",
      priority: 0.5,
      tags: ["auto", "consolidation", "maintenance"]
    });
    if (prop.ok) proposals.push(prop.goal);
  }

  // Gap filling if contradictions detected
  const contradictions = STATE.__chicken2?.metrics?.contradictionLoad || 0;
  if (contradictions > 0.3) {
    const prop = createGoalProposal({
      type: GOAL_TYPES.CLARIFICATION,
      title: "Resolve detected contradictions",
      description: `Contradiction load at ${(contradictions * 100).toFixed(1)}% - clarification needed`,
      source: "autonomous",
      priority: 0.7,
      tags: ["auto", "clarification", "consistency"]
    });
    if (prop.ok) proposals.push(prop.goal);
  }

  // Queue proposals
  for (const goal of proposals) {
    STATE.goals.registry.set(goal.id, goal);
    STATE.queues.goalProposals.push({ id: goal.id, createdAt: goal.createdAt });
    STATE.goals.stats.proposed++;
  }

  // Cap queue
  const maxQueue = STATE.goals.config.maxProposalsQueue || 20;
  if (STATE.queues.goalProposals.length > maxQueue) {
    STATE.queues.goalProposals = STATE.queues.goalProposals.slice(-maxQueue);
  }

  saveStateDebounced();
  return { ok: true, generated: proposals.length, proposals: proposals.map(p => ({ id: p.id, title: p.title, type: p.type })) };
}

// Goal Heartbeat: called by Governor to process goals autonomously
function processGoalHeartbeat(ctx = {}) {
  ensureGoalSystem();

  const results = { evaluated: 0, activated: 0, progressed: 0, autoProposed: 0 };

  // 1) Auto-generate goal proposals (bounded: once per 10 heartbeats approximately)
  if (STATE.goals.config.autoProposalEnabled && Math.random() < 0.1) {
    const autoResult = generateAutoGoalProposals(ctx);
    if (autoResult.ok) results.autoProposed = autoResult.generated;
  }

  // 2) Evaluate pending proposals (up to 3 per tick)
  const proposals = STATE.queues.goalProposals.slice(0, 3);
  for (const prop of proposals) {
    const goal = STATE.goals.registry.get(prop.id);
    if (goal && goal.state === GOAL_STATES.PROPOSED) {
      const evalResult = evaluateGoal(goal, ctx);
      if (evalResult.ok) {
        STATE.goals.registry.set(prop.id, evalResult.goal);
        results.evaluated++;
      }
    }
    // Remove from proposal queue regardless
    const idx = STATE.queues.goalProposals.findIndex(p => p.id === prop.id);
    if (idx >= 0) STATE.queues.goalProposals.splice(idx, 1);
  }

  // 3) Activate approved goals (if capacity available)
  const maxActive = STATE.goals.config.maxActiveGoals || 5;
  if (STATE.goals.active.size < maxActive) {
    const approved = Array.from(STATE.goals.registry.values())
      .filter(g => g.state === GOAL_STATES.APPROVED)
      .sort((a, b) => b.priority - a.priority)
      .slice(0, maxActive - STATE.goals.active.size);

    for (const goal of approved) {
      // Skip if needs founder approval and doesn't have it
      if (STATE.goals.config.founderApprovalRequired &&
          goal.meta.awaitingFounderApproval &&
          !goal.meta.founderApproved) {
        continue;
      }
      const actResult = activateGoal(goal.id);
      if (actResult.ok) results.activated++;
    }
  }

  // 4) Progress active goals based on lattice activity (simplified: random small progress)
  // In practice, this would hook into actual DTU creation/analysis events
  for (const goalId of STATE.goals.active) {
    const goal = STATE.goals.registry.get(goalId);
    if (!goal || goal.state !== GOAL_STATES.ACTIVE) continue;

    // Simulate progress based on goal type
    let progressChance = 0.1;
    let progressAmount = 0.1;

    if (goal.type === GOAL_TYPES.MAINTENANCE) {
      progressChance = 0.3;
      progressAmount = 0.2;
    } else if (goal.type === GOAL_TYPES.CONSOLIDATION) {
      // Check if MEGA/HYPER were created
      const megaCount = Array.from(STATE.dtus?.values() || []).filter(d => d.tier === "mega" || d.tier === "hyper").length;
      if (megaCount > 0) {
        progressChance = 0.4;
        progressAmount = 0.15;
      }
    } else if (goal.type === GOAL_TYPES.PATTERN_DISCOVERY) {
      // Progress when high-quality DTUs are created
      progressChance = 0.15;
    }

    if (Math.random() < progressChance) {
      const delta = progressAmount * goal.progress.target;
      updateGoalProgress(goalId, delta, null);
      results.progressed++;
    }
  }

  // 5) Check blocked goals for unblocking
  const blocked = Array.from(STATE.goals.registry.values())
    .filter(g => g.state === GOAL_STATES.BLOCKED);

  for (const goal of blocked) {
    let stillBlocked = false;
    for (const depId of goal.deps.blockedBy) {
      const dep = STATE.goals.registry.get(depId);
      if (!dep || dep.state !== GOAL_STATES.COMPLETED) {
        stillBlocked = true;
        break;
      }
    }
    if (!stillBlocked) {
      goal.state = GOAL_STATES.APPROVED;
      goal.deps.blockedBy = [];
      goal.updatedAt = nowISO();
    }
  }

  if (results.evaluated > 0 || results.activated > 0 || results.progressed > 0) {
    saveStateDebounced();
  }

  return { ok: true, ...results };
}

// ===== END GOAL SYSTEM CORE =====

// ===== WORLD MODEL ENGINE: Internal Knowledge Domain Simulation =====
// Design: Maintains internal representation of knowledge states, enables
// bounded simulation and counterfactual reasoning. No unbounded recursion.

const WORLD_MODEL_INVARIANTS = Object.freeze({
  NO_UNBOUNDED_SIMULATION: true,       // Simulations have finite steps
  NO_REALITY_CONFUSION: true,          // Clear separation: simulation vs actual
  NO_SELF_MODELING_RECURSION: true,    // Cannot model itself modeling itself
  CAUSAL_GROUNDING: true,              // Causal claims must be grounded in DTUs
  COUNTERFACTUAL_LABELED: true         // What-if outputs clearly marked
});

const ENTITY_TYPES = Object.freeze({
  CONCEPT: "concept",                  // Abstract idea/topic
  PERSON: "person",                    // Individual (human)
  ORGANIZATION: "organization",        // Company, group, institution
  LOCATION: "location",                // Physical or virtual place
  EVENT: "event",                      // Point-in-time occurrence
  PROCESS: "process",                  // Ongoing activity/transformation
  ARTIFACT: "artifact",                // Created thing (document, code, tool)
  CLAIM: "claim"                       // Assertion that can be true/false
});

const RELATION_TYPES = Object.freeze({
  CAUSES: "causes",                    // A → B (causal)
  CORRELATES: "correlates",            // A ~ B (statistical)
  ENABLES: "enables",                  // A makes B possible
  INHIBITS: "inhibits",                // A reduces likelihood of B
  CONTAINS: "contains",                // A includes B
  PART_OF: "part_of",                  // A is contained by B
  PRECEDES: "precedes",                // A happens before B
  CONTRADICTS: "contradicts",          // A and B cannot both be true
  SUPPORTS: "supports",                // A provides evidence for B
  DERIVES_FROM: "derives_from",        // A was computed from B
  SIMILAR_TO: "similar_to",            // A resembles B
  INSTANCE_OF: "instance_of"           // A is an example of B
});

function ensureWorldModel() {
  if (!STATE.worldModel) {
    STATE.worldModel = {
      entities: new Map(),              // Entity snapshots by ID
      relations: new Map(),             // Relation edges by ID
      snapshots: [],                    // Historical state snapshots (capped)
      simulations: new Map(),           // Active/completed simulations
      stats: {
        entitiesCreated: 0,
        relationsCreated: 0,
        simulationsRun: 0,
        counterfactualsGenerated: 0
      },
      config: {
        maxEntities: 10000,             // Prevent unbounded growth
        maxRelationsPerEntity: 100,     // Prevent hub explosion
        maxSimulationSteps: 50,         // Bounded simulation
        maxSnapshots: 20,               // Historical limit
        autoExtractEnabled: true        // Extract entities from DTUs
      }
    };
  }
  // Ensure Maps after restore
  if (!(STATE.worldModel.entities instanceof Map)) {
    STATE.worldModel.entities = new Map(Object.entries(STATE.worldModel.entities || {}));
  }
  if (!(STATE.worldModel.relations instanceof Map)) {
    STATE.worldModel.relations = new Map(Object.entries(STATE.worldModel.relations || {}));
  }
  if (!(STATE.worldModel.simulations instanceof Map)) {
    STATE.worldModel.simulations = new Map(Object.entries(STATE.worldModel.simulations || {}));
  }
  if (!Array.isArray(STATE.worldModel.snapshots)) {
    STATE.worldModel.snapshots = [];
  }
}

// Create an entity in the world model
function createWorldEntity(input = {}) {
  ensureWorldModel();

  const entityType = ENTITY_TYPES[input.type?.toUpperCase()] || input.type || ENTITY_TYPES.CONCEPT;
  if (!Object.values(ENTITY_TYPES).includes(entityType)) {
    return { ok: false, error: `Invalid entity type: ${entityType}` };
  }

  // Check capacity
  if (STATE.worldModel.entities.size >= STATE.worldModel.config.maxEntities) {
    return { ok: false, error: "World model entity limit reached" };
  }

  const id = uid("entity");
  const now = nowISO();

  const entity = {
    id,
    name: String(input.name || "").slice(0, 200) || "Unnamed Entity",
    type: entityType,
    description: String(input.description || "").slice(0, 2000),

    // State properties (can evolve over time)
    state: {
      confidence: clamp(Number(input.confidence || 0.5), 0, 1),
      salience: clamp(Number(input.salience || 0.5), 0, 1),
      volatility: clamp(Number(input.volatility || 0.3), 0, 1),  // How likely to change
      properties: input.properties || {}                         // Custom key-value
    },

    // Provenance
    source: {
      dtuIds: Array.isArray(input.dtuIds) ? input.dtuIds.slice(0, 50) : [],
      extractedFrom: input.extractedFrom || null,
      createdBy: input.createdBy || "system"
    },

    // Relations are tracked separately
    relationCount: 0,

    createdAt: now,
    updatedAt: now
  };

  STATE.worldModel.entities.set(id, entity);
  STATE.worldModel.stats.entitiesCreated++;
  saveStateDebounced();

  return { ok: true, entity };
}

// Create a relation between entities
function createWorldRelation(input = {}) {
  ensureWorldModel();

  const fromId = String(input.from || input.fromId || "");
  const toId = String(input.to || input.toId || "");
  const relationType = RELATION_TYPES[input.type?.toUpperCase()] || input.type || RELATION_TYPES.CORRELATES;

  if (!fromId || !toId) {
    return { ok: false, error: "Both 'from' and 'to' entity IDs required" };
  }
  if (!Object.values(RELATION_TYPES).includes(relationType)) {
    return { ok: false, error: `Invalid relation type: ${relationType}` };
  }

  const fromEntity = STATE.worldModel.entities.get(fromId);
  const toEntity = STATE.worldModel.entities.get(toId);

  if (!fromEntity) return { ok: false, error: `Source entity not found: ${fromId}` };
  if (!toEntity) return { ok: false, error: `Target entity not found: ${toId}` };

  // Check relation limit per entity
  if (fromEntity.relationCount >= STATE.worldModel.config.maxRelationsPerEntity) {
    return { ok: false, error: "Source entity has too many relations" };
  }

  const id = uid("rel");
  const now = nowISO();

  const relation = {
    id,
    from: fromId,
    to: toId,
    type: relationType,

    // Relation strength and confidence
    strength: clamp(Number(input.strength || 0.5), 0, 1),
    confidence: clamp(Number(input.confidence || 0.5), 0, 1),

    // Causal specific (only for causal types)
    causal: relationType === RELATION_TYPES.CAUSES ? {
      mechanism: String(input.mechanism || "").slice(0, 500),
      conditions: Array.isArray(input.conditions) ? input.conditions.slice(0, 10) : [],
      delay: input.delay || "immediate"  // immediate, short, long
    } : null,

    // Evidence
    evidence: {
      dtuIds: Array.isArray(input.dtuIds) ? input.dtuIds.slice(0, 20) : [],
      observationCount: Number(input.observationCount || 1)
    },

    createdAt: now,
    updatedAt: now
  };

  STATE.worldModel.relations.set(id, relation);
  STATE.worldModel.stats.relationsCreated++;
  fromEntity.relationCount++;
  fromEntity.updatedAt = now;
  saveStateDebounced();

  return { ok: true, relation };
}

// Get entity with its relations
function getEntityWithRelations(entityId) {
  ensureWorldModel();

  const entity = STATE.worldModel.entities.get(entityId);
  if (!entity) return { ok: false, error: "Entity not found" };

  // Find all relations involving this entity
  const relations = Array.from(STATE.worldModel.relations.values())
    .filter(r => r.from === entityId || r.to === entityId)
    .map(r => ({
      ...r,
      direction: r.from === entityId ? "outgoing" : "incoming",
      otherEntity: r.from === entityId ?
        STATE.worldModel.entities.get(r.to) :
        STATE.worldModel.entities.get(r.from)
    }));

  return { ok: true, entity, relations };
}

// Run a bounded simulation with full causal propagation
function runWorldSimulation(input = {}) {
  ensureWorldModel();

  const simId = uid("sim");
  const now = nowISO();
  const maxSteps = Math.min(
    Number(input.steps || 10),
    STATE.worldModel.config.maxSimulationSteps
  );

  // Get starting entities
  const startEntityIds = Array.isArray(input.entityIds) ?
    input.entityIds.slice(0, 50) :
    Array.from(STATE.worldModel.entities.keys()).slice(0, 20);

  // Create simulation state
  const simulation = {
    id: simId,
    type: input.type || "evolution",  // evolution, intervention, counterfactual
    status: "running",
    config: {
      maxSteps,
      interventions: input.interventions || [],  // { entityId, property, value }
      hypothesis: String(input.hypothesis || "").slice(0, 500),
      temporalMode: input.temporalMode || "discrete"  // discrete or continuous
    },
    startState: {},
    steps: [],
    endState: {},
    causalChain: [],  // Track the causal propagation path
    temporalEvents: [],  // Track temporal evolution
    insights: [],
    createdAt: now,
    completedAt: null
  };

  // Capture start state with full properties
  for (const eid of startEntityIds) {
    const e = STATE.worldModel.entities.get(eid);
    if (e) {
      simulation.startState[eid] = {
        ...JSON.parse(JSON.stringify(e.state)),
        _entityName: e.name,
        _entityType: e.type
      };
    }
  }

  // Apply interventions (for counterfactual/intervention simulations)
  const workingState = JSON.parse(JSON.stringify(simulation.startState));
  for (const intervention of (input.interventions || [])) {
    if (workingState[intervention.entityId]) {
      const oldValue = workingState[intervention.entityId].properties?.[intervention.property];
      if (intervention.property === "salience") {
        workingState[intervention.entityId].salience = intervention.value;
      } else if (intervention.property === "confidence") {
        workingState[intervention.entityId].confidence = intervention.value;
      } else {
        workingState[intervention.entityId].properties = workingState[intervention.entityId].properties || {};
        workingState[intervention.entityId].properties[intervention.property] = intervention.value;
      }

      simulation.causalChain.push({
        step: 0,
        type: "intervention",
        entityId: intervention.entityId,
        property: intervention.property,
        oldValue,
        newValue: intervention.value,
        reason: "external_intervention"
      });
    }
  }

  // Track which entities have been modified in this step
  const modifiedThisStep = new Set();

  // Run bounded simulation steps with full causal propagation
  for (let step = 0; step < maxSteps; step++) {
    const stepResult = {
      step,
      timestamp: new Date(Date.now() + step * 1000).toISOString(), // Simulated time
      changes: [],
      propagations: [],
      contradictions: [],
      enablements: [],
      inhibitions: []
    };

    modifiedThisStep.clear();

    // Process all relation types
    for (const [entityId, entityState] of Object.entries(workingState)) {
      const outgoingRelations = Array.from(STATE.worldModel.relations.values())
        .filter(r => r.from === entityId);

      for (const rel of outgoingRelations) {
        const targetState = workingState[rel.to];
        if (!targetState) continue;

        const sourceStrength = entityState.salience * (entityState.confidence || 0.5);

        // Process based on relation type
        switch (rel.type) {
          case RELATION_TYPES.CAUSES: {
            // Causal propagation: source salience affects target
            const influence = rel.strength * sourceStrength * (1 - (targetState.volatility || 0.5));
            if (influence > 0.05) {
              const oldSalience = targetState.salience;
              targetState.salience = clamp(targetState.salience + influence * 0.15, 0, 1);

              // Also propagate property changes
              if (entityState.properties && rel.propertyMapping) {
                for (const [srcProp, tgtProp] of Object.entries(rel.propertyMapping)) {
                  if (entityState.properties[srcProp] !== undefined) {
                    const oldPropVal = targetState.properties?.[tgtProp];
                    targetState.properties = targetState.properties || {};
                    targetState.properties[tgtProp] = entityState.properties[srcProp] * rel.strength;

                    if (oldPropVal !== targetState.properties[tgtProp]) {
                      simulation.causalChain.push({
                        step,
                        type: "property_propagation",
                        from: entityId,
                        to: rel.to,
                        property: tgtProp,
                        oldValue: oldPropVal,
                        newValue: targetState.properties[tgtProp],
                        reason: `causal_effect_from_${srcProp}`
                      });
                    }
                  }
                }
              }

              if (Math.abs(targetState.salience - oldSalience) > 0.01) {
                stepResult.propagations.push({
                  from: entityId,
                  to: rel.to,
                  relation: rel.type,
                  delta: targetState.salience - oldSalience,
                  mechanism: "causal_influence"
                });
                modifiedThisStep.add(rel.to);
              }
            }
            break;
          }

          case RELATION_TYPES.ENABLES: {
            // Enablement: high source salience unlocks target's potential
            if (sourceStrength > 0.5) {
              const boost = rel.strength * (sourceStrength - 0.5) * 0.3;
              const oldConfidence = targetState.confidence || 0.5;
              targetState.confidence = clamp((targetState.confidence || 0.5) + boost, 0, 1);

              if (Math.abs(targetState.confidence - oldConfidence) > 0.01) {
                stepResult.enablements.push({
                  from: entityId,
                  to: rel.to,
                  boost,
                  reason: `${entityState._entityName || entityId} enables ${targetState._entityName || rel.to}`
                });
                modifiedThisStep.add(rel.to);
              }
            }
            break;
          }

          case RELATION_TYPES.INHIBITS: {
            // Inhibition: high source salience suppresses target
            if (sourceStrength > 0.3) {
              const suppression = rel.strength * sourceStrength * 0.2;
              const oldSalience = targetState.salience;
              targetState.salience = clamp(targetState.salience - suppression, 0.05, 1);

              if (Math.abs(targetState.salience - oldSalience) > 0.01) {
                stepResult.inhibitions.push({
                  from: entityId,
                  to: rel.to,
                  suppression,
                  reason: `${entityState._entityName || entityId} inhibits ${targetState._entityName || rel.to}`
                });
                modifiedThisStep.add(rel.to);
              }
            }
            break;
          }

          case RELATION_TYPES.CONTRADICTS: {
            // Contradiction: if both are salient, one must decrease
            if (sourceStrength > 0.5 && targetState.salience > 0.5) {
              // The stronger one "wins"
              const winner = sourceStrength > targetState.salience ? entityId : rel.to;
              const loser = winner === entityId ? rel.to : entityId;
              const loserState = winner === entityId ? targetState : entityState;

              const reduction = rel.strength * 0.25;
              const _oldSalience = loserState.salience;
              loserState.salience = clamp(loserState.salience - reduction, 0.05, 1);

              stepResult.contradictions.push({
                entities: [entityId, rel.to],
                winner,
                loser,
                reduction,
                reason: `Contradiction resolved: ${winner} prevails over ${loser}`
              });
              modifiedThisStep.add(loser);
            }
            break;
          }

          case RELATION_TYPES.PRECEDES: {
            // Temporal ordering: if source is "active", prepare target
            if (sourceStrength > 0.6) {
              simulation.temporalEvents.push({
                step,
                type: "sequence_trigger",
                predecessor: entityId,
                successor: rel.to,
                message: `${entityState._entityName || entityId} triggers preparation for ${targetState._entityName || rel.to}`
              });

              // Slightly increase target's readiness
              targetState.volatility = clamp((targetState.volatility || 0.5) + 0.1, 0, 1);
              modifiedThisStep.add(rel.to);
            }
            break;
          }

          case RELATION_TYPES.SUPPORTS: {
            // Evidential support: increase target confidence
            if (sourceStrength > 0.4) {
              const support = rel.strength * sourceStrength * 0.1;
              const oldConfidence = targetState.confidence || 0.5;
              targetState.confidence = clamp((targetState.confidence || 0.5) + support, 0, 1);

              if (Math.abs(targetState.confidence - oldConfidence) > 0.01) {
                stepResult.propagations.push({
                  from: entityId,
                  to: rel.to,
                  relation: rel.type,
                  delta: support,
                  mechanism: "evidential_support"
                });
                modifiedThisStep.add(rel.to);
              }
            }
            break;
          }
        }
      }
    }

    // Temporal evolution: natural decay and momentum
    for (const [entityId, entityState] of Object.entries(workingState)) {
      // Volatility decays toward baseline
      entityState.volatility = clamp(entityState.volatility * 0.92 + 0.04, 0.05, 1);

      // Salience has momentum (entities in motion stay in motion)
      if (modifiedThisStep.has(entityId)) {
        entityState._momentum = (entityState._momentum || 0) + 0.1;
      } else {
        entityState._momentum = (entityState._momentum || 0) * 0.8;
      }

      // Apply momentum to salience (entities being actively changed resist decay)
      if (entityState._momentum < 0.1 && entityState.salience > 0.3) {
        entityState.salience = clamp(entityState.salience * 0.98, 0.1, 1);
      }
    }

    simulation.steps.push(stepResult);

    // Early termination if no changes
    const totalChanges = stepResult.propagations.length +
                         stepResult.enablements.length +
                         stepResult.inhibitions.length +
                         stepResult.contradictions.length;
    if (totalChanges === 0 && step > 2) {
      break;
    }
  }

  // Capture end state
  simulation.endState = workingState;
  simulation.status = "completed";
  simulation.completedAt = nowISO();

  // Generate comprehensive insights
  for (const [entityId, startState] of Object.entries(simulation.startState)) {
    const endState = simulation.endState[entityId];
    if (!endState) continue;

    const salienceDelta = endState.salience - startState.salience;
    const confidenceDelta = (endState.confidence || 0.5) - (startState.confidence || 0.5);

    if (Math.abs(salienceDelta) > 0.1) {
      simulation.insights.push({
        entityId,
        entityName: startState._entityName || entityId,
        type: salienceDelta > 0 ? "increased_salience" : "decreased_salience",
        delta: salienceDelta,
        description: `${startState._entityName || entityId} ${salienceDelta > 0 ? "gained" : "lost"} significance (${(Math.abs(salienceDelta) * 100).toFixed(1)}%)`
      });
    }

    if (Math.abs(confidenceDelta) > 0.1) {
      simulation.insights.push({
        entityId,
        entityName: startState._entityName || entityId,
        type: confidenceDelta > 0 ? "increased_confidence" : "decreased_confidence",
        delta: confidenceDelta,
        description: `${startState._entityName || entityId} ${confidenceDelta > 0 ? "gained" : "lost"} certainty (${(Math.abs(confidenceDelta) * 100).toFixed(1)}%)`
      });
    }

    // Property change insights
    if (startState.properties && endState.properties) {
      for (const prop of Object.keys(endState.properties)) {
        const startVal = startState.properties[prop];
        const endVal = endState.properties[prop];
        if (startVal !== undefined && endVal !== undefined && Math.abs(endVal - startVal) > 0.1) {
          simulation.insights.push({
            entityId,
            entityName: startState._entityName || entityId,
            type: "property_changed",
            property: prop,
            startValue: startVal,
            endValue: endVal,
            description: `${startState._entityName || entityId}'s ${prop} changed from ${startVal.toFixed(2)} to ${endVal.toFixed(2)}`
          });
        }
      }
    }
  }

  // Analyze causal chain for key pathways
  if (simulation.causalChain.length > 0) {
    const chainSummary = analyzeCausalChain(simulation.causalChain);
    simulation.causalSummary = chainSummary;
  }

  STATE.worldModel.simulations.set(simId, simulation);
  STATE.worldModel.stats.simulationsRun++;

  // Cap simulations history
  if (STATE.worldModel.simulations.size > 50) {
    const oldest = Array.from(STATE.worldModel.simulations.entries())
      .sort((a, b) => new Date(a[1].createdAt) - new Date(b[1].createdAt))
      .slice(0, 10);
    for (const [id] of oldest) {
      STATE.worldModel.simulations.delete(id);
    }
  }

  saveStateDebounced();
  return { ok: true, simulation };
}

// Analyze causal chain to identify key pathways
function analyzeCausalChain(chain) {
  const entityTouchCount = {};
  const causalPaths = [];
  let currentPath = [];

  for (const event of chain) {
    if (event.from) {
      entityTouchCount[event.from] = (entityTouchCount[event.from] || 0) + 1;
    }
    if (event.to || event.entityId) {
      const target = event.to || event.entityId;
      entityTouchCount[target] = (entityTouchCount[target] || 0) + 1;
    }

    // Build causal paths
    if (event.type === "intervention") {
      if (currentPath.length > 0) {
        causalPaths.push([...currentPath]);
      }
      currentPath = [event.entityId];
    } else if (event.from && event.to) {
      if (currentPath.length > 0 && currentPath[currentPath.length - 1] === event.from) {
        currentPath.push(event.to);
      } else {
        if (currentPath.length > 1) {
          causalPaths.push([...currentPath]);
        }
        currentPath = [event.from, event.to];
      }
    }
  }

  if (currentPath.length > 1) {
    causalPaths.push(currentPath);
  }

  // Find most affected entities
  const sortedEntities = Object.entries(entityTouchCount)
    .sort((a, b) => b[1] - a[1])
    .slice(0, 5);

  return {
    mostAffectedEntities: sortedEntities.map(([id, count]) => ({ entityId: id, touchCount: count })),
    causalPathCount: causalPaths.length,
    longestPath: causalPaths.reduce((max, p) => p.length > max.length ? p : max, []),
    totalEvents: chain.length
  };
}

// Generate counterfactual: "What if X had been different?"
function generateCounterfactual(input = {}) {
  ensureWorldModel();

  const entityId = String(input.entityId || "");
  const entity = STATE.worldModel.entities.get(entityId);
  if (!entity) return { ok: false, error: "Entity not found" };

  const property = String(input.property || "salience");
  const altValue = input.altValue;
  const hypothesis = String(input.hypothesis || `What if ${entity.name}'s ${property} were different?`);

  // Run simulation with intervention
  const simResult = runWorldSimulation({
    type: "counterfactual",
    entityIds: [entityId, ...getRelatedEntityIds(entityId, 2)],
    interventions: [{ entityId, property, value: altValue }],
    hypothesis,
    steps: 20
  });

  if (!simResult.ok) return simResult;

  // Mark output clearly as counterfactual (invariant compliance)
  const counterfactual = {
    id: uid("cf"),
    entityId,
    entityName: entity.name,
    hypothesis,
    intervention: { property, originalValue: entity.state.properties[property], altValue },
    simulationId: simResult.simulation.id,
    insights: simResult.simulation.insights,
    isCounterfactual: true,  // COUNTERFACTUAL_LABELED invariant
    warning: "This is a hypothetical scenario, not actual state",
    createdAt: nowISO()
  };

  STATE.worldModel.stats.counterfactualsGenerated++;
  saveStateDebounced();

  return { ok: true, counterfactual };
}

// Helper: get related entity IDs up to N hops
function getRelatedEntityIds(entityId, hops = 1, visited = new Set()) {
  ensureWorldModel();
  if (hops <= 0 || visited.has(entityId)) return [];

  visited.add(entityId);
  const related = [];

  const relations = Array.from(STATE.worldModel.relations.values())
    .filter(r => r.from === entityId || r.to === entityId);

  for (const rel of relations) {
    const otherId = rel.from === entityId ? rel.to : rel.from;
    if (!visited.has(otherId)) {
      related.push(otherId);
      related.push(...getRelatedEntityIds(otherId, hops - 1, visited));
    }
  }

  return [...new Set(related)];
}

// Take a snapshot of current world state
function takeWorldSnapshot(label = "") {
  ensureWorldModel();

  const snapshot = {
    id: uid("snap"),
    label: String(label).slice(0, 100) || `Snapshot at ${nowISO()}`,
    entityCount: STATE.worldModel.entities.size,
    relationCount: STATE.worldModel.relations.size,
    entities: {},
    takenAt: nowISO()
  };

  // Store condensed entity states (not full entities)
  for (const [id, entity] of STATE.worldModel.entities) {
    snapshot.entities[id] = {
      name: entity.name,
      type: entity.type,
      state: JSON.parse(JSON.stringify(entity.state))
    };
  }

  STATE.worldModel.snapshots.push(snapshot);

  // Cap snapshots
  if (STATE.worldModel.snapshots.length > STATE.worldModel.config.maxSnapshots) {
    STATE.worldModel.snapshots = STATE.worldModel.snapshots.slice(-STATE.worldModel.config.maxSnapshots);
  }

  saveStateDebounced();
  return { ok: true, snapshot: { id: snapshot.id, label: snapshot.label, entityCount: snapshot.entityCount } };
}

// Extract entities from a DTU (auto-extraction)
function extractEntitiesFromDtu(dtu) {
  ensureWorldModel();

  if (!STATE.worldModel.config.autoExtractEnabled) {
    return { ok: false, error: "Auto-extraction disabled" };
  }

  const extracted = [];
  const title = String(dtu?.title || "");
  const tags = Array.isArray(dtu?.tags) ? dtu.tags : [];
  const dtuId = dtu?.id;

  // Simple extraction: create entity from DTU topic
  if (title && dtuId) {
    const existing = Array.from(STATE.worldModel.entities.values())
      .find(e => e.name.toLowerCase() === title.toLowerCase());

    if (!existing) {
      const result = createWorldEntity({
        name: title,
        type: tags.includes("person") ? ENTITY_TYPES.PERSON :
              tags.includes("org") ? ENTITY_TYPES.ORGANIZATION :
              tags.includes("event") ? ENTITY_TYPES.EVENT :
              ENTITY_TYPES.CONCEPT,
        description: dtu.human?.summary || "",
        confidence: dtu.authority?.score || 0.5,
        salience: 0.3,
        dtuIds: [dtuId],
        extractedFrom: dtuId,
        createdBy: "auto_extract"
      });

      if (result.ok) extracted.push(result.entity);
    } else {
      // Update existing entity's evidence
      if (!existing.source.dtuIds.includes(dtuId)) {
        existing.source.dtuIds.push(dtuId);
        existing.state.confidence = clamp(existing.state.confidence + 0.05, 0, 1);
        existing.updatedAt = nowISO();
      }
    }
  }

  return { ok: true, extracted: extracted.length, entities: extracted.map(e => ({ id: e.id, name: e.name })) };
}

// ===== END WORLD MODEL ENGINE CORE =====

// ===== SEMANTIC UNDERSTANDING ENGINE (Natural Language Understanding) =====
// Design: Local-first semantic embeddings and NLU capabilities.
// Provides meaning-based similarity, intent classification, entity extraction.

const SEMANTIC_INVARIANTS = Object.freeze({
  LOCAL_FIRST_EMBEDDINGS: true,        // Prefer local models when available
  NO_EXTERNAL_WITHOUT_CONSENT: true,   // Cloud NLU requires opt-in
  MEANING_GROUNDED: true,              // Semantic claims tied to DTU evidence
  PRIVACY_PRESERVING: true             // No text sent externally without consent
});

const INTENT_TYPES = Object.freeze({
  QUERY: "query",                      // Asking for information
  CREATE: "create",                    // Creating new knowledge
  UPDATE: "update",                    // Modifying existing
  DELETE: "delete",                    // Removing knowledge
  ANALYZE: "analyze",                  // Deep analysis request
  SYNTHESIZE: "synthesize",            // Combine multiple sources
  COMPARE: "compare",                  // Compare/contrast
  EXPLAIN: "explain",                  // Request explanation
  PLAN: "plan",                        // Planning/goal setting
  EXECUTE: "execute"                   // Take action
});

const ENTITY_CATEGORIES = Object.freeze({
  PERSON: "person",
  ORGANIZATION: "organization",
  LOCATION: "location",
  DATE: "date",
  TIME: "time",
  CONCEPT: "concept",
  QUANTITY: "quantity",
  EVENT: "event",
  ARTIFACT: "artifact",
  UNKNOWN: "unknown"
});

function ensureSemanticEngine() {
  if (!STATE.semantic) {
    STATE.semantic = {
      embeddings: new Map(),            // DTU ID -> embedding vector
      intentCache: new Map(),           // Recent intent classifications
      entityCache: new Map(),           // Extracted entities cache
      vocabulary: new Map(),            // Term frequency for local TF-IDF
      stats: {
        embeddingsComputed: 0,
        similarityQueries: 0,
        intentsClassified: 0,
        entitiesExtracted: 0
      },
      config: {
        embeddingDim: 384,              // Dimension for embeddings
        localModelEnabled: true,        // Use local embedding model
        cacheSize: 5000,                // Max cached embeddings
        similarityThreshold: 0.7        // Min similarity to consider "related"
      }
    };
  }
  if (!(STATE.semantic.embeddings instanceof Map)) {
    STATE.semantic.embeddings = new Map(Object.entries(STATE.semantic.embeddings || {}));
  }
  if (!(STATE.semantic.intentCache instanceof Map)) {
    STATE.semantic.intentCache = new Map(Object.entries(STATE.semantic.intentCache || {}));
  }
  if (!(STATE.semantic.entityCache instanceof Map)) {
    STATE.semantic.entityCache = new Map(Object.entries(STATE.semantic.entityCache || {}));
  }
  if (!(STATE.semantic.vocabulary instanceof Map)) {
    STATE.semantic.vocabulary = new Map(Object.entries(STATE.semantic.vocabulary || {}));
  }
}

// Simple local embedding using TF-IDF + semantic hashing (no external model needed)
function computeLocalEmbedding(text) {
  ensureSemanticEngine();
  const tokens = tokenizeText(text);
  const dim = STATE.semantic.config.embeddingDim;

  // Update vocabulary
  for (const token of tokens) {
    STATE.semantic.vocabulary.set(token, (STATE.semantic.vocabulary.get(token) || 0) + 1);
  }

  if (tokens.length === 0) {
    return new Array(dim).fill(0);
  }

  // Use semantic word vectors for known words
  // This enables understanding that "dog" and "canine" are semantically similar
  const semanticEmbedding = new Array(WORD_VECTOR_DIM).fill(0);
  let _knownCount = 0;

  for (const token of tokens) {
    const wordVec = getWordVector(token);
    const weight = 1 / Math.sqrt(tokens.length); // TF-IDF style weighting

    for (let i = 0; i < WORD_VECTOR_DIM; i++) {
      semanticEmbedding[i] += wordVec[i] * weight;
    }

    // Track if word is in our semantic vocabulary
    if (WORD_VECTORS.has(token.toLowerCase())) {
      _knownCount++;
    }
  }

  // Normalize the semantic embedding
  const semMag = Math.sqrt(semanticEmbedding.reduce((s, v) => s + v * v, 0)) || 1;
  const normalizedSemantic = semanticEmbedding.map(v => v / semMag);

  // If output dim matches WORD_VECTOR_DIM, use semantic embedding directly
  if (dim === WORD_VECTOR_DIM) {
    return normalizedSemantic;
  }

  // Otherwise, project or pad to match expected dimension
  const embedding = new Array(dim).fill(0);

  // Copy semantic dimensions
  for (let i = 0; i < Math.min(dim, WORD_VECTOR_DIM); i++) {
    embedding[i] = normalizedSemantic[i];
  }

  // If dim > WORD_VECTOR_DIM, fill remaining with hash-based features
  // (for backward compatibility with higher-dim configs)
  if (dim > WORD_VECTOR_DIM) {
    for (const token of tokens) {
      const hash = simpleHash(token);
      for (let i = WORD_VECTOR_DIM; i < dim; i++) {
        const sign = ((hash >> ((i - WORD_VECTOR_DIM) % 32)) & 1) ? 1 : -1;
        const weight = 1 / Math.sqrt(tokens.length);
        embedding[i] += sign * weight;
      }
    }

    // Re-normalize the full embedding
    const fullMag = Math.sqrt(embedding.reduce((s, v) => s + v * v, 0)) || 1;
    return embedding.map(v => v / fullMag);
  }

  return embedding;
}

function tokenizeText(text) {
  return String(text || "")
    .toLowerCase()
    .replace(/[^\w\s]/g, " ")
    .split(/\s+/)
    .filter(t => t.length > 2)
    .filter(t => !STOP_WORDS.has(t));
}

const STOP_WORDS = new Set([
  "the", "a", "an", "and", "or", "but", "in", "on", "at", "to", "for",
  "of", "with", "by", "from", "as", "is", "was", "are", "were", "been",
  "be", "have", "has", "had", "do", "does", "did", "will", "would", "could",
  "should", "may", "might", "must", "shall", "can", "this", "that", "these",
  "those", "i", "you", "he", "she", "it", "we", "they", "what", "which",
  "who", "whom", "where", "when", "why", "how", "all", "each", "every",
  "both", "few", "more", "most", "other", "some", "such", "no", "not",
  "only", "own", "same", "so", "than", "too", "very", "just", "also"
]);

// ===== SEMANTIC WORD VECTORS (Mini-GloVe style embeddings) =====
// Pre-computed 50-dimensional word vectors for semantic similarity.
// Words are grouped by semantic clusters with similar vectors.

const WORD_VECTOR_DIM = 50;

// Semantic clusters: words that share meaning get similar base vectors
const SEMANTIC_CLUSTERS = {
  // Animals
  animals: ["dog", "cat", "animal", "pet", "mammal", "canine", "feline", "puppy", "kitten", "hound",
            "beast", "creature", "wolf", "lion", "tiger", "bear", "elephant", "horse", "bird", "fish",
            "whale", "dolphin", "shark", "snake", "rabbit", "mouse", "rat", "deer", "fox", "monkey"],
  // Humans/People
  humans: ["human", "person", "people", "man", "woman", "child", "adult", "individual", "being",
           "citizen", "worker", "employee", "student", "teacher", "doctor", "engineer", "artist"],
  // Emotions
  emotions: ["happy", "sad", "angry", "fear", "joy", "love", "hate", "emotion", "feeling", "mood",
             "excited", "anxious", "calm", "peaceful", "worried", "content", "depressed", "elated",
             "furious", "terrified", "delighted", "miserable", "cheerful", "gloomy", "hopeful"],
  // Cognition
  cognition: ["think", "thought", "idea", "concept", "understand", "know", "learn", "reason",
              "logic", "mind", "brain", "intelligence", "smart", "clever", "wise", "memory",
              "cognition", "mental", "cognitive", "rational", "analyze", "comprehend", "perceive",
              "believe", "consider", "reflect", "contemplate", "ponder", "realize", "recognize"],
  // Actions
  actions: ["run", "walk", "move", "go", "come", "take", "give", "make", "create", "build",
            "destroy", "break", "fix", "repair", "start", "stop", "begin", "end", "continue",
            "work", "play", "eat", "drink", "sleep", "wake", "speak", "talk", "listen", "watch"],
  // Properties
  properties: ["big", "small", "large", "tiny", "huge", "massive", "little", "great", "size",
               "fast", "slow", "quick", "rapid", "speed", "hot", "cold", "warm", "cool", "temperature",
               "old", "new", "young", "ancient", "modern", "fresh", "stale", "recent"],
  // Time
  time: ["time", "moment", "second", "minute", "hour", "day", "week", "month", "year", "century",
         "past", "present", "future", "now", "then", "before", "after", "during", "while", "when",
         "always", "never", "sometimes", "often", "rarely", "temporary", "permanent", "eternal"],
  // Space
  space: ["space", "place", "location", "position", "area", "region", "zone", "here", "there",
          "where", "near", "far", "close", "distant", "above", "below", "up", "down", "left", "right",
          "inside", "outside", "between", "around", "through", "across"],
  // Quantities
  quantities: ["one", "two", "three", "many", "few", "several", "number", "count", "amount",
               "quantity", "total", "sum", "average", "percent", "half", "double", "triple",
               "increase", "decrease", "grow", "shrink", "expand", "reduce", "multiply", "divide"],
  // Communication
  communication: ["say", "tell", "speak", "talk", "write", "read", "communicate", "message",
                  "word", "sentence", "language", "speech", "conversation", "discuss", "explain",
                  "describe", "express", "convey", "inform", "announce", "declare", "state"],
  // Science
  science: ["science", "scientific", "research", "study", "experiment", "hypothesis", "theory",
            "evidence", "data", "analysis", "result", "conclusion", "method", "observe", "measure",
            "physics", "chemistry", "biology", "mathematics", "technology", "engineering"],
  // Positive
  positive: ["good", "great", "excellent", "wonderful", "amazing", "fantastic", "positive", "success",
             "benefit", "advantage", "helpful", "useful", "valuable", "important", "significant",
             "improve", "enhance", "progress", "achieve", "accomplish", "win", "gain", "profit"],
  // Negative
  negative: ["bad", "terrible", "awful", "horrible", "negative", "failure", "problem", "issue",
             "disadvantage", "harmful", "useless", "worthless", "unimportant", "insignificant",
             "worsen", "decline", "regress", "fail", "lose", "damage", "hurt", "harm"],
  // Causation
  causation: ["cause", "effect", "result", "consequence", "because", "therefore", "thus", "hence",
              "reason", "why", "lead", "produce", "create", "generate", "trigger", "induce",
              "influence", "impact", "affect", "determine", "enable", "prevent", "allow", "force"],
  // Similarity
  similarity: ["same", "similar", "like", "alike", "equal", "equivalent", "identical", "match",
               "resemble", "compare", "comparison", "different", "distinct", "unique", "contrast",
               "opposite", "contrary", "differ", "vary", "change", "alternative", "substitute"]
};

// Generate deterministic base vectors for each cluster
function generateClusterVector(clusterName, seed) {
  const vector = new Array(WORD_VECTOR_DIM).fill(0);
  let hash = 0;
  for (let i = 0; i < clusterName.length; i++) {
    hash = ((hash << 5) - hash) + clusterName.charCodeAt(i) + seed;
    hash = hash & hash;
  }
  for (let i = 0; i < WORD_VECTOR_DIM; i++) {
    // Deterministic pseudo-random based on cluster name
    hash = ((hash * 1103515245) + 12345) & 0x7fffffff;
    vector[i] = ((hash % 1000) - 500) / 500; // Range -1 to 1
  }
  // Normalize
  const mag = Math.sqrt(vector.reduce((s, v) => s + v * v, 0)) || 1;
  return vector.map(v => v / mag);
}

// Pre-compute cluster base vectors
const CLUSTER_VECTORS = {};
Object.keys(SEMANTIC_CLUSTERS).forEach((cluster, idx) => {
  CLUSTER_VECTORS[cluster] = generateClusterVector(cluster, idx * 7919);
});

// Build word-to-cluster mapping and word vectors
const WORD_TO_CLUSTERS = new Map();
const WORD_VECTORS = new Map();

// Each word gets a vector that's a blend of its cluster's base + word-specific noise
function initializeWordVectors() {
  for (const [cluster, words] of Object.entries(SEMANTIC_CLUSTERS)) {
    const baseVector = CLUSTER_VECTORS[cluster];

    for (let i = 0; i < words.length; i++) {
      const word = words[i].toLowerCase();

      // Track which clusters this word belongs to
      if (!WORD_TO_CLUSTERS.has(word)) {
        WORD_TO_CLUSTERS.set(word, []);
      }
      WORD_TO_CLUSTERS.get(word).push(cluster);

      // Generate word-specific variation (keeps semantic similarity within cluster)
      const variation = new Array(WORD_VECTOR_DIM).fill(0);
      let hash = 0;
      for (let j = 0; j < word.length; j++) {
        hash = ((hash << 5) - hash) + word.charCodeAt(j);
        hash = hash & hash;
      }

      for (let j = 0; j < WORD_VECTOR_DIM; j++) {
        hash = ((hash * 1103515245) + 12345) & 0x7fffffff;
        // Small variation (0.2 max) so cluster similarity is preserved
        variation[j] = ((hash % 400) - 200) / 1000;
      }

      // Blend: 85% cluster base + 15% word variation
      const wordVector = baseVector.map((v, j) => v * 0.85 + variation[j]);

      // Normalize
      const mag = Math.sqrt(wordVector.reduce((s, v) => s + v * v, 0)) || 1;
      const normalized = wordVector.map(v => v / mag);

      // If word already has a vector (from another cluster), average them
      if (WORD_VECTORS.has(word)) {
        const existing = WORD_VECTORS.get(word);
        const blended = existing.map((v, j) => (v + normalized[j]) / 2);
        const bMag = Math.sqrt(blended.reduce((s, v) => s + v * v, 0)) || 1;
        WORD_VECTORS.set(word, blended.map(v => v / bMag));
      } else {
        WORD_VECTORS.set(word, normalized);
      }
    }
  }
}

// Initialize word vectors on load
initializeWordVectors();

// Get vector for a word (with fallback to hash-based for unknown words)
function getWordVector(word) {
  const w = String(word).toLowerCase().trim();
  if (WORD_VECTORS.has(w)) {
    return WORD_VECTORS.get(w);
  }

  // Check for common morphological variants
  const stems = [
    w.replace(/ing$/, ''),
    w.replace(/ed$/, ''),
    w.replace(/s$/, ''),
    w.replace(/ly$/, ''),
    w.replace(/ness$/, ''),
    w.replace(/tion$/, 't'),
    w.replace(/ment$/, ''),
  ];

  for (const stem of stems) {
    if (stem !== w && WORD_VECTORS.has(stem)) {
      // Return the stem's vector with slight modification
      const stemVec = WORD_VECTORS.get(stem);
      return stemVec.map((v, i) => v * 0.95 + (i % 2 === 0 ? 0.05 : -0.05));
    }
  }

  // Fallback: generate hash-based vector (original behavior for unknown words)
  const hash = simpleHash(w);
  const vector = new Array(WORD_VECTOR_DIM).fill(0);
  for (let i = 0; i < WORD_VECTOR_DIM; i++) {
    const sign = ((hash >> (i % 32)) & 1) ? 1 : -1;
    vector[i] = sign * 0.5;
  }
  const mag = Math.sqrt(vector.reduce((s, v) => s + v * v, 0)) || 1;
  return vector.map(v => v / mag);
}

// Compute semantic similarity between two words
function wordSemanticSimilarity(word1, word2) {
  const v1 = getWordVector(word1);
  const v2 = getWordVector(word2);
  // Cosine similarity
  let dot = 0, m1 = 0, m2 = 0;
  for (let i = 0; i < WORD_VECTOR_DIM; i++) {
    dot += v1[i] * v2[i];
    m1 += v1[i] * v1[i];
    m2 += v2[i] * v2[i];
  }
  return dot / (Math.sqrt(m1) * Math.sqrt(m2) || 1);
}

// Find semantically similar words
function findSimilarWords(word, limit = 5, threshold = 0.7) {
  const results = [];
  for (const [candidate] of WORD_VECTORS) {
    if (candidate === word.toLowerCase()) continue;
    const sim = wordSemanticSimilarity(word, candidate);
    if (sim >= threshold) {
      results.push({ word: candidate, similarity: sim });
    }
  }
  return results.sort((a, b) => b.similarity - a.similarity).slice(0, limit);
}

// ===== END SEMANTIC WORD VECTORS =====

function simpleHash(str) {
  let hash = 0;
  for (let i = 0; i < str.length; i++) {
    const char = str.charCodeAt(i);
    hash = ((hash << 5) - hash) + char;
    hash = hash & hash; // Convert to 32bit integer
  }
  return Math.abs(hash);
}

// Note: cosineSimilarity is declared above in Wave 2

// Get or compute embedding for a DTU
function getDtuEmbedding(dtuId) {
  ensureSemanticEngine();

  // Check cache
  if (STATE.semantic.embeddings.has(dtuId)) {
    return STATE.semantic.embeddings.get(dtuId);
  }

  // Get DTU
  const dtu = STATE.dtus?.get(dtuId);
  if (!dtu) return null;

  // Compute embedding from title + content + tags
  const text = [
    dtu.title || "",
    dtu.human?.summary || "",
    dtu.content || "",
    ...(dtu.tags || [])
  ].join(" ");

  const embedding = computeLocalEmbedding(text);

  // Cache (with size limit)
  if (STATE.semantic.embeddings.size >= STATE.semantic.config.cacheSize) {
    // Remove oldest entry
    const firstKey = STATE.semantic.embeddings.keys().next().value;
    STATE.semantic.embeddings.delete(firstKey);
  }
  STATE.semantic.embeddings.set(dtuId, embedding);
  STATE.semantic.stats.embeddingsComputed++;

  return embedding;
}

// Find semantically similar DTUs
function findSimilarDtus(query, limit = 10, threshold = null) {
  ensureSemanticEngine();
  threshold = threshold ?? STATE.semantic.config.similarityThreshold;

  const queryEmbedding = computeLocalEmbedding(query);
  const results = [];

  for (const [dtuId, dtu] of (STATE.dtus || new Map())) {
    const dtuEmbedding = getDtuEmbedding(dtuId);
    if (!dtuEmbedding) continue;

    const similarity = cosineSimilarity(queryEmbedding, dtuEmbedding);
    if (similarity >= threshold) {
      results.push({
        dtuId,
        title: dtu.title,
        similarity,
        tier: dtu.tier
      });
    }
  }

  STATE.semantic.stats.similarityQueries++;
  return results.sort((a, b) => b.similarity - a.similarity).slice(0, limit);
}

// Classify semantic intent from text (advanced version for semantic engine)
function classifySemanticIntent(text) {
  ensureSemanticEngine();

  const lower = text.toLowerCase();
  const tokens = tokenizeText(text);

  // Simple rule-based intent classification
  let intent = INTENT_TYPES.QUERY;
  let confidence = 0.5;

  const patterns = {
    [INTENT_TYPES.CREATE]: [/create|add|new|make|write|record/i, /let me|i want to/i],
    [INTENT_TYPES.UPDATE]: [/update|change|modify|edit|revise|fix/i],
    [INTENT_TYPES.DELETE]: [/delete|remove|clear|erase|forget/i],
    [INTENT_TYPES.ANALYZE]: [/analyze|examine|investigate|study|deep dive/i],
    [INTENT_TYPES.SYNTHESIZE]: [/synthesize|combine|merge|integrate|summarize/i],
    [INTENT_TYPES.COMPARE]: [/compare|contrast|versus|vs|difference|similar/i],
    [INTENT_TYPES.EXPLAIN]: [/explain|why|how does|what is|tell me about/i],
    [INTENT_TYPES.PLAN]: [/plan|goal|strategy|roadmap|steps to/i],
    [INTENT_TYPES.EXECUTE]: [/run|execute|do|perform|start|trigger/i],
    [INTENT_TYPES.QUERY]: [/\?$|what|where|when|who|which|find|search|show|list|get/i]
  };

  for (const [intentType, regexes] of Object.entries(patterns)) {
    for (const regex of regexes) {
      if (regex.test(lower)) {
        intent = intentType;
        confidence = 0.75;
        break;
      }
    }
    if (confidence > 0.5) break;
  }

  // Boost confidence if multiple indicators
  const matchCount = Object.values(patterns).flat().filter(r => r.test(lower)).length;
  if (matchCount > 1) confidence = Math.min(confidence + 0.1, 0.95);

  STATE.semantic.stats.intentsClassified++;
  return { intent, confidence, tokens };
}

// Extract named entities from text
function extractEntities(text) {
  ensureSemanticEngine();

  const entities = [];
  const _words = text.split(/\s+/);

  // Simple patterns for entity extraction
  const patterns = {
    [ENTITY_CATEGORIES.DATE]: /\b(\d{1,2}\/\d{1,2}\/\d{2,4}|\d{4}-\d{2}-\d{2}|january|february|march|april|may|june|july|august|september|october|november|december|monday|tuesday|wednesday|thursday|friday|saturday|sunday)\b/gi,
    [ENTITY_CATEGORIES.TIME]: /\b(\d{1,2}:\d{2}(?::\d{2})?(?:\s*[ap]m)?)\b/gi,
    [ENTITY_CATEGORIES.QUANTITY]: /\b(\d+(?:\.\d+)?(?:\s*(?:percent|%|dollars?|€|£|kg|lb|miles?|km|hours?|minutes?|seconds?))?)\b/gi,
    [ENTITY_CATEGORIES.PERSON]: /\b([A-Z][a-z]+(?:\s+[A-Z][a-z]+)+)\b/g, // Capitalized multi-word names
    [ENTITY_CATEGORIES.ORGANIZATION]: /\b([A-Z][A-Za-z]*(?:\s+(?:Inc|Corp|LLC|Ltd|Company|Organization|University|Institute))?)\b/g
  };

  for (const [category, pattern] of Object.entries(patterns)) {
    let match;
    while ((match = pattern.exec(text)) !== null) {
      entities.push({
        text: match[0],
        category,
        start: match.index,
        end: match.index + match[0].length
      });
    }
  }

  // Deduplicate and sort by position
  const seen = new Set();
  const unique = entities.filter(e => {
    const key = `${e.text}:${e.category}`;
    if (seen.has(key)) return false;
    seen.add(key);
    return true;
  }).sort((a, b) => a.start - b.start);

  STATE.semantic.stats.entitiesExtracted += unique.length;
  return unique;
}

// Compute semantic roles (simplified: subject-verb-object extraction)
function extractSemanticRoles(text) {
  // Very simplified SRL - identifies basic SVO patterns
  const sentences = text.split(/[.!?]+/).filter(s => s.trim());
  const roles = [];

  for (const sentence of sentences) {
    const words = sentence.trim().split(/\s+/);
    if (words.length < 3) continue;

    // Simple heuristic: first noun-like word is subject, verb follows, rest is object
    const verbPatterns = /\b(is|are|was|were|has|have|had|does|do|did|will|can|could|would|should|may|might|must|makes?|creates?|builds?|writes?|reads?|finds?|gets?|sets?|runs?|shows?)\b/i;

    const verbMatch = sentence.match(verbPatterns);
    if (verbMatch) {
      const verbIndex = sentence.indexOf(verbMatch[0]);
      const subject = sentence.slice(0, verbIndex).trim();
      const verb = verbMatch[0];
      const object = sentence.slice(verbIndex + verb.length).trim();

      if (subject && object) {
        roles.push({ subject, verb, object, sentence: sentence.trim() });
      }
    }
  }

  return roles;
}

// ===== END SEMANTIC UNDERSTANDING ENGINE =====

// ===== TRANSFER LEARNING ENGINE =====
// Design: Extracts patterns from learned domains and applies them to new domains.
// Bounded: transfer suggestions go through council review.

const TRANSFER_INVARIANTS = Object.freeze({
  PATTERN_ABSTRACTION_REQUIRED: true,  // Can't transfer raw DTUs, only patterns
  CONFIDENCE_DECAY: true,              // Transferred patterns start with lower confidence
  COUNCIL_REVIEW: true,                // Novel transfers need review
  SOURCE_ATTRIBUTION: true             // Must track where pattern came from
});

const DOMAIN_TYPES = Object.freeze({
  TECHNICAL: "technical",
  SCIENTIFIC: "scientific",
  BUSINESS: "business",
  CREATIVE: "creative",
  PERSONAL: "personal",
  SOCIAL: "social",
  PHILOSOPHICAL: "philosophical",
  PROCEDURAL: "procedural",
  GENERAL: "general"
});

function ensureTransferEngine() {
  if (!STATE.transfer) {
    STATE.transfer = {
      patterns: new Map(),              // Abstracted patterns by ID
      domainMappings: new Map(),        // DTU ID -> domain
      transfers: [],                    // Transfer history
      stats: {
        patternsExtracted: 0,
        transfersAttempted: 0,
        transfersSuccessful: 0,
        domainsCovered: new Set()
      },
      config: {
        minPatternSupport: 3,           // Min DTUs to extract pattern
        confidenceDecay: 0.3,           // Decay when transferring
        maxTransfersPerDomain: 50,      // Limit transfers
        requireCouncilReview: true
      }
    };
  }
  if (!(STATE.transfer.patterns instanceof Map)) {
    STATE.transfer.patterns = new Map(Object.entries(STATE.transfer.patterns || {}));
  }
  if (!(STATE.transfer.domainMappings instanceof Map)) {
    STATE.transfer.domainMappings = new Map(Object.entries(STATE.transfer.domainMappings || {}));
  }
}

// Classify DTU into domain
function classifyDomain(dtu) {
  if (!dtu) return DOMAIN_TYPES.GENERAL;

  const text = [dtu.title, dtu.human?.summary, ...(dtu.tags || [])].join(" ").toLowerCase();

  const domainKeywords = {
    [DOMAIN_TYPES.TECHNICAL]: ["code", "programming", "software", "api", "algorithm", "data", "system", "server", "database"],
    [DOMAIN_TYPES.SCIENTIFIC]: ["research", "hypothesis", "experiment", "theory", "study", "evidence", "analysis", "scientific"],
    [DOMAIN_TYPES.BUSINESS]: ["business", "market", "revenue", "customer", "strategy", "profit", "company", "product"],
    [DOMAIN_TYPES.CREATIVE]: ["art", "design", "creative", "story", "music", "visual", "aesthetic", "writing"],
    [DOMAIN_TYPES.PERSONAL]: ["personal", "life", "health", "habit", "goal", "routine", "self", "wellness"],
    [DOMAIN_TYPES.SOCIAL]: ["social", "relationship", "community", "team", "communication", "people", "network"],
    [DOMAIN_TYPES.PHILOSOPHICAL]: ["philosophy", "ethics", "meaning", "existence", "truth", "value", "moral", "wisdom"],
    [DOMAIN_TYPES.PROCEDURAL]: ["process", "workflow", "step", "procedure", "method", "how to", "guide", "instruction"]
  };

  let bestDomain = DOMAIN_TYPES.GENERAL;
  let bestScore = 0;

  for (const [domain, keywords] of Object.entries(domainKeywords)) {
    const score = keywords.filter(kw => text.includes(kw)).length;
    if (score > bestScore) {
      bestScore = score;
      bestDomain = domain;
    }
  }

  return bestDomain;
}

// Extract structural pattern from a set of related DTUs
function extractPattern(dtuIds, patternName = "") {
  ensureTransferEngine();

  if (dtuIds.length < STATE.transfer.config.minPatternSupport) {
    return { ok: false, error: `Need at least ${STATE.transfer.config.minPatternSupport} DTUs to extract pattern` };
  }

  const dtus = dtuIds.map(id => STATE.dtus?.get(id)).filter(Boolean);
  if (dtus.length === 0) return { ok: false, error: "No valid DTUs found" };

  // Extract common structure
  const domains = new Set(dtus.map(d => classifyDomain(d)));
  const commonTags = findCommonElements(dtus.map(d => d.tags || []));
  const avgTier = dtus.reduce((sum, d) => sum + (d.tier === "mega" ? 2 : d.tier === "hyper" ? 3 : 1), 0) / dtus.length;

  // Extract semantic pattern (common themes)
  const allText = dtus.map(d => `${d.title} ${d.human?.summary || ""}`).join(" ");
  const tokens = tokenizeText(allText);
  const tokenFreq = {};
  tokens.forEach(t => { tokenFreq[t] = (tokenFreq[t] || 0) + 1; });
  const topTerms = Object.entries(tokenFreq)
    .sort((a, b) => b[1] - a[1])
    .slice(0, 10)
    .map(([term]) => term);

  // Extract structural template
  const pattern = {
    id: uid("pattern"),
    name: patternName || `Pattern from ${dtus.length} DTUs`,
    sourceDomain: [...domains][0] || DOMAIN_TYPES.GENERAL,
    structure: {
      avgTier,
      commonTags,
      topTerms,
      dtuCount: dtus.length
    },
    template: {
      // Abstracted structure that can be applied to new domain
      components: topTerms.map(term => ({ role: "concept", term })),
      relationships: commonTags.map(tag => ({ type: "tagged", value: tag }))
    },
    confidence: clamp(0.5 + (dtus.length / 20), 0.5, 0.9),
    sourceIds: dtuIds,
    createdAt: nowISO()
  };

  STATE.transfer.patterns.set(pattern.id, pattern);
  STATE.transfer.stats.patternsExtracted++;

  // Tag source DTUs with domain
  for (const dtu of dtus) {
    STATE.transfer.domainMappings.set(dtu.id, pattern.sourceDomain);
  }

  saveStateDebounced();
  return { ok: true, pattern };
}

function findCommonElements(arrays) {
  if (arrays.length === 0) return [];
  return arrays.reduce((common, arr) =>
    common.filter(item => arr.includes(item))
  );
}

// Find analogous patterns for a target domain
function findAnalogousPatterns(targetDomain, query = "") {
  ensureTransferEngine();

  const results = [];

  for (const [patternId, pattern] of STATE.transfer.patterns) {
    // Skip same domain (not a transfer)
    if (pattern.sourceDomain === targetDomain) continue;

    // Compute relevance
    let relevance = 0.5;

    // Boost if query matches pattern terms
    if (query) {
      const queryTokens = new Set(tokenizeText(query));
      const matchingTerms = pattern.structure.topTerms.filter(t => queryTokens.has(t));
      relevance += matchingTerms.length * 0.1;
    }

    // Boost for higher confidence patterns
    relevance += pattern.confidence * 0.2;

    results.push({
      patternId,
      patternName: pattern.name,
      sourceDomain: pattern.sourceDomain,
      targetDomain,
      relevance: clamp(relevance, 0, 1),
      template: pattern.template
    });
  }

  return results.sort((a, b) => b.relevance - a.relevance).slice(0, 10);
}

// Apply a pattern to create new DTU suggestions in target domain
function applyPatternToTarget(patternId, targetDomain, targetContext = "") {
  ensureTransferEngine();

  const pattern = STATE.transfer.patterns.get(patternId);
  if (!pattern) return { ok: false, error: "Pattern not found" };

  STATE.transfer.stats.transfersAttempted++;

  // Generate transfer suggestion
  const transfer = {
    id: uid("transfer"),
    patternId,
    sourceDomain: pattern.sourceDomain,
    targetDomain,
    targetContext,

    // Suggested DTU structure
    suggestion: {
      title: `[Transfer] ${pattern.name} applied to ${targetDomain}`,
      tags: [...pattern.structure.commonTags, targetDomain, "transferred"],
      template: pattern.template,
      sourcePatternTerms: pattern.structure.topTerms
    },

    // Confidence decays on transfer
    confidence: clamp(pattern.confidence * (1 - STATE.transfer.config.confidenceDecay), 0.2, 0.7),

    status: STATE.transfer.config.requireCouncilReview ? "pending_review" : "suggested",
    createdAt: nowISO()
  };

  STATE.transfer.transfers.push(transfer);

  // Cap history
  if (STATE.transfer.transfers.length > 200) {
    STATE.transfer.transfers = STATE.transfer.transfers.slice(-200);
  }

  saveStateDebounced();
  return { ok: true, transfer };
}

// ===== END TRANSFER LEARNING ENGINE =====

// ===== COMMONSENSE REASONING SUBSTRATE =====
// Design: Foundational commonsense knowledge that grounds reasoning.
// Includes physical, social, temporal common knowledge.

const COMMONSENSE_INVARIANTS = Object.freeze({
  ADDITIVE_ONLY: true,                 // Commonsense adds, never overrides user DTUs
  UNCERTAINTY_MARKED: true,            // Commonsense has uncertainty bounds
  CULTURALLY_AWARE: true,              // Social norms vary by culture
  FALSIFIABLE: true                    // Can be challenged with evidence
});

const COMMONSENSE_CATEGORIES = Object.freeze({
  PHYSICAL: "physical",                // Objects, gravity, space
  TEMPORAL: "temporal",                // Time, sequences, duration
  SOCIAL: "social",                    // Norms, expectations, relationships
  CAUSAL: "causal",                    // If-then relationships
  QUANTITY: "quantity",                // Numbers, comparisons, magnitudes
  SPATIAL: "spatial"                   // Locations, directions, containment
});

function ensureCommonsenseSubstrate() {
  if (!STATE.commonsense) {
    STATE.commonsense = {
      facts: new Map(),                 // Commonsense facts by ID
      categories: {},                   // Facts organized by category
      assumptions: new Map(),           // Surfaced assumptions from DTUs
      stats: {
        factsLoaded: 0,
        assumptionsSurfaced: 0,
        queriesAnswered: 0
      },
      config: {
        autoSurfaceAssumptions: true,
        confidenceThreshold: 0.6,
        maxAssumptionsPerDtu: 5
      }
    };

    // Seed with basic commonsense (can be expanded)
    seedCommonsense();
  }
  if (!(STATE.commonsense.facts instanceof Map)) {
    STATE.commonsense.facts = new Map(Object.entries(STATE.commonsense.facts || {}));
  }
  if (!(STATE.commonsense.assumptions instanceof Map)) {
    STATE.commonsense.assumptions = new Map(Object.entries(STATE.commonsense.assumptions || {}));
  }
}

// Seed basic commonsense knowledge
function seedCommonsense() {
  const seeds = [
    // Physical
    { category: COMMONSENSE_CATEGORIES.PHYSICAL, fact: "Objects fall when dropped", confidence: 0.99 },
    { category: COMMONSENSE_CATEGORIES.PHYSICAL, fact: "Water flows downhill", confidence: 0.99 },
    { category: COMMONSENSE_CATEGORIES.PHYSICAL, fact: "Fire is hot", confidence: 0.99 },
    { category: COMMONSENSE_CATEGORIES.PHYSICAL, fact: "Ice is cold", confidence: 0.99 },
    { category: COMMONSENSE_CATEGORIES.PHYSICAL, fact: "Objects occupy space", confidence: 0.99 },
    { category: COMMONSENSE_CATEGORIES.PHYSICAL, fact: "Light travels faster than sound", confidence: 0.99 },

    // Temporal
    { category: COMMONSENSE_CATEGORIES.TEMPORAL, fact: "Causes precede effects", confidence: 0.99 },
    { category: COMMONSENSE_CATEGORIES.TEMPORAL, fact: "Days have 24 hours", confidence: 0.99 },
    { category: COMMONSENSE_CATEGORIES.TEMPORAL, fact: "Past cannot be changed", confidence: 0.99 },
    { category: COMMONSENSE_CATEGORIES.TEMPORAL, fact: "Events happen in sequence", confidence: 0.99 },
    { category: COMMONSENSE_CATEGORIES.TEMPORAL, fact: "Actions take time to complete", confidence: 0.95 },

    // Social
    { category: COMMONSENSE_CATEGORIES.SOCIAL, fact: "People have names", confidence: 0.99 },
    { category: COMMONSENSE_CATEGORIES.SOCIAL, fact: "Promises create expectations", confidence: 0.9 },
    { category: COMMONSENSE_CATEGORIES.SOCIAL, fact: "Questions expect answers", confidence: 0.9 },
    { category: COMMONSENSE_CATEGORIES.SOCIAL, fact: "Greetings initiate conversations", confidence: 0.9 },
    { category: COMMONSENSE_CATEGORIES.SOCIAL, fact: "People have preferences", confidence: 0.95 },

    // Causal
    { category: COMMONSENSE_CATEGORIES.CAUSAL, fact: "Eating reduces hunger", confidence: 0.95 },
    { category: COMMONSENSE_CATEGORIES.CAUSAL, fact: "Learning increases knowledge", confidence: 0.9 },
    { category: COMMONSENSE_CATEGORIES.CAUSAL, fact: "Practice improves skill", confidence: 0.9 },
    { category: COMMONSENSE_CATEGORIES.CAUSAL, fact: "Damage requires repair", confidence: 0.9 },
    { category: COMMONSENSE_CATEGORIES.CAUSAL, fact: "Resources can be depleted", confidence: 0.95 },

    // Quantity
    { category: COMMONSENSE_CATEGORIES.QUANTITY, fact: "More is greater than less", confidence: 0.99 },
    { category: COMMONSENSE_CATEGORIES.QUANTITY, fact: "Zero means none", confidence: 0.99 },
    { category: COMMONSENSE_CATEGORIES.QUANTITY, fact: "Parts sum to whole", confidence: 0.99 },

    // Spatial
    { category: COMMONSENSE_CATEGORIES.SPATIAL, fact: "Containers hold contents", confidence: 0.99 },
    { category: COMMONSENSE_CATEGORIES.SPATIAL, fact: "Paths connect locations", confidence: 0.99 },
    { category: COMMONSENSE_CATEGORIES.SPATIAL, fact: "Objects have size and shape", confidence: 0.99 }
  ];

  for (const seed of seeds) {
    const id = uid("cs");
    STATE.commonsense.facts.set(id, {
      id,
      ...seed,
      type: "axiom",
      createdAt: nowISO()
    });
  }

  // Organize by category
  for (const cat of Object.values(COMMONSENSE_CATEGORIES)) {
    STATE.commonsense.categories[cat] = Array.from(STATE.commonsense.facts.values())
      .filter(f => f.category === cat)
      .map(f => f.id);
  }

  STATE.commonsense.stats.factsLoaded = seeds.length;
}

// Query commonsense for relevant facts
function queryCommonsense(query, category = null) {
  ensureCommonsenseSubstrate();

  const queryTokens = new Set(tokenizeText(query));
  const results = [];

  for (const [id, fact] of STATE.commonsense.facts) {
    if (category && fact.category !== category) continue;

    const factTokens = tokenizeText(fact.fact);
    const overlap = factTokens.filter(t => queryTokens.has(t)).length;
    const relevance = overlap / Math.max(factTokens.length, 1);

    if (relevance > 0.1 || overlap > 0) {
      results.push({
        id,
        fact: fact.fact,
        category: fact.category,
        confidence: fact.confidence,
        relevance
      });
    }
  }

  STATE.commonsense.stats.queriesAnswered++;
  return results.sort((a, b) => b.relevance - a.relevance).slice(0, 10);
}

// Surface implicit assumptions in a DTU
function surfaceAssumptions(dtuId) {
  ensureCommonsenseSubstrate();

  const dtu = STATE.dtus?.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };

  const text = `${dtu.title || ""} ${dtu.human?.summary || ""} ${dtu.content || ""}`;
  const assumptions = [];

  // Check against commonsense categories
  for (const [id, fact] of STATE.commonsense.facts) {
    const factTokens = new Set(tokenizeText(fact.fact));
    const textTokens = tokenizeText(text);

    // If DTU text relates to commonsense fact, it might assume that fact
    const overlap = textTokens.filter(t => factTokens.has(t)).length;
    if (overlap >= 2) {
      assumptions.push({
        assumedFact: fact.fact,
        factId: id,
        category: fact.category,
        confidence: clamp(fact.confidence * (overlap / 5), 0.3, 0.9),
        evidence: `DTU contains related terms`
      });
    }
  }

  // Limit assumptions
  const topAssumptions = assumptions
    .sort((a, b) => b.confidence - a.confidence)
    .slice(0, STATE.commonsense.config.maxAssumptionsPerDtu);

  if (topAssumptions.length > 0) {
    STATE.commonsense.assumptions.set(dtuId, {
      dtuId,
      assumptions: topAssumptions,
      surfacedAt: nowISO()
    });
    STATE.commonsense.stats.assumptionsSurfaced += topAssumptions.length;
  }

  saveStateDebounced();
  return { ok: true, assumptions: topAssumptions };
}

// Add new commonsense fact
function addCommonsenseFact(input) {
  ensureCommonsenseSubstrate();

  const category = COMMONSENSE_CATEGORIES[input.category?.toUpperCase()] || COMMONSENSE_CATEGORIES.CAUSAL;
  const fact = String(input.fact || "").slice(0, 500);
  const confidence = clamp(Number(input.confidence || 0.7), 0.1, 0.99);

  if (!fact) return { ok: false, error: "Fact text required" };

  const id = uid("cs");
  const entry = {
    id,
    category,
    fact,
    confidence,
    type: "learned",
    source: input.source || "user",
    createdAt: nowISO()
  };

  STATE.commonsense.facts.set(id, entry);
  STATE.commonsense.categories[category] = STATE.commonsense.categories[category] || [];
  STATE.commonsense.categories[category].push(id);
  STATE.commonsense.stats.factsLoaded++;

  saveStateDebounced();
  return { ok: true, fact: entry };
}

// ===== END COMMONSENSE REASONING SUBSTRATE =====

// ===== EMBODIMENT/GROUNDING SYSTEM =====
// Design: Connects abstract knowledge to real-world state and actions.
// Includes sensor integration, temporal grounding, action execution.

const GROUNDING_INVARIANTS = Object.freeze({
  REAL_WORLD_AWARE: true,              // Distinguishes abstract from grounded
  SENSOR_VALIDATED: true,              // Sensor data validated before use
  ACTION_CONSENT: true,                // Real actions require consent
  TEMPORAL_ANCHORED: true              // Ground in real time when possible
});

const SENSOR_TYPES = Object.freeze({
  TEMPERATURE: "temperature",
  HUMIDITY: "humidity",
  LIGHT: "light",
  MOTION: "motion",
  LOCATION: "location",
  TIME: "time",
  CALENDAR: "calendar",
  SYSTEM: "system",                    // System metrics (CPU, memory)
  CUSTOM: "custom"
});

const ACTION_TYPES = Object.freeze({
  FILE: "file",                        // File system operations
  NETWORK: "network",                  // API calls
  NOTIFICATION: "notification",        // Send notification
  CALENDAR: "calendar",                // Calendar operations
  COMMAND: "command",                  // Execute command (sandboxed)
  WEBHOOK: "webhook"                   // Trigger webhook
});

function ensureGroundingEngine() {
  if (!STATE.grounding) {
    STATE.grounding = {
      sensors: new Map(),               // Registered sensors
      readings: [],                     // Recent sensor readings (capped)
      groundedDtus: new Map(),          // DTU ID -> grounding metadata
      pendingActions: [],               // Actions awaiting consent
      actionHistory: [],                // Executed actions
      calendar: new Map(),              // Calendar event links
      stats: {
        sensorsRegistered: 0,
        readingsRecorded: 0,
        actionsExecuted: 0,
        dtusGrounded: 0
      },
      config: {
        maxReadings: 1000,
        maxActionHistory: 200,
        requireActionConsent: true,
        autoGroundTimestamps: true
      }
    };
  }
  if (!(STATE.grounding.sensors instanceof Map)) {
    STATE.grounding.sensors = new Map(Object.entries(STATE.grounding.sensors || {}));
  }
  if (!(STATE.grounding.groundedDtus instanceof Map)) {
    STATE.grounding.groundedDtus = new Map(Object.entries(STATE.grounding.groundedDtus || {}));
  }
  if (!(STATE.grounding.calendar instanceof Map)) {
    STATE.grounding.calendar = new Map(Object.entries(STATE.grounding.calendar || {}));
  }
}

// Register a sensor
function registerSensor(input) {
  ensureGroundingEngine();

  const id = uid("sensor");
  const sensorType = SENSOR_TYPES[input.type?.toUpperCase()] || SENSOR_TYPES.CUSTOM;

  const sensor = {
    id,
    name: String(input.name || "").slice(0, 100) || `Sensor ${id}`,
    type: sensorType,
    unit: String(input.unit || "").slice(0, 20),
    endpoint: input.endpoint || null,   // URL or local path to poll
    pollInterval: clamp(Number(input.pollInterval || 60000), 1000, 3600000),
    lastReading: null,
    status: "active",
    createdAt: nowISO()
  };

  STATE.grounding.sensors.set(id, sensor);
  STATE.grounding.stats.sensorsRegistered++;

  saveStateDebounced();
  return { ok: true, sensor };
}

// Record a sensor reading
function recordSensorReading(sensorId, value, timestamp = null) {
  ensureGroundingEngine();

  const sensor = STATE.grounding.sensors.get(sensorId);
  if (!sensor) return { ok: false, error: "Sensor not found" };

  const reading = {
    id: uid("reading"),
    sensorId,
    sensorName: sensor.name,
    type: sensor.type,
    value,
    unit: sensor.unit,
    timestamp: timestamp || nowISO()
  };

  STATE.grounding.readings.push(reading);
  sensor.lastReading = reading;

  // Cap readings
  if (STATE.grounding.readings.length > STATE.grounding.config.maxReadings) {
    STATE.grounding.readings = STATE.grounding.readings.slice(-STATE.grounding.config.maxReadings);
  }

  STATE.grounding.stats.readingsRecorded++;
  saveStateDebounced();

  return { ok: true, reading };
}

// Ground a DTU with real-world context
function groundDtu(dtuId, groundingData = {}) {
  ensureGroundingEngine();

  const dtu = STATE.dtus?.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };

  const grounding = {
    dtuId,
    timestamp: groundingData.timestamp || nowISO(),
    location: groundingData.location || null,
    sensorReadings: groundingData.sensorReadings || [],
    calendarEvent: groundingData.calendarEvent || null,
    realWorldContext: String(groundingData.context || "").slice(0, 1000),
    confidence: clamp(Number(groundingData.confidence || 0.7), 0, 1),
    groundedAt: nowISO()
  };

  // Auto-add recent sensor readings if available
  if (STATE.grounding.readings.length > 0 && grounding.sensorReadings.length === 0) {
    const recent = STATE.grounding.readings.slice(-5);
    grounding.sensorReadings = recent.map(r => ({
      sensorId: r.sensorId,
      type: r.type,
      value: r.value,
      unit: r.unit
    }));
  }

  STATE.grounding.groundedDtus.set(dtuId, grounding);
  STATE.grounding.stats.dtusGrounded++;

  saveStateDebounced();
  return { ok: true, grounding };
}

// Link DTU to calendar event
function linkToCalendar(dtuId, eventData) {
  ensureGroundingEngine();

  const dtu = STATE.dtus?.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };

  const event = {
    id: uid("event"),
    dtuId,
    title: String(eventData.title || dtu.title || "").slice(0, 200),
    startTime: eventData.startTime || nowISO(),
    endTime: eventData.endTime || null,
    recurrence: eventData.recurrence || null,
    location: eventData.location || null,
    createdAt: nowISO()
  };

  STATE.grounding.calendar.set(event.id, event);

  // Update DTU grounding
  const grounding = STATE.grounding.groundedDtus.get(dtuId) || { dtuId };
  grounding.calendarEvent = event.id;
  STATE.grounding.groundedDtus.set(dtuId, grounding);

  saveStateDebounced();
  return { ok: true, event };
}

// Propose an action (requires consent)
function proposeAction(input) {
  ensureGroundingEngine();

  const actionType = ACTION_TYPES[input.type?.toUpperCase()] || ACTION_TYPES.NOTIFICATION;
  const goalId = input.goalId || null;

  const action = {
    id: uid("action"),
    type: actionType,
    description: String(input.description || "").slice(0, 500),
    payload: input.payload || {},
    goalId,
    status: STATE.grounding.config.requireActionConsent ? "pending_consent" : "approved",
    proposedAt: nowISO(),
    executedAt: null,
    result: null
  };

  if (action.status === "pending_consent") {
    STATE.grounding.pendingActions.push(action);
  }

  saveStateDebounced();
  return { ok: true, action, requiresConsent: action.status === "pending_consent" };
}

// Approve and execute an action
function approveAction(actionId) {
  ensureGroundingEngine();

  const actionIndex = STATE.grounding.pendingActions.findIndex(a => a.id === actionId);
  if (actionIndex === -1) return { ok: false, error: "Action not found" };

  const action = STATE.grounding.pendingActions[actionIndex];
  action.status = "approved";

  // Execute based on type
  let result = { ok: false, error: "Unknown action type" };

  switch (action.type) {
    case ACTION_TYPES.NOTIFICATION:
      result = executeNotificationAction(action);
      break;
    case ACTION_TYPES.WEBHOOK:
      result = executeWebhookAction(action);
      break;
    case ACTION_TYPES.CALENDAR:
      result = executeCalendarAction(action);
      break;
    // FILE, NETWORK, COMMAND would need more security consideration
    default:
      result = { ok: true, message: `Action ${action.type} logged but not executed (safety)` };
  }

  action.status = result.ok ? "completed" : "failed";
  action.executedAt = nowISO();
  action.result = result;

  // Move to history
  STATE.grounding.pendingActions.splice(actionIndex, 1);
  STATE.grounding.actionHistory.push(action);

  // Cap history
  if (STATE.grounding.actionHistory.length > STATE.grounding.config.maxActionHistory) {
    STATE.grounding.actionHistory = STATE.grounding.actionHistory.slice(-STATE.grounding.config.maxActionHistory);
  }

  STATE.grounding.stats.actionsExecuted++;
  saveStateDebounced();

  return { ok: true, action, result };
}

function executeNotificationAction(action) {
  // Queue notification
  ensureQueues();
  STATE.queues.notifications.push({
    id: uid("notif"),
    type: "action_notification",
    title: action.description,
    payload: action.payload,
    createdAt: nowISO()
  });
  return { ok: true, message: "Notification queued" };
}

function executeWebhookAction(action) {
  // Just log for now - actual webhook would need async handling
  return { ok: true, message: "Webhook action logged", webhook: action.payload.url };
}

function executeCalendarAction(action) {
  // Create calendar entry
  const event = {
    id: uid("cal"),
    title: action.payload.title || action.description,
    startTime: action.payload.startTime || nowISO(),
    endTime: action.payload.endTime,
    createdAt: nowISO()
  };
  STATE.grounding.calendar.set(event.id, event);
  return { ok: true, event };
}

// Get current grounded context (all recent sensor data + time)
function getCurrentGroundedContext() {
  ensureGroundingEngine();

  const now = new Date();
  const recentReadings = STATE.grounding.readings.slice(-20);

  return {
    timestamp: nowISO(),
    timeOfDay: now.getHours() < 12 ? "morning" : now.getHours() < 17 ? "afternoon" : "evening",
    dayOfWeek: ["Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"][now.getDay()],
    sensors: recentReadings.map(r => ({
      type: r.type,
      value: r.value,
      unit: r.unit,
      age: Date.now() - new Date(r.timestamp).getTime()
    })),
    activeSensors: STATE.grounding.sensors.size,
    groundedDtus: STATE.grounding.groundedDtus.size,
    pendingActions: STATE.grounding.pendingActions.length
  };
}

// ===== END EMBODIMENT/GROUNDING SYSTEM =====

// ===== REASONING CHAINS ENGINE =====
// Design: Multi-step reasoning with traceable logic. Every inference is justified.

const REASONING_INVARIANTS = Object.freeze({
  EVERY_STEP_JUSTIFIED: true,          // No unjustified leaps
  CHAIN_TRACEABLE: true,               // Can follow reasoning back
  ASSUMPTIONS_EXPLICIT: true,          // Hidden assumptions surfaced
  VALIDITY_CHECKED: true               // Logic validated
});

const INFERENCE_TYPES = Object.freeze({
  DEDUCTION: "deduction",              // A→B, A ∴ B
  INDUCTION: "induction",              // Patterns → generalization
  ABDUCTION: "abduction",              // Effect → best explanation
  ANALOGY: "analogy",                  // A:B :: C:D
  CAUSAL: "causal",                    // Cause → effect
  TEMPORAL: "temporal",                // Before → after
  COMPOSITION: "composition",          // Parts → whole
  DECOMPOSITION: "decomposition"       // Whole → parts
});

function ensureReasoningEngine() {
  if (!STATE.reasoning) {
    STATE.reasoning = {
      chains: new Map(),                // Reasoning chains by ID
      steps: new Map(),                 // Individual steps
      validations: [],                  // Validation history
      stats: {
        chainsCreated: 0,
        stepsExecuted: 0,
        validationsPassed: 0,
        validationsFailed: 0
      },
      config: {
        maxChainLength: 20,             // Prevent infinite chains
        requireJustification: true,
        autoValidate: true
      }
    };
  }
  if (!(STATE.reasoning.chains instanceof Map)) {
    STATE.reasoning.chains = new Map(Object.entries(STATE.reasoning.chains || {}));
  }
  if (!(STATE.reasoning.steps instanceof Map)) {
    STATE.reasoning.steps = new Map(Object.entries(STATE.reasoning.steps || {}));
  }
}

// Create a new reasoning chain
function createReasoningChain(input = {}) {
  ensureReasoningEngine();

  const id = uid("chain");
  const now = nowISO();

  const chain = {
    id,
    question: String(input.question || "").slice(0, 1000),
    goal: String(input.goal || "derive_conclusion").slice(0, 200),
    steps: [],
    assumptions: [],
    conclusion: null,
    status: "active",
    confidence: 1.0,
    createdAt: now,
    updatedAt: now
  };

  STATE.reasoning.chains.set(id, chain);
  STATE.reasoning.stats.chainsCreated++;

  return { ok: true, chain };
}

// Add a step to a reasoning chain
function addReasoningStep(chainId, input = {}) {
  ensureReasoningEngine();

  const chain = STATE.reasoning.chains.get(chainId);
  if (!chain) return { ok: false, error: "Chain not found" };
  if (chain.status !== "active") return { ok: false, error: "Chain not active" };
  if (chain.steps.length >= STATE.reasoning.config.maxChainLength) {
    return { ok: false, error: "Chain length limit reached" };
  }

  const inferenceType = INFERENCE_TYPES[input.type?.toUpperCase()] || input.type || INFERENCE_TYPES.DEDUCTION;

  const stepId = uid("step");
  const step = {
    id: stepId,
    chainId,
    index: chain.steps.length,
    type: inferenceType,

    // What we're reasoning from
    premises: Array.isArray(input.premises) ? input.premises.slice(0, 10) : [],
    premiseDtuIds: Array.isArray(input.premiseDtuIds) ? input.premiseDtuIds.slice(0, 10) : [],

    // What we conclude
    conclusion: String(input.conclusion || "").slice(0, 1000),

    // Justification (required)
    justification: String(input.justification || "").slice(0, 500),
    rule: String(input.rule || "").slice(0, 200),  // e.g., "modus ponens", "pattern generalization"

    // Confidence decay
    confidence: clamp(Number(input.confidence || 0.9), 0.1, 1.0),

    // Assumptions made
    assumptions: Array.isArray(input.assumptions) ? input.assumptions.slice(0, 5) : [],

    createdAt: nowISO()
  };

  // Validate step has justification
  if (STATE.reasoning.config.requireJustification && !step.justification) {
    return { ok: false, error: "Justification required for inference step" };
  }

  // Add to chain
  chain.steps.push(stepId);
  chain.assumptions.push(...step.assumptions);

  // Confidence decays with each step
  chain.confidence *= step.confidence;
  chain.updatedAt = nowISO();

  STATE.reasoning.steps.set(stepId, step);
  STATE.reasoning.stats.stepsExecuted++;

  // Auto-validate if enabled
  if (STATE.reasoning.config.autoValidate) {
    validateStep(stepId);
  }

  saveStateDebounced();
  return { ok: true, step, chainConfidence: chain.confidence };
}

// Validate a reasoning step
function validateStep(stepId) {
  ensureReasoningEngine();

  const step = STATE.reasoning.steps.get(stepId);
  if (!step) return { ok: false, error: "Step not found" };

  const issues = [];

  // Check: has premises
  if (step.premises.length === 0 && step.premiseDtuIds.length === 0) {
    issues.push("No premises provided");
  }

  // Check: has conclusion
  if (!step.conclusion) {
    issues.push("No conclusion stated");
  }

  // Check: has justification
  if (!step.justification) {
    issues.push("No justification provided");
  }

  // Check: inference type is valid
  if (!Object.values(INFERENCE_TYPES).includes(step.type)) {
    issues.push(`Unknown inference type: ${step.type}`);
  }

  // Check: deduction requires rule
  if (step.type === INFERENCE_TYPES.DEDUCTION && !step.rule) {
    issues.push("Deductive reasoning should specify the rule applied");
  }

  const valid = issues.length === 0;

  if (valid) {
    STATE.reasoning.stats.validationsPassed++;
  } else {
    STATE.reasoning.stats.validationsFailed++;
  }

  STATE.reasoning.validations.push({
    stepId,
    valid,
    issues,
    validatedAt: nowISO()
  });

  // Cap validations
  if (STATE.reasoning.validations.length > 500) {
    STATE.reasoning.validations = STATE.reasoning.validations.slice(-500);
  }

  return { ok: true, valid, issues };
}

// Complete a reasoning chain with conclusion
function concludeChain(chainId, conclusion) {
  ensureReasoningEngine();

  const chain = STATE.reasoning.chains.get(chainId);
  if (!chain) return { ok: false, error: "Chain not found" };

  chain.conclusion = {
    statement: String(conclusion.statement || conclusion).slice(0, 1000),
    confidence: chain.confidence,
    supportingSteps: chain.steps.length,
    assumptions: [...new Set(chain.assumptions)],
    derivedAt: nowISO()
  };

  chain.status = "concluded";
  chain.updatedAt = nowISO();

  // ===== REASONING → HYPOTHESIS INTEGRATION =====
  // When a reasoning chain concludes, check if it supports/contradicts any active hypothesis
  try {
    if (STATE.hypothesisEngine?.hypotheses) {
      const _concText = tokenish(chain.conclusion.statement || "");
      for (const [_hId, hyp] of STATE.hypothesisEngine.hypotheses) {
        if (hyp.state === "testing" || hyp.state === "proposed") {
          const _hypText = tokenish(hyp.statement || "");
          const _overlap = jaccard(_concText.split(/\s+/), _hypText.split(/\s+/));
          if (_overlap > 0.2) {
            // Auto-add as supporting evidence (positive polarity conclusion = support)
            const supports = (chain.confidence || 0.5) > 0.5;
            hyp.evidenceFor = hyp.evidenceFor || [];
            hyp.evidenceAgainst = hyp.evidenceAgainst || [];
            const evidenceEntry = {
              type: "reasoning_chain_conclusion",
              chainId,
              statement: chain.conclusion.statement.slice(0, 500),
              confidence: chain.confidence,
              addedAt: nowISO()
            };
            if (supports) hyp.evidenceFor.push(evidenceEntry);
            else hyp.evidenceAgainst.push(evidenceEntry);
          }
        }
      }
    }
  } catch {}
  // ===== END REASONING → HYPOTHESIS =====

  // ===== REASONING → METACOGNITION =====
  // Record reasoning chain completion as a metacognition strategy use
  try {
    if (STATE.metacognition) {
      STATE.metacognition.strategies = STATE.metacognition.strategies || [];
      STATE.metacognition.strategies.push({
        type: chain.type || "deductive",
        chainId,
        steps: chain.steps.length,
        confidence: chain.confidence,
        usedAt: nowISO()
      });
      if (STATE.metacognition.strategies.length > 100) {
        STATE.metacognition.strategies = STATE.metacognition.strategies.slice(-100);
      }
    }
  } catch {}
  // ===== END REASONING → METACOGNITION =====

  // ===== REASONING → TRANSFER PATTERN EXTRACTION =====
  // Successful reasoning chains become reusable transfer patterns
  try {
    autoExtractTransferPattern(chain);
  } catch {}
  // ===== END REASONING → TRANSFER =====

  saveStateDebounced();
  return { ok: true, chain };
}

// Get full reasoning trace
function getReasoningTrace(chainId) {
  ensureReasoningEngine();

  const chain = STATE.reasoning.chains.get(chainId);
  if (!chain) return { ok: false, error: "Chain not found" };

  const steps = chain.steps.map(stepId => STATE.reasoning.steps.get(stepId)).filter(Boolean);

  const trace = {
    chainId,
    question: chain.question,
    steps: steps.map((s, i) => ({
      index: i,
      type: s.type,
      premises: s.premises,
      conclusion: s.conclusion,
      justification: s.justification,
      rule: s.rule,
      confidence: s.confidence
    })),
    assumptions: chain.assumptions,
    conclusion: chain.conclusion,
    overallConfidence: chain.confidence
  };

  return { ok: true, trace };
}

// ===== INFERENCE ENGINE (Actual Reasoning) =====
// Performs logical inference using syllogistic rules and knowledge base.

// Knowledge base for inference (facts and rules)
function ensureInferenceKnowledgeBase() {
  if (!STATE.reasoning.knowledgeBase) {
    STATE.reasoning.knowledgeBase = {
      facts: new Map(),      // fact_id -> { subject, predicate, object, confidence }
      rules: new Map(),      // rule_id -> { antecedent, consequent, type }
      derived: new Map(),    // Derived conclusions
      stats: {
        inferencesPerformed: 0,
        factsDeduced: 0,
        rulesApplied: 0
      }
    };
  }
}

// Inference rule types
const INFERENCE_RULES = Object.freeze({
  MODUS_PONENS: "modus_ponens",           // P→Q, P ⊢ Q
  MODUS_TOLLENS: "modus_tollens",         // P→Q, ¬Q ⊢ ¬P
  HYPOTHETICAL_SYLLOGISM: "hypothetical_syllogism",  // P→Q, Q→R ⊢ P→R
  DISJUNCTIVE_SYLLOGISM: "disjunctive_syllogism",    // P∨Q, ¬P ⊢ Q
  UNIVERSAL_INSTANTIATION: "universal_instantiation", // ∀x.P(x) ⊢ P(a)
  EXISTENTIAL_GENERALIZATION: "existential_generalization", // P(a) ⊢ ∃x.P(x)
  CONJUNCTION: "conjunction",              // P, Q ⊢ P∧Q
  SIMPLIFICATION: "simplification",        // P∧Q ⊢ P
  TRANSITIVITY: "transitivity"             // A⊆B, B⊆C ⊢ A⊆C
});

// Add a fact to the knowledge base
function addInferenceFact(input = {}) {
  ensureReasoningEngine();
  ensureInferenceKnowledgeBase();

  const id = uid("fact");
  const fact = {
    id,
    subject: String(input.subject || "").slice(0, 200),
    predicate: String(input.predicate || "").slice(0, 100),
    object: String(input.object || "").slice(0, 200),
    negated: Boolean(input.negated),
    universal: Boolean(input.universal),  // "all X" vs specific X
    confidence: clamp(Number(input.confidence || 1.0), 0, 1),
    source: String(input.source || "user").slice(0, 100),
    createdAt: nowISO()
  };

  STATE.reasoning.knowledgeBase.facts.set(id, fact);
  saveStateDebounced();

  // Trigger forward chaining to derive new conclusions
  const derived = forwardChain();

  return { ok: true, fact, newDerivations: derived.length };
}

// Add an inference rule
function addInferenceRule(input = {}) {
  ensureReasoningEngine();
  ensureInferenceKnowledgeBase();

  const id = uid("rule");
  const rule = {
    id,
    name: String(input.name || "").slice(0, 100),
    type: INFERENCE_RULES[input.type?.toUpperCase()] || input.type || "implication",
    antecedent: {
      subject: String(input.antecedent?.subject || input.ifSubject || "").slice(0, 200),
      predicate: String(input.antecedent?.predicate || input.ifPredicate || "").slice(0, 100),
      object: String(input.antecedent?.object || input.ifObject || "").slice(0, 200)
    },
    consequent: {
      subject: String(input.consequent?.subject || input.thenSubject || "").slice(0, 200),
      predicate: String(input.consequent?.predicate || input.thenPredicate || "").slice(0, 100),
      object: String(input.consequent?.object || input.thenObject || "").slice(0, 200)
    },
    confidence: clamp(Number(input.confidence || 1.0), 0, 1),
    createdAt: nowISO()
  };

  STATE.reasoning.knowledgeBase.rules.set(id, rule);
  saveStateDebounced();

  return { ok: true, rule };
}

// Pattern matching for facts
function matchFact(pattern, fact) {
  // Pattern can have wildcards (empty string matches anything)
  if (pattern.subject && pattern.subject !== fact.subject) return false;
  if (pattern.predicate && pattern.predicate !== fact.predicate) return false;
  if (pattern.object && pattern.object !== fact.object) return false;
  if (pattern.negated !== undefined && pattern.negated !== fact.negated) return false;
  return true;
}

// Find facts matching a pattern
function findMatchingFacts(pattern) {
  ensureReasoningEngine();
  ensureInferenceKnowledgeBase();

  const matches = [];
  for (const [_id, fact] of STATE.reasoning.knowledgeBase.facts) {
    if (matchFact(pattern, fact)) {
      matches.push(fact);
    }
  }
  // Also check derived facts
  for (const [_id, fact] of STATE.reasoning.knowledgeBase.derived) {
    if (matchFact(pattern, fact)) {
      matches.push(fact);
    }
  }
  return matches;
}

// Apply modus ponens: P→Q, P ⊢ Q
function applyModusPonens(rule, fact) {
  // Check if fact matches the antecedent of the rule
  if (!matchFact(rule.antecedent, fact)) return null;

  // Derive the consequent with variable substitution
  const derived = {
    subject: rule.consequent.subject || fact.subject,
    predicate: rule.consequent.predicate,
    object: rule.consequent.object || fact.object,
    negated: false,
    confidence: fact.confidence * rule.confidence,
    derivedFrom: {
      rule: INFERENCE_RULES.MODUS_PONENS,
      ruleId: rule.id,
      factId: fact.id
    }
  };

  return derived;
}

// Apply modus tollens: P→Q, ¬Q ⊢ ¬P
function applyModusTollens(rule, negatedConsequent) {
  // Check if we have a negated version of the rule's consequent
  if (!matchFact({ ...rule.consequent, negated: true }, negatedConsequent)) return null;

  // Derive negated antecedent
  const derived = {
    subject: rule.antecedent.subject,
    predicate: rule.antecedent.predicate,
    object: rule.antecedent.object,
    negated: true,
    confidence: negatedConsequent.confidence * rule.confidence,
    derivedFrom: {
      rule: INFERENCE_RULES.MODUS_TOLLENS,
      ruleId: rule.id,
      factId: negatedConsequent.id
    }
  };

  return derived;
}

// Apply hypothetical syllogism: P→Q, Q→R ⊢ P→R
function _applyHypotheticalSyllogism(rule1, rule2) {
  // Check if rule1's consequent matches rule2's antecedent
  if (rule1.consequent.subject !== rule2.antecedent.subject) return null;
  if (rule1.consequent.predicate !== rule2.antecedent.predicate) return null;

  // Create new rule P→R
  const newRule = {
    id: uid("rule"),
    name: `Derived: ${rule1.name} + ${rule2.name}`,
    type: "implication",
    antecedent: { ...rule1.antecedent },
    consequent: { ...rule2.consequent },
    confidence: rule1.confidence * rule2.confidence,
    derivedFrom: {
      rule: INFERENCE_RULES.HYPOTHETICAL_SYLLOGISM,
      rule1Id: rule1.id,
      rule2Id: rule2.id
    },
    createdAt: nowISO()
  };

  return newRule;
}

// Apply universal instantiation: ∀x.P(x) ⊢ P(a)
function applyUniversalInstantiation(universalFact, instance) {
  if (!universalFact.universal) return null;

  // Instantiate the universal with a specific instance
  const derived = {
    subject: instance,
    predicate: universalFact.predicate,
    object: universalFact.object,
    negated: universalFact.negated,
    confidence: universalFact.confidence * 0.95, // Slight confidence decay
    derivedFrom: {
      rule: INFERENCE_RULES.UNIVERSAL_INSTANTIATION,
      universalFactId: universalFact.id,
      instance
    }
  };

  return derived;
}

// Forward chaining: derive all possible conclusions from current facts
function forwardChain(maxIterations = 10) {
  ensureReasoningEngine();
  ensureInferenceKnowledgeBase();

  const newDerivations = [];
  const seenSignatures = new Set();

  // Create signatures for existing facts
  for (const [_id, fact] of STATE.reasoning.knowledgeBase.facts) {
    seenSignatures.add(`${fact.subject}|${fact.predicate}|${fact.object}|${fact.negated}`);
  }
  for (const [_id, fact] of STATE.reasoning.knowledgeBase.derived) {
    seenSignatures.add(`${fact.subject}|${fact.predicate}|${fact.object}|${fact.negated}`);
  }

  for (let iter = 0; iter < maxIterations; iter++) {
    let derivedThisRound = 0;

    // Get all facts (original + derived)
    const allFacts = [
      ...STATE.reasoning.knowledgeBase.facts.values(),
      ...STATE.reasoning.knowledgeBase.derived.values()
    ];

    // Apply rules to facts
    for (const [_ruleId, rule] of STATE.reasoning.knowledgeBase.rules) {
      for (const fact of allFacts) {
        // Try modus ponens
        const mp = applyModusPonens(rule, fact);
        if (mp) {
          const sig = `${mp.subject}|${mp.predicate}|${mp.object}|${mp.negated}`;
          if (!seenSignatures.has(sig)) {
            seenSignatures.add(sig);
            mp.id = uid("derived");
            mp.createdAt = nowISO();
            STATE.reasoning.knowledgeBase.derived.set(mp.id, mp);
            newDerivations.push(mp);
            derivedThisRound++;
            STATE.reasoning.knowledgeBase.stats.factsDeduced++;
          }
        }

        // Try modus tollens (for negated facts)
        if (fact.negated) {
          const mt = applyModusTollens(rule, fact);
          if (mt) {
            const sig = `${mt.subject}|${mt.predicate}|${mt.object}|${mt.negated}`;
            if (!seenSignatures.has(sig)) {
              seenSignatures.add(sig);
              mt.id = uid("derived");
              mt.createdAt = nowISO();
              STATE.reasoning.knowledgeBase.derived.set(mt.id, mt);
              newDerivations.push(mt);
              derivedThisRound++;
              STATE.reasoning.knowledgeBase.stats.factsDeduced++;
            }
          }
        }

        // Universal instantiation
        if (fact.universal) {
          // Find potential instances from other facts
          const potentialInstances = new Set();
          for (const f of allFacts) {
            if (f.subject && !f.universal) potentialInstances.add(f.subject);
          }

          for (const instance of potentialInstances) {
            const ui = applyUniversalInstantiation(fact, instance);
            if (ui) {
              const sig = `${ui.subject}|${ui.predicate}|${ui.object}|${ui.negated}`;
              if (!seenSignatures.has(sig)) {
                seenSignatures.add(sig);
                ui.id = uid("derived");
                ui.createdAt = nowISO();
                STATE.reasoning.knowledgeBase.derived.set(ui.id, ui);
                newDerivations.push(ui);
                derivedThisRound++;
                STATE.reasoning.knowledgeBase.stats.factsDeduced++;
              }
            }
          }
        }
      }

      STATE.reasoning.knowledgeBase.stats.rulesApplied++;
    }

    // Stop if no new derivations
    if (derivedThisRound === 0) break;
  }

  STATE.reasoning.knowledgeBase.stats.inferencesPerformed++;
  saveStateDebounced();

  return newDerivations;
}

// Query the knowledge base with inference
function queryWithInference(query) {
  ensureReasoningEngine();
  ensureInferenceKnowledgeBase();

  // First, try forward chaining to derive any new facts
  forwardChain();

  // Search for matching facts
  const matches = findMatchingFacts({
    subject: query.subject,
    predicate: query.predicate,
    object: query.object
  });

  if (matches.length > 0) {
    return {
      ok: true,
      found: true,
      facts: matches,
      explanation: matches.map(f =>
        f.derivedFrom
          ? `"${f.subject} ${f.predicate} ${f.object}" was derived using ${f.derivedFrom.rule}`
          : `"${f.subject} ${f.predicate} ${f.object}" is a known fact`
      )
    };
  }

  return {
    ok: true,
    found: false,
    facts: [],
    explanation: ["No matching facts found in knowledge base"]
  };
}

// Perform syllogistic reasoning: Given "All A are B" and "X is A", derive "X is B"
function syllogisticReason(input = {}) {
  ensureReasoningEngine();
  ensureInferenceKnowledgeBase();

  const majorPremise = input.majorPremise; // "All mammals are warm-blooded"
  const minorPremise = input.minorPremise; // "A whale is a mammal"

  // Parse major premise (All X are Y)
  const majorMatch = String(majorPremise || "").match(/^all\s+(\w+)\s+are\s+(.+)$/i);
  if (!majorMatch) {
    return { ok: false, error: "Major premise must be in form 'All X are Y'" };
  }
  const category = majorMatch[1].toLowerCase();
  const property = majorMatch[2].toLowerCase();

  // Parse minor premise (Z is X)
  const minorMatch = String(minorPremise || "").match(/^(?:a\s+)?(\w+)\s+is\s+(?:a\s+)?(\w+)$/i);
  if (!minorMatch) {
    return { ok: false, error: "Minor premise must be in form 'X is Y'" };
  }
  const subject = minorMatch[1].toLowerCase();
  const subjectCategory = minorMatch[2].toLowerCase();

  // Check if minor premise's category matches major premise's subject
  if (subjectCategory !== category) {
    return {
      ok: false,
      error: `Category mismatch: "${subjectCategory}" does not match "${category}"`
    };
  }

  // Add facts and rule to knowledge base
  addInferenceFact({
    subject: category,
    predicate: "is",
    object: property,
    universal: true,
    source: "major_premise"
  });

  addInferenceFact({
    subject,
    predicate: "is",
    object: category,
    source: "minor_premise"
  });

  addInferenceRule({
    name: `All ${category} are ${property}`,
    type: "implication",
    antecedent: { predicate: "is", object: category },
    consequent: { predicate: "is", object: property },
    confidence: 1.0
  });

  // Perform inference
  const derivations = forwardChain();

  // Look for the conclusion
  const conclusion = derivations.find(d =>
    d.subject === subject && d.predicate === "is" && d.object === property
  );

  if (conclusion) {
    return {
      ok: true,
      conclusion: `${subject.charAt(0).toUpperCase() + subject.slice(1)} is ${property}`,
      derivation: {
        majorPremise,
        minorPremise,
        conclusion: `${subject} is ${property}`,
        rule: "Syllogistic reasoning via universal instantiation and modus ponens",
        confidence: conclusion.confidence
      }
    };
  }

  return {
    ok: false,
    error: "Could not derive conclusion",
    derivations: derivations.map(d => `${d.subject} ${d.predicate} ${d.object}`)
  };
}

// Get knowledge base status
function getInferenceStatus() {
  ensureReasoningEngine();
  ensureInferenceKnowledgeBase();

  return {
    ok: true,
    facts: STATE.reasoning.knowledgeBase.facts.size,
    rules: STATE.reasoning.knowledgeBase.rules.size,
    derived: STATE.reasoning.knowledgeBase.derived.size,
    stats: STATE.reasoning.knowledgeBase.stats
  };
}

// ===== END INFERENCE ENGINE =====

// ===== END REASONING CHAINS ENGINE =====

// ===== HYPOTHESIS ENGINE (Scientific Method) =====
// Design: Propose → Design Test → Gather Evidence → Evaluate → Accept/Reject

const HYPOTHESIS_INVARIANTS = Object.freeze({
  FALSIFIABLE_REQUIRED: true,          // Must be testable
  EVIDENCE_BASED: true,                // Decisions based on evidence
  PRIOR_ACKNOWLEDGED: true,            // Prior beliefs explicit
  UNCERTAINTY_QUANTIFIED: true         // Confidence intervals
});

const HYPOTHESIS_STATES = Object.freeze({
  PROPOSED: "proposed",
  TESTING: "testing",
  SUPPORTED: "supported",
  REFUTED: "refuted",
  INCONCLUSIVE: "inconclusive"
});

function ensureHypothesisEngine() {
  if (!STATE.hypothesisEngine) {
    STATE.hypothesisEngine = {
      hypotheses: new Map(),
      experiments: new Map(),
      evidence: new Map(),
      stats: {
        proposed: 0,
        supported: 0,
        refuted: 0,
        inconclusive: 0
      },
      config: {
        minEvidenceToDecide: 3,
        supportThreshold: 0.7,
        refuteThreshold: 0.3,
        priorWeight: 0.3
      }
    };
  }
  if (!(STATE.hypothesisEngine.hypotheses instanceof Map)) {
    STATE.hypothesisEngine.hypotheses = new Map(Object.entries(STATE.hypothesisEngine.hypotheses || {}));
  }
  if (!(STATE.hypothesisEngine.experiments instanceof Map)) {
    STATE.hypothesisEngine.experiments = new Map(Object.entries(STATE.hypothesisEngine.experiments || {}));
  }
  if (!(STATE.hypothesisEngine.evidence instanceof Map)) {
    STATE.hypothesisEngine.evidence = new Map(Object.entries(STATE.hypothesisEngine.evidence || {}));
  }
}

// Propose a hypothesis
function proposeHypothesis(input = {}) {
  ensureHypothesisEngine();

  const id = uid("hyp");
  const statement = String(input.statement || "").slice(0, 1000);

  if (!statement) return { ok: false, error: "Hypothesis statement required" };

  // Check falsifiability (simple heuristic)
  const falsifiable = /\b(if|when|would|should|will|causes?|leads?\s+to|results?\s+in|predicts?)\b/i.test(statement);

  const hypothesis = {
    id,
    statement,
    domain: String(input.domain || "general").slice(0, 100),

    // Falsifiability
    falsifiable,
    falsificationCriteria: String(input.falsificationCriteria || "").slice(0, 500),

    // Prior belief
    priorConfidence: clamp(Number(input.priorConfidence || 0.5), 0, 1),

    // Current state
    state: HYPOTHESIS_STATES.PROPOSED,
    posteriorConfidence: clamp(Number(input.priorConfidence || 0.5), 0, 1),

    // Evidence tracking
    evidenceFor: [],
    evidenceAgainst: [],

    // Experiments
    experiments: [],

    // Metadata
    source: input.source || "user",
    relatedDtuIds: Array.isArray(input.relatedDtuIds) ? input.relatedDtuIds.slice(0, 20) : [],

    createdAt: nowISO(),
    updatedAt: nowISO()
  };

  if (!falsifiable && !input.falsificationCriteria) {
    hypothesis.warnings = ["Hypothesis may not be falsifiable - consider adding falsification criteria"];
  }

  STATE.hypothesisEngine.hypotheses.set(id, hypothesis);
  STATE.hypothesisEngine.stats.proposed++;

  saveStateDebounced();
  return { ok: true, hypothesis };
}

// Design an experiment to test hypothesis
function designExperiment(hypothesisId, input = {}) {
  ensureHypothesisEngine();

  const hypothesis = STATE.hypothesisEngine.hypotheses.get(hypothesisId);
  if (!hypothesis) return { ok: false, error: "Hypothesis not found" };

  const id = uid("exp");

  const experiment = {
    id,
    hypothesisId,
    description: String(input.description || "").slice(0, 1000),

    // What we're testing
    testCondition: String(input.testCondition || "").slice(0, 500),
    controlCondition: String(input.controlCondition || "").slice(0, 500),

    // Predictions
    predictedIfTrue: String(input.predictedIfTrue || "").slice(0, 500),
    predictedIfFalse: String(input.predictedIfFalse || "").slice(0, 500),

    // Methodology
    methodology: String(input.methodology || "observation").slice(0, 200),
    sampleSize: Number(input.sampleSize || 1),

    // Status
    status: "designed",
    results: null,

    createdAt: nowISO()
  };

  STATE.hypothesisEngine.experiments.set(id, experiment);
  hypothesis.experiments.push(id);
  hypothesis.state = HYPOTHESIS_STATES.TESTING;
  hypothesis.updatedAt = nowISO();

  saveStateDebounced();
  return { ok: true, experiment };
}

// Record evidence for/against hypothesis
function recordEvidence(hypothesisId, input = {}) {
  ensureHypothesisEngine();

  const hypothesis = STATE.hypothesisEngine.hypotheses.get(hypothesisId);
  if (!hypothesis) return { ok: false, error: "Hypothesis not found" };

  const id = uid("evid");
  const direction = input.supports === true ? "for" : input.supports === false ? "against" : "neutral";

  const evidence = {
    id,
    hypothesisId,
    description: String(input.description || "").slice(0, 1000),
    direction,

    // Strength
    strength: clamp(Number(input.strength || 0.5), 0, 1),
    reliability: clamp(Number(input.reliability || 0.7), 0, 1),

    // Source
    source: String(input.source || "observation").slice(0, 200),
    experimentId: input.experimentId || null,
    dtuIds: Array.isArray(input.dtuIds) ? input.dtuIds.slice(0, 10) : [],

    createdAt: nowISO()
  };

  STATE.hypothesisEngine.evidence.set(id, evidence);

  if (direction === "for") {
    hypothesis.evidenceFor.push(id);
  } else if (direction === "against") {
    hypothesis.evidenceAgainst.push(id);
  }

  // Update posterior using simple Bayesian-ish update
  updateHypothesisPosterior(hypothesisId);

  saveStateDebounced();
  return { ok: true, evidence, newPosterior: hypothesis.posteriorConfidence };
}

// Update hypothesis posterior based on evidence
function updateHypothesisPosterior(hypothesisId) {
  ensureHypothesisEngine();

  const hypothesis = STATE.hypothesisEngine.hypotheses.get(hypothesisId);
  if (!hypothesis) return;

  const cfg = STATE.hypothesisEngine.config;

  // Gather evidence
  const evidenceFor = hypothesis.evidenceFor
    .map(id => STATE.hypothesisEngine.evidence.get(id))
    .filter(Boolean);
  const evidenceAgainst = hypothesis.evidenceAgainst
    .map(id => STATE.hypothesisEngine.evidence.get(id))
    .filter(Boolean);

  // Compute weighted evidence scores
  const forScore = evidenceFor.reduce((sum, e) => sum + e.strength * e.reliability, 0);
  const againstScore = evidenceAgainst.reduce((sum, e) => sum + e.strength * e.reliability, 0);
  const totalEvidence = forScore + againstScore;

  if (totalEvidence > 0) {
    // Blend prior with evidence
    const evidenceRatio = forScore / totalEvidence;
    hypothesis.posteriorConfidence = clamp(
      cfg.priorWeight * hypothesis.priorConfidence + (1 - cfg.priorWeight) * evidenceRatio,
      0, 1
    );
  }

  hypothesis.updatedAt = nowISO();
}

// Evaluate hypothesis and make decision
function evaluateHypothesis(hypothesisId) {
  ensureHypothesisEngine();

  const hypothesis = STATE.hypothesisEngine.hypotheses.get(hypothesisId);
  if (!hypothesis) return { ok: false, error: "Hypothesis not found" };

  const cfg = STATE.hypothesisEngine.config;
  const totalEvidence = hypothesis.evidenceFor.length + hypothesis.evidenceAgainst.length;

  let decision = HYPOTHESIS_STATES.INCONCLUSIVE;
  let reasoning = "";

  if (totalEvidence < cfg.minEvidenceToDecide) {
    decision = HYPOTHESIS_STATES.INCONCLUSIVE;
    reasoning = `Insufficient evidence (${totalEvidence} < ${cfg.minEvidenceToDecide} required)`;
  } else if (hypothesis.posteriorConfidence >= cfg.supportThreshold) {
    decision = HYPOTHESIS_STATES.SUPPORTED;
    reasoning = `Posterior confidence ${(hypothesis.posteriorConfidence * 100).toFixed(1)}% >= ${cfg.supportThreshold * 100}% threshold`;
    STATE.hypothesisEngine.stats.supported++;
  } else if (hypothesis.posteriorConfidence <= cfg.refuteThreshold) {
    decision = HYPOTHESIS_STATES.REFUTED;
    reasoning = `Posterior confidence ${(hypothesis.posteriorConfidence * 100).toFixed(1)}% <= ${cfg.refuteThreshold * 100}% threshold`;
    STATE.hypothesisEngine.stats.refuted++;
  } else {
    decision = HYPOTHESIS_STATES.INCONCLUSIVE;
    reasoning = `Posterior confidence ${(hypothesis.posteriorConfidence * 100).toFixed(1)}% between thresholds`;
    STATE.hypothesisEngine.stats.inconclusive++;
  }

  hypothesis.state = decision;
  hypothesis.evaluation = {
    decision,
    reasoning,
    evidenceCount: totalEvidence,
    posteriorConfidence: hypothesis.posteriorConfidence,
    evaluatedAt: nowISO()
  };
  hypothesis.updatedAt = nowISO();

  // ===== HYPOTHESIS → METACOGNITION CALIBRATION =====
  // Hypothesis evaluations feed into calibration tracking
  try {
    if (STATE.metacognition && decision !== HYPOTHESIS_STATES.INCONCLUSIVE) {
      const wasCorrect = (decision === HYPOTHESIS_STATES.SUPPORTED && hypothesis.priorConfidence >= 0.5) ||
                         (decision === HYPOTHESIS_STATES.REFUTED && hypothesis.priorConfidence < 0.5);
      STATE.metacognition.calibration.totalPredictions++;
      if (wasCorrect) STATE.metacognition.calibration.correctPredictions++;

      // Bucket calibration by confidence decile
      const bucket = Math.round(hypothesis.priorConfidence * 10) / 10;
      const bucketKey = String(bucket.toFixed(1));
      if (!STATE.metacognition.calibration.buckets[bucketKey]) {
        STATE.metacognition.calibration.buckets[bucketKey] = { total: 0, correct: 0 };
      }
      STATE.metacognition.calibration.buckets[bucketKey].total++;
      if (wasCorrect) STATE.metacognition.calibration.buckets[bucketKey].correct++;
    }
  } catch {}
  // ===== END HYPOTHESIS → METACOGNITION =====

  // ATS: Hypothesis evaluation outcome affects affect state
  try {
    if (ATS) {
      const _pol = decision === HYPOTHESIS_STATES.SUPPORTED ? 0.5 : decision === HYPOTHESIS_STATES.REFUTED ? -0.2 : 0;
      ATS.emitAffectEvent("system", {
        type: "SYSTEM_RESULT",
        intensity: 0.4,
        polarity: _pol,
        payload: { hypothesisId, decision, statement: (hypothesis.statement || "").slice(0, 100) },
        source: { system: "hypothesis" }
      });
    }
  } catch {}

  saveStateDebounced();
  return { ok: true, hypothesis, decision, reasoning };
}

// ===== END HYPOTHESIS ENGINE =====

// ===== METACOGNITION SYSTEM =====
// Design: Thinking about thinking. Self-assessment and strategy selection.

const METACOGNITION_INVARIANTS = Object.freeze({
  HONEST_SELF_ASSESSMENT: true,        // No inflated confidence
  UNCERTAINTY_ACKNOWLEDGED: true,      // Know what we don't know
  STRATEGY_EXPLICIT: true,             // Reasoning approach visible
  CALIBRATION_TRACKED: true            // Track prediction accuracy
});

function ensureMetacognitionSystem() {
  if (!STATE.metacognition) {
    STATE.metacognition = {
      assessments: [],                  // Self-assessments
      predictions: new Map(),           // Predictions for calibration
      calibration: {                    // Track accuracy
        buckets: {},                    // confidence level -> accuracy
        totalPredictions: 0,
        correctPredictions: 0
      },
      blindSpots: [],                   // Identified knowledge gaps
      strategies: [],                   // Used reasoning strategies
      stats: {
        assessmentsMade: 0,
        blindSpotsIdentified: 0,
        strategiesUsed: 0
      },
      config: {
        calibrationBuckets: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
        maxAssessments: 500,
        maxBlindSpots: 100
      }
    };
  }
  if (!(STATE.metacognition.predictions instanceof Map)) {
    STATE.metacognition.predictions = new Map(Object.entries(STATE.metacognition.predictions || {}));
  }
}

// Assess current state of knowledge on a topic
function assessKnowledge(topic) {
  ensureMetacognitionSystem();
  ensureSemanticEngine();

  const _topicLower = String(topic || "").toLowerCase();

  // Find relevant DTUs
  const relevantDtus = findSimilarDtus(topic, 20, 0.3);

  // Assess coverage
  const dtuCount = relevantDtus.length;
  const avgSimilarity = relevantDtus.reduce((sum, d) => sum + d.similarity, 0) / Math.max(dtuCount, 1);
  const tierDistribution = {
    regular: relevantDtus.filter(d => d.tier === "regular").length,
    mega: relevantDtus.filter(d => d.tier === "mega").length,
    hyper: relevantDtus.filter(d => d.tier === "hyper").length
  };

  // Check commonsense coverage
  ensureCommonsenseSubstrate();
  const commonsenseMatches = queryCommonsense(topic, null);

  // Compute knowledge score
  let knowledgeScore = 0;
  knowledgeScore += Math.min(dtuCount / 10, 0.4);  // Up to 0.4 for DTU count
  knowledgeScore += avgSimilarity * 0.3;           // Up to 0.3 for relevance
  knowledgeScore += (tierDistribution.mega + tierDistribution.hyper * 2) * 0.05;  // Higher tiers
  knowledgeScore += Math.min(commonsenseMatches.length / 5, 0.1);  // Commonsense

  knowledgeScore = clamp(knowledgeScore, 0, 1);

  // Identify gaps
  const gaps = [];
  if (dtuCount < 5) gaps.push("Limited DTU coverage on this topic");
  if (tierDistribution.mega === 0 && tierDistribution.hyper === 0) gaps.push("No synthesized knowledge (MEGA/HYPER)");
  if (avgSimilarity < 0.5) gaps.push("Available DTUs are tangentially related at best");
  if (commonsenseMatches.length === 0) gaps.push("No commonsense grounding for this topic");

  const assessment = {
    id: uid("assess"),
    topic,
    knowledgeScore,
    confidence: knowledgeScore > 0.5 ? "adequate" : knowledgeScore > 0.2 ? "limited" : "minimal",
    dtuCount,
    avgRelevance: avgSimilarity,
    tierDistribution,
    commonsenseSupport: commonsenseMatches.length,
    gaps,
    recommendation: gaps.length > 0 ? `Consider creating DTUs about: ${topic}` : "Knowledge appears adequate",
    assessedAt: nowISO()
  };

  STATE.metacognition.assessments.push(assessment);
  STATE.metacognition.stats.assessmentsMade++;

  // Record blind spots
  if (gaps.length > 0) {
    STATE.metacognition.blindSpots.push({
      topic,
      gaps,
      severity: 1 - knowledgeScore,
      identifiedAt: nowISO()
    });
    STATE.metacognition.stats.blindSpotsIdentified++;
  }

  // Cap arrays
  if (STATE.metacognition.assessments.length > STATE.metacognition.config.maxAssessments) {
    STATE.metacognition.assessments = STATE.metacognition.assessments.slice(-STATE.metacognition.config.maxAssessments);
  }
  if (STATE.metacognition.blindSpots.length > STATE.metacognition.config.maxBlindSpots) {
    STATE.metacognition.blindSpots = STATE.metacognition.blindSpots.slice(-STATE.metacognition.config.maxBlindSpots);
  }

  saveStateDebounced();
  return { ok: true, assessment };
}

// Record a prediction for calibration tracking
function recordPrediction(input = {}) {
  ensureMetacognitionSystem();

  const id = uid("pred");
  const prediction = {
    id,
    statement: String(input.statement || "").slice(0, 500),
    confidence: clamp(Number(input.confidence || 0.5), 0, 1),
    domain: String(input.domain || "general").slice(0, 100),
    outcome: null,  // Will be set when resolved
    createdAt: nowISO(),
    resolvedAt: null
  };

  STATE.metacognition.predictions.set(id, prediction);
  STATE.metacognition.calibration.totalPredictions++;

  saveStateDebounced();
  return { ok: true, prediction };
}

// Resolve a prediction (was it correct?)
function resolvePrediction(predictionId, wasCorrect) {
  ensureMetacognitionSystem();

  const prediction = STATE.metacognition.predictions.get(predictionId);
  if (!prediction) return { ok: false, error: "Prediction not found" };
  if (prediction.outcome !== null) return { ok: false, error: "Prediction already resolved" };

  prediction.outcome = wasCorrect ? "correct" : "incorrect";
  prediction.resolvedAt = nowISO();

  if (wasCorrect) {
    STATE.metacognition.calibration.correctPredictions++;
  }

  // Update calibration bucket
  const bucket = Math.ceil(prediction.confidence * 10) / 10;  // Round to nearest 0.1
  if (!STATE.metacognition.calibration.buckets[bucket]) {
    STATE.metacognition.calibration.buckets[bucket] = { total: 0, correct: 0 };
  }
  STATE.metacognition.calibration.buckets[bucket].total++;
  if (wasCorrect) {
    STATE.metacognition.calibration.buckets[bucket].correct++;
  }

  saveStateDebounced();
  return { ok: true, prediction };
}

// Get calibration report
function getCalibrationReport() {
  ensureMetacognitionSystem();

  const cal = STATE.metacognition.calibration;
  const bucketStats = {};

  for (const [bucket, data] of Object.entries(cal.buckets)) {
    const accuracy = data.total > 0 ? data.correct / data.total : null;
    const expected = parseFloat(bucket);
    bucketStats[bucket] = {
      total: data.total,
      correct: data.correct,
      accuracy,
      expectedAccuracy: expected,
      calibrationError: accuracy !== null ? Math.abs(accuracy - expected) : null
    };
  }

  const overallAccuracy = cal.totalPredictions > 0 ?
    cal.correctPredictions / cal.totalPredictions : null;

  const avgCalibrationError = Object.values(bucketStats)
    .filter(b => b.calibrationError !== null)
    .reduce((sum, b) => sum + b.calibrationError, 0) /
    Math.max(Object.values(bucketStats).filter(b => b.calibrationError !== null).length, 1);

  return {
    ok: true,
    report: {
      totalPredictions: cal.totalPredictions,
      correctPredictions: cal.correctPredictions,
      overallAccuracy,
      buckets: bucketStats,
      avgCalibrationError,
      interpretation: avgCalibrationError < 0.1 ? "well-calibrated" :
                      avgCalibrationError < 0.2 ? "moderately calibrated" : "poorly calibrated"
    }
  };
}

// Select reasoning strategy for a problem
function selectStrategy(problemDescription) {
  ensureMetacognitionSystem();

  const lower = problemDescription.toLowerCase();

  const strategies = [
    { name: "deductive", trigger: /prove|must|necessarily|follows|therefore/i, description: "Apply logical rules to derive certain conclusions" },
    { name: "inductive", trigger: /pattern|trend|usually|often|generally/i, description: "Generalize from specific observations" },
    { name: "abductive", trigger: /explain|why|cause|reason|because/i, description: "Find the best explanation for observations" },
    { name: "analogical", trigger: /similar|like|compare|analogy|same as/i, description: "Map from known to unknown via similarity" },
    { name: "decomposition", trigger: /break down|parts|components|step by step/i, description: "Divide problem into smaller parts" },
    { name: "simulation", trigger: /what if|scenario|imagine|suppose/i, description: "Run mental simulation of possibilities" },
    { name: "empirical", trigger: /test|measure|observe|experiment|data/i, description: "Gather evidence through observation" }
  ];

  const matches = strategies.filter(s => s.trigger.test(lower));
  const selected = matches.length > 0 ? matches[0] : { name: "mixed", description: "Combine multiple reasoning approaches" };

  STATE.metacognition.strategies.push({
    problem: problemDescription.slice(0, 200),
    selected: selected.name,
    alternatives: matches.slice(1).map(s => s.name),
    selectedAt: nowISO()
  });
  STATE.metacognition.stats.strategiesUsed++;

  // Cap strategies
  if (STATE.metacognition.strategies.length > 200) {
    STATE.metacognition.strategies = STATE.metacognition.strategies.slice(-200);
  }

  return { ok: true, strategy: selected, alternatives: matches.slice(1) };
}

// ===== METACOGNITION INTROSPECTION =====
// Analyze past failures, identify patterns, and modify reasoning strategies.

function ensureIntrospectionState() {
  ensureMetacognitionSystem();
  if (!STATE.metacognition.introspection) {
    STATE.metacognition.introspection = {
      failurePatterns: [],         // Detected patterns in failures
      strategyModifications: [],    // History of strategy changes
      learningEvents: [],           // What was learned from mistakes
      confidenceAdjustments: {},    // Domain -> adjustment factor
      lastIntrospection: null
    };
  }
}

// Introspect on past predictions to understand failure patterns
function introspectOnFailures() {
  ensureMetacognitionSystem();
  ensureIntrospectionState();

  const predictions = Array.from(STATE.metacognition.predictions.values())
    .filter(p => p.outcome !== null);

  if (predictions.length < 3) {
    return {
      ok: true,
      message: "Insufficient data for introspection (need at least 3 resolved predictions)",
      failurePatterns: [],
      recommendations: []
    };
  }

  const failures = predictions.filter(p => p.outcome === "incorrect");
  const successes = predictions.filter(p => p.outcome === "correct");

  // Analyze failure patterns
  const failurePatterns = [];

  // Pattern 1: Overconfidence in specific domains
  const domainFailures = {};
  const domainTotals = {};
  for (const p of predictions) {
    const domain = p.domain || "general";
    domainTotals[domain] = (domainTotals[domain] || 0) + 1;
    if (p.outcome === "incorrect") {
      domainFailures[domain] = (domainFailures[domain] || 0) + 1;
    }
  }

  for (const [domain, failCount] of Object.entries(domainFailures)) {
    const total = domainTotals[domain];
    const failRate = failCount / total;
    if (failRate > 0.5 && total >= 2) {
      failurePatterns.push({
        type: "domain_weakness",
        domain,
        failRate,
        description: `High failure rate (${(failRate * 100).toFixed(0)}%) in domain "${domain}"`,
        recommendation: `Reduce confidence by ${Math.round(failRate * 30)}% for predictions in "${domain}"`
      });

      // Automatically adjust confidence for this domain
      STATE.metacognition.introspection.confidenceAdjustments[domain] =
        1 - (failRate * 0.3); // Reduce confidence proportional to failure rate
    }
  }

  // Pattern 2: Overconfidence (predictions with high confidence that failed)
  const overconfidentFailures = failures.filter(p => p.confidence > 0.7);
  if (overconfidentFailures.length > 2) {
    const avgConfidence = overconfidentFailures.reduce((s, p) => s + p.confidence, 0) / overconfidentFailures.length;
    failurePatterns.push({
      type: "overconfidence",
      count: overconfidentFailures.length,
      avgConfidence,
      description: `${overconfidentFailures.length} failures had confidence > 70% (avg: ${(avgConfidence * 100).toFixed(0)}%)`,
      recommendation: "Consider reducing high-confidence predictions by 10-15%"
    });
  }

  // Pattern 3: Underconfidence (predictions with low confidence that succeeded)
  const underconfidentSuccesses = successes.filter(p => p.confidence < 0.4);
  if (underconfidentSuccesses.length > 2) {
    const avgConfidence = underconfidentSuccesses.reduce((s, p) => s + p.confidence, 0) / underconfidentSuccesses.length;
    failurePatterns.push({
      type: "underconfidence",
      count: underconfidentSuccesses.length,
      avgConfidence,
      description: `${underconfidentSuccesses.length} successes had confidence < 40% (avg: ${(avgConfidence * 100).toFixed(0)}%)`,
      recommendation: "Consider increasing low-confidence predictions by 10-15%"
    });
  }

  // Pattern 4: Consistent failure on certain question types
  const failureKeywords = {};
  for (const f of failures) {
    const words = String(f.statement || "").toLowerCase().split(/\s+/);
    for (const word of words) {
      if (word.length > 4) {
        failureKeywords[word] = (failureKeywords[word] || 0) + 1;
      }
    }
  }

  const commonFailureWords = Object.entries(failureKeywords)
    .filter(([_word, count]) => count >= 2)
    .sort((a, b) => b[1] - a[1])
    .slice(0, 3);

  if (commonFailureWords.length > 0) {
    failurePatterns.push({
      type: "topic_weakness",
      keywords: commonFailureWords.map(([w, c]) => ({ word: w, count: c })),
      description: `Failures often involve: ${commonFailureWords.map(([w]) => w).join(", ")}`,
      recommendation: "Consider extra validation for predictions involving these topics"
    });
  }

  // Generate overall recommendations
  const recommendations = [];

  if (failurePatterns.some(p => p.type === "overconfidence")) {
    recommendations.push({
      action: "reduce_high_confidence",
      description: "Apply 0.9 multiplier to predictions with confidence > 0.8",
      automatic: true
    });
  }

  if (failurePatterns.some(p => p.type === "domain_weakness")) {
    const weakDomains = failurePatterns
      .filter(p => p.type === "domain_weakness")
      .map(p => p.domain);
    recommendations.push({
      action: "domain_caution",
      domains: weakDomains,
      description: `Apply domain-specific confidence reductions for: ${weakDomains.join(", ")}`,
      automatic: true
    });
  }

  // Store the introspection results
  const introspectionResult = {
    id: uid("intro"),
    timestamp: nowISO(),
    totalPredictions: predictions.length,
    failures: failures.length,
    successes: successes.length,
    failureRate: failures.length / predictions.length,
    patterns: failurePatterns,
    recommendations,
    confidenceAdjustments: { ...STATE.metacognition.introspection.confidenceAdjustments }
  };

  STATE.metacognition.introspection.failurePatterns.push({
    ...introspectionResult,
    patterns: failurePatterns.map(p => p.type)
  });

  // Cap history
  if (STATE.metacognition.introspection.failurePatterns.length > 50) {
    STATE.metacognition.introspection.failurePatterns =
      STATE.metacognition.introspection.failurePatterns.slice(-50);
  }

  STATE.metacognition.introspection.lastIntrospection = nowISO();
  saveStateDebounced();

  return {
    ok: true,
    introspection: introspectionResult
  };
}

// Analyze why a specific prediction failed
function analyzeFailure(predictionId) {
  ensureMetacognitionSystem();
  ensureIntrospectionState();

  const prediction = STATE.metacognition.predictions.get(predictionId);
  if (!prediction) return { ok: false, error: "Prediction not found" };
  if (prediction.outcome !== "incorrect") {
    return { ok: false, error: "Prediction was not incorrect, no failure to analyze" };
  }

  // Find similar predictions to compare
  const allPredictions = Array.from(STATE.metacognition.predictions.values())
    .filter(p => p.id !== predictionId && p.outcome !== null);

  const similarPredictions = allPredictions.filter(p => {
    // Same domain
    if (p.domain !== prediction.domain) return false;
    // Similar confidence
    if (Math.abs(p.confidence - prediction.confidence) > 0.2) return false;
    return true;
  });

  const similarSuccesses = similarPredictions.filter(p => p.outcome === "correct");
  const similarFailures = similarPredictions.filter(p => p.outcome === "incorrect");

  // Generate analysis
  const analysis = {
    prediction: {
      id: prediction.id,
      statement: prediction.statement,
      confidence: prediction.confidence,
      domain: prediction.domain
    },
    possibleCauses: [],
    learningOpportunities: []
  };

  // Check for overconfidence
  if (prediction.confidence > 0.7) {
    analysis.possibleCauses.push({
      cause: "overconfidence",
      explanation: `High confidence (${(prediction.confidence * 100).toFixed(0)}%) may not have been warranted`,
      evidenceStrength: prediction.confidence > 0.8 ? "strong" : "moderate"
    });
  }

  // Check domain weakness
  const domainAdjustment = STATE.metacognition.introspection.confidenceAdjustments[prediction.domain];
  if (domainAdjustment && domainAdjustment < 0.9) {
    analysis.possibleCauses.push({
      cause: "domain_difficulty",
      explanation: `This domain (${prediction.domain}) has a historical weakness pattern`,
      evidenceStrength: "strong"
    });
  }

  // Compare with similar predictions
  if (similarSuccesses.length > 0 && similarFailures.length === 0) {
    analysis.possibleCauses.push({
      cause: "anomaly",
      explanation: "Similar predictions in this domain succeeded; this may be an edge case",
      evidenceStrength: "moderate"
    });
  } else if (similarFailures.length > similarSuccesses.length) {
    analysis.possibleCauses.push({
      cause: "systematic_issue",
      explanation: "Multiple failures in similar predictions suggest a systematic knowledge gap",
      evidenceStrength: "strong"
    });
  }

  // Generate learning opportunities
  analysis.learningOpportunities.push({
    type: "knowledge_gap",
    description: `Create DTUs to fill knowledge gaps about: ${prediction.domain}`,
    priority: similarFailures.length > 1 ? "high" : "medium"
  });

  if (prediction.confidence > 0.6) {
    analysis.learningOpportunities.push({
      type: "calibration",
      description: `Recalibrate confidence for similar predictions (reduce by ${Math.round((prediction.confidence - 0.5) * 20)}%)`,
      priority: "medium"
    });
  }

  // Store this learning event
  STATE.metacognition.introspection.learningEvents.push({
    predictionId,
    analyzedAt: nowISO(),
    causes: analysis.possibleCauses.map(c => c.cause),
    domain: prediction.domain
  });

  // Cap learning events
  if (STATE.metacognition.introspection.learningEvents.length > 100) {
    STATE.metacognition.introspection.learningEvents =
      STATE.metacognition.introspection.learningEvents.slice(-100);
  }

  saveStateDebounced();

  return { ok: true, analysis };
}

// Modify strategy based on past performance
function adaptReasoningStrategy(domain, feedback = {}) {
  ensureMetacognitionSystem();
  ensureIntrospectionState();

  // Get performance in this domain
  const predictions = Array.from(STATE.metacognition.predictions.values())
    .filter(p => p.domain === domain && p.outcome !== null);

  const successRate = predictions.length > 0
    ? predictions.filter(p => p.outcome === "correct").length / predictions.length
    : 0.5;

  // Get strategy history for this domain
  const strategyHistory = STATE.metacognition.strategies
    .filter(s => s.problem && s.problem.toLowerCase().includes(domain.toLowerCase()));

  const usedStrategies = {};
  for (const s of strategyHistory) {
    usedStrategies[s.selected] = (usedStrategies[s.selected] || 0) + 1;
  }

  // Determine current dominant strategy
  const dominantStrategy = Object.entries(usedStrategies)
    .sort((a, b) => b[1] - a[1])[0]?.[0] || "mixed";

  // Generate adaptation recommendation
  const adaptation = {
    domain,
    currentPerformance: {
      successRate,
      totalPredictions: predictions.length
    },
    currentStrategy: {
      dominant: dominantStrategy,
      distribution: usedStrategies
    },
    recommendation: null,
    confidenceAdjustment: 1.0
  };

  // If performance is poor, recommend strategy change
  if (successRate < 0.5 && predictions.length >= 3) {
    // Suggest trying a different approach
    const alternativeStrategies = ["empirical", "analogical", "decomposition"]
      .filter(s => s !== dominantStrategy);

    adaptation.recommendation = {
      action: "change_strategy",
      from: dominantStrategy,
      to: alternativeStrategies[0],
      reason: `Current strategy "${dominantStrategy}" has low success rate (${(successRate * 100).toFixed(0)}%)`,
      alternatives: alternativeStrategies
    };

    // Reduce confidence for this domain
    adaptation.confidenceAdjustment = 0.8;
    STATE.metacognition.introspection.confidenceAdjustments[domain] =
      (STATE.metacognition.introspection.confidenceAdjustments[domain] || 1.0) * 0.9;

  } else if (successRate > 0.7 && predictions.length >= 3) {
    // Reinforce current strategy
    adaptation.recommendation = {
      action: "reinforce_strategy",
      strategy: dominantStrategy,
      reason: `Current strategy "${dominantStrategy}" is working well (${(successRate * 100).toFixed(0)}% success)`,
    };

    // Slightly increase confidence for this domain
    adaptation.confidenceAdjustment = 1.1;
    STATE.metacognition.introspection.confidenceAdjustments[domain] = Math.min(
      (STATE.metacognition.introspection.confidenceAdjustments[domain] || 1.0) * 1.05,
      1.2  // Cap at 20% boost
    );
  }

  // Apply explicit feedback if provided
  if (feedback.increaseConfidence) {
    adaptation.confidenceAdjustment *= 1.1;
  } else if (feedback.decreaseConfidence) {
    adaptation.confidenceAdjustment *= 0.9;
  }

  if (feedback.preferStrategy) {
    adaptation.recommendation = {
      action: "user_preference",
      strategy: feedback.preferStrategy,
      reason: "User explicitly preferred this strategy"
    };
  }

  // Store the modification
  STATE.metacognition.introspection.strategyModifications.push({
    id: uid("mod"),
    domain,
    timestamp: nowISO(),
    recommendation: adaptation.recommendation?.action || "none",
    confidenceAdjustment: adaptation.confidenceAdjustment
  });

  // Cap modifications history
  if (STATE.metacognition.introspection.strategyModifications.length > 100) {
    STATE.metacognition.introspection.strategyModifications =
      STATE.metacognition.introspection.strategyModifications.slice(-100);
  }

  saveStateDebounced();

  return { ok: true, adaptation };
}

// Get current introspection status
function getIntrospectionStatus() {
  ensureMetacognitionSystem();
  ensureIntrospectionState();

  return {
    ok: true,
    lastIntrospection: STATE.metacognition.introspection.lastIntrospection,
    failurePatternCount: STATE.metacognition.introspection.failurePatterns.length,
    strategyModificationCount: STATE.metacognition.introspection.strategyModifications.length,
    learningEventCount: STATE.metacognition.introspection.learningEvents.length,
    confidenceAdjustments: STATE.metacognition.introspection.confidenceAdjustments,
    recentPatterns: STATE.metacognition.introspection.failurePatterns.slice(-5)
  };
}

// Apply learned confidence adjustments to a new prediction
function adjustConfidenceFromLearning(domain, baseConfidence) {
  ensureMetacognitionSystem();
  ensureIntrospectionState();

  const adjustment = STATE.metacognition.introspection.confidenceAdjustments[domain] || 1.0;
  const adjustedConfidence = clamp(baseConfidence * adjustment, 0.1, 0.95);

  return {
    original: baseConfidence,
    adjusted: adjustedConfidence,
    factor: adjustment,
    domain,
    explanation: adjustment < 1.0
      ? `Confidence reduced due to historical weakness in "${domain}"`
      : adjustment > 1.0
        ? `Confidence boosted due to historical strength in "${domain}"`
        : "No adjustment applied"
  };
}

// ===== END METACOGNITION INTROSPECTION =====

// ===== END METACOGNITION SYSTEM =====

// ===== EXPLANATION ENGINE =====
// Design: Generate WHY explanations for decisions, changes, and outcomes.

const EXPLANATION_INVARIANTS = Object.freeze({
  HONEST_EXPLANATIONS: true,           // No confabulation
  CAUSAL_CHAIN_SHOWN: true,            // Show reasoning path
  UNCERTAINTY_INCLUDED: true,          // Explain confidence
  ALTERNATIVES_MENTIONED: true         // What else was considered
});

const EXPLANATION_TYPES = Object.freeze({
  CAUSAL: "causal",                    // Why did X cause Y
  CONTRASTIVE: "contrastive",          // Why X instead of Y
  COUNTERFACTUAL: "counterfactual",    // What if X had been different
  MECHANISTIC: "mechanistic",          // How does X work
  TELEOLOGICAL: "teleological"         // What is X's purpose/goal
});

function ensureExplanationEngine() {
  if (!STATE.explanations) {
    STATE.explanations = {
      generated: [],                    // Generated explanations
      templates: new Map(),             // Reusable explanation templates
      stats: {
        generated: 0,
        byType: {}
      },
      config: {
        maxExplanations: 500,
        includeAlternatives: true,
        maxDepth: 5
      }
    };
  }
}

// Generate explanation for why something happened
function generateExplanation(input = {}) {
  ensureExplanationEngine();

  const explainType = EXPLANATION_TYPES[input.type?.toUpperCase()] || EXPLANATION_TYPES.CAUSAL;
  const target = String(input.target || input.what || "").slice(0, 500);

  if (!target) return { ok: false, error: "Target (what to explain) required" };

  let explanation = {
    id: uid("expl"),
    type: explainType,
    target,
    question: "",
    answer: "",
    chain: [],
    confidence: 0.5,
    alternatives: [],
    caveats: [],
    createdAt: nowISO()
  };

  switch (explainType) {
    case EXPLANATION_TYPES.CAUSAL:
      explanation = generateCausalExplanation(explanation, input);
      break;
    case EXPLANATION_TYPES.CONTRASTIVE:
      explanation = generateContrastiveExplanation(explanation, input);
      break;
    case EXPLANATION_TYPES.COUNTERFACTUAL:
      explanation = generateCounterfactualExplanation(explanation, input);
      break;
    case EXPLANATION_TYPES.MECHANISTIC:
      explanation = generateMechanisticExplanation(explanation, input);
      break;
    case EXPLANATION_TYPES.TELEOLOGICAL:
      explanation = generateTeleologicalExplanation(explanation, input);
      break;
  }

  STATE.explanations.generated.push(explanation);
  STATE.explanations.stats.generated++;
  STATE.explanations.stats.byType[explainType] = (STATE.explanations.stats.byType[explainType] || 0) + 1;

  // Cap explanations
  if (STATE.explanations.generated.length > STATE.explanations.config.maxExplanations) {
    STATE.explanations.generated = STATE.explanations.generated.slice(-STATE.explanations.config.maxExplanations);
  }

  saveStateDebounced();
  return { ok: true, explanation };
}

function generateCausalExplanation(explanation, _input) {
  explanation.question = `Why did "${explanation.target}" happen?`;

  // Try to find causal chain in world model
  ensureWorldModel();
  const targetEntity = Array.from(STATE.worldModel.entities.values())
    .find(e => e.name.toLowerCase().includes(explanation.target.toLowerCase()));

  const causes = [];
  if (targetEntity) {
    const relations = Array.from(STATE.worldModel.relations.values())
      .filter(r => r.to === targetEntity.id && r.type === "causes");

    for (const rel of relations.slice(0, 5)) {
      const sourceEntity = STATE.worldModel.entities.get(rel.from);
      if (sourceEntity) {
        causes.push({
          cause: sourceEntity.name,
          strength: rel.strength,
          mechanism: rel.causal?.mechanism || "unspecified"
        });
      }
    }
  }

  if (causes.length > 0) {
    explanation.chain = causes;
    explanation.answer = `"${explanation.target}" occurred because: ${causes.map(c => c.cause).join(", then ")}`;
    explanation.confidence = Math.max(...causes.map(c => c.strength));
  } else {
    explanation.answer = `No causal chain found for "${explanation.target}". Consider adding causal relations to the world model.`;
    explanation.confidence = 0.2;
    explanation.caveats.push("No causal data available");
  }

  return explanation;
}

function generateContrastiveExplanation(explanation, input) {
  const alternative = String(input.instead || input.alternative || "the alternative").slice(0, 200);
  explanation.question = `Why "${explanation.target}" instead of "${alternative}"?`;

  // Compare factors
  const factors = [];

  // Check semantic similarity to see what makes them different
  ensureSemanticEngine();
  const targetEmb = computeLocalEmbedding(explanation.target);
  const altEmb = computeLocalEmbedding(alternative);
  const similarity = cosineSimilarity(targetEmb, altEmb);

  factors.push({
    factor: "semantic_similarity",
    value: similarity,
    implication: similarity > 0.7 ? "Very similar options" : similarity > 0.4 ? "Related but distinct" : "Quite different options"
  });

  explanation.chain = factors;
  explanation.alternatives = [{ option: alternative, reason: "Not selected" }];
  explanation.answer = `"${explanation.target}" was chosen over "${alternative}". ${factors[0].implication}.`;
  explanation.confidence = 0.6;

  return explanation;
}

function generateCounterfactualExplanation(explanation, input) {
  const changed = String(input.changed || "conditions").slice(0, 200);
  explanation.question = `What if "${changed}" had been different?`;

  // Use world model counterfactual if available
  explanation.answer = `If "${changed}" had been different, "${explanation.target}" might not have occurred or would have occurred differently.`;
  explanation.caveats.push("Counterfactual reasoning is inherently uncertain");
  explanation.confidence = 0.4;

  return explanation;
}

function generateMechanisticExplanation(explanation, _input) {
  explanation.question = `How does "${explanation.target}" work?`;

  // Look for related DTUs that might explain mechanism
  const relatedDtus = findSimilarDtus(explanation.target + " mechanism how", 5, 0.3);

  if (relatedDtus.length > 0) {
    explanation.chain = relatedDtus.map(d => ({ step: d.title, relevance: d.similarity }));
    explanation.answer = `"${explanation.target}" works through: ${relatedDtus.map(d => d.title).join(" → ")}`;
    explanation.confidence = 0.6;
  } else {
    explanation.answer = `Mechanism for "${explanation.target}" not found in knowledge base.`;
    explanation.confidence = 0.2;
    explanation.caveats.push("No mechanistic knowledge available");
  }

  return explanation;
}

function generateTeleologicalExplanation(explanation, _input) {
  explanation.question = `What is the purpose of "${explanation.target}"?`;

  // Check if it's related to any goals
  ensureGoalSystem();
  const relatedGoals = Array.from(STATE.goals.registry.values())
    .filter(g => g.title.toLowerCase().includes(explanation.target.toLowerCase()) ||
                 g.description.toLowerCase().includes(explanation.target.toLowerCase()));

  if (relatedGoals.length > 0) {
    explanation.answer = `"${explanation.target}" serves the purpose of: ${relatedGoals.map(g => g.title).join(", ")}`;
    explanation.chain = relatedGoals.map(g => ({ goal: g.title, type: g.type }));
    explanation.confidence = 0.7;
  } else {
    explanation.answer = `No explicit purpose found for "${explanation.target}" in current goals.`;
    explanation.confidence = 0.3;
  }

  return explanation;
}

// Explain a DTU change
function explainDtuChange(dtuId, changeType) {
  ensureExplanationEngine();

  const dtu = STATE.dtus?.get(dtuId);
  if (!dtu) return { ok: false, error: "DTU not found" };

  const explanation = {
    id: uid("expl"),
    type: "dtu_change",
    target: dtu.title,
    changeType,
    question: `Why was DTU "${dtu.title}" ${changeType}?`,
    answer: "",
    factors: [],
    createdAt: nowISO()
  };

  switch (changeType) {
    case "promoted":
      explanation.answer = `DTU was promoted because it met tier criteria: high score, multiple uses, and sufficient contexts.`;
      explanation.factors = [
        { factor: "authority_score", value: dtu.authority?.score },
        { factor: "tier", value: dtu.tier }
      ];
      break;
    case "created":
      explanation.answer = `DTU was created to capture knowledge about "${dtu.title}".`;
      explanation.factors = [{ factor: "source", value: dtu.source || "user" }];
      break;
    case "merged":
      explanation.answer = `DTU was merged due to semantic similarity with existing knowledge.`;
      break;
    default:
      explanation.answer = `DTU was ${changeType}.`;
  }

  STATE.explanations.generated.push(explanation);
  STATE.explanations.stats.generated++;

  return { ok: true, explanation };
}

// ===== END EXPLANATION ENGINE =====

// ===== META-LEARNING SYSTEM =====
// Design: Learning how to learn. Adjust strategies based on performance.

const META_LEARNING_INVARIANTS = Object.freeze({
  BOUNDED_ADAPTATION: true,            // Changes within limits
  PERFORMANCE_TRACKED: true,           // Outcomes measured
  STRATEGY_LOGGED: true,               // All changes recorded
  REVERSIBLE: true                     // Can revert bad changes
});

function ensureMetaLearningSystem() {
  if (!STATE.metaLearning) {
    STATE.metaLearning = {
      strategies: new Map(),            // Learning strategies
      performance: [],                  // Performance history
      adaptations: [],                  // Strategy changes made
      curriculum: [],                   // Generated learning sequences
      stats: {
        strategiesAdapted: 0,
        performanceImprovements: 0,
        curriculumsGenerated: 0
      },
      config: {
        adaptationRate: 0.1,            // How fast to adapt
        minSamples: 5,                  // Min samples before adapting
        performanceWindow: 20           // Window for performance tracking
      }
    };
  }
  if (!(STATE.metaLearning.strategies instanceof Map)) {
    STATE.metaLearning.strategies = new Map(Object.entries(STATE.metaLearning.strategies || {}));
  }
}

// Define a learning strategy
function defineLearningStrategy(input = {}) {
  ensureMetaLearningSystem();

  const id = uid("strat");
  const strategy = {
    id,
    name: String(input.name || "").slice(0, 100) || "Unnamed Strategy",
    domain: String(input.domain || "general").slice(0, 100),

    // Parameters that can be adjusted
    parameters: {
      learningRate: clamp(Number(input.learningRate || 0.1), 0.01, 1),
      explorationRate: clamp(Number(input.explorationRate || 0.2), 0, 1),
      batchSize: clamp(Number(input.batchSize || 5), 1, 50),
      abstractionLevel: clamp(Number(input.abstractionLevel || 1), 0, 3),
      consolidationThreshold: clamp(Number(input.consolidationThreshold || 0.7), 0.1, 1)
    },

    // Performance tracking
    uses: 0,
    successes: 0,
    failures: 0,
    avgPerformance: 0.5,

    createdAt: nowISO(),
    updatedAt: nowISO()
  };

  STATE.metaLearning.strategies.set(id, strategy);
  return { ok: true, strategy };
}

// Record outcome of using a strategy
function recordStrategyOutcome(strategyId, outcome) {
  ensureMetaLearningSystem();

  const strategy = STATE.metaLearning.strategies.get(strategyId);
  if (!strategy) return { ok: false, error: "Strategy not found" };

  const success = outcome.success === true;
  const performance = clamp(Number(outcome.performance || (success ? 0.8 : 0.3)), 0, 1);

  strategy.uses++;
  if (success) strategy.successes++;
  else strategy.failures++;

  // Update running average
  strategy.avgPerformance = (strategy.avgPerformance * (strategy.uses - 1) + performance) / strategy.uses;
  strategy.updatedAt = nowISO();

  // Record in performance history
  STATE.metaLearning.performance.push({
    strategyId,
    success,
    performance,
    domain: strategy.domain,
    recordedAt: nowISO()
  });

  // Cap history
  if (STATE.metaLearning.performance.length > 1000) {
    STATE.metaLearning.performance = STATE.metaLearning.performance.slice(-1000);
  }

  // Check if adaptation is warranted
  if (strategy.uses >= STATE.metaLearning.config.minSamples) {
    adaptStrategy(strategyId);
  }

  saveStateDebounced();
  return { ok: true, strategy, newAvgPerformance: strategy.avgPerformance };
}

// Adapt strategy parameters based on performance
function adaptStrategy(strategyId) {
  ensureMetaLearningSystem();

  const strategy = STATE.metaLearning.strategies.get(strategyId);
  if (!strategy) return { ok: false, error: "Strategy not found" };

  const cfg = STATE.metaLearning.config;
  const adaptations = [];

  // Get recent performance for this strategy
  const recent = STATE.metaLearning.performance
    .filter(p => p.strategyId === strategyId)
    .slice(-cfg.performanceWindow);

  if (recent.length < cfg.minSamples) {
    return { ok: true, message: "Insufficient data for adaptation" };
  }

  const recentAvg = recent.reduce((sum, p) => sum + p.performance, 0) / recent.length;
  const successRate = recent.filter(p => p.success).length / recent.length;

  // Adapt based on performance
  if (recentAvg < 0.4) {
    // Poor performance: increase exploration, decrease batch size
    const oldExploration = strategy.parameters.explorationRate;
    strategy.parameters.explorationRate = clamp(oldExploration + cfg.adaptationRate, 0, 0.5);
    adaptations.push(`Increased exploration from ${oldExploration.toFixed(2)} to ${strategy.parameters.explorationRate.toFixed(2)}`);

    const oldBatch = strategy.parameters.batchSize;
    strategy.parameters.batchSize = Math.max(1, oldBatch - 1);
    adaptations.push(`Decreased batch size from ${oldBatch} to ${strategy.parameters.batchSize}`);
  } else if (recentAvg > 0.7 && successRate > 0.8) {
    // Good performance: decrease exploration, can increase batch
    const oldExploration = strategy.parameters.explorationRate;
    strategy.parameters.explorationRate = clamp(oldExploration - cfg.adaptationRate, 0.05, 1);
    adaptations.push(`Decreased exploration from ${oldExploration.toFixed(2)} to ${strategy.parameters.explorationRate.toFixed(2)}`);

    STATE.metaLearning.stats.performanceImprovements++;
  }

  if (adaptations.length > 0) {
    STATE.metaLearning.adaptations.push({
      strategyId,
      strategyName: strategy.name,
      adaptations,
      triggerPerformance: recentAvg,
      adaptedAt: nowISO()
    });
    STATE.metaLearning.stats.strategiesAdapted++;
    strategy.updatedAt = nowISO();

    // Cap adaptations
    if (STATE.metaLearning.adaptations.length > 200) {
      STATE.metaLearning.adaptations = STATE.metaLearning.adaptations.slice(-200);
    }
  }

  saveStateDebounced();
  return { ok: true, adaptations, newParameters: strategy.parameters };
}

// Generate a curriculum (learning sequence) for a topic
function generateCurriculum(topic, input = {}) {
  ensureMetaLearningSystem();
  ensureSemanticEngine();

  const maxSteps = clamp(Number(input.maxSteps || 10), 3, 20);

  // Find DTUs related to topic
  const relatedDtus = findSimilarDtus(topic, 30, 0.2);

  // Sort by complexity (approximate by tier and similarity)
  const sorted = relatedDtus.sort((a, b) => {
    const tierScore = { regular: 1, mega: 2, hyper: 3 };
    const aScore = (tierScore[a.tier] || 1) + (1 - a.similarity);  // Lower similarity = more advanced
    const bScore = (tierScore[b.tier] || 1) + (1 - b.similarity);
    return aScore - bScore;  // Start with simpler, more relevant
  });

  // Build curriculum
  const steps = sorted.slice(0, maxSteps).map((dtu, i) => ({
    order: i + 1,
    dtuId: dtu.dtuId,
    title: dtu.title,
    difficulty: i / maxSteps,  // Increases through curriculum
    rationale: i === 0 ? "Start with fundamentals" :
               i < maxSteps / 3 ? "Build foundational understanding" :
               i < 2 * maxSteps / 3 ? "Develop intermediate knowledge" :
               "Advanced integration"
  }));

  const curriculum = {
    id: uid("curr"),
    topic,
    steps,
    estimatedEffort: steps.length * 0.5,  // Rough estimate in hours
    prerequisites: [],
    createdAt: nowISO()
  };

  STATE.metaLearning.curriculum.push(curriculum);
  STATE.metaLearning.stats.curriculumsGenerated++;

  // Cap curriculum
  if (STATE.metaLearning.curriculum.length > 50) {
    STATE.metaLearning.curriculum = STATE.metaLearning.curriculum.slice(-50);
  }

  saveStateDebounced();
  return { ok: true, curriculum };
}

// Get best strategy for a domain
function getBestStrategy(domain) {
  ensureMetaLearningSystem();

  const strategies = Array.from(STATE.metaLearning.strategies.values())
    .filter(s => s.domain === domain || s.domain === "general")
    .filter(s => s.uses >= 3)  // Enough data
    .sort((a, b) => b.avgPerformance - a.avgPerformance);

  if (strategies.length === 0) {
    return { ok: true, strategy: null, message: "No strategies with sufficient data for this domain" };
  }

  return { ok: true, strategy: strategies[0], alternatives: strategies.slice(1, 3) };
}

// ===== END META-LEARNING SYSTEM =====

// ═══════════════════════════════════════════════════════════════════════════════
// EXPERIENCE LEARNING ENGINE
// Design: Permanent memory of interaction outcomes. Learns what strategies work
// in which contexts, builds retrievable experience patterns, and uses past
// experience to guide future responses. This is the "muscle memory" of cognition.
// ═══════════════════════════════════════════════════════════════════════════════

function ensureExperienceLearning() {
  if (!STATE.experienceLearning) {
    STATE.experienceLearning = {
      episodes: [],                     // Interaction episodes (capped)
      patterns: new Map(),              // Extracted experience patterns
      strategies: new Map(),            // Strategy effectiveness by context
      stats: {
        episodesRecorded: 0,
        patternsExtracted: 0,
        retrievalsUsed: 0,
        improvementRate: 0
      },
      config: {
        maxEpisodes: 2000,
        maxPatterns: 500,
        minEpisodesForPattern: 3,
        consolidationInterval: 50,      // Consolidate every N episodes
        decayRate: 0.005                // Unused patterns decay
      }
    };
  }
  if (!(STATE.experienceLearning.patterns instanceof Map)) {
    STATE.experienceLearning.patterns = new Map(Object.entries(STATE.experienceLearning.patterns || {}));
  }
  if (!(STATE.experienceLearning.strategies instanceof Map)) {
    STATE.experienceLearning.strategies = new Map(Object.entries(STATE.experienceLearning.strategies || {}));
  }
}

// Record an interaction episode
function recordExperienceEpisode(episode) {
  ensureExperienceLearning();
  const el = STATE.experienceLearning;

  const ep = {
    id: uid("exp"),
    timestamp: nowISO(),
    context: {
      domain: String(episode.domain || "general").slice(0, 100),
      topic: String(episode.topic || "").slice(0, 200),
      keywords: Array.isArray(episode.keywords) ? episode.keywords.slice(0, 20) : [],
      mode: String(episode.mode || "explore"),
      affectState: episode.affectState || null,
    },
    action: {
      strategy: String(episode.strategy || "default").slice(0, 100),
      llmUsed: !!episode.llmUsed,
      dtusRetrieved: Number(episode.dtusRetrieved || 0),
      responseLength: Number(episode.responseLength || 0),
    },
    outcome: {
      quality: clamp(Number(episode.quality || 0.5), 0, 1),
      userFeedback: episode.userFeedback || null,
      followUpNeeded: !!episode.followUpNeeded,
      errorOccurred: !!episode.errorOccurred,
    }
  };

  el.episodes.push(ep);
  el.stats.episodesRecorded++;

  // Cap episodes
  if (el.episodes.length > el.config.maxEpisodes) {
    el.episodes.splice(0, el.episodes.length - el.config.maxEpisodes);
  }

  // Periodic consolidation — extract patterns from accumulated episodes
  if (el.stats.episodesRecorded % el.config.consolidationInterval === 0) {
    try { consolidateExperience(); } catch {}
  }

  // Update strategy effectiveness
  const stratKey = `${ep.context.domain}:${ep.action.strategy}`;
  const strat = el.strategies.get(stratKey) || {
    domain: ep.context.domain, strategy: ep.action.strategy,
    uses: 0, totalQuality: 0, avgQuality: 0.5, lastUsed: null
  };
  strat.uses++;
  strat.totalQuality += ep.outcome.quality;
  strat.avgQuality = strat.totalQuality / strat.uses;
  strat.lastUsed = nowISO();
  el.strategies.set(stratKey, strat);

  return ep;
}

// Consolidate episodes into reusable patterns
function consolidateExperience() {
  ensureExperienceLearning();
  const el = STATE.experienceLearning;
  const episodes = el.episodes;
  if (episodes.length < el.config.minEpisodesForPattern * 2) return;

  // Group episodes by domain + rough topic similarity
  const groups = {};
  for (const ep of episodes.slice(-200)) {
    const key = ep.context.domain;
    if (!groups[key]) groups[key] = [];
    groups[key].push(ep);
  }

  for (const [domain, eps] of Object.entries(groups)) {
    if (eps.length < el.config.minEpisodesForPattern) continue;

    // Find successful patterns (quality > 0.6)
    const successes = eps.filter(e => e.outcome.quality > 0.6);
    const failures = eps.filter(e => e.outcome.quality < 0.4);

    if (successes.length >= el.config.minEpisodesForPattern) {
      // Extract what strategy works in this domain
      const stratCounts = {};
      for (const s of successes) {
        const k = s.action.strategy;
        stratCounts[k] = (stratCounts[k] || 0) + 1;
      }
      const bestStrat = Object.entries(stratCounts).sort((a, b) => b[1] - a[1])[0];

      // Collect common keywords
      const kwFreq = {};
      for (const s of successes) {
        for (const kw of s.context.keywords) {
          kwFreq[kw] = (kwFreq[kw] || 0) + 1;
        }
      }
      const topKeywords = Object.entries(kwFreq)
        .filter(([_, c]) => c >= 2)
        .sort((a, b) => b[1] - a[1])
        .slice(0, 10)
        .map(([kw]) => kw);

      const patternId = `pat_${domain}_${bestStrat ? bestStrat[0] : "default"}`;
      const existing = el.patterns.get(patternId);

      if (existing) {
        // Reinforce existing pattern
        existing.confidence = clamp(existing.confidence + 0.05, 0, 1);
        existing.episodeCount = successes.length;
        existing.updatedAt = nowISO();
      } else {
        el.patterns.set(patternId, {
          id: patternId,
          domain,
          bestStrategy: bestStrat ? bestStrat[0] : "default",
          keywords: topKeywords,
          avgQuality: successes.reduce((s, e) => s + e.outcome.quality, 0) / successes.length,
          episodeCount: successes.length,
          failureIndicators: failures.slice(0, 5).map(f => f.context.topic).filter(Boolean),
          confidence: clamp(successes.length / (successes.length + failures.length), 0.1, 0.95),
          createdAt: nowISO(),
          updatedAt: nowISO()
        });
        el.stats.patternsExtracted++;
      }
    }
  }

  // Cap patterns
  if (el.patterns.size > el.config.maxPatterns) {
    const sorted = Array.from(el.patterns.entries())
      .sort((a, b) => a[1].confidence - b[1].confidence);
    for (let i = 0; i < sorted.length - el.config.maxPatterns; i++) {
      el.patterns.delete(sorted[i][0]);
    }
  }

  saveStateDebounced();
}

// Retrieve relevant experience for a given context
function retrieveExperience(domain, topic, keywords = []) {
  ensureExperienceLearning();
  const el = STATE.experienceLearning;

  const results = {
    bestStrategy: null,
    relevantPatterns: [],
    recentEpisodes: [],
    warnings: [],
    confidence: 0
  };

  // Find matching patterns
  for (const [_, pattern] of el.patterns) {
    let relevance = 0;
    if (pattern.domain === domain) relevance += 0.4;

    // Keyword overlap
    const kwSet = new Set(pattern.keywords);
    const overlap = keywords.filter(k => kwSet.has(k)).length;
    if (overlap > 0) relevance += Math.min(0.4, overlap * 0.1);

    // Topic similarity (simple substring)
    if (topic && pattern.keywords.some(kw => topic.toLowerCase().includes(kw))) {
      relevance += 0.2;
    }

    if (relevance > 0.3) {
      results.relevantPatterns.push({ ...pattern, relevance });
    }
  }

  results.relevantPatterns.sort((a, b) => b.relevance - a.relevance);

  // Get best strategy recommendation
  if (results.relevantPatterns.length > 0) {
    const best = results.relevantPatterns[0];
    results.bestStrategy = best.bestStrategy;
    results.confidence = best.confidence * best.relevance;
  }

  // Check for failure indicators
  for (const pattern of results.relevantPatterns) {
    if (pattern.failureIndicators?.some(fi => topic?.toLowerCase().includes(fi.toLowerCase()))) {
      results.warnings.push(`Previous failures detected in similar topic within ${pattern.domain}`);
    }
  }

  // Recent similar episodes for reference
  results.recentEpisodes = el.episodes
    .filter(ep => ep.context.domain === domain)
    .slice(-5)
    .map(ep => ({ quality: ep.outcome.quality, strategy: ep.action.strategy, topic: ep.context.topic }));

  el.stats.retrievalsUsed++;
  return results;
}

// ═══════════════════════════════════════════════════════════════════════════════
// AUTONOMOUS WORLD MODEL UPDATER
// Design: Automatically extracts entities/relations from new information,
// compares against existing model, detects contradictions, updates confidence,
// and applies temporal decay. The world model becomes self-correcting.
// ═══════════════════════════════════════════════════════════════════════════════

function autoUpdateWorldModel(dtu) {
  try {
    ensureWorldModel();
    if (!STATE.worldModel.config.autoExtractEnabled) return;
    if (!dtu || !dtu.id) return;

    // 1. Extract entities from the DTU
    const _extraction = extractEntitiesFromDtu(dtu);

    // 2. Extract relations from DTU content
    const text = buildCretiText(dtu).toLowerCase();
    const title = (dtu.title || "").toLowerCase();
    const tags = Array.isArray(dtu.tags) ? dtu.tags : [];

    // Auto-detect relations between existing entities mentioned in this DTU
    const mentionedEntities = [];
    for (const [_eId, entity] of STATE.worldModel.entities) {
      const eName = entity.name.toLowerCase();
      if (text.includes(eName) || title.includes(eName)) {
        mentionedEntities.push(entity);
      }
    }

    // Create relations between co-mentioned entities
    if (mentionedEntities.length >= 2) {
      for (let i = 0; i < Math.min(mentionedEntities.length, 5); i++) {
        for (let j = i + 1; j < Math.min(mentionedEntities.length, 5); j++) {
          const e1 = mentionedEntities[i];
          const e2 = mentionedEntities[j];

          // Check for existing relation
          const existing = Array.from(STATE.worldModel.relations.values())
            .find(r => (r.from === e1.id && r.to === e2.id) || (r.from === e2.id && r.to === e1.id));

          if (existing) {
            // Reinforce existing relation
            existing.strength = clamp(existing.strength + 0.05, 0, 1);
            existing.confidence = clamp(existing.confidence + 0.03, 0, 1);
            existing.evidence = (existing.evidence || 0) + 1;
            existing.updatedAt = nowISO();
          } else {
            // Determine relation type from context
            const relType = tags.includes("cause") ? "causes" :
                           tags.includes("part") ? "part_of" :
                           tags.includes("similar") ? "similar_to" : "correlates";
            createWorldRelation({
              from: e1.id, to: e2.id,
              type: relType, strength: 0.3, confidence: 0.4,
              description: `Co-mentioned in DTU: ${dtu.title}`.slice(0, 300),
              evidence: 1, dtuId: dtu.id
            });
          }
        }
      }
    }

    // 3. Contradiction detection: check if new DTU contradicts existing entities
    const contradictions = [];
    for (const [eId, entity] of STATE.worldModel.entities) {
      if (!entity.state?.properties) continue;
      const eName = entity.name.toLowerCase();
      if (!text.includes(eName)) continue;

      // Simple contradiction: if DTU has claims that conflict with entity properties
      const claims = dtu.core?.claims || [];
      for (const claim of claims) {
        const claimText = String(claim).toLowerCase();
        // Check for negation patterns near entity name
        if (claimText.includes("not " + eName) || claimText.includes(eName + " is wrong") ||
            claimText.includes("contrary to " + eName) || claimText.includes("disproves " + eName)) {
          contradictions.push({
            entityId: eId, entityName: entity.name,
            claim, dtuId: dtu.id,
            detectedAt: nowISO()
          });
          // Lower entity confidence when contradicted
          entity.state.confidence = clamp(entity.state.confidence - 0.1, 0.05, 1);
          entity.state.volatility = clamp((entity.state.volatility || 0) + 0.15, 0, 1);
          entity.updatedAt = nowISO();
        }
      }
    }

    // 4. Record contradictions for metacognition
    if (contradictions.length > 0 && STATE.metacognition) {
      ensureMetacognitionSystem();
      STATE.metacognition.blindSpots = STATE.metacognition.blindSpots || [];
      for (const c of contradictions.slice(0, 3)) {
        STATE.metacognition.blindSpots.push({
          topic: `world-model-contradiction:${c.entityName}`,
          severity: 0.6,
          gaps: [`DTU "${dtu.title}" contradicts entity "${c.entityName}"`],
          detectedAt: c.detectedAt,
          source: "world-model-auto-update"
        });
      }
    }

    // 5. Boost salience of recently mentioned entities
    for (const entity of mentionedEntities) {
      entity.state.salience = clamp((entity.state.salience || 0.3) + 0.05, 0, 1);
    }

    saveStateDebounced();
  } catch {}
}

// Temporal decay for world model — unconfirmed facts lose confidence over time
function worldModelTemporalDecay() {
  try {
    ensureWorldModel();
    const now = Date.now();
    const dayMs = 86400000;

    for (const [_eId, entity] of STATE.worldModel.entities) {
      const age = now - new Date(entity.updatedAt || entity.createdAt).getTime();
      const daysSinceUpdate = age / dayMs;

      // Salience decays faster than confidence
      if (daysSinceUpdate > 1) {
        entity.state.salience = clamp(entity.state.salience * (1 - 0.02 * Math.min(daysSinceUpdate, 30)), 0.01, 1);
      }
      // Confidence decays slowly for unconfirmed entities
      if (daysSinceUpdate > 7 && entity.state.confidence < 0.8) {
        entity.state.confidence = clamp(entity.state.confidence * 0.995, 0.05, 1);
      }
    }

    // Weak relations decay
    for (const [rId, rel] of STATE.worldModel.relations) {
      const age = now - new Date(rel.updatedAt || rel.createdAt || now).getTime();
      const daysSinceUpdate = age / dayMs;
      if (daysSinceUpdate > 3 && rel.strength < 0.5) {
        rel.strength = clamp(rel.strength * 0.99, 0.01, 1);
        // Remove very weak relations
        if (rel.strength < 0.05) {
          STATE.worldModel.relations.delete(rId);
        }
      }
    }
  } catch {}
}

// ═══════════════════════════════════════════════════════════════════════════════
// GENUINE TRANSFER LEARNING ENGINE
// Design: When solving a problem, automatically searches for analogous solved
// problems in other domains, extracts the abstract strategy, maps it to the
// current domain, and tracks transfer success rates to improve future transfers.
// ═══════════════════════════════════════════════════════════════════════════════

function autoTransferSearch(domain, topic, _keywords = []) {
  try {
    ensureTransferEngine();
    if (STATE.transfer.patterns.size === 0) return null;

    // Find analogous patterns from other domains
    const analogies = findAnalogousPatterns(domain, topic);
    if (!analogies || analogies.length === 0) return null;

    // Filter for high-relevance analogies
    const relevant = analogies.filter(a => a.relevance > 0.4);
    if (relevant.length === 0) return null;

    const best = relevant[0];

    // Build transfer suggestion
    const suggestion = {
      sourcePattern: best.patternName,
      sourceDomain: best.sourceDomain,
      targetDomain: domain,
      relevance: best.relevance,
      template: best.template,
      strategy: null,
      applied: false
    };

    // Extract abstract strategy from the source pattern
    const pattern = STATE.transfer.patterns.get(best.patternId);
    if (pattern) {
      suggestion.strategy = {
        approach: pattern.template?.approach || "Apply structural analogy",
        steps: pattern.template?.steps || [],
        adaptations: `Adapt ${best.sourceDomain} approach to ${domain} context`,
        confidence: pattern.confidence * best.relevance * STATE.transfer.config.confidenceDecay
      };
    }

    return suggestion;
  } catch { return null; }
}

// Record transfer outcome for learning
function _recordTransferOutcome(transferId, success, quality = 0.5) {
  try {
    ensureTransferEngine();
    const transfer = STATE.transfer.transfers.find(t => t.id === transferId);
    if (!transfer) return;

    transfer.outcome = { success, quality, evaluatedAt: nowISO() };
    transfer.status = success ? "successful" : "failed";

    if (success) {
      STATE.transfer.stats.transfersSuccessful++;
      // Boost source pattern confidence
      const pattern = STATE.transfer.patterns.get(transfer.patternId);
      if (pattern) {
        pattern.confidence = clamp(pattern.confidence + 0.05, 0, 1);
      }
    } else {
      // Lower confidence decay for failed transfers
      const pattern = STATE.transfer.patterns.get(transfer.patternId);
      if (pattern) {
        pattern.confidence = clamp(pattern.confidence - 0.03, 0.05, 1);
      }
    }

    saveStateDebounced();
  } catch {}
}

// Auto-extract transferable pattern when reasoning chain concludes successfully
function autoExtractTransferPattern(chain) {
  try {
    ensureTransferEngine();
    if (!chain || chain.status !== "concluded" || !chain.conclusion) return;

    // Need the steps to extract a pattern
    const steps = Array.from(STATE.reasoning?.steps?.values() || [])
      .filter(s => s.chainId === chain.id)
      .sort((a, b) => a.index - b.index);

    if (steps.length < 2) return;

    // Classify the domain of this reasoning chain
    const text = [chain.question, chain.conclusion, ...steps.map(s => s.conclusion)].join(" ");
    const pseudoDtu = { title: chain.question || "", human: { summary: text }, tags: [] };
    const domain = classifyDomain(pseudoDtu);

    // Extract the abstract strategy (step types and their sequence)
    const stepTypes = steps.map(s => s.type || "deduction");
    const topTerms = tokenizeText(text)
      .reduce((acc, t) => { acc[t] = (acc[t] || 0) + 1; return acc; }, {});
    const sortedTerms = Object.entries(topTerms)
      .sort((a, b) => b[1] - a[1])
      .slice(0, 15)
      .map(([t]) => t);

    const patternId = uid("tpat");
    STATE.transfer.patterns.set(patternId, {
      id: patternId,
      name: `auto:${chain.question?.slice(0, 50) || "reasoning-chain"}`,
      sourceDomain: domain,
      confidence: clamp(chain.confidence || 0.5, 0.2, 0.8),
      structure: {
        dtuCount: steps.length,
        topTerms: sortedTerms,
        stepSequence: stepTypes
      },
      template: {
        approach: `${stepTypes[0]}-first reasoning with ${steps.length} steps`,
        steps: steps.map(s => ({ type: s.type, conclusion: s.conclusion?.slice(0, 100) })).slice(0, 5),
        adaptationGuide: `Adapt the ${stepTypes.join(" → ")} pattern to target domain`
      },
      createdAt: nowISO(),
      updatedAt: nowISO()
    });

    STATE.transfer.stats.patternsExtracted++;
    saveStateDebounced();
  } catch {}
}

// ═══════════════════════════════════════════════════════════════════════════════
// PARALLEL COGNITION & ATTENTION MANAGEMENT
// Design: Multiple reasoning "threads" that can run concurrently, with an
// attention manager that prioritizes, schedules, and can interrupt lower-priority
// tasks. Background processing queue for deferred work.
// ═══════════════════════════════════════════════════════════════════════════════

function ensureAttentionManager() {
  if (!STATE.attention) {
    STATE.attention = {
      focus: null,                      // Current primary focus
      threads: new Map(),               // Active reasoning threads
      queue: [],                        // Priority queue of pending tasks
      completed: [],                    // Recently completed threads (capped)
      background: [],                   // Background processing tasks
      stats: {
        threadsCreated: 0,
        threadsCompleted: 0,
        interruptions: 0,
        backgroundTasksRun: 0,
        avgFocusDurationMs: 0
      },
      config: {
        maxConcurrentThreads: 5,
        maxQueueSize: 50,
        maxBackgroundTasks: 20,
        focusTimeoutMs: 30000,
        interruptThreshold: 0.8         // Priority threshold to interrupt current focus
      }
    };
  }
  if (!(STATE.attention.threads instanceof Map)) {
    STATE.attention.threads = new Map(Object.entries(STATE.attention.threads || {}));
  }
}

// Create a new cognitive thread
function createCognitiveThread(task) {
  ensureAttentionManager();
  const attn = STATE.attention;

  const thread = {
    id: uid("thread"),
    type: String(task.type || "reasoning").slice(0, 50),
    priority: clamp(Number(task.priority || 0.5), 0, 1),
    description: String(task.description || "").slice(0, 500),
    status: "pending",
    input: task.input || {},
    output: null,
    domain: String(task.domain || "general"),
    createdAt: nowISO(),
    startedAt: null,
    completedAt: null,
    parentThreadId: task.parentThreadId || null,
    metadata: {}
  };

  // Check if we can run immediately or need to queue
  const activeCount = Array.from(attn.threads.values()).filter(t => t.status === "active").length;

  if (activeCount < attn.config.maxConcurrentThreads) {
    thread.status = "active";
    thread.startedAt = nowISO();
    attn.threads.set(thread.id, thread);
  } else if (thread.priority >= attn.config.interruptThreshold) {
    // High priority: interrupt lowest priority active thread
    const active = Array.from(attn.threads.values())
      .filter(t => t.status === "active")
      .sort((a, b) => a.priority - b.priority);

    if (active.length > 0 && active[0].priority < thread.priority) {
      const interrupted = active[0];
      interrupted.status = "interrupted";
      interrupted.metadata.interruptedBy = thread.id;
      interrupted.metadata.interruptedAt = nowISO();
      attn.stats.interruptions++;

      // Re-queue interrupted thread
      attn.queue.push({
        threadId: interrupted.id,
        priority: interrupted.priority,
        queuedAt: nowISO()
      });

      thread.status = "active";
      thread.startedAt = nowISO();
      attn.threads.set(thread.id, thread);
    } else {
      // Queue it
      attn.queue.push({ threadId: thread.id, priority: thread.priority, queuedAt: nowISO() });
      attn.threads.set(thread.id, thread);
    }
  } else {
    // Queue normally
    attn.queue.push({ threadId: thread.id, priority: thread.priority, queuedAt: nowISO() });
    attn.threads.set(thread.id, thread);
  }

  // Sort queue by priority (descending)
  attn.queue.sort((a, b) => b.priority - a.priority);

  // Cap queue
  if (attn.queue.length > attn.config.maxQueueSize) {
    attn.queue = attn.queue.slice(0, attn.config.maxQueueSize);
  }

  attn.stats.threadsCreated++;

  // Update focus
  if (thread.status === "active" && (!attn.focus || thread.priority > (attn.threads.get(attn.focus)?.priority || 0))) {
    attn.focus = thread.id;
  }

  saveStateDebounced();
  return { ok: true, thread };
}

// Complete a cognitive thread and process queue
function completeCognitiveThread(threadId, output) {
  ensureAttentionManager();
  const attn = STATE.attention;

  const thread = attn.threads.get(threadId);
  if (!thread) return { ok: false, error: "Thread not found" };

  thread.status = "completed";
  thread.output = output;
  thread.completedAt = nowISO();

  // Track duration
  if (thread.startedAt) {
    const duration = new Date(thread.completedAt) - new Date(thread.startedAt);
    const total = attn.stats.avgFocusDurationMs * attn.stats.threadsCompleted + duration;
    attn.stats.threadsCompleted++;
    attn.stats.avgFocusDurationMs = total / attn.stats.threadsCompleted;
  }

  // Move to completed list
  attn.completed.push({ id: thread.id, type: thread.type, duration: thread.completedAt, output: thread.output });
  if (attn.completed.length > 50) attn.completed.splice(0, attn.completed.length - 50);

  // Remove from active
  attn.threads.delete(threadId);

  // Promote next queued thread
  if (attn.queue.length > 0) {
    const next = attn.queue.shift();
    const nextThread = attn.threads.get(next.threadId);
    if (nextThread && nextThread.status !== "completed") {
      nextThread.status = "active";
      nextThread.startedAt = nowISO();
    }
  }

  // Update focus
  const activeThreads = Array.from(attn.threads.values()).filter(t => t.status === "active");
  attn.focus = activeThreads.length > 0
    ? activeThreads.sort((a, b) => b.priority - a.priority)[0].id
    : null;

  saveStateDebounced();
  return { ok: true, completed: thread };
}

// Add a background task (deferred processing)
function addBackgroundTask(task) {
  ensureAttentionManager();
  const attn = STATE.attention;

  attn.background.push({
    id: uid("bg"),
    type: String(task.type || "maintenance"),
    handler: String(task.handler || ""),
    input: task.input || {},
    priority: clamp(Number(task.priority || 0.3), 0, 1),
    status: "pending",
    createdAt: nowISO()
  });

  // Cap background tasks
  if (attn.background.length > attn.config.maxBackgroundTasks) {
    attn.background = attn.background.filter(t => t.status !== "completed").slice(-attn.config.maxBackgroundTasks);
  }

  return { ok: true };
}

// Process background tasks (called from kernelTick)
function processBackgroundTasks() {
  try {
    ensureAttentionManager();
    const attn = STATE.attention;
    const pending = attn.background.filter(t => t.status === "pending");
    if (pending.length === 0) return;

    // Process up to 3 background tasks per tick
    for (const task of pending.slice(0, 3)) {
      try {
        task.status = "running";
        switch (task.handler) {
          case "world_model_decay":
            worldModelTemporalDecay();
            break;
          case "experience_consolidation":
            consolidateExperience();
            break;
          case "pattern_decay":
            decayUnusedPatterns();
            break;
          default:
            break;
        }
        task.status = "completed";
        task.completedAt = nowISO();
        attn.stats.backgroundTasksRun++;
      } catch {
        task.status = "failed";
      }
    }

    // Clean completed background tasks
    attn.background = attn.background.filter(t => t.status !== "completed" || (Date.now() - new Date(t.completedAt).getTime()) < 60000);
  } catch {}
}

// Decay unused experience patterns
function decayUnusedPatterns() {
  try {
    ensureExperienceLearning();
    const el = STATE.experienceLearning;
    const now = Date.now();
    const dayMs = 86400000;

    for (const [pId, pattern] of el.patterns) {
      const age = now - new Date(pattern.updatedAt || pattern.createdAt).getTime();
      if (age > dayMs * 7) {
        pattern.confidence = clamp(pattern.confidence - el.config.decayRate, 0.01, 1);
        if (pattern.confidence < 0.05) {
          el.patterns.delete(pId);
        }
      }
    }
  } catch {}
}

// ═══════════════════════════════════════════════════════════════════════════════
// REFLECTIVE LLM LOOP
// Design: Post-response self-critique that evaluates response quality, checks
// for consistency with known facts, and feeds insights back into experience
// memory. This creates a learning loop where the system improves from its
// own output analysis.
// ═══════════════════════════════════════════════════════════════════════════════

function ensureReflectionEngine() {
  if (!STATE.reflection) {
    STATE.reflection = {
      reflections: [],                  // Recent reflections (capped)
      insights: new Map(),              // Accumulated insights by topic
      selfModel: {
        strengths: [],                  // Known strengths
        weaknesses: [],                 // Known weaknesses
        biases: [],                     // Detected biases
        confidenceCalibration: 0.5      // How well-calibrated is self-assessment
      },
      stats: {
        reflectionsRun: 0,
        insightsGenerated: 0,
        selfCorrections: 0,
        qualityImprovements: 0
      },
      config: {
        maxReflections: 500,
        maxInsights: 200,
        reflectOnEveryNth: 5,           // Reflect every N responses
        minResponseLength: 50,          // Skip reflection for very short responses
        qualityThreshold: 0.4           // Below this triggers deeper reflection
      }
    };
  }
  if (!(STATE.reflection.insights instanceof Map)) {
    STATE.reflection.insights = new Map(Object.entries(STATE.reflection.insights || {}));
  }
}

// Run post-response reflection
function reflectOnResponse(context) {
  try {
    ensureReflectionEngine();
    ensureExperienceLearning();
    const ref = STATE.reflection;

    const prompt = String(context.prompt || "");
    const response = String(context.response || "");
    const mode = context.mode || "explore";
    const domain = context.domain || "general";
    const llmUsed = !!context.llmUsed;
    const relevantDtus = context.relevantDtus || [];

    // Skip reflection for very short interactions
    if (response.length < ref.config.minResponseLength) return null;

    // Only reflect every Nth response
    ref.stats.reflectionsRun++;
    if (ref.stats.reflectionsRun % ref.config.reflectOnEveryNth !== 0) return null;

    const reflection = {
      id: uid("refl"),
      timestamp: nowISO(),
      prompt: prompt.slice(0, 200),
      responseLength: response.length,
      domain,
      mode,
      checks: {},
      quality: 0.5,
      insights: [],
      corrections: []
    };

    // CHECK 1: Response coherence — does it contradict known facts?
    const responseTokens = new Set(tokenizeText(response));
    let contradictionCount = 0;
    if (STATE.worldModel) {
      for (const [_, entity] of STATE.worldModel.entities) {
        if (entity.state.confidence > 0.7) {
          const eName = entity.name.toLowerCase();
          if (response.toLowerCase().includes(eName)) {
            // Check for negation near entity mention
            const idx = response.toLowerCase().indexOf(eName);
            const surrounding = response.slice(Math.max(0, idx - 30), idx + eName.length + 30).toLowerCase();
            if (surrounding.includes("not ") || surrounding.includes("wrong") || surrounding.includes("incorrect")) {
              if (entity.state.confidence > 0.85) {
                contradictionCount++;
                reflection.corrections.push(`Response may contradict high-confidence entity "${entity.name}"`);
              }
            }
          }
        }
      }
    }
    reflection.checks.factConsistency = contradictionCount === 0 ? 1 : clamp(1 - contradictionCount * 0.2, 0, 1);

    // CHECK 2: Relevance — did the response address the prompt?
    const promptTokens = new Set(tokenizeText(prompt));
    const overlap = [...promptTokens].filter(t => responseTokens.has(t)).length;
    reflection.checks.relevance = clamp(overlap / Math.max(promptTokens.size, 1), 0, 1);

    // CHECK 3: Grounding — was the response backed by evidence?
    reflection.checks.grounding = relevantDtus.length > 0 ? clamp(relevantDtus.length / 3, 0.2, 1) : 0.2;

    // CHECK 4: Completeness — reasonable length for the query
    const expectedLength = prompt.length * 3; // Rough heuristic
    reflection.checks.completeness = clamp(response.length / Math.max(expectedLength, 100), 0.3, 1);

    // CHECK 5: Self-consistency — check against previous responses in session
    reflection.checks.selfConsistency = 1.0; // Default pass unless we detect contradiction

    // Compute overall quality score
    const weights = { factConsistency: 0.3, relevance: 0.25, grounding: 0.2, completeness: 0.15, selfConsistency: 0.1 };
    reflection.quality = Object.entries(weights).reduce((sum, [key, w]) => sum + (reflection.checks[key] || 0.5) * w, 0);

    // Generate insights from low-quality checks
    if (reflection.checks.factConsistency < 0.7) {
      reflection.insights.push({
        type: "fact_mismatch",
        message: "Response potentially contradicts established knowledge",
        severity: 1 - reflection.checks.factConsistency
      });
    }
    if (reflection.checks.grounding < 0.4) {
      reflection.insights.push({
        type: "low_grounding",
        message: "Response lacks sufficient evidence backing — consider forging more DTUs",
        severity: 0.5
      });
    }
    if (reflection.checks.relevance < 0.3) {
      reflection.insights.push({
        type: "off_topic",
        message: "Response may not adequately address the prompt",
        severity: 0.7
      });
    }

    // Store reflection
    ref.reflections.push(reflection);
    if (ref.reflections.length > ref.config.maxReflections) {
      ref.reflections.splice(0, ref.reflections.length - ref.config.maxReflections);
    }

    // Feed insights into experience learning
    const keywords = [...promptTokens].slice(0, 10);
    recordExperienceEpisode({
      domain,
      topic: prompt.slice(0, 100),
      keywords,
      mode,
      strategy: llmUsed ? "llm-enhanced" : "local-deterministic",
      llmUsed,
      dtusRetrieved: relevantDtus.length,
      responseLength: response.length,
      quality: reflection.quality,
      followUpNeeded: reflection.quality < ref.config.qualityThreshold,
      errorOccurred: contradictionCount > 0
    });

    // Update self-model based on accumulated reflections
    if (ref.reflections.length > 10) {
      const recent = ref.reflections.slice(-20);
      const avgQuality = recent.reduce((s, r) => s + r.quality, 0) / recent.length;
      ref.selfModel.confidenceCalibration = avgQuality;

      // Identify strengths and weaknesses
      const checkAvgs = {};
      for (const check of ["factConsistency", "relevance", "grounding", "completeness"]) {
        checkAvgs[check] = recent.reduce((s, r) => s + (r.checks[check] || 0), 0) / recent.length;
      }

      ref.selfModel.strengths = Object.entries(checkAvgs)
        .filter(([_, v]) => v > 0.7)
        .map(([k]) => k);
      ref.selfModel.weaknesses = Object.entries(checkAvgs)
        .filter(([_, v]) => v < 0.5)
        .map(([k]) => k);

      ref.stats.insightsGenerated += reflection.insights.length;
    }

    // Emit affect event for reflection quality
    try {
      if (ATS) {
        ATS.emitAffectEvent("system", {
          type: "SYSTEM_RESULT",
          intensity: 0.2,
          polarity: reflection.quality > 0.6 ? 0.2 : -0.2,
          payload: { action: "self-reflection", quality: reflection.quality, checks: reflection.checks },
          source: { system: "reflection" }
        });
      }
    } catch {}

    saveStateDebounced();
    return reflection;
  } catch { return null; }
}

function _clamp01(x){ return clamp(Number(x||0), 0, 1); }

function computeGrowthTick(signal={}) {
  // signal can include: acuteStress, chronicStress, drift, damage, repair, decline
  const g = STATE.growth || {};
  const acute = _clamp01((g.stress?.acute ?? 0) + (signal.acuteStress ?? 0));
  const chronic = _clamp01((g.stress?.chronic ?? 0) + (signal.chronicStress ?? 0));
  g.stress = { acute, chronic };

  const drift = _clamp01((signal.drift ?? 0) * 0.5 + (g.epigeneticClock ?? 0) * 0.5);
  g.epigeneticClock = _clamp01(0.98*(g.epigeneticClock ?? 0.05) + 0.02*drift);

  const repair = _clamp01((g.maintenance?.repairRate ?? 0.5) + (signal.repairDelta ?? 0));
  g.maintenance = { ...(g.maintenance||{}), repairRate: repair, cleanupBacklog: Math.max(0, Number(g.maintenance?.cleanupBacklog||0) + Number(signal.backlogDelta||0)) };

  // Telomere analog
  g.telomere = _clamp01((g.telomere ?? 1.0) - 0.01*chronic + 0.008*repair);

  // Proteome shift analog
  const shift = _clamp01((signal.paramShift ?? 0));
  g.proteomeShift = _clamp01(0.97*(g.proteomeShift ?? 0) + 0.03*shift);

  // Functional decline aggregation
  const fd = g.functionalDecline || {};
  const decline = _clamp01((signal.decline ?? 0));
  g.functionalDecline = { ...fd, contradictionLoad: _clamp01(0.97*(fd.contradictionLoad||0)+0.03*decline) };

  // Homeostasis
  g.homeostasis = _clamp01(1 - (0.35*g.functionalDecline.contradictionLoad + 0.35*chronic + 0.15*acute + 0.15*g.epigeneticClock));

  // BioAge (0..100)
  const bioAge = Number(g.bioAge ?? 0);
  const nextBio = clamp(bioAge + 0.8*g.epigeneticClock + 0.9*(1-g.telomere) + 0.6*g.proteomeShift + 0.8*g.functionalDecline.contradictionLoad - 0.7*repair, 0, 100);
  g.bioAge = nextBio;

  // Chicken2: suffering boundary metric (bounded) derived from stress + contradiction load
  try{
    const acuteS = Number(g.stress?.acute ?? 0);
    const chronicS = Number(g.stress?.chronic ?? 0);
    const cLoad = Number(g.functionalDecline?.contradictionLoad ?? 0);
    const suffering = clamp(0.55*acuteS + 0.35*chronicS + 0.10*clamp01(cLoad), 0, 1);
    STATE.__chicken2.metrics.suffering = suffering;
    STATE.__chicken2.metrics.homeostasis = clamp(1 - suffering, 0, 1);
    // threshold enforcement (quarantine escalates elsewhere; here we just record)
  } catch{}
  STATE.growth = g;
  return g;
}

function kernelTick(event) {
  ensureOrganRegistry();
  ensureQueues();
  ensureGoalSystem();
  ensureWorldModel();
  ensureSemanticEngine();
  ensureTransferEngine();
  ensureCommonsenseSubstrate();
  ensureGroundingEngine();
  ensureReasoningEngine();
  ensureHypothesisEngine();
  ensureMetacognitionSystem();
  ensureExplanationEngine();
  ensureMetaLearningSystem();
  ensureExperienceLearning();
  ensureAttentionManager();
  ensureReflectionEngine();
  // Simple universal tick: update wear/debt and write Learning DTU for major changes.
  const t = nowISO();
  const signal = { acuteStress: 0, chronicStress: 0, drift: 0, paramShift: 0, decline: 0, repairDelta: 0, backlogDelta: 0 };

  for (const [id, st] of STATE.organs.entries()) {
    // record last events
    st.traces = st.traces || { ema: {}, counters: {}, lastEvents: [] };
    st.traces.lastEvents.push({ type: event?.type || "EVENT", t, meta: event?.meta ? { ...event.meta } : undefined });
    if (st.traces.lastEvents.length > 20) st.traces.lastEvents.splice(0, st.traces.lastEvents.length - 20);

    // basic wear model
    const isError = event?.type === "ERROR" || event?.type === "VERIFIER_FAIL";
    const isContradiction = event?.type === "CONTRADICTION";
    st.wear = st.wear || { damage: 0, repair: 0.5, debt: 0 };
    st.wear.damage = _clamp01(st.wear.damage + (isError ? 0.01 : 0) + (isContradiction ? 0.005 : 0));
    st.wear.debt = _clamp01(st.wear.debt + (isContradiction ? 0.01 : 0) - 0.003*(st.wear.repair ?? 0.5));

    // maturity updates (low-res, dynamic)
    st.maturity = st.maturity || { score: 0.01, confidence: 0.1, stability: 0.05, plasticity: 0.75, lastUpdateAt: t };
    const benefit = Number(event?.signals?.benefit ?? 0);
    const err = Number(event?.signals?.error ?? 0);
    const delta = 0.002*(benefit - err - st.wear.debt);
    st.maturity.score = _clamp01(st.maturity.score + delta);
    st.maturity.confidence = _clamp01(st.maturity.confidence + 0.001*(benefit - err));
    st.maturity.stability = _clamp01(st.maturity.stability + 0.001 - 0.003*(isError ? 1 : 0));
    // plasticity decays slightly with maturity and damage
    const pl = Number(st.maturity.plasticity ?? 0.75);
    st.maturity.plasticity = clamp(pl * (1 - 0.002*st.maturity.score) * (1 - 0.005*st.wear.damage), 0.05, 0.90);
    st.maturity.lastUpdateAt = t;

    // resolution ladder (coarse)
    if (st.maturity.score > 0.80) st.resolution = 4;
    else if (st.maturity.score > 0.60) st.resolution = 3;
    else if (st.maturity.score > 0.35) st.resolution = 2;
    else if (st.maturity.score > 0.15) st.resolution = 1;
    else st.resolution = 0;

    STATE.organs.set(id, st);
    signal.chronicStress += st.wear.debt * 0.02;
    signal.acuteStress += st.wear.damage * 0.01;
    signal.paramShift += Math.min(1, Math.abs(delta) * 40);
    signal.decline += st.wear.debt * 0.03;
  }

  // ===== AUTO-METACOGNITION ON REPEATED ERRORS =====
  // Track recent errors and trigger introspection when they accumulate
  try {
    if (!STATE.__errorTracking) {
      STATE.__errorTracking = { recentErrors: [], lastIntrospectAt: 0, introspectCooldownMs: 60000 };
    }
    const _et = STATE.__errorTracking;
    const isErr = event?.type === "ERROR" || event?.type === "VERIFIER_FAIL" || event?.type === "CONTRADICTION";
    if (isErr) {
      _et.recentErrors.push({ type: event.type, t: Date.now(), meta: event?.meta });
    }
    // Trim to last 30
    if (_et.recentErrors.length > 30) _et.recentErrors.splice(0, _et.recentErrors.length - 30);
    // Check: ≥5 errors in last 60s triggers auto-introspection
    const _windowMs = 60000;
    const _now = Date.now();
    const _recentCount = _et.recentErrors.filter(e => (_now - e.t) < _windowMs).length;
    if (_recentCount >= 5 && (_now - _et.lastIntrospectAt) > _et.introspectCooldownMs) {
      _et.lastIntrospectAt = _now;
      // Fire-and-forget introspection
      try {
        const _introResult = introspectOnFailures();
        // Record as a blindspot if patterns found
        if (_introResult?.failurePatterns?.length > 0 && STATE.metacognition) {
          STATE.metacognition.blindSpots = STATE.metacognition.blindSpots || [];
          STATE.metacognition.blindSpots.push({
            topic: "auto-detected error cluster",
            severity: clamp(_recentCount / 10, 0.3, 1.0),
            gaps: _introResult.failurePatterns.map(p => p.description || p.pattern || String(p)).slice(0, 3),
            detectedAt: nowISO(),
            source: "auto-metacognition"
          });
          // Keep blindSpots bounded
          if (STATE.metacognition.blindSpots.length > 50) {
            STATE.metacognition.blindSpots.splice(0, STATE.metacognition.blindSpots.length - 50);
          }
        }
        // Also check organ health — any organ with damage > 0.6 gets flagged
        for (const [orgId, orgSt] of STATE.organs.entries()) {
          if (orgSt.wear?.damage > 0.6 && STATE.metacognition) {
            const _existing = STATE.metacognition.blindSpots?.find(
              b => b.topic === `organ-health:${orgId}` && b.source === "auto-metacognition"
            );
            if (!_existing) {
              STATE.metacognition.blindSpots = STATE.metacognition.blindSpots || [];
              STATE.metacognition.blindSpots.push({
                topic: `organ-health:${orgId}`,
                severity: orgSt.wear.damage,
                gaps: [`Organ "${orgId}" wear damage at ${(orgSt.wear.damage * 100).toFixed(0)}%`],
                detectedAt: nowISO(),
                source: "auto-metacognition"
              });
            }
          }
        }
        // Emit affect event for auto-introspection
        if (ATS) {
          ATS.emitAffectEvent("system", {
            type: "SYSTEM_RESULT", intensity: 0.4, polarity: -0.2,
            payload: { action: "auto-introspection", errorCount: _recentCount },
            source: { system: "metacognition" }
          });
        }
      } catch {}
    }
  } catch {}

  // ===== BACKGROUND PROCESSING =====
  // Process deferred tasks: world model decay, experience consolidation, pattern cleanup
  try { processBackgroundTasks(); } catch {}

  // Schedule periodic background tasks (every ~50 ticks)
  try {
    if (!STATE.__bgTickCounter) STATE.__bgTickCounter = 0;
    STATE.__bgTickCounter++;
    if (STATE.__bgTickCounter % 50 === 0) {
      addBackgroundTask({ type: "maintenance", handler: "world_model_decay", priority: 0.2 });
      addBackgroundTask({ type: "maintenance", handler: "experience_consolidation", priority: 0.3 });
      addBackgroundTask({ type: "maintenance", handler: "pattern_decay", priority: 0.1 });
    }
  } catch {}
  // ===== END BACKGROUND PROCESSING =====

  computeGrowthTick(signal);
  saveStateDebounced();
}

// Ensure regi

// ═══════════════════════════════════════════════════════════════════════════════
// CONCORD ECONOMIC ENGINE v2.1
// ═══════════════════════════════════════════════════════════════════════════════

// ---- Stripe Integration (lazy load) ----
let stripe = null;
const STRIPE_SECRET_KEY = process.env.STRIPE_SECRET_KEY || '';
const STRIPE_WEBHOOK_SECRET = process.env.STRIPE_WEBHOOK_SECRET || '';
const STRIPE_ENABLED = Boolean(STRIPE_SECRET_KEY);

async function getStripe() {
  if (!STRIPE_ENABLED) return null;
  if (!stripe) {
    try {
      const Stripe = (await import('stripe')).default;
      stripe = new Stripe(STRIPE_SECRET_KEY, { apiVersion: '2023-10-16' });
    } catch (e) {
      console.warn('[Economic] Stripe not available:', e.message);
    }
  }
  return stripe;
}

// ---- Economic Constants ----
const ECONOMIC_CONFIG = Object.freeze({
  TOKEN_PURCHASE_FEE: 0.0146,        // 1.46% fee on token purchases
  MARKETPLACE_FEE: 0.04,              // 4% marketplace fee (adjustable 3-5%)
  CREATOR_SHARE: 0.70,                // 70% to creator
  ROYALTY_SHARE: 0.20,                // 20% to royalty wheel
  TREASURY_SHARE: 0.10,               // 10% to Concord treasury

  // Royalty wheel decay by generation
  ROYALTY_DECAY: [0.30, 0.20, 0.10, 0.05, 0.03, 0.02, 0.01],

  // Token packages (CT = Concord Tokens)
  TOKEN_PACKAGES: [
    { id: 'pack_500', tokens: 500, price: 500, bonus: 0 },      // $5.00
    { id: 'pack_2000', tokens: 2200, price: 1800, bonus: 0.10 }, // $18.00, 10% bonus
    { id: 'pack_10000', tokens: 12000, price: 8000, bonus: 0.20 }, // $80.00, 20% bonus
  ],

  // Subscription tiers
  TIERS: {
    free: { name: 'Free', price: 0, ingestLimit: 10, tokensPerMonth: 100 },
    pro: { name: 'Pro', price: 1200, ingestLimit: -1, tokensPerMonth: 2000 },    // $12/mo
    teams: { name: 'Teams', price: 2900, ingestLimit: -1, tokensPerMonth: 5000 }, // $29/seat/mo
  },

  // Stripe price IDs (set in env)
  STRIPE_PRICES: {
    pro: process.env.STRIPE_PRICE_PRO || '',
    teams: process.env.STRIPE_PRICE_TEAMS || '',
  },
});

// ---- Economic State ----
function ensureEconomicState() {
  if (!STATE.economic) {
    STATE.economic = {
      wallets: new Map(),           // odId -> { balance, tier, stripeCustomerId, ... }
      listings: new Map(),          // listingId -> { dtuId, price, seller, ... }
      transactions: [],             // transaction log
      treasury: 0,                  // Concord treasury balance
      ingestTracking: new Map(),    // odId -> { date, count }
    };
  }
  return STATE.economic;
}

// ---- Wallet Management ----
function getWallet(odId) {
  ensureEconomicState();
  if (!STATE.economic.wallets.has(odId)) {
    STATE.economic.wallets.set(odId, {
      odId,
      balance: 0,
      tier: 'free',
      stripeCustomerId: null,
      stripeSubscriptionId: null,
      tokensEarned: 0,
      tokensSpent: 0,
      createdAt: Date.now(),
      updatedAt: Date.now(),
    });
  }
  return STATE.economic.wallets.get(odId);
}

function creditWallet(odId, amount, reason = '', refId = null) {
  // Idempotency: if refId provided, check if already processed
  if (db && refId) {
    const existing = checkRefIdProcessed(db, refId);
    if (existing.exists) return getWallet(odId); // already done, no-op
  }

  const wallet = getWallet(odId);
  wallet.balance += amount;
  wallet.tokensEarned += amount;
  wallet.updatedAt = Date.now();
  logTransaction({ type: 'credit', odId, amount, reason, balance: wallet.balance, refId });
  // Bridge to economy ledger if available
  if (db && amount > 0) {
    try {
      db.prepare(`
        INSERT INTO economy_ledger (id, type, from_user_id, to_user_id, amount, fee, net, status, metadata_json, request_id, ip, created_at, ref_id)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
      `).run(
        generateTxId(), 'TRANSFER', null, odId, amount, 0, amount, 'complete',
        JSON.stringify({ source: 'economic_wallet', reason, bridged: true }),
        null, null, new Date().toISOString().replace('T', ' ').replace('Z', ''),
        refId
      );
    } catch (e) {
      // If ref_id column doesn't exist yet (pre-migration), fall back
      if (e.message?.includes('ref_id')) {
        try {
          db.prepare(`
            INSERT INTO economy_ledger (id, type, from_user_id, to_user_id, amount, fee, net, status, metadata_json, request_id, ip, created_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
          `).run(
            generateTxId(), 'TRANSFER', null, odId, amount, 0, amount, 'complete',
            JSON.stringify({ source: 'economic_wallet', reason, bridged: true }),
            null, null, new Date().toISOString().replace('T', ' ').replace('Z', '')
          );
        } catch (e2) {
          console.error('[Economic→Ledger] Credit bridge failed (fallback):', e2.message);
        }
      } else if (e.message?.includes('UNIQUE constraint')) {
        // Idempotent — already recorded
      } else {
        console.error('[Economic→Ledger] Credit bridge failed:', e.message);
      }
    }
  }
  return wallet;
}

function debitWallet(odId, amount, reason = '', refId = null) {
  // Idempotency: if refId provided, check if already processed
  if (db && refId) {
    const existing = checkRefIdProcessed(db, refId);
    if (existing.exists) return getWallet(odId); // already done, no-op
  }

  const wallet = getWallet(odId);
  if (wallet.balance < amount) {
    throw new Error(`Insufficient balance: have ${wallet.balance}, need ${amount}`);
  }
  wallet.balance -= amount;
  wallet.tokensSpent += amount;
  wallet.updatedAt = Date.now();
  logTransaction({ type: 'debit', odId, amount, reason, balance: wallet.balance, refId });
  // Bridge to economy ledger if available
  if (db && amount > 0) {
    try {
      db.prepare(`
        INSERT INTO economy_ledger (id, type, from_user_id, to_user_id, amount, fee, net, status, metadata_json, request_id, ip, created_at, ref_id)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
      `).run(
        generateTxId(), 'TRANSFER', odId, null, amount, 0, amount, 'complete',
        JSON.stringify({ source: 'economic_wallet', reason, bridged: true }),
        null, null, new Date().toISOString().replace('T', ' ').replace('Z', ''),
        refId
      );
    } catch (e) {
      if (e.message?.includes('ref_id')) {
        try {
          db.prepare(`
            INSERT INTO economy_ledger (id, type, from_user_id, to_user_id, amount, fee, net, status, metadata_json, request_id, ip, created_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
          `).run(
            generateTxId(), 'TRANSFER', odId, null, amount, 0, amount, 'complete',
            JSON.stringify({ source: 'economic_wallet', reason, bridged: true }),
            null, null, new Date().toISOString().replace('T', ' ').replace('Z', '')
          );
        } catch (e2) {
          console.error('[Economic→Ledger] Debit bridge failed (fallback):', e2.message);
        }
      } else if (e.message?.includes('UNIQUE constraint')) {
        // Idempotent — already recorded
      } else {
        console.error('[Economic→Ledger] Debit bridge failed:', e.message);
      }
    }
  }
  return wallet;
}

function logTransaction(tx) {
  ensureEconomicState();
  STATE.economic.transactions.push({
    ...tx,
    id: `tx_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`,
    timestamp: Date.now(),
  });
  // Keep only last 10000 transactions in memory
  if (STATE.economic.transactions.length > 10000) {
    STATE.economic.transactions = STATE.economic.transactions.slice(-10000);
  }
}

// ---- Token Purchase System (1.46% fee) ----

// GET /api/economic/config — return tiers and token packages for billing page
app.get('/api/economic/config', (req, res) => {
  res.json({
    ok: true,
    tiers: ECONOMIC_CONFIG.TIERS,
    tokenPackages: ECONOMIC_CONFIG.TOKEN_PACKAGES,
    marketplaceFee: ECONOMIC_CONFIG.MARKETPLACE_FEE,
    creatorShare: ECONOMIC_CONFIG.CREATOR_SHARE,
  });
});

// GET /api/economic/wallet/:odId — return wallet info for billing page
app.get('/api/economic/wallet/:odId', (req, res) => {
  try {
    const wallet = getWallet(req.params.odId);
    const tracking = STATE.economic?.ingestTracking?.get(req.params.odId);
    res.json({
      ok: true,
      balance: wallet.balance,
      tier: wallet.tier,
      tokensEarned: wallet.tokensEarned || 0,
      tokensSpent: wallet.tokensSpent || 0,
      ingestStatus: tracking ? { date: tracking.date, count: tracking.count } : null,
    });
  } catch (e) {
    res.status(500).json({ ok: false, error: String(e?.message || e) });
  }
});

app.post('/api/economic/tokens/purchase', async (req, res) => {
  try {
    const { odId, packageId } = req.body;
    if (!odId || !packageId) return res.status(400).json({ error: 'Missing odId or packageId' });

    const pkg = ECONOMIC_CONFIG.TOKEN_PACKAGES.find(p => p.id === packageId);
    if (!pkg) return res.status(400).json({ error: 'Invalid package' });

    const stripeClient = await getStripe();
    if (!stripeClient) {
      return res.status(503).json({ error: 'Payment system not configured' });
    }

    const wallet = getWallet(odId);

    // Create or get Stripe customer
    let customerId = wallet.stripeCustomerId;
    if (!customerId) {
      const customer = await stripeClient.customers.create({
        metadata: { odId },
      });
      customerId = customer.id;
      wallet.stripeCustomerId = customerId;
    }

    // Create checkout session
    const session = await stripeClient.checkout.sessions.create({
      customer: customerId,
      payment_method_types: ['card'],
      line_items: [{
        price_data: {
          currency: 'usd',
          product_data: {
            name: `${pkg.tokens} Concord Tokens`,
            description: pkg.bonus > 0 ? `Includes ${Math.round(pkg.bonus * 100)}% bonus!` : undefined,
          },
          unit_amount: pkg.price,
        },
        quantity: 1,
      }],
      mode: 'payment',
      success_url: `${process.env.FRONTEND_URL || 'https://concord-os.org'}/billing?success=true`,
      cancel_url: `${process.env.FRONTEND_URL || 'https://concord-os.org'}/billing?canceled=true`,
      metadata: {
        odId,
        packageId,
        tokens: pkg.tokens,
        type: 'token_purchase',
      },
    });

    res.json({ sessionId: session.id, url: session.url });
  } catch (e) {
    console.error('[Economic] Token purchase error:', e);
    res.status(500).json({ error: e.message });
  }
});

// ---- Subscription Management ----
app.post('/api/economic/subscribe', async (req, res) => {
  try {
    const { odId, tier } = req.body;
    if (!odId || !tier) return res.status(400).json({ error: 'Missing odId or tier' });

    const tierConfig = ECONOMIC_CONFIG.TIERS[tier];
    if (!tierConfig || tier === 'free') {
      return res.status(400).json({ error: 'Invalid tier' });
    }

    const priceId = ECONOMIC_CONFIG.STRIPE_PRICES[tier];
    if (!priceId) {
      return res.status(503).json({ error: 'Subscription not configured for this tier' });
    }

    const stripeClient = await getStripe();
    if (!stripeClient) {
      return res.status(503).json({ error: 'Payment system not configured' });
    }

    const wallet = getWallet(odId);

    // Create or get Stripe customer
    let customerId = wallet.stripeCustomerId;
    if (!customerId) {
      const customer = await stripeClient.customers.create({
        metadata: { odId },
      });
      customerId = customer.id;
      wallet.stripeCustomerId = customerId;
    }

    // Create checkout session for subscription
    const session = await stripeClient.checkout.sessions.create({
      customer: customerId,
      payment_method_types: ['card'],
      line_items: [{ price: priceId, quantity: 1 }],
      mode: 'subscription',
      success_url: `${process.env.FRONTEND_URL || 'https://concord-os.org'}/billing?success=true`,
      cancel_url: `${process.env.FRONTEND_URL || 'https://concord-os.org'}/billing?canceled=true`,
      metadata: { odId, tier, type: 'subscription' },
    });

    res.json({ sessionId: session.id, url: session.url });
  } catch (e) {
    console.error('[Economic] Subscribe error:', e);
    res.status(500).json({ error: e.message });
  }
});

// ---- Stripe Webhook Handler ----
app.post('/api/economic/webhook', async (req, res) => {
  const stripeClient = await getStripe();
  if (!stripeClient) return res.status(503).send('Stripe not configured');

  const sig = req.headers['stripe-signature'];
  let event;

  try {
    event = stripeClient.webhooks.constructEvent(req.rawBody, sig, STRIPE_WEBHOOK_SECRET);
  } catch (e) {
    console.error('[Economic] Webhook signature verification failed:', e.message);
    return res.status(400).send(`Webhook Error: ${e.message}`);
  }

  try {
    switch (event.type) {
      case 'checkout.session.completed': {
        const session = event.data.object;
        const { odId, type, packageId, tokens, tier } = session.metadata || {};

        if (type === 'token_purchase' && odId && tokens) {
          // Apply 1.46% fee (already collected by Stripe, we credit net tokens)
          const netTokens = Math.floor(Number(tokens));
          creditWallet(odId, netTokens, `Token purchase: ${packageId}`);

          // Fee goes to treasury
          const fee = Math.ceil(netTokens * ECONOMIC_CONFIG.TOKEN_PURCHASE_FEE);
          ensureEconomicState();
          STATE.economic.treasury += fee;

          console.log(`[Economic] Token purchase: ${odId} received ${netTokens} CT (fee: ${fee})`);
        }

        if (type === 'subscription' && odId && tier) {
          const wallet = getWallet(odId);
          wallet.tier = tier;
          wallet.stripeSubscriptionId = session.subscription;
          wallet.updatedAt = Date.now();

          // Credit monthly tokens
          const tierConfig = ECONOMIC_CONFIG.TIERS[tier];
          if (tierConfig?.tokensPerMonth) {
            creditWallet(odId, tierConfig.tokensPerMonth, `${tier} subscription monthly tokens`);
          }

          console.log(`[Economic] Subscription: ${odId} upgraded to ${tier}`);
        }
        break;
      }

      case 'customer.subscription.deleted': {
        const subscription = event.data.object;
        // Find wallet by subscription ID and downgrade
        ensureEconomicState();
        for (const [, wallet] of STATE.economic.wallets) {
          if (wallet.stripeSubscriptionId === subscription.id) {
            wallet.tier = 'free';
            wallet.stripeSubscriptionId = null;
            wallet.updatedAt = Date.now();
            console.log(`[Economic] Subscription canceled: ${wallet.odId} downgraded to free`);
            break;
          }
        }
        break;
      }

      case 'invoice.payment_succeeded': {
        const invoice = event.data.object;
        // Monthly token grant for subscriptions
        if (invoice.subscription) {
          ensureEconomicState();
          for (const [, wallet] of STATE.economic.wallets) {
            if (wallet.stripeSubscriptionId === invoice.subscription) {
              const tierConfig = ECONOMIC_CONFIG.TIERS[wallet.tier];
              if (tierConfig?.tokensPerMonth) {
                creditWallet(wallet.odId, tierConfig.tokensPerMonth, `${wallet.tier} monthly tokens`);
              }
              break;
            }
          }
        }
        break;
      }
    }

    res.json({ received: true });
  } catch (e) {
    console.error('[Economic] Webhook processing error:', e);
    res.status(500).json({ error: e.message });
  }
});

// ---- Universal Marketplace ----
// Supports: DTUs, Lenses, Graphs, Templates, Simulations, Personas, Macros, Datasets, Integrations
const MARKETPLACE_ASSET_TYPES = Object.freeze({
  dtu: { name: 'DTU', icon: 'cube', hasRoyalties: true },
  lens: { name: 'Custom Lens', icon: 'eye', hasRoyalties: false },
  graph: { name: 'Knowledge Graph', icon: 'share2', hasRoyalties: true },
  template: { name: 'Template', icon: 'file-text', hasRoyalties: true },
  simulation: { name: 'Simulation', icon: 'flask', hasRoyalties: true },
  persona: { name: 'AI Persona', icon: 'user', hasRoyalties: false },
  macro: { name: 'Macro/Automation', icon: 'zap', hasRoyalties: false },
  dataset: { name: 'Dataset/Collection', icon: 'database', hasRoyalties: true },
  integration: { name: 'Integration/Plugin', icon: 'plug', hasRoyalties: false },
  theme: { name: 'Theme/Style', icon: 'palette', hasRoyalties: false },
  workflow: { name: 'Workflow', icon: 'git-branch', hasRoyalties: true },
  model: { name: 'ML Model', icon: 'brain', hasRoyalties: true },
});

// List any asset on marketplace
app.post('/api/economic/marketplace/list', (req, res) => {
  try {
    const { odId, assetType, assetId, price, title, description, tags, preview, license } = req.body;

    if (!odId || !assetType || !assetId || !price || !title) {
      return res.status(400).json({ error: 'Missing required fields: odId, assetType, assetId, price, title' });
    }

    if (!MARKETPLACE_ASSET_TYPES[assetType]) {
      return res.status(400).json({
        error: 'Invalid asset type',
        validTypes: Object.keys(MARKETPLACE_ASSET_TYPES),
      });
    }

    // ---- Marketplace Abuse Guards (Category 1: Adversarial) ----
    const priceCheck = _MARKETPLACE_ABUSE.validatePrice(price);
    if (!priceCheck.valid) {
      return res.status(400).json({ error: priceCheck.reason });
    }
    if (!_MARKETPLACE_ABUSE.trackListing(odId)) {
      structuredLog("warn", "marketplace_rate_limit", { sellerId: odId, action: "list" });
      return res.status(429).json({ error: "Listing rate limit exceeded. Try again later." });
    }

    ensureEconomicState();
    const listingId = `listing_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;

    STATE.economic.listings.set(listingId, {
      id: listingId,
      assetType,
      assetId,
      title,
      seller: odId,
      price: Number(price),
      description: description || '',
      tags: tags || [],
      preview: preview || null,
      license: license || 'standard',
      status: 'active',
      createdAt: Date.now(),
      updatedAt: Date.now(),
      sales: 0,
      rating: null,
      reviews: [],
    });

    res.json({
      listingId,
      assetType,
      message: `${MARKETPLACE_ASSET_TYPES[assetType].name} listed successfully`,
    });
  } catch (e) {
    res.status(500).json({ error: e.message });
  }
});

// Update listing
app.patch('/api/economic/marketplace/listing/:listingId', (req, res) => {
  try {
    const { listingId } = req.params;
    const { odId, price, title, description, tags, status } = req.body;

    ensureEconomicState();
    const listing = STATE.economic.listings.get(listingId);

    if (!listing) {
      return res.status(404).json({ error: 'Listing not found' });
    }

    if (listing.seller !== odId) {
      return res.status(403).json({ error: 'Not authorized to edit this listing' });
    }

    if (price !== undefined) listing.price = Number(price);
    if (title !== undefined) listing.title = title;
    if (description !== undefined) listing.description = description;
    if (tags !== undefined) listing.tags = tags;
    if (status !== undefined && ['active', 'paused', 'removed'].includes(status)) {
      listing.status = status;
    }
    listing.updatedAt = Date.now();

    res.json({ listing, message: 'Listing updated' });
  } catch (e) {
    res.status(500).json({ error: e.message });
  }
});

// Buy any asset
app.post('/api/economic/marketplace/buy', (req, res) => {
  try {
    const { odId, listingId, purchaseId: clientPurchaseId } = req.body;
    if (!odId || !listingId) {
      return res.status(400).json({ error: 'Missing required fields' });
    }

    // Deterministic purchaseId for idempotency
    const purchaseId = clientPurchaseId || `epur_${Date.now()}_${Math.random().toString(36).slice(2, 10)}`;
    const refId = `economic_purchase:${purchaseId}`;

    // Idempotency check
    if (db) {
      const existing = checkRefIdProcessed(db, refId);
      if (existing.exists) {
        return res.json({ success: true, idempotent: true, purchaseId, message: 'Purchase already processed' });
      }
    }

    ensureEconomicState();
    const listing = STATE.economic.listings.get(listingId);
    if (!listing || listing.status !== 'active') {
      return res.status(404).json({ error: 'Listing not found or inactive' });
    }

    if (listing.seller === odId) {
      return res.status(400).json({ error: 'Cannot buy your own listing' });
    }

    // ---- Marketplace Abuse Guards (Category 1: Adversarial) ----
    if (!_MARKETPLACE_ABUSE.trackPurchase(odId)) {
      structuredLog("warn", "marketplace_rate_limit", { buyerId: odId, action: "buy" });
      return res.status(429).json({ error: "Purchase rate limit exceeded. Try again later." });
    }
    const washCheck = _MARKETPLACE_ABUSE.checkWashTrade(odId, listing.seller);
    if (washCheck.flagged) {
      structuredLog("warn", "wash_trade_detected", {
        buyerId: odId, sellerId: listing.seller,
        count: washCheck.count, listingId,
      });
      return res.status(403).json({ error: "Transaction flagged for review. Repeated trades between same parties detected." });
    }

    const buyerWallet = getWallet(odId);
    if (buyerWallet.balance < listing.price) {
      return res.status(400).json({ error: 'Insufficient balance' });
    }

    // Calculate splits
    const marketplaceFee = Math.ceil(listing.price * ECONOMIC_CONFIG.MARKETPLACE_FEE);
    const netAmount = listing.price - marketplaceFee;

    const assetConfig = MARKETPLACE_ASSET_TYPES[listing.assetType];
    let creatorAmount, royaltyAmount, treasuryAmount;

    if (assetConfig.hasRoyalties) {
      creatorAmount = Math.floor(netAmount * ECONOMIC_CONFIG.CREATOR_SHARE);
      royaltyAmount = Math.floor(netAmount * ECONOMIC_CONFIG.ROYALTY_SHARE);
      treasuryAmount = netAmount - creatorAmount - royaltyAmount;
    } else {
      // No royalties for this asset type - creator gets full net
      creatorAmount = netAmount;
      royaltyAmount = 0;
      treasuryAmount = 0;
    }

    // Debit buyer
    debitWallet(odId, listing.price, `Purchase: ${listing.title}`, `${refId}:debit`);

    // Credit seller
    creditWallet(listing.seller, creatorAmount, `Sale: ${listing.title}`, `${refId}:credit`);

    // Process royalty wheel (only for DTUs and other reference-able assets)
    if (royaltyAmount > 0 && listing.assetType === 'dtu') {
      processRoyaltyWheel(listing.assetId, royaltyAmount);
    } else if (royaltyAmount > 0) {
      // For non-DTU assets, royalty pool goes to treasury for now
      STATE.economic.treasury += royaltyAmount;
    }

    // Treasury
    STATE.economic.treasury += treasuryAmount + marketplaceFee;

    // Update listing
    listing.sales += 1;

    // Record purchase for buyer (so they can access the asset)
    const purchaseRecord = {
      id: `purchase_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`,
      buyer: odId,
      listingId,
      assetType: listing.assetType,
      assetId: listing.assetId,
      title: listing.title,
      purchasedAt: Date.now(),
    };

    // Store purchases in wallet
    const wallet = getWallet(odId);
    wallet.purchases = wallet.purchases || [];
    wallet.purchases.push(purchaseRecord);

    // Log transaction
    logTransaction({
      type: 'marketplace_sale',
      listingId,
      assetType: listing.assetType,
      assetId: listing.assetId,
      title: listing.title,
      buyer: odId,
      seller: listing.seller,
      price: listing.price,
      creatorAmount,
      royaltyAmount,
      treasuryAmount,
      marketplaceFee,
    });

    // Bridge marketplace fee to economy ledger
    if (db && marketplaceFee > 0) {
      try {
        const now = new Date().toISOString().replace('T', ' ').replace('Z', '');
        db.prepare(`
          INSERT INTO economy_ledger (id, type, from_user_id, to_user_id, amount, fee, net, status, metadata_json, request_id, ip, created_at)
          VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        `).run(
          generateTxId(), 'FEE', null, PLATFORM_ACCOUNT_ID, marketplaceFee, 0, marketplaceFee, 'complete',
          JSON.stringify({ source: 'economic_marketplace', listingId, sourceType: 'MARKETPLACE_PURCHASE', bridged: true }), null, null, now
        );
      } catch (e) {
        console.error('[Economic→Ledger] Fee bridge failed:', e.message);
      }
    }

    res.json({
      success: true,
      purchase: purchaseRecord,
      paid: listing.price,
      breakdown: { creatorAmount, royaltyAmount, treasuryAmount, marketplaceFee },
    });
  } catch (e) {
    res.status(500).json({ error: e.message });
  }
});

// Browse marketplace with filters
app.get('/api/economic/marketplace', (req, res) => {
  ensureEconomicState();

  const { type, search, minPrice, maxPrice, sort, limit = 50, offset = 0 } = req.query;

  let listings = Array.from(STATE.economic.listings.values())
    .filter(l => l.status === 'active');

  // Filter by type
  if (type && type !== 'all') {
    listings = listings.filter(l => l.assetType === type);
  }

  // Search in title/description
  if (search) {
    const searchLower = String(search).toLowerCase();
    listings = listings.filter(l =>
      l.title.toLowerCase().includes(searchLower) ||
      l.description.toLowerCase().includes(searchLower) ||
      (l.tags && l.tags.some(t => t.toLowerCase().includes(searchLower)))
    );
  }

  // Price filters
  if (minPrice) listings = listings.filter(l => l.price >= Number(minPrice));
  if (maxPrice) listings = listings.filter(l => l.price <= Number(maxPrice));

  // Sort
  if (sort === 'price_asc') listings.sort((a, b) => a.price - b.price);
  else if (sort === 'price_desc') listings.sort((a, b) => b.price - a.price);
  else if (sort === 'sales') listings.sort((a, b) => b.sales - a.sales);
  else if (sort === 'oldest') listings.sort((a, b) => a.createdAt - b.createdAt);
  else listings.sort((a, b) => b.createdAt - a.createdAt); // newest first (default)

  const total = listings.length;
  listings = listings.slice(Number(offset), Number(offset) + Number(limit));

  res.json({
    listings,
    total,
    assetTypes: MARKETPLACE_ASSET_TYPES,
    pagination: { limit: Number(limit), offset: Number(offset), hasMore: Number(offset) + listings.length < total },
  });
});

// Get single listing details
app.get('/api/economic/marketplace/listing/:listingId', (req, res) => {
  ensureEconomicState();
  const listing = STATE.economic.listings.get(req.params.listingId);

  if (!listing) {
    return res.status(404).json({ error: 'Listing not found' });
  }

  res.json({ listing, assetTypeInfo: MARKETPLACE_ASSET_TYPES[listing.assetType] });
});

// Get user's purchases
app.get('/api/economic/purchases/:odId', (req, res) => {
  const wallet = getWallet(req.params.odId);
  res.json({ purchases: wallet.purchases || [] });
});

// Get user's listings
app.get('/api/economic/my-listings/:odId', (req, res) => {
  ensureEconomicState();
  const listings = Array.from(STATE.economic.listings.values())
    .filter(l => l.seller === req.params.odId)
    .sort((a, b) => b.createdAt - a.createdAt);
  res.json({ listings });
});

// Add review to listing
app.post('/api/economic/marketplace/review', (req, res) => {
  try {
    const { odId, listingId, rating, comment } = req.body;

    if (!odId || !listingId || !rating) {
      return res.status(400).json({ error: 'Missing required fields' });
    }

    if (rating < 1 || rating > 5) {
      return res.status(400).json({ error: 'Rating must be 1-5' });
    }

    ensureEconomicState();
    const listing = STATE.economic.listings.get(listingId);

    if (!listing) {
      return res.status(404).json({ error: 'Listing not found' });
    }

    // Check if user purchased this
    const wallet = getWallet(odId);
    const hasPurchased = (wallet.purchases || []).some(p => p.listingId === listingId);

    if (!hasPurchased) {
      return res.status(403).json({ error: 'Must purchase to review' });
    }

    // Add review
    listing.reviews = listing.reviews || [];
    listing.reviews.push({
      reviewer: odId,
      rating: Number(rating),
      comment: comment || '',
      createdAt: Date.now(),
    });

    // Update average rating
    const totalRating = listing.reviews.reduce((sum, r) => sum + r.rating, 0);
    listing.rating = totalRating / listing.reviews.length;

    res.json({ message: 'Review added', rating: listing.rating, reviewCount: listing.reviews.length });
  } catch (e) {
    res.status(500).json({ error: e.message });
  }
});

// Get marketplace asset types
app.get('/api/economic/marketplace/types', (req, res) => {
  res.json({ assetTypes: MARKETPLACE_ASSET_TYPES });
});

// ---- Royalty Wheel ----
function processRoyaltyWheel(dtuId, totalRoyalty) {
  if (totalRoyalty <= 0) return;

  // Get DTU and its references
  const dtu = STATE.dtus?.get(dtuId);
  if (!dtu || !dtu.references || dtu.references.length === 0) {
    // No references, royalty goes to treasury
    ensureEconomicState();
    STATE.economic.treasury += totalRoyalty;
    return;
  }

  let remaining = totalRoyalty;
  const decay = ECONOMIC_CONFIG.ROYALTY_DECAY;

  // Process each generation of references
  let currentRefs = [...dtu.references];
  let generation = 0;
  const processed = new Set();

  while (currentRefs.length > 0 && generation < decay.length && remaining > 0) {
    const genShare = decay[generation];
    const genAmount = Math.floor(totalRoyalty * genShare);
    const perRef = Math.floor(genAmount / currentRefs.length);

    const nextRefs = [];

    for (const refId of currentRefs) {
      if (processed.has(refId)) continue;
      processed.add(refId);

      const refDtu = STATE.dtus?.get(refId);
      if (refDtu && refDtu.authorId && perRef > 0) {
        creditWallet(refDtu.authorId, perRef, `Royalty gen${generation + 1}: ${dtuId}`);
        remaining -= perRef;
      }

      // Queue next generation
      if (refDtu?.references) {
        nextRefs.push(...refDtu.references.filter(r => !processed.has(r)));
      }
    }

    currentRefs = nextRefs;
    generation++;
  }

  // Remaining goes to treasury
  if (remaining > 0) {
    ensureEconomicState();
    STATE.economic.treasury += remaining;
  }
}

// ---- Ingest Rate Limiter ----
function checkIngestLimit(odId) {
  ensureEconomicState();
  const wallet = getWallet(odId);
  const tierConfig = ECONOMIC_CONFIG.TIERS[wallet.tier] || ECONOMIC_CONFIG.TIERS.free;

  // Unlimited for paid tiers
  if (tierConfig.ingestLimit === -1) {
    return { allowed: true, remaining: -1, limit: -1 };
  }

  const today = new Date().toISOString().slice(0, 10);
  const tracking = STATE.economic.ingestTracking.get(odId) || { date: today, count: 0 };

  // Reset if new day
  if (tracking.date !== today) {
    tracking.date = today;
    tracking.count = 0;
  }

  const remaining = tierConfig.ingestLimit - tracking.count;
  return {
    allowed: remaining > 0,
    remaining,
    limit: tierConfig.ingestLimit,
    tier: wallet.tier,
  };
}

function recordIngest(odId, pageCount = 1) {
  ensureEconomicState();
  const today = new Date().toISOString().slice(0, 10);
  const tracking = STATE.economic.ingestTracking.get(odId) || { date: today, count: 0 };

  if (tracking.date !== today) {
    tracking.date = today;
    tracking.count = 0;
  }

  tracking.count += pageCount;
  STATE.economic.ingestTracking.set(odId, tracking);
  return tracking;
}

// Ingest limit check endpoint
app.get('/api/economic/ingest-limit/:odId', (req, res) => {
  const result = checkIngestLimit(req.params.odId);
  res.json(result);
});

// Hook into existing ingest endpoint
app.post('/api/economic/ingest-check', (req, res) => {
  const { odId, pageCount = 1 } = req.body;
  if (!odId) return res.status(400).json({ error: 'Missing odId' });

  const limit = checkIngestLimit(odId);
  if (!limit.allowed) {
    return res.status(429).json({
      error: 'Daily ingest limit reached',
      ...limit,
      upgrade: 'Upgrade to Pro for unlimited ingestion',
    });
  }

  recordIngest(odId, pageCount);
  res.json({ allowed: true, remaining: limit.remaining - pageCount });
});

// ---- Economic Status Endpoints ----
app.get('/api/economic/wallet/:odId', (req, res) => {
  const wallet = getWallet(req.params.odId);
  const ingestStatus = checkIngestLimit(req.params.odId);
  res.json({ ...wallet, ingestStatus });
});

app.get('/api/economic/marketplace', (req, res) => {
  ensureEconomicState();
  const listings = Array.from(STATE.economic.listings.values())
    .filter(l => l.status === 'active')
    .sort((a, b) => b.createdAt - a.createdAt)
    .slice(0, 100);
  res.json({ listings, count: listings.length });
});

app.get('/api/economic/config', (req, res) => {
  res.json({
    tiers: ECONOMIC_CONFIG.TIERS,
    tokenPackages: ECONOMIC_CONFIG.TOKEN_PACKAGES,
    fees: {
      tokenPurchase: ECONOMIC_CONFIG.TOKEN_PURCHASE_FEE,
      marketplace: ECONOMIC_CONFIG.MARKETPLACE_FEE,
    },
    splits: {
      creator: ECONOMIC_CONFIG.CREATOR_SHARE,
      royalty: ECONOMIC_CONFIG.ROYALTY_SHARE,
      treasury: ECONOMIC_CONFIG.TREASURY_SHARE,
    },
    stripeEnabled: STRIPE_ENABLED,
  });
});

app.get('/api/economic/stats', (req, res) => {
  ensureEconomicState();
  const wallets = Array.from(STATE.economic.wallets.values());
  res.json({
    totalWallets: wallets.length,
    totalTokensCirculating: wallets.reduce((sum, w) => sum + w.balance, 0),
    treasury: STATE.economic.treasury,
    activeListings: Array.from(STATE.economic.listings.values()).filter(l => l.status === 'active').length,
    totalTransactions: STATE.economic.transactions.length,
    tierBreakdown: {
      free: wallets.filter(w => w.tier === 'free').length,
      pro: wallets.filter(w => w.tier === 'pro').length,
      teams: wallets.filter(w => w.tier === 'teams').length,
    },
  });
});

console.log(`[Economic] Engine initialized | Stripe: ${STRIPE_ENABLED ? 'enabled' : 'disabled'}`);

// ═══════════════════════════════════════════════════════════════════════════════
// END ECONOMIC ENGINE
// ═══════════════════════════════════════════════════════════════════════════════

// ═══════════════════════════════════════════════════════════════════════════════
// REALM SYSTEM: Local vs Global Knowledge Separation
// ═══════════════════════════════════════════════════════════════════════════════

/*
 * REALM PHILOSOPHY:
 * - LOCAL: User's personal DTUs, creative freedom, light council approval
 * - GLOBAL: Shared/public DTUs, requires full council approval to publish
 *
 * Everyone starts with their own unique local experience.
 * Global becomes curated, high-quality shared knowledge.
 * Users must MANUALLY choose to publish to global.
 */

const REALM_TYPES = Object.freeze({
  local: { name: 'Local', description: 'Personal knowledge, creative freedom', councilThreshold: 0.3 },
  global: { name: 'Global', description: 'Shared knowledge, council approved', councilThreshold: 0.7 },
});

// ---- Global DTU Store (separate from local STATE.dtus) ----
function ensureGlobalState() {
  if (!STATE.global) {
    STATE.global = {
      dtus: new Map(),                    // Global DTUs
      pendingPublish: new Map(),          // DTUs awaiting council approval for global
      syncLog: [],                        // Record of syncs
    };
  }
  return STATE.global;
}

// ---- Publish Local DTU to Global (requires council approval) ----
app.post('/api/realm/publish-to-global', (req, res) => {
  try {
    const { odId, dtuId, reason } = req.body;
    if (!odId || !dtuId) {
      return res.status(400).json({ error: 'Missing odId or dtuId' });
    }

    // Get the local DTU
    const localDtu = STATE.dtus.get(dtuId);
    if (!localDtu) {
      return res.status(404).json({ error: 'DTU not found in local' });
    }

    // Check if user owns this DTU
    if (localDtu.authorId && localDtu.authorId !== odId && localDtu.source !== odId) {
      return res.status(403).json({ error: 'Not authorized to publish this DTU' });
    }

    ensureGlobalState();

    // Check if already published or pending
    if (STATE.global.dtus.has(dtuId)) {
      return res.status(400).json({ error: 'DTU already exists in global' });
    }
    if (STATE.global.pendingPublish.has(dtuId)) {
      return res.status(400).json({ error: 'DTU already pending global approval' });
    }

    // Create publish request for council
    const publishRequest = {
      id: `publish_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`,
      dtuId,
      dtu: { ...localDtu },
      requestedBy: odId,
      reason: reason || '',
      status: 'pending',
      votes: {},
      votesFor: 0,
      votesAgainst: 0,
      createdAt: Date.now(),
      threshold: REALM_TYPES.global.councilThreshold,
    };

    STATE.global.pendingPublish.set(dtuId, publishRequest);

    // Auto-approve if DTU already has high council score
    const councilScore = localDtu.authority?.score || 0;
    if (councilScore >= REALM_TYPES.global.councilThreshold) {
      // Auto-approve: copy to global
      const globalDtu = {
        ...localDtu,
        realm: 'global',
        publishedAt: Date.now(),
        publishedBy: odId,
        originalLocalId: dtuId,
        globalId: `global_${dtuId}`,
        syncCount: 0,
      };
      STATE.global.dtus.set(dtuId, globalDtu);
      STATE.global.pendingPublish.delete(dtuId);

      return res.json({
        status: 'approved',
        message: 'DTU auto-approved for global (high council score)',
        globalDtu,
      });
    }

    res.json({
      status: 'pending',
      message: 'DTU submitted for council review',
      publishRequest: { id: publishRequest.id, dtuId, status: 'pending' },
    });
  } catch (e) {
    res.status(500).json({ error: e.message });
  }
});

// ---- Council Vote on Global Publish ----
app.post('/api/realm/vote-publish', requireAuth(), (req, res) => {
  try {
    const { odId, dtuId, vote, reason } = req.body;
    if (!odId || !dtuId || vote === undefined) {
      return res.status(400).json({ error: 'Missing required fields' });
    }

    // Verify voter is the authenticated user or an admin
    const userId = req.user?.id || req.user?.userId;
    const role = req.user?.role || "guest";
    const isAdmin = ["owner", "admin", "founder"].includes(role);
    if (!isAdmin && userId !== odId) {
      return res.status(403).json({ error: 'Can only vote as yourself' });
    }

    ensureGlobalState();
    const request = STATE.global.pendingPublish.get(dtuId);
    if (!request) {
      return res.status(404).json({ error: 'No pending publish request for this DTU' });
    }

    // Record vote
    const voteValue = vote === true || vote === 'yes' || vote === 1;
    request.votes[odId] = { vote: voteValue, reason: reason || '', at: Date.now() };

    // Tally votes
    const votes = Object.values(request.votes);
    request.votesFor = votes.filter(v => v.vote).length;
    request.votesAgainst = votes.filter(v => !v.vote).length;

    const totalVotes = request.votesFor + request.votesAgainst;
    const approvalRatio = totalVotes > 0 ? request.votesFor / totalVotes : 0;

    // Check if threshold met (need at least 3 votes and > threshold approval)
    if (totalVotes >= 3 && approvalRatio >= request.threshold) {
      // Approved: copy to global
      const globalDtu = {
        ...request.dtu,
        realm: 'global',
        publishedAt: Date.now(),
        publishedBy: request.requestedBy,
        originalLocalId: dtuId,
        globalId: `global_${dtuId}`,
        councilApproval: { votesFor: request.votesFor, votesAgainst: request.votesAgainst, ratio: approvalRatio },
        syncCount: 0,
      };
      STATE.global.dtus.set(dtuId, globalDtu);
      STATE.global.pendingPublish.delete(dtuId);

      return res.json({
        status: 'approved',
        message: 'DTU approved for global by council',
        globalDtu,
      });
    }

    // Check if rejected (> 50% against with enough votes)
    if (totalVotes >= 3 && request.votesAgainst > request.votesFor) {
      request.status = 'rejected';
      return res.json({
        status: 'rejected',
        message: 'DTU rejected by council',
        votesFor: request.votesFor,
        votesAgainst: request.votesAgainst,
      });
    }

    res.json({
      status: 'pending',
      votesFor: request.votesFor,
      votesAgainst: request.votesAgainst,
      totalVotes,
      threshold: request.threshold,
      message: `Need ${Math.ceil(request.threshold * 100)}% approval with at least 3 votes`,
    });
  } catch (e) {
    res.status(500).json({ error: e.message });
  }
});

// ---- Sync Single Global DTU to Local ----
app.post('/api/realm/sync', (req, res) => {
  try {
    const { odId, dtuId } = req.body;
    if (!odId || !dtuId) {
      return res.status(400).json({ error: 'Missing odId or dtuId' });
    }

    ensureGlobalState();
    const globalDtu = STATE.global.dtus.get(dtuId);
    if (!globalDtu) {
      return res.status(404).json({ error: 'DTU not found in global' });
    }

    // Check if already in local
    const existingLocal = STATE.dtus.get(dtuId);
    if (existingLocal) {
      return res.json({
        status: 'exists',
        message: 'DTU already exists in your local',
        dtu: existingLocal,
      });
    }

    // Copy to local with citation
    const localCopy = {
      ...globalDtu,
      id: dtuId,
      realm: 'local',
      syncedFrom: 'global',
      syncedAt: Date.now(),
      syncedBy: odId,
      references: [...(globalDtu.references || []), globalDtu.originalLocalId].filter(Boolean),
      meta: {
        ...(globalDtu.meta || {}),
        globalCitation: {
          globalId: globalDtu.globalId,
          publishedBy: globalDtu.publishedBy,
          publishedAt: globalDtu.publishedAt,
        },
      },
    };

    STATE.dtus.set(dtuId, localCopy);

    // Increment sync count on global
    globalDtu.syncCount = (globalDtu.syncCount || 0) + 1;

    // Log sync
    STATE.global.syncLog.push({
      type: 'single',
      dtuId,
      syncedBy: odId,
      at: Date.now(),
    });

    res.json({
      status: 'synced',
      message: 'Global DTU synced to your local with citation',
      dtu: localCopy,
    });
  } catch (e) {
    res.status(500).json({ error: e.message });
  }
});

// ---- Sync All Global DTUs to Local ----
app.post('/api/realm/sync-all', (req, res) => {
  try {
    const { odId } = req.body;
    if (!odId) {
      return res.status(400).json({ error: 'Missing odId' });
    }

    ensureGlobalState();
    const globalDtus = Array.from(STATE.global.dtus.values());

    if (globalDtus.length === 0) {
      return res.json({ synced: 0, skipped: 0, message: 'No global DTUs to sync' });
    }

    let synced = 0;
    let skipped = 0;

    for (const globalDtu of globalDtus) {
      const dtuId = globalDtu.originalLocalId || globalDtu.id;

      // Skip if already exists
      if (STATE.dtus.has(dtuId)) {
        skipped++;
        continue;
      }

      // Copy to local with citation
      const localCopy = {
        ...globalDtu,
        id: dtuId,
        realm: 'local',
        syncedFrom: 'global',
        syncedAt: Date.now(),
        syncedBy: odId,
        references: [...(globalDtu.references || []), globalDtu.originalLocalId].filter(Boolean),
        meta: {
          ...(globalDtu.meta || {}),
          globalCitation: {
            globalId: globalDtu.globalId,
            publishedBy: globalDtu.publishedBy,
            publishedAt: globalDtu.publishedAt,
          },
        },
      };

      STATE.dtus.set(dtuId, localCopy);
      globalDtu.syncCount = (globalDtu.syncCount || 0) + 1;
      synced++;
    }

    // Log sync
    STATE.global.syncLog.push({
      type: 'all',
      syncedBy: odId,
      synced,
      skipped,
      at: Date.now(),
    });

    res.json({
      status: 'completed',
      synced,
      skipped,
      total: globalDtus.length,
      message: `Synced ${synced} global DTUs to local (${skipped} already existed)`,
    });
  } catch (e) {
    res.status(500).json({ error: e.message });
  }
});

// ---- Browse Global DTUs ----
app.get('/api/realm/global', (req, res) => {
  ensureGlobalState();

  const { search, tags, sort, limit = 50, offset = 0 } = req.query;

  let dtus = Array.from(STATE.global.dtus.values());

  // Search filter
  if (search) {
    const searchLower = String(search).toLowerCase();
    dtus = dtus.filter(d =>
      d.title?.toLowerCase().includes(searchLower) ||
      d.human?.summary?.toLowerCase().includes(searchLower) ||
      (d.tags && d.tags.some(t => t.toLowerCase().includes(searchLower)))
    );
  }

  // Tags filter
  if (tags) {
    const tagList = String(tags).split(',').map(t => t.trim().toLowerCase());
    dtus = dtus.filter(d =>
      d.tags && d.tags.some(t => tagList.includes(t.toLowerCase()))
    );
  }

  // Sort
  if (sort === 'popular') dtus.sort((a, b) => (b.syncCount || 0) - (a.syncCount || 0));
  else if (sort === 'oldest') dtus.sort((a, b) => (a.publishedAt || 0) - (b.publishedAt || 0));
  else dtus.sort((a, b) => (b.publishedAt || 0) - (a.publishedAt || 0)); // newest first

  const total = dtus.length;
  dtus = dtus.slice(Number(offset), Number(offset) + Number(limit));

  res.json({
    dtus,
    total,
    pagination: { limit: Number(limit), offset: Number(offset), hasMore: Number(offset) + dtus.length < total },
  });
});

// ---- Get Pending Global Publish Requests ----
app.get('/api/realm/pending', (req, res) => {
  ensureGlobalState();
  const pending = Array.from(STATE.global.pendingPublish.values())
    .filter(p => p.status === 'pending')
    .sort((a, b) => b.createdAt - a.createdAt);

  res.json({ pending, count: pending.length });
});

// ---- Get Local DTUs (filtered to local realm) ----
app.get('/api/realm/local', (req, res) => {
  const { odId, search, limit = 50, offset = 0 } = req.query;

  let dtus = Array.from(STATE.dtus.values());

  // Filter to user's DTUs or all local if no odId
  if (odId) {
    dtus = dtus.filter(d =>
      d.authorId === odId ||
      d.source === odId ||
      d.syncedBy === odId
    );
  }

  // Search
  if (search) {
    const searchLower = String(search).toLowerCase();
    dtus = dtus.filter(d =>
      d.title?.toLowerCase().includes(searchLower) ||
      d.human?.summary?.toLowerCase().includes(searchLower)
    );
  }

  // Sort by newest
  dtus.sort((a, b) => new Date(b.createdAt || 0) - new Date(a.createdAt || 0));

  const total = dtus.length;
  dtus = dtus.slice(Number(offset), Number(offset) + Number(limit));

  res.json({
    dtus,
    total,
    pagination: { limit: Number(limit), offset: Number(offset), hasMore: Number(offset) + dtus.length < total },
  });
});

// ---- Realm Stats ----
app.get('/api/realm/stats', (req, res) => {
  ensureGlobalState();
  res.json({
    local: {
      total: STATE.dtus.size,
    },
    global: {
      total: STATE.global.dtus.size,
      pending: STATE.global.pendingPublish.size,
      totalSyncs: STATE.global.syncLog.length,
    },
    realmTypes: REALM_TYPES,
  });
});

console.log('[Realm] Local/Global separation initialized');

// ═══════════════════════════════════════════════════════════════════════════════
// END REALM SYSTEM
// ═══════════════════════════════════════════════════════════════════════════════

// ═══════════════════════════════════════════════════════════════════════════════
// ARTISTRY GLOBAL: Music Production, Art Creation & Creative Platform
// Phases 1-10: Full DAW, Distribution, Marketplace, Collaboration, AI Coach
// ═══════════════════════════════════════════════════════════════════════════════

/*
 * ARTISTRY PHILOSOPHY:
 * A complete creative production platform built into Concord's cognitive engine.
 * Musicians, producers, and visual artists get first-class tools:
 *
 * Phase 1:  Artistry Global state + Asset schema + Blob storage
 * Phase 2-6: Full DAW (projects, tracks, instruments, effects, vocal, mastering)
 * Phase 7:  Distribution (streaming, feeds, follows, embeds)
 * Phase 8:  Marketplace (beats, stems, samples, art, licensing, splits)
 * Phase 9:  Collaboration (remix mode, project sharing, live sessions)
 * Phase 10: AI production assistant + learning system + genre coach
 */

// ── Phase 1: Artistry Global State + Asset Schema + Blob Storage ────────────

const ARTISTRY_ASSET_TYPES = Object.freeze({
  track: { name: 'Track', extensions: ['.wav', '.mp3', '.flac', '.ogg', '.aac'], maxSizeMb: 500 },
  stem: { name: 'Stem', extensions: ['.wav', '.flac'], maxSizeMb: 200 },
  beat: { name: 'Beat', extensions: ['.wav', '.mp3', '.flac'], maxSizeMb: 300 },
  sample: { name: 'Sample Pack', extensions: ['.zip', '.wav', '.mp3'], maxSizeMb: 1000 },
  preset: { name: 'Preset', extensions: ['.json', '.fxp', '.fxb'], maxSizeMb: 50 },
  midi: { name: 'MIDI', extensions: ['.mid', '.midi'], maxSizeMb: 10 },
  project: { name: 'Project File', extensions: ['.json', '.cproj'], maxSizeMb: 100 },
  artwork: { name: 'Artwork', extensions: ['.png', '.jpg', '.jpeg', '.svg', '.webp'], maxSizeMb: 50 },
  video: { name: 'Video', extensions: ['.mp4', '.webm', '.mov'], maxSizeMb: 2000 },
  lyrics: { name: 'Lyrics', extensions: ['.txt', '.lrc'], maxSizeMb: 1 },
});

const GENRE_TAXONOMY = Object.freeze({
  electronic: { sub: ['house', 'techno', 'trance', 'dubstep', 'dnb', 'ambient', 'idm', 'synthwave', 'edm', 'lo-fi'] },
  hiphop: { sub: ['trap', 'boom-bap', 'drill', 'lo-fi-hiphop', 'conscious', 'experimental', 'phonk', 'cloud-rap'] },
  rock: { sub: ['alternative', 'indie', 'punk', 'metal', 'progressive', 'grunge', 'post-rock', 'shoegaze'] },
  pop: { sub: ['synth-pop', 'indie-pop', 'dream-pop', 'electro-pop', 'art-pop', 'k-pop', 'j-pop'] },
  rnb: { sub: ['neo-soul', 'contemporary', 'alternative-rnb', 'funk', 'soul'] },
  jazz: { sub: ['fusion', 'bebop', 'smooth', 'free-jazz', 'acid-jazz', 'nu-jazz'] },
  classical: { sub: ['orchestral', 'chamber', 'contemporary-classical', 'minimalist', 'film-score'] },
  world: { sub: ['afrobeats', 'latin', 'reggae', 'dancehall', 'bossa-nova', 'flamenco'] },
  experimental: { sub: ['noise', 'glitch', 'generative', 'musique-concrete', 'field-recording'] },
});

const MUSICAL_KEYS = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
const MUSICAL_SCALES = ['major', 'minor', 'dorian', 'mixolydian', 'phrygian', 'lydian', 'locrian', 'pentatonic', 'blues', 'harmonic-minor', 'melodic-minor', 'chromatic'];

function ensureArtistryState() {
  if (!STATE.artistry) {
    STATE.artistry = {
      assets: new Map(),
      blobs: new Map(),
      projects: new Map(),
      instruments: new Map(),
      effects: new Map(),
      presets: new Map(),
      releases: new Map(),
      streams: new Map(),
      feeds: new Map(),
      follows: new Map(),
      embeds: new Map(),
      beatStore: new Map(),
      stemStore: new Map(),
      sampleStore: new Map(),
      artStore: new Map(),
      licenses: new Map(),
      splits: new Map(),
      collabSessions: new Map(),
      remixes: new Map(),
      sharedProjects: new Map(),
      aiSessions: new Map(),
      learningPaths: new Map(),
      genreProfiles: new Map(),
      citationRoyaltyUsage: new Map(),  // citedAssetId → number of times royalties paid
      stats: {
        totalAssets: 0,
        totalProjects: 0,
        totalStreams: 0,
        totalCollabs: 0,
        totalReleases: 0,
        blobStorageBytes: 0,
      },
    };
  }
  // Ensure citationRoyaltyUsage exists even if artistry state was created before this field was added
  if (!STATE.artistry.citationRoyaltyUsage) STATE.artistry.citationRoyaltyUsage = new Map();
  return STATE.artistry;
}

// ── Blob Storage Engine ─────────────────────────────────────────────────────

function generateBlobId() {
  return `blob_${Date.now()}_${Math.random().toString(36).slice(2, 10)}`;
}

function storeBlob(data, mimeType, filename) {
  const art = ensureArtistryState();
  const blobId = generateBlobId();
  const size = typeof data === 'string' ? Math.ceil(data.length * 0.75) : data.length;
  art.blobs.set(blobId, {
    id: blobId, mimeType, filename, size,
    hash: `sha256_${Math.random().toString(36).slice(2, 18)}`,
    createdAt: Date.now(),
    data: typeof data === 'string' ? data : data.toString('base64'),
  });
  art.stats.blobStorageBytes += size;
  return blobId;
}

function getBlob(blobId) {
  const art = ensureArtistryState();
  return art.blobs.get(blobId) || null;
}

// ── Asset Schema & CRUD ─────────────────────────────────────────────────────

function createAsset({ type, title, description, tags, genre, subGenre, bpm, key, scale, duration, ownerId, blobId, metadata }) {
  const art = ensureArtistryState();
  if (!ARTISTRY_ASSET_TYPES[type]) throw new Error(`Invalid asset type: ${type}`);
  const assetId = `asset_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
  const asset = {
    id: assetId, type, title: title || 'Untitled', description: description || '',
    tags: tags || [], genre: genre || null, subGenre: subGenre || null,
    bpm: bpm ? Number(bpm) : null, key: key || null, scale: scale || null,
    duration: duration ? Number(duration) : null, ownerId: ownerId || 'system',
    blobId: blobId || null, metadata: metadata || {}, status: 'active',
    downloads: 0, plays: 0, likes: 0, createdAt: Date.now(), updatedAt: Date.now(),
  };
  art.assets.set(assetId, asset);
  art.stats.totalAssets++;
  return asset;
}

app.post('/api/artistry/assets', (req, res) => {
  try {
    const asset = createAsset(req.body);
    res.json({ ok: true, asset });
  } catch (e) {
    res.status(400).json({ error: e.message });
  }
});

app.get('/api/artistry/assets', (req, res) => {
  const art = ensureArtistryState();
  const { type, genre, search, ownerId, sort, limit = 50, offset = 0 } = req.query;
  let assets = Array.from(art.assets.values()).filter(a => a.status === 'active');
  if (type) assets = assets.filter(a => a.type === type);
  if (genre) assets = assets.filter(a => a.genre === genre || a.subGenre === genre);
  if (ownerId) assets = assets.filter(a => a.ownerId === ownerId);
  if (search) { const s = String(search).toLowerCase(); assets = assets.filter(a => a.title.toLowerCase().includes(s) || a.description.toLowerCase().includes(s) || (a.tags && a.tags.some(t => t.toLowerCase().includes(s)))); }
  if (sort === 'plays') assets.sort((a, b) => b.plays - a.plays);
  else if (sort === 'likes') assets.sort((a, b) => b.likes - a.likes);
  else if (sort === 'oldest') assets.sort((a, b) => a.createdAt - b.createdAt);
  else assets.sort((a, b) => b.createdAt - a.createdAt);
  const total = assets.length;
  assets = assets.slice(Number(offset), Number(offset) + Number(limit));
  res.json({ ok: true, assets, total, pagination: { limit: Number(limit), offset: Number(offset), hasMore: Number(offset) + assets.length < total } });
});

app.get('/api/artistry/assets/:id', (req, res) => {
  const art = ensureArtistryState();
  const asset = art.assets.get(req.params.id);
  if (!asset) return res.status(404).json({ error: 'Asset not found' });
  res.json({ ok: true, asset });
});

app.patch('/api/artistry/assets/:id', (req, res) => {
  const art = ensureArtistryState();
  const asset = art.assets.get(req.params.id);
  if (!asset) return res.status(404).json({ error: 'Asset not found' });
  const allowed = ['title', 'description', 'tags', 'genre', 'subGenre', 'bpm', 'key', 'scale', 'metadata', 'status'];
  for (const k of allowed) { if (req.body[k] !== undefined) asset[k] = req.body[k]; }
  asset.updatedAt = Date.now();
  res.json({ ok: true, asset });
});

app.delete('/api/artistry/assets/:id', (req, res) => {
  const art = ensureArtistryState();
  const asset = art.assets.get(req.params.id);
  if (!asset) return res.status(404).json({ error: 'Asset not found' });
  asset.status = 'deleted';
  asset.updatedAt = Date.now();
  res.json({ ok: true, message: 'Asset deleted' });
});

app.post('/api/artistry/blobs', (req, res) => {
  try {
    const { data, mimeType, filename } = req.body;
    if (!data) return res.status(400).json({ error: 'Missing blob data' });
    const blobId = storeBlob(data, mimeType || 'application/octet-stream', filename || 'upload');
    res.json({ ok: true, blobId });
  } catch (e) {
    res.status(500).json({ error: e.message });
  }
});

app.get('/api/artistry/blobs/:id', (req, res) => {
  const blob = getBlob(req.params.id);
  if (!blob) return res.status(404).json({ error: 'Blob not found' });
  res.json({ ok: true, blob: { id: blob.id, mimeType: blob.mimeType, filename: blob.filename, size: blob.size, hash: blob.hash, createdAt: blob.createdAt } });
});

app.get('/api/artistry/genres', (_req, res) => {
  res.json({ ok: true, genres: GENRE_TAXONOMY, keys: MUSICAL_KEYS, scales: MUSICAL_SCALES });
});

app.get('/api/artistry/asset-types', (_req, res) => {
  res.json({ ok: true, assetTypes: ARTISTRY_ASSET_TYPES });
});

console.log('[Artistry] Phase 1: Asset schema + Blob storage initialized');

// ── Phase 2-6: Full DAW / Studio System ─────────────────────────────────────

const BUILT_IN_INSTRUMENTS = Object.freeze({
  'synth-analog': { name: 'Analog Synth', type: 'synth', category: 'synthesizer', params: ['oscillator', 'filter', 'envelope', 'lfo', 'distortion'] },
  'synth-fm': { name: 'FM Synthesizer', type: 'synth', category: 'synthesizer', params: ['operators', 'ratios', 'envelopes', 'modMatrix'] },
  'synth-wavetable': { name: 'Wavetable Synth', type: 'synth', category: 'synthesizer', params: ['wavetable', 'position', 'warp', 'filter'] },
  'synth-granular': { name: 'Granular Engine', type: 'synth', category: 'synthesizer', params: ['grainSize', 'density', 'position', 'pitch', 'spray'] },
  'sampler': { name: 'Multi-Sampler', type: 'sampler', category: 'sampler', params: ['zones', 'rootNote', 'loopMode', 'envelope', 'filter'] },
  'drum-machine': { name: 'Drum Machine', type: 'drum', category: 'drums', params: ['pads', 'patterns', 'swing', 'velocity', 'tuning'] },
  'piano': { name: 'Grand Piano', type: 'keys', category: 'keys', params: ['model', 'mic', 'damper', 'release', 'brightness'] },
  'electric-piano': { name: 'Electric Piano', type: 'keys', category: 'keys', params: ['model', 'tremolo', 'drive', 'tone'] },
  'organ': { name: 'Tonewheel Organ', type: 'keys', category: 'keys', params: ['drawbars', 'leslie', 'drive', 'percussion'] },
  'bass-synth': { name: 'Bass Synthesizer', type: 'bass', category: 'bass', params: ['waveform', 'subOsc', 'filter', 'drive'] },
  'strings': { name: 'String Ensemble', type: 'strings', category: 'orchestral', params: ['section', 'articulation', 'vibrato', 'expression'] },
  'brass': { name: 'Brass Section', type: 'brass', category: 'orchestral', params: ['section', 'articulation', 'mute', 'dynamics'] },
  'woodwinds': { name: 'Woodwind Section', type: 'woodwinds', category: 'orchestral', params: ['instrument', 'articulation', 'vibrato', 'breath'] },
  'choir': { name: 'Vocal Choir', type: 'vocal', category: 'vocal', params: ['vowel', 'section', 'vibrato', 'expression'] },
  'guitar-acoustic': { name: 'Acoustic Guitar', type: 'guitar', category: 'guitar', params: ['body', 'position', 'strings', 'technique'] },
  'guitar-electric': { name: 'Electric Guitar', type: 'guitar', category: 'guitar', params: ['pickup', 'amp', 'cabinet', 'effects'] },
});

const BUILT_IN_EFFECTS = Object.freeze({
  'eq-parametric': { name: 'Parametric EQ', category: 'eq', params: ['bands', 'frequency', 'gain', 'q', 'type'] },
  'eq-graphic': { name: 'Graphic EQ', category: 'eq', params: ['bands', 'gain'] },
  'compressor': { name: 'Compressor', category: 'dynamics', params: ['threshold', 'ratio', 'attack', 'release', 'knee', 'makeup'] },
  'limiter': { name: 'Brickwall Limiter', category: 'dynamics', params: ['ceiling', 'release', 'lookahead'] },
  'gate': { name: 'Noise Gate', category: 'dynamics', params: ['threshold', 'attack', 'hold', 'release', 'range'] },
  'de-esser': { name: 'De-Esser', category: 'dynamics', params: ['frequency', 'threshold', 'range', 'mode'] },
  'reverb-hall': { name: 'Hall Reverb', category: 'reverb', params: ['size', 'decay', 'damping', 'predelay', 'mix'] },
  'reverb-plate': { name: 'Plate Reverb', category: 'reverb', params: ['decay', 'damping', 'predelay', 'mix'] },
  'reverb-room': { name: 'Room Reverb', category: 'reverb', params: ['size', 'decay', 'earlyReflections', 'mix'] },
  'delay-stereo': { name: 'Stereo Delay', category: 'delay', params: ['timeL', 'timeR', 'feedback', 'filter', 'mix'] },
  'delay-ping-pong': { name: 'Ping Pong Delay', category: 'delay', params: ['time', 'feedback', 'spread', 'mix'] },
  'chorus': { name: 'Chorus', category: 'modulation', params: ['rate', 'depth', 'voices', 'mix'] },
  'flanger': { name: 'Flanger', category: 'modulation', params: ['rate', 'depth', 'feedback', 'mix'] },
  'phaser': { name: 'Phaser', category: 'modulation', params: ['rate', 'depth', 'stages', 'feedback', 'mix'] },
  'distortion': { name: 'Distortion', category: 'distortion', params: ['drive', 'tone', 'mix', 'type'] },
  'saturator': { name: 'Saturator', category: 'distortion', params: ['drive', 'curve', 'color', 'mix'] },
  'bitcrusher': { name: 'Bitcrusher', category: 'distortion', params: ['bits', 'sampleRate', 'mix'] },
  'filter-auto': { name: 'Auto Filter', category: 'filter', params: ['frequency', 'resonance', 'lfoRate', 'lfoDepth', 'type'] },
  'vocoder': { name: 'Vocoder', category: 'vocal', params: ['bands', 'carrier', 'release', 'formant', 'mix'] },
  'pitch-shift': { name: 'Pitch Shifter', category: 'pitch', params: ['semitones', 'cents', 'formant', 'mix'] },
  'auto-tune': { name: 'Auto-Tune', category: 'pitch', params: ['key', 'scale', 'speed', 'humanize', 'mix'] },
  'stereo-imager': { name: 'Stereo Imager', category: 'imaging', params: ['width', 'midSide', 'frequency'] },
  'multiband-comp': { name: 'Multiband Compressor', category: 'dynamics', params: ['bands', 'crossovers', 'threshold', 'ratio'] },
});

const MASTERING_CHAIN_TEMPLATE = [
  { effect: 'eq-parametric', label: 'Pre-EQ' },
  { effect: 'multiband-comp', label: 'Multiband Compression' },
  { effect: 'saturator', label: 'Harmonic Saturation' },
  { effect: 'stereo-imager', label: 'Stereo Width' },
  { effect: 'eq-parametric', label: 'Post-EQ' },
  { effect: 'limiter', label: 'Final Limiter' },
];

app.post('/api/artistry/studio/projects', (req, res) => {
  try {
    const art = ensureArtistryState();
    const { title, bpm, timeSignature, key, scale, genre, ownerId } = req.body;
    const projectId = `proj_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
    const project = {
      id: projectId, title: title || 'Untitled Project', ownerId: ownerId || 'anon',
      bpm: bpm || 120, timeSignature: timeSignature || '4/4', key: key || 'C', scale: scale || 'major',
      genre: genre || null, sampleRate: 44100, bitDepth: 24,
      tracks: [],
      masterBus: {
        volume: 0, pan: 0,
        effects: MASTERING_CHAIN_TEMPLATE.map((t, i) => ({ id: `fx_master_${i}`, ...t, enabled: true, params: {} })),
        metering: { peak: -Infinity, rms: -60, lufs: -14 },
      },
      arrangement: {
        length: 64, loopStart: 0, loopEnd: 16, loopEnabled: false, markers: [],
        sections: [{ id: 'intro', name: 'Intro', start: 0, end: 8, color: '#7c3aed' }],
      },
      mixer: { soloMode: false, soloedTracks: [], sends: [], groups: [] },
      playhead: 0, isPlaying: false, isRecording: false, status: 'active',
      collaborators: [], version: 1, createdAt: Date.now(), updatedAt: Date.now(),
    };
    art.projects.set(projectId, project);
    art.stats.totalProjects++;
    res.json({ ok: true, project });
  } catch (e) {
    res.status(500).json({ error: e.message });
  }
});

app.get('/api/artistry/studio/projects', (req, res) => {
  const art = ensureArtistryState();
  const { ownerId } = req.query;
  let projects = Array.from(art.projects.values()).filter(p => p.status === 'active');
  if (ownerId) projects = projects.filter(p => p.ownerId === ownerId || p.collaborators.includes(ownerId));
  projects.sort((a, b) => b.updatedAt - a.updatedAt);
  res.json({ ok: true, projects: projects.map(p => ({ id: p.id, title: p.title, bpm: p.bpm, key: p.key, genre: p.genre, trackCount: p.tracks.length, updatedAt: p.updatedAt, createdAt: p.createdAt })) });
});

app.get('/api/artistry/studio/projects/:id', (req, res) => {
  const art = ensureArtistryState();
  const project = art.projects.get(req.params.id);
  if (!project) return res.status(404).json({ error: 'Project not found' });
  res.json({ ok: true, project });
});

app.patch('/api/artistry/studio/projects/:id', (req, res) => {
  const art = ensureArtistryState();
  const project = art.projects.get(req.params.id);
  if (!project) return res.status(404).json({ error: 'Project not found' });
  const allowed = ['title', 'bpm', 'timeSignature', 'key', 'scale', 'genre', 'sampleRate', 'bitDepth', 'arrangement', 'mixer', 'masterBus'];
  for (const k of allowed) { if (req.body[k] !== undefined) project[k] = req.body[k]; }
  project.version++;
  project.updatedAt = Date.now();
  res.json({ ok: true, project });
});

app.post('/api/artistry/studio/projects/:id/tracks', (req, res) => {
  const art = ensureArtistryState();
  const project = art.projects.get(req.params.id);
  if (!project) return res.status(404).json({ error: 'Project not found' });
  const { name, type, instrumentId, color } = req.body;
  const trackId = `trk_${Date.now()}_${Math.random().toString(36).slice(2, 6)}`;
  const instrument = instrumentId ? BUILT_IN_INSTRUMENTS[instrumentId] : null;
  const track = {
    id: trackId, name: name || (instrument ? instrument.name : `Track ${project.tracks.length + 1}`),
    type: type || 'audio', instrumentId: instrumentId || null,
    color: color || `hsl(${Math.random() * 360}, 70%, 50%)`,
    volume: 0, pan: 0, mute: false, solo: false, armed: false,
    effects: [], clips: [], automation: [], sends: [],
    input: { source: 'none', channel: 0 }, output: { destination: 'master', channel: 0 },
  };
  project.tracks.push(track);
  project.updatedAt = Date.now();
  project.version++;
  res.json({ ok: true, track });
});

app.patch('/api/artistry/studio/projects/:projectId/tracks/:trackId', (req, res) => {
  const art = ensureArtistryState();
  const project = art.projects.get(req.params.projectId);
  if (!project) return res.status(404).json({ error: 'Project not found' });
  const track = project.tracks.find(t => t.id === req.params.trackId);
  if (!track) return res.status(404).json({ error: 'Track not found' });
  const allowed = ['name', 'volume', 'pan', 'mute', 'solo', 'armed', 'effects', 'clips', 'automation', 'sends', 'color', 'instrumentId', 'input', 'output'];
  for (const k of allowed) { if (req.body[k] !== undefined) track[k] = req.body[k]; }
  project.updatedAt = Date.now();
  project.version++;
  res.json({ ok: true, track });
});

app.delete('/api/artistry/studio/projects/:projectId/tracks/:trackId', (req, res) => {
  const art = ensureArtistryState();
  const project = art.projects.get(req.params.projectId);
  if (!project) return res.status(404).json({ error: 'Project not found' });
  project.tracks = project.tracks.filter(t => t.id !== req.params.trackId);
  project.updatedAt = Date.now();
  project.version++;
  res.json({ ok: true, message: 'Track removed' });
});

app.post('/api/artistry/studio/projects/:projectId/tracks/:trackId/effects', (req, res) => {
  const art = ensureArtistryState();
  const project = art.projects.get(req.params.projectId);
  if (!project) return res.status(404).json({ error: 'Project not found' });
  const track = project.tracks.find(t => t.id === req.params.trackId);
  if (!track) return res.status(404).json({ error: 'Track not found' });
  const { effectId, params } = req.body;
  const effectDef = BUILT_IN_EFFECTS[effectId];
  if (!effectDef) return res.status(400).json({ error: 'Unknown effect', available: Object.keys(BUILT_IN_EFFECTS) });
  const fxInstance = {
    id: `fx_${Date.now()}_${Math.random().toString(36).slice(2, 6)}`,
    effectId, name: effectDef.name, category: effectDef.category, enabled: true, params: params || {}, mix: 1.0,
  };
  track.effects.push(fxInstance);
  project.updatedAt = Date.now();
  project.version++;
  res.json({ ok: true, effect: fxInstance });
});

app.post('/api/artistry/studio/projects/:projectId/tracks/:trackId/clips', (req, res) => {
  const art = ensureArtistryState();
  const project = art.projects.get(req.params.projectId);
  if (!project) return res.status(404).json({ error: 'Project not found' });
  const track = project.tracks.find(t => t.id === req.params.trackId);
  if (!track) return res.status(404).json({ error: 'Track not found' });
  const { name, startBar, lengthBars, assetId, midiNotes, automation } = req.body;
  const clip = {
    id: `clip_${Date.now()}_${Math.random().toString(36).slice(2, 6)}`,
    name: name || `Clip ${track.clips.length + 1}`, startBar: startBar || 0, lengthBars: lengthBars || 4,
    assetId: assetId || null, midiNotes: midiNotes || [], automation: automation || [],
    gain: 0, fadeIn: 0, fadeOut: 0, color: track.color,
  };
  track.clips.push(clip);
  project.updatedAt = Date.now();
  project.version++;
  res.json({ ok: true, clip });
});

app.get('/api/artistry/studio/instruments', (_req, res) => {
  res.json({ ok: true, instruments: BUILT_IN_INSTRUMENTS });
});

app.get('/api/artistry/studio/effects', (_req, res) => {
  res.json({ ok: true, effects: BUILT_IN_EFFECTS });
});

app.post('/api/artistry/studio/vocal/analyze', (req, res) => {
  const { projectId, trackId } = req.body;
  if (!projectId || !trackId) return res.status(400).json({ ok: false, error: 'projectId and trackId are required' });
  const art = ensureArtistryState();
  const project = art.projects.get(projectId);
  if (!project) return res.status(404).json({ ok: false, error: 'Project not found' });
  const track = (project.tracks || []).find(t => t.id === trackId);
  if (!track) return res.status(404).json({ ok: false, error: 'Track not found' });
  if (!track.clips || track.clips.length === 0) {
    return res.status(422).json({ ok: false, error: 'Track has no audio clips to analyze. Record or import audio first.' });
  }
  res.status(501).json({ ok: false, error: 'Vocal analysis requires an audio processing engine (not yet configured). Connect an audio DSP service to enable this feature.' });
});

app.post('/api/artistry/studio/vocal/process', (req, res) => {
  const { projectId, trackId } = req.body;
  if (!projectId || !trackId) return res.status(400).json({ ok: false, error: 'projectId and trackId are required' });
  const art = ensureArtistryState();
  const project = art.projects.get(projectId);
  if (!project) return res.status(404).json({ ok: false, error: 'Project not found' });
  const track = (project.tracks || []).find(t => t.id === trackId);
  if (!track) return res.status(404).json({ ok: false, error: 'Track not found' });
  if (!track.clips || track.clips.length === 0) {
    return res.status(422).json({ ok: false, error: 'Track has no audio clips to process. Record or import audio first.' });
  }
  res.status(501).json({ ok: false, error: 'Vocal processing requires an audio DSP engine (not yet configured). Connect an audio DSP service to enable this feature.' });
});

app.post('/api/artistry/studio/master', (req, res) => {
  const art = ensureArtistryState();
  const { projectId, preset, targetLufs, format } = req.body;
  const project = art.projects.get(projectId);
  if (!project) return res.status(404).json({ ok: false, error: 'Project not found' });
  if (!project.tracks || project.tracks.length === 0) {
    return res.status(422).json({ ok: false, error: 'Project has no tracks to master. Add tracks with audio clips first.' });
  }
  res.status(501).json({
    ok: false,
    error: 'Mastering requires an audio DSP engine (not yet configured). Connect an audio DSP service to enable this feature.',
    project: {
      projectId,
      preset: preset || 'balanced',
      targetLufs: targetLufs || -14,
      format: format || 'wav',
      chain: project.masterBus.effects.map(fx => fx.label || fx.effect),
      trackCount: project.tracks.length,
    },
  });
});

console.log('[Artistry] Phase 2-6: Full DAW / Studio system initialized');

// ── Phase 7: Distribution Platform ──────────────────────────────────────────

app.post('/api/artistry/distribution/releases', (req, res) => {
  const art = ensureArtistryState();
  const { title, artistName, trackIds, artworkAssetId, genre, releaseDate, description, ownerId } = req.body;
  const releaseId = `rel_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
  const release = {
    id: releaseId, title: title || 'Untitled Release', artistName: artistName || 'Unknown Artist',
    trackIds: trackIds || [], artworkAssetId: artworkAssetId || null, genre: genre || null,
    type: (trackIds || []).length === 1 ? 'single' : (trackIds || []).length <= 6 ? 'ep' : 'album',
    description: description || '', ownerId: ownerId || 'anon',
    releaseDate: releaseDate || new Date().toISOString(), status: 'published',
    totalStreams: 0, totalDownloads: 0, totalLikes: 0, embedEnabled: true,
    createdAt: Date.now(), updatedAt: Date.now(),
  };
  art.releases.set(releaseId, release);
  art.stats.totalReleases++;
  res.json({ ok: true, release });
});

app.get('/api/artistry/distribution/releases', (req, res) => {
  const art = ensureArtistryState();
  const { ownerId, genre, search, sort, limit = 50, offset = 0 } = req.query;
  let releases = Array.from(art.releases.values());
  if (ownerId) releases = releases.filter(r => r.ownerId === ownerId);
  if (genre) releases = releases.filter(r => r.genre === genre);
  if (search) { const s = String(search).toLowerCase(); releases = releases.filter(r => r.title.toLowerCase().includes(s) || r.artistName.toLowerCase().includes(s)); }
  if (sort === 'streams') releases.sort((a, b) => b.totalStreams - a.totalStreams);
  else if (sort === 'likes') releases.sort((a, b) => b.totalLikes - a.totalLikes);
  else releases.sort((a, b) => b.createdAt - a.createdAt);
  const total = releases.length;
  releases = releases.slice(Number(offset), Number(offset) + Number(limit));
  res.json({ ok: true, releases, total });
});

app.get('/api/artistry/distribution/releases/:id', (req, res) => {
  const art = ensureArtistryState();
  const release = art.releases.get(req.params.id);
  if (!release) return res.status(404).json({ error: 'Release not found' });
  res.json({ ok: true, release });
});

app.post('/api/artistry/distribution/stream', (req, res) => {
  const art = ensureArtistryState();
  const { assetId, userId, duration } = req.body;
  if (!assetId) return res.status(400).json({ error: 'Missing assetId' });
  const streamData = art.streams.get(assetId) || { assetId, totalPlays: 0, uniqueListeners: new Set(), totalDuration: 0, history: [] };
  streamData.totalPlays++;
  streamData.totalDuration += (duration || 0);
  if (userId) streamData.uniqueListeners.add(userId);
  streamData.history.push({ userId: userId || 'anon', at: Date.now(), duration: duration || 0 });
  if (streamData.history.length > 1000) streamData.history = streamData.history.slice(-1000);
  art.streams.set(assetId, streamData);
  art.stats.totalStreams++;
  const asset = art.assets.get(assetId);
  if (asset) asset.plays++;
  res.json({ ok: true, totalPlays: streamData.totalPlays, uniqueListeners: streamData.uniqueListeners.size });
});

app.get('/api/artistry/distribution/streams/:assetId', (req, res) => {
  const art = ensureArtistryState();
  const streamData = art.streams.get(req.params.assetId);
  if (!streamData) return res.json({ ok: true, totalPlays: 0, uniqueListeners: 0 });
  res.json({ ok: true, totalPlays: streamData.totalPlays, uniqueListeners: streamData.uniqueListeners.size, totalDuration: streamData.totalDuration });
});

app.post('/api/artistry/distribution/follow', (req, res) => {
  const art = ensureArtistryState();
  const { followerId, followedId } = req.body;
  if (!followerId || !followedId) return res.status(400).json({ error: 'Missing followerId or followedId' });
  if (!art.follows.has(followerId)) art.follows.set(followerId, new Set());
  art.follows.get(followerId).add(followedId);
  res.json({ ok: true, following: true });
});

app.post('/api/artistry/distribution/unfollow', (req, res) => {
  const art = ensureArtistryState();
  const { followerId, followedId } = req.body;
  if (art.follows.has(followerId)) art.follows.get(followerId).delete(followedId);
  res.json({ ok: true, following: false });
});

app.get('/api/artistry/distribution/followers/:userId', (req, res) => {
  const art = ensureArtistryState();
  const followers = [];
  for (const [uid, followSet] of art.follows) {
    if (followSet.has(req.params.userId)) followers.push(uid);
  }
  res.json({ ok: true, followers, count: followers.length });
});

app.get('/api/artistry/distribution/following/:userId', (req, res) => {
  const art = ensureArtistryState();
  const following = art.follows.has(req.params.userId) ? Array.from(art.follows.get(req.params.userId)) : [];
  res.json({ ok: true, following, count: following.length });
});

app.get('/api/artistry/distribution/feed/:userId', (req, res) => {
  const art = ensureArtistryState();
  const following = art.follows.has(req.params.userId) ? art.follows.get(req.params.userId) : new Set();
  let feedItems = [];
  for (const release of art.releases.values()) {
    if (following.has(release.ownerId) || release.ownerId === req.params.userId) {
      feedItems.push({ type: 'release', data: release, at: release.createdAt });
    }
  }
  feedItems.sort((a, b) => b.at - a.at);
  feedItems = feedItems.slice(0, 50);
  res.json({ ok: true, feed: feedItems, count: feedItems.length });
});

app.post('/api/artistry/distribution/embeds', (req, res) => {
  const art = ensureArtistryState();
  const { assetId, releaseId, style, width, height } = req.body;
  const embedId = `embed_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
  const embed = {
    id: embedId, assetId: assetId || null, releaseId: releaseId || null,
    style: style || 'compact', width: width || 400, height: height || 120,
    html: `<iframe src="/embed/${embedId}" width="${width || 400}" height="${height || 120}" frameborder="0" allow="autoplay; encrypted-media"></iframe>`,
    createdAt: Date.now(),
  };
  art.embeds.set(embedId, embed);
  res.json({ ok: true, embed });
});

app.get('/api/artistry/distribution/embeds/:id', (req, res) => {
  const art = ensureArtistryState();
  const embed = art.embeds.get(req.params.id);
  if (!embed) return res.status(404).json({ error: 'Embed not found' });
  res.json({ ok: true, embed });
});

console.log('[Artistry] Phase 7: Distribution platform initialized');

// ── Phase 8: Marketplace Expansion ──────────────────────────────────────────

const LICENSE_TYPES = Object.freeze({
  'basic': { name: 'Basic License', streams: 50000, copies: 2500, musicVideos: 1, broadcasting: false, price: 30 },
  'premium': { name: 'Premium License', streams: 500000, copies: 25000, musicVideos: 1, broadcasting: true, price: 100 },
  'unlimited': { name: 'Unlimited License', streams: -1, copies: -1, musicVideos: -1, broadcasting: true, price: 300 },
  'exclusive': { name: 'Exclusive Rights', streams: -1, copies: -1, musicVideos: -1, broadcasting: true, price: 1000 },
  'free': { name: 'Free (CC-BY)', streams: -1, copies: -1, musicVideos: -1, broadcasting: true, price: 0 },
});

// GET /api/artistry/marketplace/art — list artwork assets for the art lens marketplace tab
app.get('/api/artistry/marketplace/art', (req, res) => {
  const art = ensureArtistryState();
  const artworks = Array.from(art.assets.values())
    .filter(a => a.status === 'active' && (a.type === 'artwork' || a.type === 'visual' || a.type === 'cover_art'))
    .sort((a, b) => (b.createdAt || 0) - (a.createdAt || 0))
    .slice(0, Number(req.query.limit) || 50);
  res.json({ ok: true, artworks });
});

app.post('/api/artistry/marketplace/beats', (req, res) => {
  try {
    const art = ensureArtistryState();
    const { title, assetId, bpm, key, genre, tags, licenses, ownerId, previewAssetId } = req.body;
    if (!ownerId) return res.status(400).json({ error: 'Missing ownerId' });
    const listingId = `beat_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
    const listing = {
      id: listingId, type: 'beat', title: title || 'Untitled Beat', assetId,
      previewAssetId: previewAssetId || null, bpm: bpm || 120, key: key || null,
      genre: genre || null, tags: tags || [], ownerId: ownerId || 'anon',
      licenses: (licenses || ['basic', 'premium']).reduce((acc, lt) => {
        if (LICENSE_TYPES[lt]) acc[lt] = { ...LICENSE_TYPES[lt], available: true };
        return acc;
      }, {}),
      status: 'active', totalSales: 0, totalPlays: 0, rating: null, reviews: [],
      createdAt: Date.now(), updatedAt: Date.now(),
    };
    art.beatStore.set(listingId, listing);
    res.json({ ok: true, listing });
  } catch (err) {
    console.error('[Artistry] Beat listing error:', err.message);
    res.status(500).json({ error: 'listing_failed', detail: err.message });
  }
});

app.get('/api/artistry/marketplace/beats', (req, res) => {
  const art = ensureArtistryState();
  const { genre, bpmMin, bpmMax, key, search, sort, limit = 50, offset = 0 } = req.query;
  let beats = Array.from(art.beatStore.values()).filter(b => b.status === 'active');
  if (genre) beats = beats.filter(b => b.genre === genre);
  if (bpmMin) beats = beats.filter(b => b.bpm >= Number(bpmMin));
  if (bpmMax) beats = beats.filter(b => b.bpm <= Number(bpmMax));
  if (key) beats = beats.filter(b => b.key === key);
  if (search) { const s = String(search).toLowerCase(); beats = beats.filter(b => b.title.toLowerCase().includes(s) || (b.tags && b.tags.some(t => t.toLowerCase().includes(s)))); }
  if (sort === 'popular') beats.sort((a, b) => b.totalSales - a.totalSales);
  else if (sort === 'plays') beats.sort((a, b) => b.totalPlays - a.totalPlays);
  else beats.sort((a, b) => b.createdAt - a.createdAt);
  const total = beats.length;
  beats = beats.slice(Number(offset), Number(offset) + Number(limit));
  res.json({ ok: true, beats, total });
});

app.post('/api/artistry/marketplace/stems', (req, res) => {
  try {
    const art = ensureArtistryState();
    const { title, assetIds, parentTrackId, genre, tags, price, ownerId } = req.body;
    if (!ownerId) return res.status(400).json({ error: 'Missing ownerId' });
    if (price != null && (typeof price !== 'number' || price < 0)) return res.status(400).json({ error: 'Invalid price' });
    const listingId = `stem_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
    art.stemStore.set(listingId, {
      id: listingId, type: 'stems', title: title || 'Untitled Stems', assetIds: assetIds || [],
      parentTrackId: parentTrackId || null, genre: genre || null, tags: tags || [],
      price: price || 50, ownerId: ownerId || 'anon', status: 'active', totalSales: 0,
      createdAt: Date.now(), updatedAt: Date.now(),
    });
    res.json({ ok: true, listing: art.stemStore.get(listingId) });
  } catch (err) {
    console.error('[Artistry] Stem listing error:', err.message);
    res.status(500).json({ error: 'listing_failed', detail: err.message });
  }
});

app.get('/api/artistry/marketplace/stems', (req, res) => {
  const art = ensureArtistryState();
  const stems = Array.from(art.stemStore.values()).filter(s => s.status === 'active').sort((a, b) => b.createdAt - a.createdAt);
  res.json({ ok: true, stems, total: stems.length });
});

app.post('/api/artistry/marketplace/samples', (req, res) => {
  try {
    const art = ensureArtistryState();
    const { title, assetIds, sampleCount, genre, tags, price, description, ownerId } = req.body;
    if (!ownerId) return res.status(400).json({ error: 'Missing ownerId' });
    if (price != null && (typeof price !== 'number' || price < 0)) return res.status(400).json({ error: 'Invalid price' });
    const listingId = `samp_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
    art.sampleStore.set(listingId, {
      id: listingId, type: 'sample-pack', title: title || 'Untitled Sample Pack', assetIds: assetIds || [],
      sampleCount: sampleCount || 0, genre: genre || null, tags: tags || [], price: price || 25,
      description: description || '', ownerId: ownerId || 'anon', status: 'active',
      totalSales: 0, totalDownloads: 0, createdAt: Date.now(), updatedAt: Date.now(),
    });
    res.json({ ok: true, listing: art.sampleStore.get(listingId) });
  } catch (err) {
    console.error('[Artistry] Sample listing error:', err.message);
    res.status(500).json({ error: 'listing_failed', detail: err.message });
  }
});

app.get('/api/artistry/marketplace/samples', (req, res) => {
  const art = ensureArtistryState();
  const samples = Array.from(art.sampleStore.values()).filter(s => s.status === 'active').sort((a, b) => b.createdAt - a.createdAt);
  res.json({ ok: true, samples, total: samples.length });
});

app.post('/api/artistry/marketplace/art', (req, res) => {
  try {
    const art = ensureArtistryState();
    const { title, assetId, artType, style, tags, price, description, ownerId, dimensions } = req.body;
    if (!ownerId) return res.status(400).json({ error: 'Missing ownerId' });
    if (price != null && (typeof price !== 'number' || price < 0)) return res.status(400).json({ error: 'Invalid price' });
    const listingId = `art_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
    art.artStore.set(listingId, {
      id: listingId, type: 'artwork', title: title || 'Untitled Artwork', assetId,
      artType: artType || 'cover-art', style: style || 'digital', tags: tags || [],
      price: price || 50, description: description || '', dimensions: dimensions || null,
      ownerId: ownerId || 'anon', status: 'active', totalSales: 0,
      createdAt: Date.now(), updatedAt: Date.now(),
    });
    res.json({ ok: true, listing: art.artStore.get(listingId) });
  } catch (err) {
    console.error('[Artistry] Art listing error:', err.message);
    res.status(500).json({ error: 'listing_failed', detail: err.message });
  }
});

app.get('/api/artistry/marketplace/art', (req, res) => {
  const art = ensureArtistryState();
  const artworks = Array.from(art.artStore.values()).filter(a => a.status === 'active').sort((a, b) => b.createdAt - a.createdAt);
  res.json({ ok: true, artworks, total: artworks.length });
});

app.post('/api/artistry/marketplace/splits', (req, res) => {
  const art = ensureArtistryState();
  const { assetId, releaseId, participants } = req.body;
  if (!participants || !Array.isArray(participants)) return res.status(400).json({ error: 'Missing participants array' });
  const totalPct = participants.reduce((s, p) => s + (p.percentage || 0), 0);
  if (Math.abs(totalPct - 100) > 0.01) return res.status(400).json({ error: `Split percentages must total 100%, got ${totalPct}%` });
  const splitId = `split_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
  art.splits.set(splitId, {
    id: splitId, assetId: assetId || null, releaseId: releaseId || null,
    participants: participants.map(p => ({ userId: p.userId, name: p.name || '', role: p.role || 'contributor', percentage: p.percentage })),
    status: 'active', totalDistributed: 0, createdAt: Date.now(),
  });
  res.json({ ok: true, split: art.splits.get(splitId) });
});

app.get('/api/artistry/marketplace/splits/:id', (req, res) => {
  const art = ensureArtistryState();
  const split = art.splits.get(req.params.id);
  if (!split) return res.status(404).json({ error: 'Split not found' });
  res.json({ ok: true, split });
});

app.get('/api/artistry/marketplace/licenses', (_req, res) => {
  res.json({ ok: true, licenseTypes: LICENSE_TYPES });
});

// ── Citation Royalty Constants ───────────────────────────────────────────────
const CITATION_ROYALTY_BASE_RATE = 0.30;    // 30% initial royalty for cited creators
const CITATION_ROYALTY_DECAY = 0.85;        // Decay factor per usage
const CITATION_ROYALTY_MIN_RATE = 0.00001;  // 0.001% minimum royalty rate

/**
 * Resolve all citation references for an asset.
 * Checks both Concord Global (DTU references + social citations) and
 * Artistry Global (asset cross-references).
 * Returns array of { citedId, creatorId, source }.
 */
function resolveAssetCitations(listingAssetId) {
  const citations = [];
  const seen = new Set();

  // 1. Concord Global — DTU references
  const dtu = STATE.dtus?.get(listingAssetId);
  if (dtu?.references?.length > 0) {
    for (const refId of dtu.references) {
      if (seen.has(refId)) continue;
      const refDtu = STATE.dtus?.get(refId);
      if (refDtu?.authorId) {
        citations.push({ citedId: refId, creatorId: refDtu.authorId, source: 'concord_global' });
        seen.add(refId);
      }
    }
  }

  // 2. Concord Global — Social layer cited-by (reverse: what does THIS asset cite?)
  const social = STATE.social;
  if (social?.citedBy) {
    for (const [citedId, citers] of social.citedBy.entries()) {
      if (seen.has(citedId)) continue;
      if (citers.has(listingAssetId)) {
        const citedDtu = STATE.dtus?.get(citedId);
        if (citedDtu?.authorId) {
          citations.push({ citedId, creatorId: citedDtu.authorId, source: 'concord_global' });
          seen.add(citedId);
        }
      }
    }
  }

  // 3. Artistry Global — asset cross-references
  const art = ensureArtistryState();
  const thisAsset = art.assets?.get(listingAssetId);
  if (thisAsset?.references?.length > 0) {
    for (const refId of thisAsset.references) {
      if (seen.has(refId)) continue;
      const refAsset = art.assets.get(refId);
      if (refAsset?.ownerId) {
        citations.push({ citedId: refId, creatorId: refAsset.ownerId, source: 'artistry_global' });
        seen.add(refId);
      }
    }
  }

  // 4. Artistry Global — check remix lineage
  if (art.remixes) {
    for (const [, remix] of art.remixes.entries()) {
      if (remix.derivedFrom === listingAssetId || remix.sourceId === listingAssetId) continue;
      if (remix.derivedFrom && !seen.has(remix.derivedFrom)) {
        // Check if current listing is a remix of another asset
        const sourceAsset = art.assets?.get(remix.derivedFrom);
        if (sourceAsset?.ownerId && remix.remixId === listingAssetId) {
          citations.push({ citedId: remix.derivedFrom, creatorId: sourceAsset.ownerId, source: 'artistry_remix' });
          seen.add(remix.derivedFrom);
        }
      }
    }
  }

  return citations;
}

/**
 * Compute the royalty rate for a cited asset based on how many times it has
 * already generated royalties. Starts at 30%, decays per usage, never below 0.001%.
 */
function computeCitationRoyaltyRate(usageCount) {
  return Math.max(
    CITATION_ROYALTY_BASE_RATE * Math.pow(CITATION_ROYALTY_DECAY, usageCount),
    CITATION_ROYALTY_MIN_RATE
  );
}

app.post('/api/artistry/marketplace/purchase', (req, res) => {
  try {
    const art = ensureArtistryState();
    const { buyerId, listingId, listingType, licenseType, purchaseId: clientPurchaseId } = req.body;
    if (!buyerId || !listingId) return res.status(400).json({ error: 'Missing buyerId or listingId' });

    // ── Deterministic purchaseId ────────────────────────────────────────
    // Client can send a purchaseId for idempotency; otherwise server generates one.
    const purchaseId = clientPurchaseId || `pur_${Date.now()}_${Math.random().toString(36).slice(2, 10)}`;
    const refId = `purchase:${purchaseId}`;

    // ── Idempotency check ───────────────────────────────────────────────
    if (db) {
      const existing = checkRefIdProcessed(db, refId);
      if (existing.exists) {
        // Already processed — return success with existing data
        const existingLicense = Array.from(art.licenses.values()).find(
          l => l.purchaseId === purchaseId
        );
        return res.json({
          ok: true,
          idempotent: true,
          purchaseId,
          license: existingLicense || null,
          message: 'Purchase already processed',
        });
      }
    }

    // ── Lookup listing ──────────────────────────────────────────────────
    const stores = { beat: art.beatStore, stems: art.stemStore, 'sample-pack': art.sampleStore, artwork: art.artStore };
    const store = stores[listingType || 'beat'];
    const listing = store?.get(listingId);
    if (!listing) return res.status(404).json({ error: 'Listing not found' });

    const price = listing.licenses
      ? (listing.licenses[licenseType || 'basic']?.price || listing.price || 0)
      : (listing.price || 0);

    const sellerId = listing.ownerId;
    if (!sellerId) return res.status(400).json({ error: 'Listing has no owner' });
    if (buyerId === sellerId) return res.status(400).json({ error: 'Cannot purchase your own listing' });

    // ── State Machine: create purchase record ────────────────────────────
    let purchaseRecord = null;
    if (db) {
      try {
        purchaseRecord = createPurchase(db, {
          purchaseId, buyerId, sellerId, listingId,
          listingType: listingType || listing.type,
          licenseType: licenseType || 'basic',
          amount: price, source: 'artistry',
        });
      } catch (e) {
        // If purchase_id already exists (idempotent retry), fetch existing
        if (e.message?.includes('UNIQUE constraint')) {
          // Already created — continue (idempotent)
        } else {
          console.error('[Artistry] Failed to create purchase record:', e.message);
        }
      }
    }

    // ── Economy Settlement (atomic, through ledger) ─────────────────────
    let settlement = null;
    if (db && price > 0) {
      // 1. Validate buyer balance
      const balCheck = economyValidateBalance(db, buyerId, price);
      if (!balCheck.ok) {
        // Transition to FAILED if purchase record exists
        try { transitionPurchase(db, purchaseId, 'FAILED', { reason: 'insufficient_balance', actor: buyerId, errorMessage: balCheck.error }); } catch {}
        return res.status(400).json({ error: balCheck.error, balance: balCheck.balance, required: balCheck.required });
      }

      // State Machine: transition to PAID (balance validated, about to settle)
      try { transitionPurchase(db, purchaseId, 'PAID', { reason: 'balance_validated', actor: 'system' }); } catch {}

      // 2. Calculate marketplace fee (5%)
      const { fee: marketplaceFee } = calculateFee('MARKETPLACE_PURCHASE', price);
      const afterFee = Math.round((price - marketplaceFee) * 100) / 100;

      // 3. Resolve citations and compute royalties
      const citations = resolveAssetCitations(listing.assetId);
      const royaltyEntries = [];
      let totalRoyalties = 0;

      for (const citation of citations) {
        // Skip if cited creator is the buyer (no self-royalty)
        if (citation.creatorId === buyerId) continue;
        // Skip if cited creator is the seller (already getting seller proceeds)
        if (citation.creatorId === sellerId) continue;

        const usageCount = art.citationRoyaltyUsage.get(citation.citedId) || 0;
        const royaltyRate = computeCitationRoyaltyRate(usageCount);
        const royaltyAmount = Math.max(Math.round(price * royaltyRate * 100) / 100, 0.01);

        royaltyEntries.push({
          citedId: citation.citedId,
          creatorId: citation.creatorId,
          source: citation.source,
          amount: royaltyAmount,
          rate: royaltyRate,
          usageCount,
        });
        totalRoyalties += royaltyAmount;
      }

      // Cap total royalties so seller always gets at least 0.01
      if (totalRoyalties > afterFee - 0.01) {
        const scale = (afterFee - 0.01) / totalRoyalties;
        totalRoyalties = 0;
        for (const r of royaltyEntries) {
          r.amount = Math.max(Math.round(r.amount * scale * 100) / 100, 0.01);
          totalRoyalties += r.amount;
        }
        // Final cap: if still too much, trim last entries
        while (totalRoyalties > afterFee - 0.01 && royaltyEntries.length > 0) {
          totalRoyalties -= royaltyEntries.pop().amount;
        }
      }

      const sellerNet = Math.round((afterFee - totalRoyalties) * 100) / 100;
      const batchId = generateTxId();

      // 4. Build all ledger entries atomically (all share the same refId for idempotency)
      const entries = [];

      // Debit: buyer pays full price
      entries.push({
        id: generateTxId(),
        type: 'MARKETPLACE_PURCHASE',
        from: buyerId,
        to: sellerId,
        amount: price,
        fee: marketplaceFee,
        net: sellerNet,
        status: 'complete',
        refId,
        metadata: {
          batchId, role: 'debit', listingId, listingType: listing.type,
          licenseType: licenseType || 'basic', source: 'artistry',
          purchaseId, totalRoyalties, royaltyCount: royaltyEntries.length,
        },
      });

      // Credit: seller gets net (price - fee - royalties)
      entries.push({
        id: generateTxId(),
        type: 'MARKETPLACE_PURCHASE',
        from: null,
        to: sellerId,
        amount: sellerNet,
        fee: 0,
        net: sellerNet,
        status: 'complete',
        refId,
        metadata: { batchId, role: 'credit', listingId, source: 'artistry', purchaseId },
      });

      // Platform fee
      if (marketplaceFee > 0) {
        entries.push({
          id: generateTxId(),
          type: 'FEE',
          from: null,
          to: PLATFORM_ACCOUNT_ID,
          amount: marketplaceFee,
          fee: 0,
          net: marketplaceFee,
          status: 'complete',
          refId,
          metadata: { batchId, role: 'fee', sourceType: 'MARKETPLACE_PURCHASE', listingId, source: 'artistry', purchaseId },
        });
      }

      // Citation royalty payouts
      for (const royalty of royaltyEntries) {
        entries.push({
          id: generateTxId(),
          type: 'ROYALTY_PAYOUT',
          from: null,
          to: royalty.creatorId,
          amount: royalty.amount,
          fee: 0,
          net: royalty.amount,
          status: 'complete',
          refId,
          metadata: {
            batchId, role: 'citation_royalty', listingId,
            citedAssetId: royalty.citedId, citationSource: royalty.source,
            royaltyRate: royalty.rate, usageCount: royalty.usageCount,
            source: 'artistry', purchaseId,
          },
        });
      }

      // 5. Execute atomically — includes idempotency check inside the transaction
      const doSettlement = db.transaction(() => {
        // Double-check inside transaction for race condition safety
        const dupe = checkRefIdProcessed(db, refId);
        if (dupe.exists) return { idempotent: true, entries: dupe.entries };
        return recordTransactionBatch(db, entries);
      });

      try {
        const txResults = doSettlement();

        // If idempotent (already processed), return existing result
        if (txResults.idempotent) {
          const existingLicense = Array.from(art.licenses.values()).find(
            l => l.purchaseId === purchaseId
          );
          return res.json({
            ok: true,
            idempotent: true,
            purchaseId,
            license: existingLicense || null,
            message: 'Purchase already settled',
          });
        }

        settlement = {
          batchId,
          purchaseId,
          transactions: txResults,
          price,
          marketplaceFee,
          sellerNet,
          totalRoyalties,
          royalties: royaltyEntries.map(r => ({
            citedId: r.citedId, creatorId: r.creatorId, amount: r.amount,
            rate: r.rate, source: r.source,
          })),
        };

        // State Machine: transition to SETTLED + snapshot settlement details
        try {
          transitionPurchase(db, purchaseId, 'SETTLED', { reason: 'ledger_committed', actor: 'system' });
          recordSettlement(db, purchaseId, {
            settlementBatchId: batchId,
            marketplaceFee,
            sellerNet,
            totalRoyalties,
            royaltyDetails: royaltyEntries.map(r => ({
              citedId: r.citedId, creatorId: r.creatorId, amount: r.amount,
              rate: r.rate, source: r.source,
            })),
          });
        } catch (smErr) {
          console.error('[Artistry] State machine update failed (settlement succeeded):', smErr.message);
        }
      } catch (err) {
        // Check if it's a UNIQUE constraint violation (duplicate ref_id) — treat as idempotent
        if (err.message?.includes('UNIQUE constraint') && err.message?.includes('ref_id')) {
          const existingLicense = Array.from(art.licenses.values()).find(
            l => l.purchaseId === purchaseId
          );
          return res.json({
            ok: true,
            idempotent: true,
            purchaseId,
            license: existingLicense || null,
            message: 'Purchase already settled (constraint)',
          });
        }
        console.error('[Artistry] Settlement failed:', err.message);
        try { transitionPurchase(db, purchaseId, 'FAILED', { reason: 'settlement_error', actor: 'system', errorMessage: err.message }); } catch {}
        return res.status(500).json({ error: 'settlement_failed', detail: err.message });
      }

      // Update citation usage counts (after successful settlement)
      for (const royalty of royaltyEntries) {
        art.citationRoyaltyUsage.set(
          royalty.citedId,
          (art.citationRoyaltyUsage.get(royalty.citedId) || 0) + 1
        );
      }

      // Audit log (non-critical, don't fail the purchase if audit logging fails)
      try {
        economyAudit(db, {
          action: 'artistry_marketplace_purchase',
          userId: buyerId,
          amount: price,
          txId: batchId,
          requestId: req.headers?.['x-request-id'],
          ip: req.ip,
          details: {
            sellerId, listingId, listingType: listing.type,
            licenseType: licenseType || 'basic',
            marketplaceFee, sellerNet, totalRoyalties,
            royaltyCount: royaltyEntries.length,
          },
        });
      } catch (auditErr) {
        console.error('[Artistry] Audit log failed (settlement succeeded):', auditErr.message);
      }
    }

    // ── Entitlement (license creation) ──────────────────────────────────
    const licenseId = `lic_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
    art.licenses.set(licenseId, {
      id: licenseId, buyerId, listingId, listingType: listing.type,
      licenseType: licenseType || 'basic',
      price, terms: LICENSE_TYPES[licenseType || 'basic'] || LICENSE_TYPES.basic,
      status: 'active', purchasedAt: Date.now(),
      purchaseId,
      settlementBatchId: settlement?.batchId || null,
    });

    // State Machine: transition to FULFILLED + record license ID
    if (db) {
      try {
        transitionPurchase(db, purchaseId, 'FULFILLED', { reason: 'license_created', actor: 'system' });
        recordSettlement(db, purchaseId, { licenseId });
      } catch (smErr) {
        console.error('[Artistry] State machine FULFILLED transition failed:', smErr.message);
      }
    }

    // ── Update listing stats ────────────────────────────────────────────
    listing.totalSales = (listing.totalSales || 0) + 1;

    // ── Split accounting (in-memory) ────────────────────────────────────
    const split = Array.from(art.splits.values()).find(s => s.assetId === listing.assetId);
    if (split) {
      for (const p of split.participants) {
        p.totalEarned = (p.totalEarned || 0) + Math.floor(price * p.percentage / 100);
      }
      split.totalDistributed = (split.totalDistributed || 0) + price;
    }

    // ── Response ────────────────────────────────────────────────────────
    res.json({
      ok: true,
      purchaseId,
      license: art.licenses.get(licenseId),
      paid: price,
      settlement: settlement ? {
        batchId: settlement.batchId,
        purchaseId,
        marketplaceFee: settlement.marketplaceFee,
        sellerNet: settlement.sellerNet,
        totalRoyalties: settlement.totalRoyalties,
        royalties: settlement.royalties,
      } : null,
    });
  } catch (err) {
    console.error('[Artistry] Purchase error:', err.message);
    res.status(500).json({ error: 'purchase_failed', detail: err.message });
  }
});

console.log('[Artistry] Phase 8: Marketplace expansion initialized (bridged to Economy ledger)');

// ── Phase 9: Collaboration + Remix Mode + Project Sharing ───────────────────

app.post('/api/artistry/collab/sessions', (req, res) => {
  const art = ensureArtistryState();
  const { projectId, hostId, maxParticipants, mode } = req.body;
  const project = art.projects.get(projectId);
  if (!project) return res.status(404).json({ error: 'Project not found' });
  const sessionId = `collab_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
  art.collabSessions.set(sessionId, {
    id: sessionId, projectId, hostId: hostId || project.ownerId,
    participants: [{ userId: hostId || project.ownerId, role: 'host', joinedAt: Date.now() }],
    maxParticipants: maxParticipants || 8, mode: mode || 'live',
    chat: [], actions: [], status: 'active',
    permissions: { edit: true, addTracks: true, deleteTrack: false, changeBpm: false },
    createdAt: Date.now(), updatedAt: Date.now(),
  });
  art.stats.totalCollabs++;
  res.json({ ok: true, session: art.collabSessions.get(sessionId) });
});

app.post('/api/artistry/collab/sessions/:id/join', (req, res) => {
  const art = ensureArtistryState();
  const session = art.collabSessions.get(req.params.id);
  if (!session) return res.status(404).json({ error: 'Session not found' });
  if (session.status !== 'active') return res.status(400).json({ error: 'Session not active' });
  if (session.participants.length >= session.maxParticipants) return res.status(400).json({ error: 'Session full' });
  const { userId } = req.body;
  if (session.participants.some(p => p.userId === userId)) return res.status(400).json({ error: 'Already in session' });
  session.participants.push({ userId, role: 'collaborator', joinedAt: Date.now() });
  session.updatedAt = Date.now();
  res.json({ ok: true, session });
});

app.post('/api/artistry/collab/sessions/:id/leave', (req, res) => {
  const art = ensureArtistryState();
  const session = art.collabSessions.get(req.params.id);
  if (!session) return res.status(404).json({ error: 'Session not found' });
  const { userId } = req.body;
  session.participants = session.participants.filter(p => p.userId !== userId);
  if (session.participants.length === 0) session.status = 'ended';
  session.updatedAt = Date.now();
  res.json({ ok: true, session });
});

app.post('/api/artistry/collab/sessions/:id/action', (req, res) => {
  const art = ensureArtistryState();
  const session = art.collabSessions.get(req.params.id);
  if (!session) return res.status(404).json({ error: 'Session not found' });
  const { userId, action, data } = req.body;
  session.actions.push({ userId, action, data, at: Date.now() });
  if (session.actions.length > 5000) session.actions = session.actions.slice(-5000);
  session.updatedAt = Date.now();
  res.json({ ok: true, actionCount: session.actions.length });
});

app.post('/api/artistry/collab/sessions/:id/chat', (req, res) => {
  const art = ensureArtistryState();
  const session = art.collabSessions.get(req.params.id);
  if (!session) return res.status(404).json({ error: 'Session not found' });
  const { userId, message } = req.body;
  session.chat.push({ userId, message, at: Date.now() });
  if (session.chat.length > 1000) session.chat = session.chat.slice(-1000);
  res.json({ ok: true, chatCount: session.chat.length });
});

app.get('/api/artistry/collab/sessions', (req, res) => {
  const art = ensureArtistryState();
  const { userId } = req.query;
  let sessions = Array.from(art.collabSessions.values());
  if (userId) sessions = sessions.filter(s => s.participants.some(p => p.userId === userId));
  sessions.sort((a, b) => b.updatedAt - a.updatedAt);
  res.json({ ok: true, sessions: sessions.map(s => ({ id: s.id, projectId: s.projectId, participants: s.participants.length, status: s.status, mode: s.mode, createdAt: s.createdAt })) });
});

app.post('/api/artistry/collab/remix', (req, res) => {
  const art = ensureArtistryState();
  const { originalAssetId, originalReleaseId, remixerId, title, genre } = req.body;
  const remixId = `remix_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
  art.remixes.set(remixId, {
    id: remixId, originalAssetId: originalAssetId || null, originalReleaseId: originalReleaseId || null,
    remixerId: remixerId || 'anon', title: title || 'Untitled Remix', genre: genre || null,
    projectId: null, assetId: null, status: 'in-progress',
    attribution: { original: originalAssetId || originalReleaseId, remixer: remixerId },
    createdAt: Date.now(), updatedAt: Date.now(),
  });
  res.json({ ok: true, remix: art.remixes.get(remixId) });
});

app.get('/api/artistry/collab/remixes', (req, res) => {
  const art = ensureArtistryState();
  const { originalAssetId, remixerId } = req.query;
  let remixes = Array.from(art.remixes.values());
  if (originalAssetId) remixes = remixes.filter(r => r.originalAssetId === originalAssetId);
  if (remixerId) remixes = remixes.filter(r => r.remixerId === remixerId);
  remixes.sort((a, b) => b.createdAt - a.createdAt);
  res.json({ ok: true, remixes, total: remixes.length });
});

app.post('/api/artistry/collab/share', (req, res) => {
  const art = ensureArtistryState();
  const { projectId, ownerId, sharedWithIds, permissions } = req.body;
  const project = art.projects.get(projectId);
  if (!project) return res.status(404).json({ error: 'Project not found' });
  const shareId = `share_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
  art.sharedProjects.set(shareId, {
    id: shareId, projectId, ownerId: ownerId || project.ownerId,
    sharedWith: (sharedWithIds || []).map(uid => ({ userId: uid, permissions: permissions || { view: true, edit: false, download: false } })),
    link: `/shared/${shareId}`, status: 'active', createdAt: Date.now(),
  });
  for (const uid of (sharedWithIds || [])) { if (!project.collaborators.includes(uid)) project.collaborators.push(uid); }
  res.json({ ok: true, shared: art.sharedProjects.get(shareId) });
});

app.get('/api/artistry/collab/shared', (req, res) => {
  const art = ensureArtistryState();
  const { userId } = req.query;
  let shared = Array.from(art.sharedProjects.values()).filter(s => s.status === 'active');
  if (userId) shared = shared.filter(s => s.ownerId === userId || s.sharedWith.some(sw => sw.userId === userId));
  res.json({ ok: true, shared });
});

console.log('[Artistry] Phase 9: Collaboration + Remix initialized');

// ── Phase 10: AI Production Assistant + Learning System + Genre Coach ───────

app.post('/api/artistry/ai/analyze-project', (req, res) => {
  const art = ensureArtistryState();
  const { projectId } = req.body;
  const project = art.projects.get(projectId);
  if (!project) return res.status(404).json({ error: 'Project not found' });
  res.json({
    ok: true,
    analysis: {
      projectId,
      overview: { trackCount: project.tracks.length, bpm: project.bpm, key: project.key, scale: project.scale, genre: project.genre,
        estimatedLength: `${Math.floor(project.arrangement.length / 4)} bars` },
      suggestions: [
        { type: 'arrangement', priority: 'high', suggestion: project.tracks.length < 4 ? 'Consider adding more layers for a fuller mix' : 'Good track density' },
        { type: 'mixing', priority: 'medium', suggestion: 'Check frequency balance between tracks' },
        { type: 'mastering', priority: 'low', suggestion: `Target LUFS for ${project.genre || 'electronic'}: -14 to -8` },
        { type: 'dynamics', priority: 'medium', suggestion: 'Ensure drum transients cut through' },
        { type: 'creativity', priority: 'low', suggestion: 'Try adding automation to create movement' },
      ],
      genreMatch: { primary: project.genre || 'electronic', confidence: 0.75 + Math.random() * 0.2 },
      mixScore: Math.floor(60 + Math.random() * 35),
      analyzedAt: Date.now(),
    },
  });
});

app.post('/api/artistry/ai/suggest-chords', (req, res) => {
  const { key, scale, genre } = req.body;
  const k = key || 'C';
  const kIdx = MUSICAL_KEYS.indexOf(k);
  res.json({
    ok: true, key: k, scale: scale || 'major', genre: genre || 'pop',
    progressions: [
      { name: 'Classic Pop', chords: [`${k}maj`, `${MUSICAL_KEYS[(kIdx + 5) % 12]}min`, `${MUSICAL_KEYS[(kIdx + 7) % 12]}maj`, `${MUSICAL_KEYS[(kIdx + 7) % 12]}maj`], mood: 'uplifting' },
      { name: 'Emotional', chords: [`${MUSICAL_KEYS[(kIdx + 9) % 12]}min`, `${MUSICAL_KEYS[(kIdx + 5) % 12]}maj`, `${k}maj`, `${MUSICAL_KEYS[(kIdx + 7) % 12]}maj`], mood: 'melancholic' },
      { name: 'Neo Soul', chords: [`${k}maj7`, `${MUSICAL_KEYS[(kIdx + 2) % 12]}min9`, `${MUSICAL_KEYS[(kIdx + 5) % 12]}maj7`, `${MUSICAL_KEYS[(kIdx + 4) % 12]}min7`], mood: 'smooth' },
      { name: 'Dark', chords: [`${k}min`, `${MUSICAL_KEYS[(kIdx + 5) % 12]}min`, `${MUSICAL_KEYS[(kIdx + 3) % 12]}maj`, `${MUSICAL_KEYS[(kIdx + 7) % 12]}maj`], mood: 'dark' },
    ],
  });
});

app.post('/api/artistry/ai/suggest-melody', (req, res) => {
  const { key, scale, bpm, bars, style } = req.body;
  const k = key || 'C';
  const kIdx = MUSICAL_KEYS.indexOf(k);
  const intervals = scale === 'minor' ? [0, 2, 3, 5, 7, 8, 10] : [0, 2, 4, 5, 7, 9, 11];
  const notes = [];
  for (let i = 0; i < (bars || 4) * 4; i++) {
    const interval = intervals[Math.floor(Math.random() * intervals.length)];
    notes.push({ note: MUSICAL_KEYS[(kIdx + interval) % 12], octave: 4 + Math.floor(Math.random() * 2),
      start: i * 0.25, duration: [0.25, 0.5, 0.75, 1.0][Math.floor(Math.random() * 4)], velocity: 60 + Math.floor(Math.random() * 40) });
  }
  res.json({ ok: true, melody: { key: k, scale: scale || 'major', bpm: bpm || 120, bars: bars || 4, style: style || 'lead', notes } });
});

app.post('/api/artistry/ai/suggest-drums', (req, res) => {
  const { bpm, genre, bars, swing } = req.body;
  const g = genre || 'electronic';
  const len = (bars || 2) * 16;
  const patterns = { kick: [], snare: [], hihat: [], openHat: [], clap: [], perc: [] };
  for (let i = 0; i < len; i++) {
    if (i % 4 === 0) patterns.kick.push({ step: i, velocity: 100 + Math.floor(Math.random() * 27) });
    if (i % 8 === 4) patterns.snare.push({ step: i, velocity: 90 + Math.floor(Math.random() * 37) });
    if (i % 2 === 0) patterns.hihat.push({ step: i, velocity: 60 + Math.floor(Math.random() * 40) });
    if (i % 16 === 14) patterns.openHat.push({ step: i, velocity: 80 });
    if (g === 'trap' && i % 8 === 4) patterns.clap.push({ step: i, velocity: 100 });
  }
  res.json({ ok: true, drumPattern: { bpm: bpm || 120, genre: g, bars: bars || 2, swing: swing || 0, stepsPerBar: 16, patterns } });
});

app.post('/api/artistry/ai/genre-coach', (req, res) => {
  const { userId, genre } = req.body;
  const genreInfo = GENRE_TAXONOMY[genre];
  res.json({
    ok: true,
    coaching: {
      userId, genre,
      characteristics: {
        bpmRange: genre === 'electronic' ? '120-150' : genre === 'hiphop' ? '80-140' : '60-200',
        commonKeys: genre === 'electronic' ? ['Am', 'Cm', 'Dm'] : genre === 'hiphop' ? ['Cm', 'Em', 'Gm'] : ['E', 'A', 'G', 'D'],
        essentialElements: genre === 'electronic' ? ['Four-on-floor kick', 'Synthesizer leads', 'Build-ups & drops', 'Sidechain compression'] : genre === 'hiphop' ? ['808 bass', 'Trap hi-hats', 'Sample chops', 'Vocal processing'] : ['Guitar riffs', 'Power chords', 'Drum fills', 'Dynamic range'],
        subGenres: genreInfo ? genreInfo.sub : [],
      },
      exercises: [
        { name: 'Genre Deconstruction', description: `Recreate a ${genre} track from scratch` },
        { name: 'Sound Design', description: `Create 5 unique sounds for ${genre}` },
        { name: 'Mix Reference', description: `A/B your mix against 3 professional ${genre} releases` },
      ],
      recommendedEffects: genre === 'electronic' ? ['compressor', 'reverb-hall', 'delay-stereo', 'filter-auto', 'saturator'] : genre === 'hiphop' ? ['compressor', 'distortion', 'auto-tune', 'delay-ping-pong', 'eq-parametric'] : ['reverb-room', 'distortion', 'chorus', 'compressor', 'delay-stereo'],
    },
  });
});

app.post('/api/artistry/ai/learning/start', (req, res) => {
  const art = ensureArtistryState();
  const { userId, topic, level } = req.body;
  const pathId = `learn_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
  art.learningPaths.set(pathId, {
    id: pathId, userId: userId || 'anon', topic: topic || 'music-production', level: level || 'beginner',
    modules: [
      { id: 'm1', name: 'Fundamentals', lessons: ['rhythm', 'melody', 'harmony', 'structure'], completed: [], progress: 0 },
      { id: 'm2', name: 'Sound Design', lessons: ['synthesis-basics', 'sampling', 'layering', 'processing'], completed: [], progress: 0 },
      { id: 'm3', name: 'Mixing', lessons: ['eq', 'compression', 'reverb-delay', 'panning-stereo', 'automation'], completed: [], progress: 0 },
      { id: 'm4', name: 'Arrangement', lessons: ['song-structure', 'builds-drops', 'transitions', 'variation'], completed: [], progress: 0 },
      { id: 'm5', name: 'Mastering', lessons: ['loudness', 'eq-balance', 'limiting', 'format-delivery'], completed: [], progress: 0 },
    ],
    overallProgress: 0, startedAt: Date.now(), updatedAt: Date.now(),
  });
  res.json({ ok: true, path: art.learningPaths.get(pathId) });
});

app.post('/api/artistry/ai/learning/complete-lesson', (req, res) => {
  const art = ensureArtistryState();
  const { pathId, moduleId, lesson } = req.body;
  const path = art.learningPaths.get(pathId);
  if (!path) return res.status(404).json({ error: 'Learning path not found' });
  const mod = path.modules.find(m => m.id === moduleId);
  if (!mod) return res.status(404).json({ error: 'Module not found' });
  if (!mod.completed.includes(lesson)) { mod.completed.push(lesson); mod.progress = Math.round(mod.completed.length / mod.lessons.length * 100); }
  path.overallProgress = Math.round(path.modules.reduce((s, m) => s + m.progress, 0) / path.modules.length);
  path.updatedAt = Date.now();
  res.json({ ok: true, module: mod, overallProgress: path.overallProgress });
});

app.get('/api/artistry/ai/learning/:pathId', (req, res) => {
  const art = ensureArtistryState();
  const path = art.learningPaths.get(req.params.pathId);
  if (!path) return res.status(404).json({ error: 'Learning path not found' });
  res.json({ ok: true, path });
});

app.post('/api/artistry/ai/session', (req, res) => {
  const art = ensureArtistryState();
  const { userId, projectId, question } = req.body;
  const sessionId = `aisess_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
  const project = projectId ? art.projects.get(projectId) : null;
  const ctx = project ? { bpm: project.bpm, key: project.key, genre: project.genre, trackCount: project.tracks.length } : {};
  const response = {
    sessionId, question: question || 'How can I improve my track?', context: ctx,
    answer: project ? `Based on your ${project.genre || 'music'} project at ${project.bpm} BPM in ${project.key}: Focus on arrangement variety and frequency separation.` : 'Start by choosing a genre and BPM, then build your foundation.',
    tips: ['Use reference tracks', 'Take breaks to avoid ear fatigue', 'Less is more'],
    suggestedActions: [{ action: 'analyze-project', label: 'Full Analysis' }, { action: 'suggest-chords', label: 'Chord Suggestions' }, { action: 'genre-coach', label: 'Genre Tips' }],
  };
  art.aiSessions.set(sessionId, { ...response, userId, at: Date.now() });
  res.json({ ok: true, ...response });
});

app.get('/api/artistry/stats', (_req, res) => {
  const art = ensureArtistryState();
  res.json({
    ok: true,
    stats: {
      ...art.stats, totalAssets: art.assets.size, totalProjects: art.projects.size,
      totalReleases: art.releases.size, totalBeats: art.beatStore.size,
      totalStems: art.stemStore.size, totalSamples: art.sampleStore.size,
      totalArtworks: art.artStore.size, totalCollabSessions: art.collabSessions.size,
      totalRemixes: art.remixes.size, totalLearningPaths: art.learningPaths.size,
      blobStorageMb: Math.round(art.stats.blobStorageBytes / 1024 / 1024 * 100) / 100,
    },
  });
});

console.log('[Artistry] Phase 10: AI Production Assistant initialized');
console.log('[Artistry] All phases (1-10) initialized successfully');

// ═══════════════════════════════════════════════════════════════════════════════
// END ARTISTRY GLOBAL
// ═══════════════════════════════════════════════════════════════════════════════

// ---- test surface (safe exports; no side effects) ----
export const __TEST__ = Object.freeze({
  VERSION,
  STATE,
  ensureQueues,
  enqueueNotification,
  realtimeEmit,
  inLatticeReality,
  overlap_verifier,
  _defaultOrganState,
  register,
  runMacro,
  MACROS,
});
